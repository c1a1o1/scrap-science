"http://ieeexplore.ieee.org/search/searchresult.jsp?bulkSetSize=2000&queryText%3Ddeep+learning+healthcare",2017/09/18 11:30:43
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","License","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"Deep learning for healthcare decision making with EMRs","Z. Liang; G. Zhang; J. X. Huang; Q. V. Hu","School of Information Technology, York University, Toronto, ON, M3J1P3, Canada","2014 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)","20150115","2014","","","556","559","Computer aid technology is widely applied in decision-making and outcome assessment of healthcare delivery, in which modeling knowledge and expert experience is technically important. However, the conventional rule-based models are incapable of capturing the underlying knowledge because they are incapable of simulating the complexity of human brains and highly rely on feature representation of problem domains. Thus we attempt to apply a deep model to overcome this weakness. The deep model can simulate the thinking procedure of human and combine feature representation and learning in a unified model. A modified version of convolutional deep belief networks is used as an effective training method for large-scale data sets. Then it is tested by two instances: a dataset on hypertension retrieved from a HIS system, and a dataset on Chinese medical diagnosis and treatment prescription from a manual converted electronic medical record (EMR) database. The experimental results indicate that the proposed deep model is able to reveal previously unknown concepts and performs much better than the conventional shallow models.","","Electronic:978-1-4799-5669-2; POD:978-1-4799-5670-8","10.1109/BIBM.2014.6999219","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6999219","deep belief network;deep learning;restricted Boltzmann machine;syndrome classification;unsupervised feature learning","Brain modeling;Data models;Hypertension;Medical diagnostic imaging;Support vector machines;Training","belief networks;brain;brain-computer interfaces;decision making;electronic health records;health care;patient diagnosis;patient treatment;unsupervised learning","Chinese medical diagnosis;Chinese medical treatment prescription;EMR database;HIS system;belief networks;computer aid technology;decision making;deep learning;electronic medical record database;feature representation;healthcare;human brains;shallow models;training method","","3","","18","","","","2-5 Nov. 2014","","IEEE","IEEE Conference Publications"
"Staged Inference using Conditional Deep Learning for energy efficient real-time smart diagnosis","M. Parsa; P. Panda; S. Sen; K. Roy","School of Electrical and Computer Engineering, Purdue University, West Lafayette, IN 47907, USA","2017 39th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)","20170914","2017","","","78","81","Recent progress in biosensor technology and wearable devices has created a formidable opportunity for remote healthcare monitoring systems as well as real-time diagnosis and disease prevention. The use of data mining techniques is indispensable for analysis of the large pool of data generated by the wearable devices. Deep learning is among the promising methods for analyzing such data for healthcare applications and disease diagnosis. However, the conventional deep neural networks are computationally intensive and it is impractical to use them in real-time diagnosis with low-powered on-body devices. We propose Staged Inference using Conditional Deep Learning (SICDL), as an energy efficient approach for creating healthcare monitoring systems. For smart diagnostics, we observe that all diagnoses are not equally challenging. The proposed approach thus decomposes the diagnoses into preliminary analysis (such as healthy vs unhealthy) and detailed analysis (such as identifying the specific type of cardio disease). The preliminary diagnosis is conducted real-time with a low complexity neural network realized on the resource-constrained on-body device. The detailed diagnosis requires a larger network that is implemented remotely in cloud and is conditionally activated only for detailed diagnosis (unhealthy individuals). We evaluated the proposed approach using available physiological sensor data from Physionet databases, and achieved 38% energy reduction in comparison to the conventional deep learning approach.","","Electronic:978-1-5090-2809-2; POD:978-1-5090-2810-8","10.1109/EMBC.2017.8036767","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8036767","","","","","","","","","","","","11-15 July 2017","","IEEE","IEEE Conference Publications"
"Comparing deep neural network and other machine learning algorithms for stroke prediction in a large-scale population-based electronic medical claims database","C. Y. Hung; W. C. Chen; P. T. Lai; C. H. Lin; C. C. Lee","Department of Electrical Engineering, National Tsing Hua University, Hsinchu, Taiwan","2017 39th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)","20170914","2017","","","3110","3113","Electronic medical claims (EMCs) can be used to accurately predict the occurrence of a variety of diseases, which can contribute to precise medical interventions. While there is a growing interest in the application of machine learning (ML) techniques to address clinical problems, the use of deep-learning in healthcare have just gained attention recently. Deep learning, such as deep neural network (DNN), has achieved impressive results in the areas of speech recognition, computer vision, and natural language processing in recent years. However, deep learning is often difficult to comprehend due to the complexities in its framework. Furthermore, this method has not yet been demonstrated to achieve a better performance comparing to other conventional ML algorithms in disease prediction tasks using EMCs. In this study, we utilize a large population-based EMC database of around 800,000 patients to compare DNN with three other ML approaches for predicting 5-year stroke occurrence. The result shows that DNN and gradient boosting decision tree (GBDT) can result in similarly high prediction accuracies that are better compared to logistic regression (LR) and support vector machine (SVM) approaches. Meanwhile, DNN achieves optimal results by using lesser amounts of patient data when comparing to GBDT method.","","Electronic:978-1-5090-2809-2; POD:978-1-5090-2810-8","10.1109/EMBC.2017.8037515","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8037515","","","","","","","","","","","","11-15 July 2017","","IEEE","IEEE Conference Publications"
"Oro Vision: Deep Learning for Classifying Orofacial Diseases","R. Anantharaman; V. Anantharaman; Y. Lee","","2017 IEEE International Conference on Healthcare Informatics (ICHI)","20170914","2017","","","39","45","This experiment is an attempt to apply deep learning techniques to orofacial image analysis. Health promotion is recognized as a viable approach to preventing diseases and disorders and promoting changes in health behaviors or practices. Each year, oral cancer kills more people in the US than does cervical cancer, malignant melanoma, or Hodgkin's disease. A first line of defense against oral diseases is an orofacial selfexamination. The goal of this experiment titled ""Oro Vision"" is to provide an assessment tool for field workers to perform initial examinations of orofacial diseases, using a camera enabled mobile phone. For this experiment, we chose to implement Oro Vision to detect mouth sores. The goal is to extend this model to identify several other Oral diseases such as Thrush, Leukoplakia, Lichenplanus, etc. One variety of mouth sore, referred to as the ""cold sore"" is highly contagious and an infected person can easily pass on the infection to another person just through skin to skin contact. ""Oro Vision"" is implemented as an HTML5 mobile responsive web app that can be accessed through any mobile or standard browser. Oro Vision uses deep learning to train a model and subsequently uses this trained model to distinguish a cold sore from a canker sore. In addition, an accurate diagnosis by a trained healthcare professional is required before any kind of treatment is discussed since several other conditions of the mouth including oral cancer may mimic canker sores.","","Electronic:978-1-5090-4881-6; POD:978-1-5090-4882-3","10.1109/ICHI.2017.69","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8031130","clarifai;deep learning;mouth sore;retrained inception","Cancer;Machine learning;Mobile communication;Mouth;Tools","","","","","","","","","","23-26 Aug. 2017","","IEEE","IEEE Conference Publications"
"Continuous Assessment of Children’s Emotional States Using Acoustic Analysis","Y. Gong; C. Poellabauer","","2017 IEEE International Conference on Healthcare Informatics (ICHI)","20170914","2017","","","171","178","Emotional and behavioral disorders (EBD) are a widespread healthcare concern in children and adolescents. Prevention and early intervention are the most powerful tools in ameliorating the problem, and therefore, timely and accurate detection of abnormal emotional patterns is of vital importance. In this paper, we propose a system that detects second-level emotional states of children using hour-level audio recordings. The proposed system consists of an audio segmentation and speaker tracking front-end along with an emotion recognition back-end. Supervised support vector machine is used in the front-end to improve its robustness to short and inconsistent child speech pattern and end-to-end deep learning is used in the emotion recognition back-end to improve its robustness to noise and segmentation error. We further demonstrate the potential of the proposed system as an automated emotion analysis tool.","","Electronic:978-1-5090-4881-6; POD:978-1-5090-4882-3","10.1109/ICHI.2017.53","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8031145","children emotion recognition;continuous emotion assessment;deep neural networks;emotional and behavioral disorders","Acoustics;Emotion recognition;Medical treatment;Pediatrics;Speaker recognition;Speech;Speech recognition","","","","","","","","","","23-26 Aug. 2017","","IEEE","IEEE Conference Publications"
"Visual FHIR: An Interactive Browser to Navigate HL7 FHIR Specification","N. Hong; K. Wang; L. Yao; G. Jiang","","2017 IEEE International Conference on Healthcare Informatics (ICHI)","20170914","2017","","","26","30","The HL7 Fast Healthcare Interoperability Resources (FHIR) specification is emerging as a next generation standards framework for the exchange of electronic health records (EHR) data. The rich semantic representation and sophisticated structure definition of the FHIR requires a relatively deep learning curve to understand and utilize. The objective of our study is to design and develop a user-friendly interface for navigating and manipulating the FHIR specification. We prototyped a visualization platform for interactively exploring FHIR core resources and profiles. We evaluated the utility of the FHIR visualization platform using the evaluation metrics mainly focusing on its usability, interactive mechanisms and content expressiveness. We demonstrated that the visualization techniques are helpful for navigating the HL7 FHIR specification and aiding its profiling.","","Electronic:978-1-5090-4881-6; POD:978-1-5090-4882-3","10.1109/ICHI.2017.54","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8031128","HL7 FHIR;Interactive;Visualization;clinical data model","Browsers;Data models;Data visualization;Medical services;Navigation;Standards;Visualization","","","","","","","","","","23-26 Aug. 2017","","IEEE","IEEE Conference Publications"
"A Deep-Learning-Based Method of Estimating Water Intake","Y. Yamada; T. Saito; S. Kawasaki; D. Iketa; M. Katagiri; M. Nishimura; H. Mineno","","2017 IEEE 41st Annual Computer Software and Applications Conference (COMPSAC)","20170911","2017","02","","96","101","In Japan, which has become a very aged society, the increasing burden of nursing care is an issue. Services and systems related to automatic recording of healthcare management of elderly people have been proposed in order to reduce the burden of nursing care. Water intake is one of the items necessary for healthcare management of elderly people. However, it is not currently automated, which is a burden on caregivers. In the case of the conventional method, the swallowing sound is used for estimating the water intake. However, the estimation error for each subject is large. Accuracy of estimated water intake is improved by using deep learning. Specifically, three features, namely, mel frequency cepstral coefficient (MFCC), duration of water intake, and a RASTA filter auditory spectrum, are extracted from a subject's swallowing sound (which is thought to be highly correlated with water intake). A method of estimating water intake, which considers abstract features that are difficult for people to find, is proposed and verified. It is experimentally shown that RMSE of water intake estimated by the proposed method using deep learning is reduced compared with that estimated by conventional methods.","0730-3157;07303157","Electronic:978-1-5386-0367-3; POD:978-1-5386-0368-0","10.1109/COMPSAC.2017.14","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8029900","deep learning;estimation;healthcare;water intake","Feature extraction;Hidden Markov models;Lungs;Machine learning;Medical services;Microphones;Senior citizens","","","","","","","","","","4-8 July 2017","","IEEE","IEEE Conference Publications"
"Classification of various daily behaviors using deep learning and smart watch","M. C. Kwon; M. Ju; S. Choi","Dept. of Secured Smart Electric Vehicle, Kookmin University, Seoul, Korea 02707","2017 Ninth International Conference on Ubiquitous and Future Networks (ICUFN)","20170727","2017","","","735","740","In traditional healthcare and therapy, human behavior has been classified into only two categories: specific behavior and active behavior. As internet of things and wearable devices become popular, however, it is necessary to classify human behavior into more various categories for providing useful services. In this paper, we propose a novel classification scheme that classifies human behavior into 11 different categories including active and inactive activities in daily life. We collect data with smart watch and use deep learning model with a neural network for the classification. Extensive evaluation shows that various daily human behavior can be classified with 99.24% accuracy, and that the classification of human behavior can be used for various services.","","Electronic:978-1-5090-4749-9; POD:978-1-5090-4750-5; USB:978-1-5090-4748-2","10.1109/ICUFN.2017.7993888","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7993888","classification;deep learning;human behavior;internet of things;smart watch","Acceleration;Feature extraction;Games;Intelligent sensors;Machine learning;Medical services","Internet of Things;behavioural sciences computing;medical computing;neural nets;patient monitoring;patient treatment;pattern classification;wearable computers","Internet of things;active behavior;classification scheme;daily behaviors classification;daily life;deep learning;healthcare;human behavior;inactive activities;neural network;smart watch;specific behavior;therapy;wearable devices","","","","","","","","4-7 July 2017","","IEEE","IEEE Conference Publications"
"Deep Features Learning for Medical Image Analysis with Convolutional Autoencoder Neural Network","M. Chen; X. Shi; Y. Zhang; D. Wu; M. Guizani","School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, HuBei China (e-mail: minchen@ieee.org)","IEEE Transactions on Big Data","","2017","PP","99","1","1","At present, computed tomography (CT) are widely used to assist diagnosis. Especially, computer aided diagnosis (CAD) based on artificial intelligence (AI) is an extremely important research field in intelligent healthcare. However, it is a great challenge to establish an adequate labeled dataset for CT analysis assistance, due to the privacy and security issues. Therefore, this paper proposes a convolutional autoencoder deep learning framework to support unsupervised image features learning for lung nodule through unlabeled data, which only needs a small amount of labeled data for efficient feature learning. Through comprehensive experiments, it evaluates that the proposed scheme is superior to other approaches, which effectively solves the intrinsic labor-intensive problem during of artificial image labeling. Moreover, it verifies that the proposed convolutional autoencoder approach can be extended for similarity measurement of lung nodules images. Especially, the features extracted through unsupervised learning are also applicable in other related scenarios.","","","10.1109/TBDATA.2017.2717439","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7954012","Convolutional autoencoder neural network;Feature learning;Hand-craft feature;Lung nodule;Unsupervised learning","Biomedical imaging;Computed tomography;Convolutional codes;Feature extraction;Image analysis;Lungs;Training","","","","","","","","","20170620","","","IEEE","IEEE Early Access Articles"
"Automated 5-year mortality prediction using deep learning and radiomics features from chest computed tomography","G. Carneiro; L. Oakden-Rayner; A. P. Bradley; J. Nascimento; L. Palmer","Australian Centre for Visual Technologies, The University of Adelaide, Australia","2017 IEEE 14th International Symposium on Biomedical Imaging (ISBI 2017)","20170619","2017","","","130","134","In this paper, we propose new prognostic methods that predict 5-year mortality in elderly individuals using chest computed tomography (CT). The methods consist of a classifier that performs this prediction using a set of features extracted from the CT image and segmentation maps of multiple anatomic structures. We explore two approaches: 1) a unified framework based on two state-of-the-art deep learning models extended to 3-D inputs, where features and classifier are automatically learned in a single optimisation process; and 2) a multi-stage framework based on the design and selection and extraction of hand-crafted radiomics features, followed by the classifier learning process. Experimental results, based on a dataset of 48 annotated chest CTs, show that the deep learning models produces a mean 5-year mortality prediction AUC in [68.8%,69.8%] and accuracy in [64.5%,66.5%], while radiomics produces a mean AUC of 64.6% and accuracy of 64.6%. The successful development of the proposed models has the potential to make a profound impact in preventive and personalised healthcare.","","Electronic:978-1-5090-1172-8; POD:978-1-5090-1173-5","10.1109/ISBI.2017.7950485","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7950485","computed tomography;deep learning;feature learning;five-year mortality;hand-designed features;radiomics","Biomedical imaging;Computed tomography;Fats;Feature extraction;Image segmentation;Machine learning;Training","computerised tomography;feature extraction;geriatrics;health care;image classification;image segmentation;learning (artificial intelligence);medical image processing;optimisation","3-D inputs;CT image;annotated chest CT;automated 5-year mortality prediction;chest computed tomography;classifier learning process;deep learning models;elderly individuals;feature extraction;hand-crafted radiomics features;mean 5-year mortality prediction AUC;multiple anatomic structures;multistage framework;personalised healthcare;preventive healthcare;prognostic methods;segmentation maps;single optimisation process;unified framework","","","","","","","","18-21 April 2017","","IEEE","IEEE Conference Publications"
"Massive-Scale Automation in Cyber-Physical Systems: Vision & Challenges","D. W. McKee; S. J. Clement; J. Almutairi; J. Xu","Sch. of Comput., Univ. of Leeds, Leeds, UK","2017 IEEE 13th International Symposium on Autonomous Decentralized System (ISADS)","20170608","2017","","","5","11","The next era of computing is the evolution of the Internet of Things (IoT) and Smart Cities with development of the Internet of Simulation (IoS). The existing technologies of Cloud, Edge, and Fog computing as well as HPC being applied to the domains of Big Data and deep learning are not adequate to handle the scale and complexity of the systems required to facilitate a fully integrated and automated smart city. This integration of existing systems will create an explosion of data streams at a scale not yet experienced. The additional data can be combined with simulations as services (SIMaaS) to provide a shared model of reality across all integrated systems, things, devices, and individuals within the city. There are also numerous challenges in managing the security and safety of the integrated systems. This paper presents an overview of the existing state-of-the-art in automating, augmenting, and integrating systems across the domains of smart cities, autonomous vehicles, energy efficiency, smart manufacturing in Industry 4.0, and healthcare. Additionally the key challenges relating to Big Data, a model of reality, augmentation of systems, computation, and security are examined.","","Electronic:978-1-5090-4042-1; POD:978-1-5090-4043-8","10.1109/ISADS.2017.56","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7940213","Big Data;Cloud;Edge;Fog;HPC;Industry 4.0;IoS;IoT;SIMaaS;SOA;Security;Services;Simulation;Smart Cities;Stream Processing;WFaaS;Workflows","Automation;Big Data;Cloud computing;Computational modeling;Mathematical model;Robots;Smart cities","Big Data;Internet of Things;cloud computing;cyber-physical systems;learning (artificial intelligence);parallel processing;smart cities","Big Data;HPC;Internet of Simulation;Internet of Things;IoS;IoT;SIMaaS;cloud computing;cyber-physical systems;deep learning;edge computing;fog computing;massive-scale automation;simulations as services;smart cities","","","","","","","","22-24 March 2017","","IEEE","IEEE Conference Publications"
"A Deep Learning Approach to on-Node Sensor Data Analytics for Mobile or Wearable Devices","D. Ravì; C. Wong; B. Lo; G. Z. Yang","Hamlyn Centre, Imperial College London, London, U.K.","IEEE Journal of Biomedical and Health Informatics","20170520","2017","21","1","56","64","The increasing popularity of wearable devices in recent years means that a diverse range of physiological and functional data can now be captured continuously for applications in sports, wellbeing, and healthcare. This wealth of information requires efficient methods of classification and analysis where deep learning is a promising technique for large-scale data analytics. While deep learning has been successful in implementations that utilize high-performance computing platforms, its use on low-power wearable devices is limited by resource constraints. In this paper, we propose a deep learning methodology, which combines features learned from inertial sensor data together with complementary information from a set of shallow features to enable accurate and real-time activity classification. The design of this combined method aims to overcome some of the limitations present in a typical deep learning framework where on-node computation is required. To optimize the proposed method for real-time on-node computation, spectral domain preprocessing is used before the data are passed onto the deep learning framework. The classification accuracy of our proposed deep learning approach is evaluated against state-of-the-art methods using both laboratory and real world activity datasets. Our results show the validity of the approach on different human activity datasets, outperforming other methods, including the two methods used within our combined pipeline. We also demonstrate that the computation times for the proposed method are consistent with the constraints of real-time on-node processing on smartphones and a wearable sensor platform.","2168-2194;21682194","","10.1109/JBHI.2016.2633287","EPSRC-NIHR HTC Partnership Award; 10.13039/501100000266 - EPSRC; ","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7797232","ActiveMiles;Human Activity Recognition (HAR);Internet-of-Things (IoT);deep learning;low-power devices;wearable","Feature extraction;Machine learning;Performance evaluation;Pipelines;Real-time systems;Spectrogram;Time-frequency analysis","Internet of Things;data analysis;health care;learning (artificial intelligence);wearable computers","HAR;Human Activity Recognition;Internet-of-Things;deep learning approach;inertial sensor;on-node sensor data analytics;smartphones;spectral domain preprocessing;wearable devices","","","","","","","20161223","Jan. 2017","","IEEE","IEEE Journals & Magazines"
"Deep learning Parkinson's from smartphone data","C. Stamate; G. D. Magoulas; S. Kueppers; E. Nomikou; I. Daskalopoulos; M. U. Luchini; T. Moussouri; G. Roussos","Birkbeck College, University of London, UK","2017 IEEE International Conference on Pervasive Computing and Communications (PerCom)","20170504","2017","","","31","40","The cloudUPDRS app is a Class I medical device, namely an active transient non-invasive instrument, certified by the Medicines and Healthcare products Regulatory Agency in the UK for the clinical assessment of the motor symptoms of Parkinson's Disease. The app follows closely the Unified Parkinson's Disease Rating Scale which is the most commonly used protocol in the clinical study of PD; can be used by patients and their carers at home or in the community; and, requires the user to perform a sequence of iterated movements which are recorded by the phone sensors. This paper discusses how the cloudUPDRS system addresses two key challenges towards meeting essential consistency and efficiency requirements, namely: (i) How to ensure high-quality data collection especially considering the unsupervised nature of the test, in particular, how to achieve firm user adherence to the prescribed movements; and (ii) How to reduce test duration from approximately 25 minutes typically required by an experienced patient, to below 4 minutes, a threshold identified as critical to obtain significant improvements in clinical compliance. To address the former, we combine a bespoke design of the user experience tailored so as to constrain context, with a deep learning approach used to identify failures to follow the movement protocol while at the same time limiting false positives to avoid unnecessary repetition. We address the latter by developing a machine learning approach to personalise assessments by selecting those elements of the UPDRS protocol that most closely match individual symptom profiles and thus offer the highest inferential power hence closely estimating the patent's overall UPRDS score.","","Electronic:978-1-5090-4327-9; POD:978-1-5090-4328-6","10.1109/PERCOM.2017.7917848","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7917848","","Conferences;Diseases;Machine learning;Market research;Pervasive computing;Protocols;Sensors","cloud computing;learning (artificial intelligence);medical computing;medical disorders;smart phones","Medicines-and-Healthcare products Regulatory Agency;UK;UPDRS protocol;active transient noninvasive instrument;class-I medical device;clinical assessment;cloudUPDRS application;data collection;deep learning approach;false positives;machine learning approach;motor symptoms;smart phone data;test duration reduction;unified Parkinson's disease rating scale;user experience","","","","","","","","13-17 March 2017","","IEEE","IEEE Conference Publications"
"Medic: An artificially intelligent system to provide healthcare services to society and medical assistance to doctors","S. Jayawant","","2016 International Conference on Communication and Electronics Systems (ICCES)","20170330","2016","","","1","6","Since the last decade, number of applications of Artificial Intelligence in daily livelihood has drastically increased. This is primarily because of the inclusion of high-tech gadgets in our day-to-day lives. These gadgets provide high computational capabilities and geographical reach. These two features could be exerted to provide medical services to the society. This paper is based on a project which emphasizes on creating a software infrastructure which would provide healthcare services like diagnosis of diseases, advising medical tests to patients, providing medical prescription to patients by making use of personalized medicine problem solving algorithms etc., and providing medical assistance to doctors. This project, Medic, makes use of natural language processing, fuzzy logic, deep learning and a constantly evolving knowledge base to correctly diagnose diseases. It also provides various services to doctors which would help them while making decisions regarding any patient's medical treatment.","","DVD:978-1-5090-1064-6; Electronic:978-1-5090-1066-0; POD:978-1-5090-1067-7; Paper:978-1-5090-1065-3","10.1109/CESYS.2016.7889878","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7889878","Artificial Intelligence;Artificial neural networks;Convolution neural networks;Deep learning;Image recognition;Natural language processing","Biological neural networks;Convolution;Diseases;Medical diagnostic imaging;Natural language processing","diseases;fuzzy logic;health care;image recognition;learning (artificial intelligence);medical information systems;natural language processing;problem solving","Medic;artificially intelligent system;constantly evolving knowledge base;decision making;deep learning;disease diagnosis;fuzzy logic;healthcare services;high-tech gadgets;image recognition;medical assistance;medical prescription;medical services;medical tests;medical treatment;natural language processing;patient treatment;personalized medicine problem solving algorithms;software infrastructure","","","","","","","","21-22 Oct. 2016","","IEEE","IEEE Conference Publications"
"Build watson: An overview of DeepQA for the Jeopardy! Challenge","D. Ferrucci","IBM Research, Hawthorne, NY, USA","2010 19th International Conference on Parallel Architectures and Compilation Techniques (PACT)","20170213","2010","","","1","1","Computer systems that can directly and accurately answer peoples' questions over a broad domain of human knowledge have been envisioned by scientists and writers since the advent of computers themselves. Open domain question answering holds tremendous promise for facilitating informed decision making over vast volumes of natural language content. Applications in business intelligence, healthcare, customer support, enterprise knowledge management, social computing, science and government would all benefit from deep language processing. The DeepQA project (www.ibm.com/deepqa) is aimed at illustrating how the advancement and integration of Natural Language Processing (NLP), Information Retrieval (IR), Machine Learning (ML), massively parallel computation and Knowledge Representation and Reasoning (KR&R) can greatly advance open-domain automatic Question Answering. An exciting proof-point in this challenge is to develop a computer system that can successfully compete against top human players at the Jeopardy! quiz show (www.jeopardy.com). Attaining champion-level performance Jeopardy! requires a computer to rapidly answer rich open-domain questions, and to predict its own performance on any given category/question. The system must deliver high degrees of precision and confidence over a very broad range of knowledge and natural language content and with a 3-second response time. To do this DeepQA generates, evidences and evaluates many competing hypotheses. A key to success is automatically learning and combining accurate confidences across an array of complex algorithms and over different dimensions of evidence. Accurate confidences are needed to know when to “buzz in” against your competitors and how much to bet. Critical for winning at Jeopardy!, High precision and accurate confidence computations are just as critical for providing real value in business settings where helping users focus on the right content sooner and with gre- ter confidence can make all the difference. The need for speed and high precision demands a massively parallel compute platform capable of generating, evaluating and combing 1000's of hypotheses and their associated evidence. In this talk I will introduce the audience to the Jeopardy! Challenge and describe our technical approach and our progress on this grand-challenge problem.","","Electronic:978-1-4503-0178-7; POD:978-1-5090-5032-1","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7851501","Algorithms;Design;Experimentation;Human Factors;Performance","Cognition;Computers;Decision making;Knowledge discovery;Knowledge representation;Natural language processing","information retrieval;knowledge management;knowledge representation;learning (artificial intelligence);natural language processing","DeepQA;IR;Information Retrieval;Jeopardy;KR&R;ML;NLP;business intelligence;business settings;decision making;deep language processing;enterprise knowledge management;human knowledge;knowledge representation-and-reasoning;machine learning;natural language processing;open-domain automatic question answering;social computing","","","","","","","","11-15 Sept. 2010","","IEEE","IEEE Conference Publications"
"Semi-automated annotation of signal events in clinical EEG data","S. Yang; S. López; M. Golmohammadi; I. Obeid; J. Picone","Neural Engineering Data Consortium, Temple University, Philadelphia, Pennsylvania, USA","2016 IEEE Signal Processing in Medicine and Biology Symposium (SPMB)","20170209","2016","","","1","5","To be effective, state of the art machine learning technology needs large amounts of annotated data. There are numerous compelling applications in healthcare that can benefit from high performance automated decision support systems provided by deep learning technology, but they lack the comprehensive data resources required to apply sophisticated machine learning models. Further, for economic reasons, it is very difficult to justify the creation of large annotated corpora for these applications. Hence, automated annotation techniques become increasingly important. In this study, we investigated the effectiveness of using an active learning algorithm to automatically annotate a large EEG corpus. The algorithm is designed to annotate six types of EEG events. Two model training schemes, namely threshold-based and volume-based, are evaluated. In the threshold-based scheme the threshold of confidence scores is optimized in the initial training iteration, whereas for the volume-based scheme only a certain amount of data is preserved after each iteration. Recognition performance is improved 2% absolute and the system is capable of automatically annotating previously unlabeled data. Given that the interpretation of clinical EEG data is an exceedingly difficult task, this study provides some evidence that the proposed method is a viable alternative to expensive manual annotation.","","Electronic:978-1-5090-6713-8; POD:978-1-5090-6714-5","10.1109/SPMB.2016.7846855","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7846855","","Brain models;Data models;Electroencephalography;Hidden Markov models;Sensitivity;Training","electroencephalography;health care;iterative methods;learning (artificial intelligence);medical signal processing","EEG corpus;clinical EEG data;confidence scores;deep learning;healthcare;high-performance automated decision support systems;initial training iteration;machine learning;signal events semi-automated annotation","","","","","","","","3-3 Dec. 2016","","IEEE","IEEE Conference Publications"
"Temporal Pattern Recognition in Gait Activities Recorded With a Footprint Imaging Sensor System","O. Costilla-Reyes; P. Scully; K. B. Ozanyan","School of Electrical and Electronic Engineering, Photon Science Institute, University of Manchester, Manchester, U.K.","IEEE Sensors Journal","20161117","2016","16","24","8815","8822","In this paper, we assess the capability of a unique unobtrusive footprint imaging sensor system, based on plastic optical fiber technology, to allow efficient gait analysis from time domain sensor data by pattern recognition techniques. Trial gait classification experiments are executed as ten manners of walking, affecting the amplitude and frequency characteristics of the temporal signals. The data analysis involves the design of five temporal features, subsequently analyzed in 14 different machine learning models, representing linear, non-linear, ensemble, and deep learning models. The model performance is presented as cross-validated accuracy scores for the best model-feature combinations, along with the optimal hyper-parameters for each of them. The best classification performance was observed for a random forest model with the adjacent mean feature, yielding a mean validation score of 90.84% ± 2.46%. We conclude that the floor sensor system is capable of detecting changes in gait by means of pattern recognition techniques applied in the time domain. This suggests that the footprint imaging sensor system is suitable for gait analysis applications ranging from healthcare to security.","1530-437X;1530437X","","10.1109/JSEN.2016.2583260","U.K. Engineering and Physical Sciences Research Council through the Knowledge Transfer Scheme; 10.13039/501100007350 - Consejo Nacional de Ciencia y Tecnolog¿a; ","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7496802","Floor sensor;gait analysis;machine learning;pattern recognition;sensor fusion","Floors;Imaging;Intelligent sensors;Legged locomotion;Optical fibers;Sensor systems","biomedical optical imaging;fibre optic sensors;gait analysis;image classification;learning (artificial intelligence);medical image processing","deep learning model;ensemble model;footprint imaging sensor system;gait activities;gait classification experiments;healthcare;machine learning models;model-feature combinations;nonlinear model;plastic optical fiber technology;random forest model;temporal pattern recognition;temporal signals;time domain sensor data;walking","","","","","","","20160621","Dec.15, 15 2016","","IEEE","IEEE Journals & Magazines"
"The effects of deep network topology on mortality prediction","H. Du; M. M. Ghassemi; M. Feng","School of Electrical and Electronic Engineering, Nanyang Technology University, Singapore","2016 38th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)","20161018","2016","","","2602","2605","Deep learning has achieved remarkable results in the areas of computer vision, speech recognition, natural language processing and most recently, even playing Go. The application of deep-learning to problems in healthcare, however, has gained attention only in recent years, and it's ultimate place at the bedside remains a topic of skeptical discussion. While there is a growing academic interest in the application of Machine Learning (ML) techniques to clinical problems, many in the clinical community see little incentive to upgrade from simpler methods, such as logistic regression, to deep learning. Logistic regression, after all, provides odds ratios, p-values and confidence intervals that allow for ease of interpretation, while deep nets are often seen as `black-boxes' which are difficult to understand and, as of yet, have not demonstrated performance levels far exceeding their simpler counterparts. If deep learning is to ever take a place at the bedside, it will require studies which (1) showcase the performance of deep-learning methods relative to other approaches and (2) interpret the relationships between network structure, model performance, features and outcomes. We have chosen these two requirements as the goal of this study. In our investigation, we utilized a publicly available EMR dataset of over 32,000 intensive care unit patients and trained a Deep Belief Network (DBN) to predict patient mortality at discharge. Utilizing an evolutionary algorithm, we demonstrate automated topology selection for DBNs. We demonstrate that with the correct topology selection, DBNs can achieve better prediction performance compared to several bench-marking methods.","1557-170X;1557170X","Electronic:978-1-4577-0220-4; POD:978-1-4577-0219-8","10.1109/EMBC.2016.7591263","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7591263","","Bioinformatics;Genomics;Machine learning;Network topology;Neural networks;Topology;Training","belief networks;electronic health records;evolutionary computation;health care;learning (artificial intelligence);medical computing","EMR dataset;deep belief network;deep network topology;deep-learning methods;electronic medical record;evolutionary algorithm;healthcare;intensive care unit patients;network structure;patient mortality prediction","","","","","","","","16-20 Aug. 2016","","IEEE","IEEE Conference Publications"
"An adaptive deep learning approach for PPG-based identification","V. Jindal; J. Birjandtalab; M. B. Pouyan; M. Nourani","Quality of Life Technology Laboratory, The University of Texas at Dallas, Richardson, TX 75080","2016 38th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)","20161018","2016","","","6401","6404","Wearable biosensors have become increasingly popular in healthcare due to their capabilities for low cost and long term biosignal monitoring. This paper presents a novel two-stage technique to offer biometric identification using these biosensors through Deep Belief Networks and Restricted Boltzman Machines. Our identification approach improves robustness in current monitoring procedures within clinical, e-health and fitness environments using Photoplethysmography (PPG) signals through deep learning classification models. The approach is tested on TROIKA dataset using 10-fold cross validation and achieved an accuracy of 96.1%.","1557-170X;1557170X","Electronic:978-1-4577-0220-4; POD:978-1-4577-0219-8","10.1109/EMBC.2016.7592193","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7592193","","Biological system modeling;Biomedical monitoring;Brain modeling;Feature extraction;Machine learning;Neural networks;Training","Boltzmann machines;belief networks;biometrics (access control);biosensors;body sensor networks;health care;learning (artificial intelligence);medical signal processing;patient monitoring;photoplethysmography","10-fold cross validation;Deep Belief Networks;PPG-based identification;Restricted Boltzman Machines;TROIKA dataset;adaptive deep learning approach;biometric identification;biosignal monitoring;clinical environments;deep learning classification models;e-health environments;fitness environments;healthcare;photoplethysmography signals;two-stage technique;wearable biosensors","","","","","","","","16-20 Aug. 2016","","IEEE","IEEE Conference Publications"
"Improving Tuberculosis Diagnostics Using Deep Learning and Mobile Health Technologies among Resource-Poor and Marginalized Communities","Y. Cao; C. Liu; B. Liu; M. J. Brunette; N. Zhang; T. Sun; P. Zhang; J. Peinado; E. S. Garavito; L. L. Garcia; W. H. Curioso","Dept. of Comput. Sci., Univ. of Massachusetts-Lowell, Lowell, MA, USA","2016 IEEE First International Conference on Connected Health: Applications, Systems and Engineering Technologies (CHASE)","20160818","2016","","","274","281","Tuberculosis (TB) is a chronic infectious disease worldwide and remains a major cause of death globally. Of the estimated 9 million people who developed TB in 2013, over 80% were in South-East Asia, Western Pacific, and African. The majority of the infected populations was from resource-poor and marginalized communities with weak healthcare infrastructure. Reducing TB diagnosis delay is critical in mitigating disease transmission and minimizing the reproductive rate of the tuberculosis epidemic. The combination of machine learning and mobile computing techniques offers a unique opportunity to accelerate the TB diagnosis among these communities. The ultimate goal of our research is to reduce patient wait times for being diagnosed with this infectious disease by developing new machine learning and mobile health techniques to the TB diagnosis problem. In this paper, we first introduce major technique barriers and proposed system architecture. Then we report two major progresses we recently made. The first activity aims to develop large-scale, real-world and well-annotated X-ray image database dedicated for automated TB screening. The second research activity focus on developing effective and efficient computational models (in particularly, deep convolutional neural networks (CNN)-based models) to classify the image into different category of TB manifestations. Experimental results have demonstrated the effectiveness of our approach. Our future work includes: (1) to further improve the performance of the algorithms, and (2) to deploy our system in the city of Carabayllo in Perú, a densely occupied urban community and high-burden TB.","","Electronic:978-1-5090-0943-5; POD:978-1-5090-0944-2","10.1109/CHASE.2016.18","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7545842","Perú;deep convolutional neural networks;deep learning;diagnosis;mHealth;mobile computing;tuberculosis","Diagnostic radiography;Image databases;Mobile communication;Mobile computing;Mobile handsets;X-ray imaging","diagnostic radiography;diseases;epidemics;image classification;learning (artificial intelligence);medical image processing;mobile computing;neural nets;patient diagnosis;visual databases","African;CNN-based models;Deep Learning;Mobile Health Technologies;South-East Asia;TB diagnosis delay;Tuberculosis Diagnostics;Western Pacific;X-ray image database;automated TB screening;chronic infectious disease;deep convolutional neural network-based models;disease transmission;healthcare;image classification;machine learning;mobile computing;tuberculosis epidemic","","","","","","","","27-29 June 2016","","IEEE","IEEE Conference Publications"
"Deep learning for human activity recognition: A resource efficient implementation on low-power devices","D. Ravi; C. Wong; B. Lo; G. Z. Yang","The Hamlyn Centre, Imperial College London, London","2016 IEEE 13th International Conference on Wearable and Implantable Body Sensor Networks (BSN)","20160721","2016","","","71","76","Human Activity Recognition provides valuable contextual information for wellbeing, healthcare, and sport applications. Over the past decades, many machine learning approaches have been proposed to identify activities from inertial sensor data for specific applications. Most methods, however, are designed for offline processing rather than processing on the sensor node. In this paper, a human activity recognition technique based on a deep learning methodology is designed to enable accurate and real-time classification for low-power wearable devices. To obtain invariance against changes in sensor orientation, sensor placement, and in sensor acquisition rates, we design a feature generation process that is applied to the spectral domain of the inertial data. Specifically, the proposed method uses sums of temporal convolutions of the transformed input. Accuracy of the proposed approach is evaluated against the current state-of-the-art methods using both laboratory and real world activity datasets. A systematic analysis of the feature generation parameters and a comparison of activity recognition computation times on mobile devices and sensor nodes are also presented.","","Electronic:978-1-5090-3087-3; POD:978-1-5090-3088-0","10.1109/BSN.2016.7516235","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7516235","ActiveMiles;Deep Learning;HAR;Low-Power Devices","Convolution;Data mining;Feature extraction;Machine learning;Spectrogram;Time-frequency analysis","convolution;feature extraction;image recognition;learning (artificial intelligence);sensor placement","contextual information;deep learning;feature generation;human activity recognition;inertial sensor data;low-power wearable devices;machine learning;mobile devices;offline processing;resource efficient implementation;sensor acquisition rates;sensor nodes;sensor placement;spectral domain;temporal convolutions","","","","","","","","14-17 June 2016","","IEEE","IEEE Conference Publications"
"A restricted Boltzmann machine based two-lead electrocardiography classification","Y. Yan; X. Qin; Y. Wu; N. Zhang; J. Fan; L. Wang","Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences","2015 IEEE 12th International Conference on Wearable and Implantable Body Sensor Networks (BSN)","20151019","2015","","","1","9","An restricted Boltzmann machine learning algorithm were proposed in the two-lead heart beat classification problem. ECG classification is a complex pattern recognition problem. The unsupervised learning algorithm of restricted Boltzmann machine is ideal in mining the massive unlabelled ECG wave beats collected in the heart healthcare monitoring applications. A restricted Boltzmann machine (RBM) is a generative stochastic artificial neural network that can learn a probability distribution over its set of inputs. In this paper a deep belief network was constructed and the RBM based algorithm was used in the classification problem. Under the recommended twelve classes by the ANSI/AAMI EC57: 1998/(R)2008 standard as the waveform labels, the algorithm was evaluated on the two-lead ECG dataset of MIT-BIH and gets the performance with accuracy of 98.829%. The proposed algorithm performed well in the two-lead ECG classification problem, which could be generalized to multi-lead unsupervised ECG classification or detection problems.","2376-8886;23768886","Electronic:978-1-4673-7201-5; POD:978-1-4673-7202-2","10.1109/BSN.2015.7299399","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7299399","big data;deep belief network;electrocardiography classification;restricted Boltzmann machine","Accuracy;Data models;Electrocardiography;Feature extraction;Heart beat;Signal processing algorithms;Training","Boltzmann machines;diseases;electrocardiography;learning (artificial intelligence);medical signal processing;signal classification;stochastic processes","MIT-BIH arrhythmia database;RBM learning algorithm;complex pattern recognition;heart healthcare monitoring;massive unlabelled ECG wave beat;multilead unsupervised ECG classification;probability distribution;restricted Boltzmann machine;stochastic artificial neural network;two-lead ECG classification;two-lead ECG dataset;two-lead heart beat classification","","2","","31","","","","9-12 June 2015","","IEEE","IEEE Conference Publications"
"Inexpensive user tracking using Boltzmann Machines","E. Mocanu; D. C. Mocanu; H. B. Ammar; Z. Zivkovic; A. Liotta; E. Smirnov","Department of Electrical Engineering, Eindhoven University of Technology, Netherlands","2014 IEEE International Conference on Systems, Man, and Cybernetics (SMC)","20141204","2014","","","1","6","Inexpensive user tracking is an important problem in various application domains such as healthcare, human-computer interaction, energy savings, safety, robotics, security and so on. Yet, it cannot be easily solved due to its probabilistic nature, high level of abstraction and uncertainties, on the one side, and to the limitations of our current technologies and learning algorithms, on the other side. In this paper, we tackle this problem by using the Multi-integrated Sensor Technology, which comes at a low price. At the same time, we are aiming to address the lightweight learning requirements by investigating Factored Conditional Restricted Boltzmann Machines (FCRBMs), a form of Deep Learning, that has proven to be an efficient and effective machine learning framework. However, due to their construction properties, the conventional FCRBMs are only capable of performing predictions but are not capable of making classification. Herein, we are proposing extended FCRBMs (eFCRBMs), which incorporate a novel classification scheme, to solve this problem. Experiments performed on both artificially generated as well as real-world data demonstrate the effectiveness and efficiency of the proposed technique. We show that eFCRBMs outperform popular approaches including Support Vector Machines, Naive Bayes, AdaBoost, and Gaussian Mixture Models.","1062-922X;1062922X","Electronic:978-1-4799-3840-7; POD:978-1-4799-3841-4; USB:978-1-4799-3839-1","10.1109/SMC.2014.6973875","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6973875","","Computers;History;Neurons;Probabilistic logic;Robot sensing systems;TV;Time series analysis","Boltzmann machines;Gaussian processes;image classification;image fusion;learning (artificial intelligence);object detection;object tracking;recurrent neural nets;support vector machines","AdaBoost;Gaussian mixture models;classification scheme;deep learning;energy savings;extended FCRBM;factored conditional restricted Boltzmann machines;healthcare;human-computer interaction;inexpensive user tracking;learning requirements;machine learning framework;multiintegrated sensor technology;naive Bayes;people detection;people tracking;robotics;support vector machines","","4","","17","","","","5-8 Oct. 2014","","IEEE","IEEE Conference Publications"
"Predictive Modeling of Therapy Decisions in Metastatic Breast Cancer with Recurrent Neural Network Encoder and Multinomial Hierarchical Regression Decoder","Y. Yang; P. A. Fasching; V. Tresp","","2017 IEEE International Conference on Healthcare Informatics (ICHI)","20170914","2017","","","46","55","The increasing availability of novel health-related data sources —e.g., from molecular analysis, health Apps and electronic health records— might eventually overwhelm the physician, and the community is investigating analytics approaches that might be useful to support clinical decisions. In particular, the success of the latest developments in Deep Learning has demonstrated that machine learning models are capable of handling —and actually profiting from— high dimensional and possibly sequential data. In this work, we propose an encoder-decoder network approach to model the physician's therapy decisions. Our approach also provides physicians with a list of similar historical patient cases to support the recommended decisions. By using a combination of a Recurrent Neural Network Encoder and a Multinomial Hierarchical Regression Decoder, we specifically tackle two common challenges in modeling clinical data:First, the issue of handling episodic data of variable lengths and, second, the need to represent hierarchical decision procedures. We conduct experiments on a large real-world dataset collected from thousands of metastatic breast cancer patients and show that our model outperforms more traditional approaches.","","Electronic:978-1-5090-4881-6; POD:978-1-5090-4882-3","10.1109/ICHI.2017.51","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8031131","Decision Support;Encoder-Decoder Framework;Hierarchical Regression;Recurrent Neural Networks","Breast cancer;Decoding;Metastasis;Predictive models;Surgery","","","","","","","","","","23-26 Aug. 2017","","IEEE","IEEE Conference Publications"
"Language-Based Process Phase Detection in the Trauma Resuscitation","Y. Gu; X. Li; S. Chen; H. Li; R. A. Farneth; I. Marsic; R. S. Burd","","2017 IEEE International Conference on Healthcare Informatics (ICHI)","20170914","2017","","","239","247","Process phase detection has been widely used in surgical process modeling (SPM) to track process progression. These studies mostly used video and embedded sensor data, but spoken language also provides rich semantic information directly related to process progression. We present a long-short term memory (LSTM) deep learning model to predict trauma resuscitation phases using verbal communication logs. We first use an LSTM to extract the sentence meaning representations, and then sequentially feed them into another LSTM to extract the mean-ing of a sentence group within a time window. This information is ultimately used for phase prediction. We used 24 manually-transcribed trauma resuscitation cases to train, and the remain-ing 6 cases to test our model. We achieved 79.12% accuracy, and showed performance advantages over existing visual-audio systems for critical phases of the process. In addition to language information, we evaluated a multimodal phase prediction structure that also uses audio input. We finally identified the challenges of substituting manual transcription with automatic speech recognition in trauma resuscitation.","","Electronic:978-1-5090-4881-6; POD:978-1-5090-4882-3","10.1109/ICHI.2017.50","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8031153","LSTM;deep learning;process phase detection;semantic representation;verbal communication logs","Logic gates;Microphones;Phase detection;Semantics;Speech;Surgery","","","","","","","","","","23-26 Aug. 2017","","IEEE","IEEE Conference Publications"
"Construction of Discharge Summaries Classifier","S. Tsumoto; T. Kimura; H. Iwata; S. Hirano","","2017 IEEE International Conference on Healthcare Informatics (ICHI)","20170914","2017","","","74","82","This paper proposes a method for construction of classifiers for discharge summaries. First, morphological analysis is applied to a set of summaries and a term matrix is generated. Second, correspond analysis is applied to the classification labels and the term matrixand generates two dimensional coordinates. By measuring thedistance between categories and the assigned points, ranking of key wordswill be generated. Then, keywords are selected as attributes according to the rank, andtraining example for classifiers will be generated. Finally learning methodsare applied to the training examples. Experimental validation shows that random forest achieved the best performance and the second best was the deep learner with a small difference, but decision tree methods with many keywords performed only a little worse than neural network or deep learning methods.","","Electronic:978-1-5090-4881-6; POD:978-1-5090-4882-3","10.1109/ICHI.2017.92","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8031134","Discharge summary;SVM;classification;correspondence analysis;decision tree;deep learning;random forest;text mining","Cancer;Decision trees;Hospitals;Support vector machines;Surgery;Text mining;Training","","","","","","","","","","23-26 Aug. 2017","","IEEE","IEEE Conference Publications"
"Deep Reinforcement Learning for Dynamic Treatment Regimes on Medical Registry Data","Y. Liu; B. Logan; N. Liu; Z. Xu; J. Tang; Y. Wang","","2017 IEEE International Conference on Healthcare Informatics (ICHI)","20170914","2017","","","380","385","In this paper, we propose the first deep reinforce-ment learning framework to estimate the optimal Dynamic Treat-ment Regimes from observational medical data. This framework is more flexible and adaptive for high dimensional action and state spaces than existing reinforcement learning methods to model real life complexity in heterogeneous disease progression and treatment choices, with the goal to provide doctor and patients the data-driven personalized decision recommendations. The proposed deep reinforcement learning framework contains a supervised learning step to predict the most possible expert actions; and a deep reinforcement learning step to estimate the long term value function of Dynamic Treatment Regimes. We motivated and implemented the proposed framework on a data set from the Center for International Bone Marrow Transplant Research (CIBMTR) registry database, focusing on the sequence of prevention and treatments for acute and chronic graft versus host disease. We showed results of the initial implementation that demonstrates promising accuracy in predicting human expert decisions and initial implementation for the reinforcement learning step.","","Electronic:978-1-5090-4881-6; POD:978-1-5090-4882-3","10.1109/ICHI.2017.45","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8031178","","Biomedical imaging;Decision making;Diseases;Games;Learning (artificial intelligence);Machine learning","","","","","","","","","","23-26 Aug. 2017","","IEEE","IEEE Conference Publications"
"CVRT: Cognitive Visual Recognition Tracker","M. Velazquez; Y. Lee","","2017 IEEE International Conference on Healthcare Informatics (ICHI)","20170914","2017","","","31","38","Studies on visual attention of patients with Alzheimer's disease and Dementia is a promising way for keeping track of the individual patient's image recognition ability over. This research seeks to expand upon the current applications of combining the Android operating system with TensorFlow by providing a visual question answering platform for image analysis. This application, Cognitive Visual Recognition Tracker (CVRT), provides an entry point by which the user can ask questions concerning any image of their choosing, and then receive cumulative metrics over time to better assess any diminishing cognitive ability (i.e. Alzheimer's patients). In this work, recurrent neural networks as well as semantic analysis are leveraged to provide an interactive VQA experience. One of the main objectives of CVRT is for physicians to be able to determine trends from patient data that could either be applicable to the individual patient, or to many patients if an aggregate is formed from many individual datasets. On an individual level, these metrics would provide a way for the physician to monitor daily cognitive capability, whereas on a grander scale, these joint datasets could be used to provide better overall treatment for the disease with the future inclusion of predictive analytics. The final contribution is an interactive metrics platform by which other users can assess the primary user's cognitive capacity based on features of their questioning, and to then provide them with accurate trending or possible remediation plans based on their condition.","","Electronic:978-1-5090-4881-6; POD:978-1-5090-4882-3","10.1109/ICHI.2017.65","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8031129","Alzheimer's disease and Dementia;Deep Learning;Visual Question Answering","Conferences;Informatics;Medical services","","","","","","","","","","23-26 Aug. 2017","","IEEE","IEEE Conference Publications"
"Automated EEG-Based Epileptic Seizure Detection Using Deep Neural Networks","J. Birjandtalab; M. Heydarzadeh; M. Nourani","","2017 IEEE International Conference on Healthcare Informatics (ICHI)","20170914","2017","","","552","555","Millions of people around the world suffer from epilepsy. It is very important to provide a method to efficiently monitor the seizures and alert the caregivers to help patients. It is proven that EEG signals are the best markers for diagnosis of the epileptic seizures. In this paper, we used the frequency domain features (normalized in-band power spectral density) to extract information from EEG signals. We applied a deep learning technique based on multilayer perceptrons to improve the accuracy of seizure detection. The results indicate that our nonlinear technique is able to efficiently and automatically detect seizure and non-seizure episodes with an F-measure accuracy of around 95%.","","Electronic:978-1-5090-4881-6; POD:978-1-5090-4882-3","10.1109/ICHI.2017.55","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8031211","Deep Neural Networks;EEG signals;Feature extraction;Multi Layer Perceptron;Seizure detection","Biological neural networks;Electroencephalography;Feature extraction;Multilayer perceptrons;Training","","","","","","","","","","23-26 Aug. 2017","","IEEE","IEEE Conference Publications"
"Medical Concept Normalization for Online User-Generated Texts","K. Lee; S. A. Hasan; O. Farri; A. Choudhary; A. Agrawal","","2017 IEEE International Conference on Healthcare Informatics (ICHI)","20170914","2017","","","462","469","Social media has become an important tool for sharing content in the last decade. People often talk about their experiences and opinions on different health-related issues e.g. they write reviews on medications, describe symptoms and ask informal questions about various health concerns. Due to the colloquial nature of the languages used in the social media, it is often difficult for an automated system to accurately interpret them for appropriate clinical understanding. To address this challenge, this paper proposes a novel approach for medical concept normalization of user-generated texts to map a health condition described in the colloquial language to a medical concept defined in standard clinical terminologies. We use multiple deep learning architectures such as convolutional neural networks (CNN) and recurrent neural networks (RNN) with input word embeddings trained on various clinical domain-specific knowledge sources. Extensive experiments on two benchmark datasets demonstrate that the proposed models can achieve up to 21.28% accuracy improvements over the existing models when we use the combination of all knowledge sources to learn neural embeddings.","","Electronic:978-1-5090-4881-6; POD:978-1-5090-4882-3","10.1109/ICHI.2017.59","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8031195","deep learning;medical concept normalization;social media","Drugs;Hair;Hidden Markov models;Medical diagnostic imaging;Pain;Recurrent neural networks;Social network services","","","","","","","","","","23-26 Aug. 2017","","IEEE","IEEE Conference Publications"
"Deep Learning Based Recognition of Meltdown in Autistic Kids","V. S. P. Patnam; F. T. George; K. George; A. Verma","","2017 IEEE International Conference on Healthcare Informatics (ICHI)","20170914","2017","","","391","396","Children with autism often experience sudden meltdowns which not only makes the moment tough for the caretakers/parents but also make the children hurt themselves physically. Studies have discovered that children with autistic spectrum disorder exhibit certain actions through which we can anticipate mutilating meltdowns in them. The objective of our project is to build a system that can recognize such kind of actions using deep learning techniques thereby, notifying the caretakers/parents so that they can get the situation under control in lesser time. Using deep learning RCNNs, we can train the system faster yet reliable because unlike all the machine learning algorithms, deep learning algorithms are more efficient and have more scope into future. We have trained a classifier on images that are gathered from videos and reliable internet sources with most predictive gestures, through which we can detect the meltdowns more precisely. We have trained a model that validated the accuracy by ~93% which is accompanied by a loss/train classifier with a minimal 0.4% loss. Functional testing was done through feeding the deep neural network with chosen actions performed by five individuals that resulted in an accuracy of ~92% in all cases, which can assure the real-time usage of the system.","","Electronic:978-1-5090-4881-6; POD:978-1-5090-4882-3","10.1109/ICHI.2017.35","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8031180","Autistic spectrum disorder;Convolution Neural Network;Graphics Processing Unit;deep learning;inference;training classifiers","Autism;Convolution;Databases;Ear;Machine learning;Neural networks;Training","","","","","","","","","","23-26 Aug. 2017","","IEEE","IEEE Conference Publications"
"Single Sensor Techniques for Sleep Apnea Diagnosis Using Deep Learning","R. K. Pathinarupothi; D. P. J; E. S. Rangan; G. E. A; V. R; K. P. Soman","","2017 IEEE International Conference on Healthcare Informatics (ICHI)","20170914","2017","","","524","529","A large number of obstructive sleep apnea (OSA) cases are under-diagnosed due unavailability, inconvenience or expense of sleep labs. Hence, an automated detection by applying computational techniques to multivariate signals has already become a well-researched subject. However, the best-known techniques that use various features have not achieved the gold standard of polysomnography (PSG) tests. In this paper, we substantiate the medical conjecture that OSA directly impacts body parameters such as Instantaneous Heart Rate (IHR) and blood oxygen saturation (SpO2). We then use a deep learning technique called LSTM-RNN (long short-term memory recurrent neural networks) to experimentally prove that OSA severity detection can be solely based on either IHR or SpO2 signals, which can be easily, obtained using off-the-shelf non-intrusive wearable single sensors. The results obtained from LSTM-RNN model shows an area under curve (AUC) of 0.98 associated with very high accuracy on a dataset of more than 16,000 apnea non-apnea minutes. These results have encouraged our collaborating doctors to further come up with a diagnostic protocol that is based on LSTM-RNN, SpO2, and IHR, thereby increasing the chances of larger adoption among medical community.","","Electronic:978-1-5090-4881-6; POD:978-1-5090-4882-3","10.1109/ICHI.2017.37","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8031206","Instantaneous Heart Rate and SpO2;LSTM-RNN;Obstructive sleep apnea","Electrocardiography;Heart rate variability;Medical diagnostic imaging;Sleep apnea;Time series analysis","","","","","","","","","","23-26 Aug. 2017","","IEEE","IEEE Conference Publications"
"Extracting Drug-Drug Interactions with Word and Character-Level Recurrent Neural Networks","R. Kavuluru; A. Rios; T. Tran","","2017 IEEE International Conference on Healthcare Informatics (ICHI)","20170914","2017","","","5","12","Drug-drug interactions (DDIs) are known to be responsible for nearly a third of all adverse drug reactions. Hence several current efforts focus on extracting signal from EMRs to prioritize DDIs that need further exploration. To this end, being able to extract explicit mentions of DDIs in free text narratives is an important task. In this paper, we explore recurrent neural network (RNN) architectures to detect and classify DDIs from unstructured text using the DDIExtraction dataset from the SemEval 2013 (task 9) shared task. Our methods are in line with those used in other recent deep learning efforts for relation extraction including DDI extraction. However, to our knowledge, we are the first to investigate the potential of character-level RNNs (Char-RNNs) for DDI extraction (and relation extraction in general). Furthermore, we explore a simple but effective model bootstrapping method to (a). build model averaging ensembles, (b). derive confidence intervals around mean micro-F scores (MMF), and (c). assess the average behavior of our methods. Without any rule based filtering of negative examples, a popular heuristic used by most earlier efforts, we achieve an MMF of 69.13. By adding simple replicable heuristics to filter negative instances we are able to achieve an MMF of 70.38. Furthermore, our best ensembles produce micro F-scores of 70.81 (without filtering) and 72.13 (with filtering), which are superior to metrics reported in published results. Although Char-RNNs turnout to be inferior to regular word based RNN models in overall comparisons, we find that ensembling models from both architectures results in nontrivial gains over simply using either alone, indicating that they complement each other.","","Electronic:978-1-5090-4881-6; POD:978-1-5090-4882-3","10.1109/ICHI.2017.15","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8031125","drug-drug interactions;recurrent neural networks;relation classification","Computer architecture;Drugs;Kernel;Logic gates;Recurrent neural networks;Support vector machines","","","","","","","","","","23-26 Aug. 2017","","IEEE","IEEE Conference Publications"
"Big Social Data Analytics for Public Health: Predicting Facebook Post Performance Using Artificial Neural Networks and Deep Learning","N. Straton; R. R. Mukkamala; R. Vatrapu","","2017 IEEE International Congress on Big Data (BigData Congress)","20170911","2017","","","89","96","Facebook ""post popularity"" analysis is fundamental for differentiating between relevant posts and posts with low user engagement and consequently their characteristics. This research study aims at health and care organizations to improve information dissemination on social media platforms by reducing clutter and noise. At the same time, it will help users navigate through vast amount of information in direction of the relevant health and care content. Furthermore, study explores prediction of popularity of healthcare posts on the largest social media platform Facebook. Methodology is presented in this paper to predict user engagement based on eleven characteristics of the post: Post Type, Hour Span, Facebook Wall Category, Level, Country, isHoliday, Season, Created Year, Month, Day of the Week, Time of the Day. Finally, post performance prediction is conducted using Artificial Neural Networks (ANN) and Deep Neural Networks (DNN). Different network topology measures are used to achieve best accuracy prediction followed by examples and discussion on why DNN might not be optimal technique for the given data set.","","Electronic:978-1-5386-1996-4; POD:978-1-5386-1997-1; USB:978-1-5386-1995-7","10.1109/BigDataCongress.2017.21","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8029313","Artificial Neural Network (ANN);Deep Neural Network (DNN);Negative Entropy;Post Performance;Purity","Data analysis;Entropy;Facebook;Neural networks;Public healthcare","","","","","","","","","","25-30 June 2017","","IEEE","IEEE Conference Publications"
"Implementing WEKA for medical data classification and early disease prediction","N. Kumar; S. Khatri","Department of Computer Science & Engineering, University Institute of Engineering & Technology, Babasaheb Bhimrao Ambedkar University, Lucknow, India","2017 3rd International Conference on Computational Intelligence & Communication Technology (CICT)","20170713","2017","","","1","6","In recent years, the advent of latest web and data technologies has encouraged massive data growth in almost every sector. Businesses and leading industries are viewing these huge data repositories as a tool to design future strategies, prediction models by analyzing patterns and gaining knowledge from this unstructured data by applying different data mining techniques. Medical domain has now become richer in term of maintaining digital records of patients related to their diagnosis and treatment. These huge data repositories can range from patient personnel data, diagnosis, treatment histories, test diagnosis, images and various scans. This terabytes of medical data is quantity rich but weaker in information in terms of knowledge and robust tools to identify hidden patterns of knowledge specifically in medical sector. Data Mining as a field of research has already well proven capabilities of identifying hidden patterns, analysis and knowledge applied on different research domains, now gaining popularity day by day among researchers and scientist towards generating novel and deep insights of these large biomedical datasets also. Uncovering new biomedical and healthcare related knowledge in order to support clinical decision making, is another dimension of data mining. Through massive literature survey, it is found that early disease prediction is the most demanded area of research in health care sector. As health care domain is bit wider domain and having different disease characteristics, different techniques have their own prediction efficiencies, which can be enhanced and changed in order to get into most optimize way. In this research work, authors have comprehensively compared different data classification techniques and their prediction accuracy for chronic kidney disease. Authors have compared J48, Naive Bayes, Random Forest, SVM and k-NN classifiers using performance measures like ROC, kappa statistics, RMSE and MAE using WEKA tool. Authors have also compar- d these classifiers on various accuracy measures like TP rate, FP rate, precision, recall and f-measure by implementing on WEKA. Experimental result shows that random forest classifier has better classification accuracy over others for chronic kidney disease dataset.","","Electronic:978-1-5090-6218-8; POD:978-1-5090-6219-5","10.1109/CIACT.2017.7977277","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7977277","Classification;Data Mining;Healthcare;WEKA","Algorithm design and analysis;Classification algorithms;Data mining;Diseases;Kidney;Medical diagnostic imaging","data mining;diseases;electronic health records;health care;learning (artificial intelligence);patient diagnosis;patient treatment;pattern classification","J48;MAE;Naive Bayes;RMSE;ROC;SVM;WEKA tool;Waikato environment for knowledge analysis;biomedical datasets;chronic kidney disease dataset;clinical decision making;data mining techniques;data repositories;data technologies;early disease prediction;health care sector;k-NN classifiers;kappa statistics;massive data growth;medical data classification;medical domain;patient diagnosis;patient digital records;patient personnel data;patient treatment;pattern analysis;performance measures;random forest classifier;test diagnosis","","","","","","","","9-10 Feb. 2017","","IEEE","IEEE Conference Publications"
"Deep Temporal Multimodal Fusion for Medical Procedure Monitoring using Wearable Sensors","E. A. Bernal; X. Yang; Q. Li; J. Kumar; S. Madhvanath; P. Ramesh; R. Bala","Decision Support and Machine Intelligence, United Technologies Research Center, 129535 East Hartford, Connecticut United States (e-mail: eabernal@gmail.com)","IEEE Transactions on Multimedia","","2017","PP","99","1","1","Process monitoring and verification have a wide range of uses in the medical and healthcare fields. Currently, such tasks are often carried out by a trained specialist, which makes them expensive, inefficient, and time-consuming. Recent advances in automated video- and multimodal-data-based action and activity recognition have made it possible to reduce the extent of manual intervention required to effectively carry out process supervision tasks. In this paper, we propose algorithms for automated egocentric human action and activity recognition from multimodal data, with a target application of monitoring and assisting a user perform a multi-step medical procedure. We propose a supervised deep multimodal fusion framework that relies on concurrent processing of motion data acquired with wearable sensors and video data acquired with an egocentric or body-mounted camera. We demonstrate the effectiveness of the algorithm on a public multimodal dataset and conclude that automated process monitoring via the use of multiple heterogeneous sensors is a viable alternative to its manual counterpart. Furthermore, we demonstrate that the application of previously proposed adaptive sampling schemes to the video processing branch of the multimodal framework results in significant performance improvements.","1520-9210;15209210","","10.1109/TMM.2017.2726187","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7976382","Wearable sensors;action and activity recognition;deep learning;deep temporal fusion;egocentric vision;hand localization;medical procedures;multimodal fusion","Activity recognition;Biomedical monitoring;Data integration;Medical services;Monitoring;Wearable sensors","","","","","","","","","20170712","","","IEEE","IEEE Early Access Articles"
"FaceNet2ExpNet: Regularizing a Deep Face Recognition Net for Expression Recognition","H. Ding; S. K. Zhou; R. Chellappa","Univ. of Maryland, College Park, MD, USA","2017 12th IEEE International Conference on Automatic Face & Gesture Recognition (FG 2017)","20170629","2017","","","118","126","Relatively small data sets available for expression recognition research make the training of deep networks very challenging. Although fine-tuning can partially alleviate the issue, the performance is still below acceptable levels as the deep features probably contain redundant information from the pretrained domain. In this paper, we present FaceNet2ExpNet, a novel idea to train an expression recognition network based on static images. We first propose a new distribution function to model the high-level neurons of the expression network. Based on this, a two-stage training algorithm is carefully designed. In the pre-training stage, we train the convolutional layers of the expression net, regularized by the face net; In the refining stage, we append fully-connected layers to the pre-trained convolutional layers and train the whole network jointly. Visualization results show that the model trained with our method captures improved high-level expression semantics. Evaluations on four public expression databases, CK+, Oulu- CASIA, TFD, and SFEW demonstrate that our method achieves better results than state-of-the-art.","","Electronic:978-1-5090-4023-0; POD:978-1-5090-4024-7","10.1109/FG.2017.23","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7961731","","Convolution;Distribution functions;Face;Face recognition;Image recognition;Neurons;Training","convolution;data visualisation;emotion recognition;face recognition;learning (artificial intelligence)","CK+;FaceNet2ExpNet;Oulu- CASIA;SFEW;TFD;convolutional layer training;deep convolutional neural networks;deep face recognition net;deep network training;expression recognition;static images;visualization","","","","","","","","May 30 2017-June 3 2017","","IEEE","IEEE Conference Publications"
"Automated assessment of endometrium from transvaginal ultrasound using Deep Learned Snake","N. Singhal; S. Mukherjee; C. Perrey","GE Global Research, Bangalore, India","2017 IEEE 14th International Symposium on Biomedical Imaging (ISBI 2017)","20170619","2017","","","283","286","Endometrium assessment via thickness measurement is commonly performed in routine gynecological ultrasound examination for assessing the reproductive health of patients undergoing fertility related treatments and endometrium cancer screening in women with post-menopausal bleeding. This paper introduces a fully automated technique for endometrium thickness measurement from three-dimensional transvaginal ultrasound (TVUS) images. The algorithm combines the robustness of deep neural networks with the more interpretable level set method for segmentation. We propose a hybrid variational curve propagation model which embeds a deep-learned endometrium probability map in the segmentation energy functional. This solution provides approximately 30% performance improvement over a contemporary supervised learning method on a database of 59 TVUS images and the thickness measurement is found to be within ±2mm of the manual measurement in 87% of the cases.","","Electronic:978-1-5090-1172-8; POD:978-1-5090-1173-5","10.1109/ISBI.2017.7950520","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7950520","Endometrium;deep learning;level set;segmentation;ultrasound;uterus","Image segmentation;Level set;Shape;Thickness measurement;Three-dimensional displays;Training;Ultrasonic imaging","biomedical measurement;biomedical ultrasonics;cancer;image segmentation;learning (artificial intelligence);medical image processing;neural nets;support vector machines;thickness measurement","3D TVUS images;3D transvaginal ultrasound images;automated endometrium assessment;deep learned snake;deep neural networks;deep-learned endometrium probability map;endometrium cancer screening;endometrium thickness measurement;gynecological ultrasound examination;image segmentation;post-menopausal bleeding;supervised learning method;variational curve propagation model","","","","","","","","18-21 April 2017","","IEEE","IEEE Conference Publications"
"Ultrasound Standard Plane Detection Using a Composite Neural Network Framework","H. Chen; L. Wu; Q. Dou; J. Qin; S. Li; J. Z. Cheng; D. Ni; P. A. Heng","Department of Computer Science and Engineering, Chinese University of Hong Kong, Hong Kong","IEEE Transactions on Cybernetics","20170520","2017","47","6","1576","1586","Ultrasound (US) imaging is a widely used screening tool for obstetric examination and diagnosis. Accurate acquisition of fetal standard planes with key anatomical structures is very crucial for substantial biometric measurement and diagnosis. However, the standard plane acquisition is a labor-intensive task and requires operator equipped with a thorough knowledge of fetal anatomy. Therefore, automatic approaches are highly demanded in clinical practice to alleviate the workload and boost the examination efficiency. The automatic detection of standard planes from US videos remains a challenging problem due to the high intraclass and low interclass variations of standard planes, and the relatively low image quality. Unlike previous studies which were specifically designed for individual anatomical standard planes, respectively, we present a general framework for the automatic identification of different standard planes from US videos. Distinct from conventional way that devises hand-crafted visual features for detection, our framework explores in- and between-plane feature learning with a novel composite framework of the convolutional and recurrent neural networks. To further address the issue of limited training data, a multitask learning framework is implemented to exploit common knowledge across detection tasks of distinctive standard planes for the augmentation of feature learning. Extensive experiments have been conducted on hundreds of US fetus videos to corroborate the better efficacy of the proposed framework on the difficult standard plane detection problem.","2168-2267;21682267","","10.1109/TCYB.2017.2685080","National Basic Research Program of China, 973 Program; National Natural Science Foundation of China; Research Grants Council of Hong Kong Special Administrative Region; ","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7890445","Convolutional neural network (CNN);deep learning;knowledge transfer;recurrent neural network (RNN);standard plane;ultrasound (US)","Biomedical imaging;Feature extraction;Fetus;Machine learning;Standards;Training data;Videos","","","","","","","","","20170330","June 2017","","IEEE","IEEE Journals & Magazines"
"Standard Plane Localization in Fetal Ultrasound via Domain Transferred Deep Neural Networks","H. Chen; D. Ni; J. Qin; S. Li; X. Yang; T. Wang; P. A. Heng","Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong","IEEE Journal of Biomedical and Health Informatics","20170520","2015","19","5","1627","1636","Automatic localization of the standard plane containing complicated anatomical structures in ultrasound (US) videos remains a challenging problem. In this paper, we present a learning-based approach to locate the fetal abdominal standard plane (FASP) in US videos by constructing a domain transferred deep convolutional neural network (CNN). Compared with previous works based on low-level features, our approach is able to represent the complicated appearance of the FASP and hence achieve better classification performance. More importantly, in order to reduce the overfitting problem caused by the small amount of training samples, we propose a transfer learning strategy, which transfers the knowledge in the low layers of a base CNN trained from a large database of natural images to our task-specific CNN. Extensive experiments demonstrate that our approach outperforms the state-of-the-art method for the FASP localization as well as the CNN only trained on the limited US training samples. The proposed approach can be easily extended to other similar medical image computing problems, which often suffer from the insufficient training samples when exploiting the deep CNN to represent high-level features.","2168-2194;21682194","","10.1109/JBHI.2015.2425041","Hong Kong Innovation and Technology Fund; Research Grants Council of Hong Kong; Shenzhen Key Basic Research Project; Shenzhen-Hong Kong Innovation Circle Funding Program; 10.13039/501100001809 - National Natural Science Foundation of China; ","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7090943","Convolutional neural network (CNN);Ultrasound;convolutional neural network;deep learning;domain transfer;knowledge transfer;standard plane;ultrasound (US)","Biomedical imaging;Dictionaries;Feature extraction;Informatics;Standards;Training;Videos","biomedical ultrasonics;image classification;learning (artificial intelligence);medical image processing;neural nets;object detection;obstetrics","FASP localization;US videos;automatic standard plane localization;classification performance;domain transferred deep convolutional neural network;fetal abdominal standard plane;fetal ultrasound;high-level features;learning-based approach;low-level features;medical image computing problems;natural images;overfitting problem;task-specific CNN;transfer learning strategy;ultrasound videos","0;Abdomen;Female;Fetus;Humans;Image Processing, Computer-Assisted;Neural Networks (Computer);Pregnancy;ROC Curve;Ultrasonography, Prenatal","32","","37","","","20150421","Sept. 2015","","IEEE","IEEE Journals & Magazines"
"The chatbot feels you - a counseling service using emotional response generation","Dongkeon Lee; Kyo-Joong Oh; Ho-Jin Choi","School of Computing, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, Korea","2017 IEEE International Conference on Big Data and Smart Computing (BigComp)","20170320","2017","","","437","440","Early study tries to use chatbot for counseling services. They changed drinking habit of who being consulted by leading them via intervene chatbot. However, the application did not concerned about psychiatric status through continuous conversation with user monitoring. Furthermore, they had no ethical judgment method that about the intervention of the chatbot. We argue that more reasonable and continuous emotion recognition will make better mental healthcare experiment. It will be more proper clinical psychiatric consolation in ethical view as well. This paper suggests a introduce a novel chatbot system for psychiatric counseling service. Our system understands content of conversation based on recent natural language processing (NLP) methods with emotion recognition. It senses emotional flow through the continuous observation of conversation. Also, we generate personalized counseling response from user input, to do this, we use additional constrains to generation model for the proper response generation which can detect conversational context, user emotion and expected reaction.","","Electronic:978-1-5090-3015-6; POD:978-1-5090-3016-3; USB:978-1-5090-3014-9","10.1109/BIGCOMP.2017.7881752","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7881752","conversational service;deep learning;response generation","Context;Data models;Emotion recognition;Employee welfare;Medical services;Natural language processing;Probabilistic logic","emotion recognition;ethical aspects;health care;natural language processing;psychology","NLP;clinical psychiatric consolation;continuous conversation observation;continuous emotion recognition;conversation content;drinking habit;emotional flow;emotional response generation;ethical view;expected reaction;intervene chatbot;mental healthcare experiment;natural language processing;personalized counseling response;psychiatric counseling service;user emotion;user input","","","","","","","","13-16 Feb. 2017","","IEEE","IEEE Conference Publications"
"Clinical named entity recognition: Challenges and opportunities","S. R. Kundeti; J. Vijayananda; S. Mujjiga; M. Kalyan","Data Science, Philips Healthcare, Bangalore, India","2016 IEEE International Conference on Big Data (Big Data)","20170206","2016","","","1937","1945","Information Extraction (IE), one of the important tasks in text analysis and Natural Language Processing (NLP), involves extracting meaningful pieces of knowledge from unstructured information sources, as unstructured data is computationally opaque. The intent of IE is to produce a knowledge base i.e. organize the information in a way that it is useful to people and arrange the information in a semantic way so that algorithms can make certain useful inferences from it. Named Entity Recognition (NER) is a sub-task of IE which finds and classifies the names/entities. Once these Named Entities (NE) are extracted, they can then be indexed and made searchable, relations can be derived, questions can be answered and many more. NER techniques are different for different domains, because of the uniqueness that exists in each of the domains, although the process depends on a number of fundamental Natural Language Processing (NLP) steps such as tokenization, part-of-speech tagging, parsing and model building. As an example, NER in the medical domain involves handling of a number of vital tasks such as identification of medical terms, attributes such as negation, severity, identification of relationships between entities and mapping terms in the document to concepts in domain specific ontologies. There is also a heavy dependence on domain specific resources such as medical dictionaries and ontologies such as the Unified Medical Language System (UMLS)[34]. In this paper, we focus on NER in the clinical domain. In particular, we will focus on the NER challenges and the qualitative analysis of clinical reports on the approaches we took for the named entities: anatomies, findings, location qualifier, and procedures.","","Electronic:978-1-4673-9005-7; POD:978-1-4673-9006-4","10.1109/BigData.2016.7840814","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7840814","Deep Learning;Language Modelling;Long short-term memory;Machine Learning;Natural Language Processing;Ontologies;Text Analytics","Data mining;Dictionaries;Medical diagnostic imaging;Medical services;Ontologies;Unified modeling language","knowledge acquisition;learning (artificial intelligence);medical computing;natural language processing;ontologies (artificial intelligence);pattern classification;text analysis","IE;NER techniques;NLP;UMLS;clinical named entity recognition;domain specific ontology;entity classification;information extraction;knowledge extraction;machine learning;medical domain;medical term identification;name classification;natural language processing;term mapping;text analysis;unified medical language system;unstructured data;unstructured information sources","","","","","","","","5-8 Dec. 2016","","IEEE","IEEE Conference Publications"
"Model Accuracy and Runtime Tradeoff in Distributed Deep Learning: A Systematic Study","S. Gupta; W. Zhang; F. Wang","IBM T. J. Watson Res. Center, Yorktown Heights, NY, USA","2016 IEEE 16th International Conference on Data Mining (ICDM)","20170202","2016","","","171","180","Deep learning with a large number of parameters requires distributed training, where model accuracy and runtime are two important factors to be considered. However, there has been no systematic study of the tradeoff between these two factors during the model training process. This paper presents Rudra, a parameter server based distributed computing framework tuned for training large-scale deep neural networks. Using variants of the asynchronous stochastic gradient descent algorithm we study the impact of synchronization protocol, stale gradient updates, mini batch size, learning rates, and number of learners on run time performance and model accuracy. We introduce a new learning rate modulation strategy to counter the effect of stale gradients and propose a new synchronization protocol that can effectively bound the staleness in gradients, improve runtime performance and achieve good model accuracy. Our empirical investigation reveals a principled approach for distributed training of neural networks: the mini-batch size per learner should be reduced as more learners are added to the system to preserve the model accuracy. We validate this approach using commonly-used image classification benchmarks: CIFAR10 and ImageNet.","","Electronic:978-1-5090-5473-2; POD:978-1-5090-5474-9","10.1109/ICDM.2016.0028","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7837841","","Computational modeling;Mathematical model;Neural networks;Protocols;Servers;Synchronization;Training","gradient methods;image classification;learning (artificial intelligence);neural nets","CIFAR10;ImageNet;Rudra;asynchronous stochastic gradient descent algorithm;commonly-used image classification benchmarks;distributed deep learning;distributed neural network training;distributed training;large-scale deep neural networks;learning rate modulation strategy;learning rates;mini batch size;mini-batch size per learner;model accuracy;model training process;parameter server based distributed computing framework;runtime tradeoff;stale gradient updates;stale gradients;synchronization protocol","","","","","","","","12-15 Dec. 2016","","IEEE","IEEE Conference Publications"
"Feature Fusion for Denoising and Sparse Autoencoders: Application to Neuroimaging Data","A. Moussavi-Khalkhali; M. Jamshidi; S. Wijemanne","Dept. of Electr. & Comput. Eng., Univ. of Texas at San Antonio, San Antonio, TX, USA","2016 15th IEEE International Conference on Machine Learning and Applications (ICMLA)","20170202","2016","","","605","610","Although there is no cure to date, Alzheimer's disease detection in early stages has a significant impact on the patient's life in terms of cost, the progress, and helping to plan in advance for an appropriate healthcare in the life ahead as well as providing clinical etiologies for further research. This paper discusses implementing a feature fusion method utilizing sparse and denoising autoencoders to reveal the stage of Alzheimer's disease. Four cohorts consisted of individuals with Alzheimer's disease, late mild cognitive impairment, early mild cognitive impairment, and normal control groups are classified using multinomial logistic regression fueled by the fusion of high-level and low-level features. The high-level features are extracted from the stacked autoencoders. The results show that feature fusion enhance the performance of typical autoencoders. However, the performance of feature fusion using denoising autoencoders is superior to that of the sparse training of autoencoders in terms of overall accuracy, precision, and recall.","","Electronic:978-1-5090-6167-9; POD:978-1-5090-6168-6","10.1109/ICMLA.2016.0106","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7838210","Alzheimer's disease stage detection;deep learning;feature fusion;sacked sparse autoencoders;stacked denoising autoencoders","Alzheimer's disease;Classification algorithms;Feature extraction;Magnetic resonance imaging;Noise reduction;Training","diseases;feature extraction;image coding;image denoising;image fusion;medical image processing;neurophysiology;regression analysis","Alzheimer disease detection;clinical etiologies;denoising autoencoders;feature fusion method;high-level features;low-level features;mild cognitive impairment;multinomial logistic regression;neuroimaging data;normal control groups;sparse autoencoder training;stacked autoencoders","","","","","","","","18-20 Dec. 2016","","IEEE","IEEE Conference Publications"
"Measuring Patient Similarities via a Deep Architecture with Medical Concept Embedding","Z. Zhu; C. Yin; B. Qian; Y. Cheng; J. Wei; F. Wang","Xi'an Jiaotong Univ., Xi'an, China","2016 IEEE 16th International Conference on Data Mining (ICDM)","20170202","2016","","","749","758","Evaluating the clinical similarities between pairwise patients is a fundamental problem in healthcare informatics. Aproper patient similarity measure enables various downstream applications, such as cohort study and treatment comparative effectiveness research. One major carrier for conducting patient similarity research is the Electronic Health Records(EHRs), which are usually heterogeneous, longitudinal, and sparse. Though existing studies on learning patient similarity from EHRs have shown being useful in solving real clinical problems, their applicability is limited due to the lack of medical interpretations. Moreover, most previous methods assume a vector based representation for patients, which typically requires aggregation of medical events over a certain time period. As aconsequence, the temporal information will be lost. In this paper, we propose a patient similarity evaluation framework based on temporal matching of longitudinal patient EHRs. Two efficient methods are presented, unsupervised and supervised, both of which preserve the temporal properties in EHRs. The supervised scheme takes a convolutional neural network architecture, and learns an optimal representation of patient clinical records with medical concept embedding. The empirical results on real-world clinical data demonstrate substantial improvement over the baselines.","","Electronic:978-1-5090-5473-2; POD:978-1-5090-5474-9","10.1109/ICDM.2016.0086","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7837899","Deep Matching;Medical Concept Embedding;Patient Similarity","Context;Diseases;Medical diagnostic imaging;Natural language processing;Neural networks","electronic health records;health care;patient care;pattern matching;unsupervised learning","EHR;clinical similarities;convolutional neural network architecture;deep architecture;electronic health records;healthcare informatics;medical concept embedding;medical interpretations;patient similarity evaluation;patient similarity measurement;patient similarity research;real-world clinical data;temporal longitudinal patient EHR matching;vector based representation","","","","","","","","12-15 Dec. 2016","","IEEE","IEEE Conference Publications"
"Deep Decision Network for Multi-class Image Classification","V. N. Murthy; V. Singh; T. Chen; R. Manmatha; D. Comaniciu","Sch. of Comput. Sci., Univ. of Massachusetts, Amherst, MA, USA","2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)","20161212","2016","","","2240","2248","In this paper, we present a novel Deep Decision Network (DDN) that provides an alternative approach towards building an efficient deep learning network. During the learning phase, starting from the root network node, DDN automatically builds a network that splits the data into disjoint clusters of classes which would be handled by the subsequent expert networks. This results in a tree-like structured network driven by the data. The proposed method provides an insight into the data by identifying the group of classes that are hard to classify and require more attention when compared to others. DDN also has the ability to make early decisions thus making it suitable for timesensitive applications. We validate DDN on two publicly available benchmark datasets: CIFAR-10 and CIFAR-100 and it yields state-of-the-art classification performance on both the datasets. The proposed algorithm has no limitations to be applied to any generic classification problems.","","Electronic:978-1-4673-8851-1; POD:978-1-4673-8852-8","10.1109/CVPR.2016.246","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7780615","","Airplanes;Covariance matrices;Decision trees;Machine learning;Symmetric matrices;Training;Vegetation","image classification;learning (artificial intelligence);trees (mathematics)","CIFAR-100;DDN;deep decision network;deep learning network;multiclass image classification;tree-like structured network","","","","","","","","27-30 June 2016","","IEEE","IEEE Conference Publications"
"Predicting Seizures from Electroencephalography Recordings: A Knowledge Transfer Strategy","J. Liang; R. Lu; C. Zhang; F. Wang","Dept. of Autom., Tsinghua Univ., Beijing, China","2016 IEEE International Conference on Healthcare Informatics (ICHI)","20161208","2016","","","184","191","Epilepsy, a brain disorder afflicts nearly 1% of the world's population, is characterized by the occurrence of spontaneous seizures. For most epilepsy patients, the drugs are either not effective or produce severe side-effects. Seizure forecasting systems have the potential to help patients with epilepsy lead more normal lives. Recently multi-center clinical studies showed evidence of premonitory symptoms in 6.2% of 500 patients with epilepsy, and some interviews of epilepsy patients also found that a certain amount of patients felt ""auras"". All these are promising signs suggesting that seizure might be predictable. In this paper, we will study the application of deep learning techniques for seizure prediction with EEG signals. Deep learning methods have been shown to be very effective on exploring the latent structures from continuous signals and they have achieved state-of-the-art performance on speech analysis. One potential requirement for deep learning algorithms to work is a huge training set, which could be difficult for a specific medical problem. Therefore we specifically investigated a transfer learning strategy: we performed the major seizure prediction task on the data from American Epilepsy Society Seizure Prediction Challenge1, and we adopted another 6 publicly available EEG datasets2, which are not directly related to seizure prediction, as auxiliary information to pre-train the deep neural network for getting a good initial point. Our results show that with those auxiliary information, the prediction performance can be boosted. This observation is validated with different predictive models, which opens another gate for effective integration and utilization of medical data resources.","","Electronic:978-1-5090-6117-4; POD:978-1-5090-6118-1","10.1109/ICHI.2016.27","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7776343","","Brain models;Electroencephalography;Epilepsy;Feature extraction;Machine learning;Training","brain;electroencephalography;knowledge management;learning (artificial intelligence);medical disorders;medical signal processing;neural nets","American Epilepsy Society Seizure Prediction Challenge;EEG datasets;EEG signals;brain disorder;deep learning techniques;deep neural network pretraining;electroencephalography recordings;epilepsy patients;knowledge transfer strategy;medical data resource utilization;seizure prediction;speech analysis;spontaneous seizures;transfer learning strategy","","","","","","","","4-7 Oct. 2016","","IEEE","IEEE Conference Publications"
"Fetal facial standard plane recognition via very deep convolutional networks","Z. Yu; D. Ni; S. Chen; S. Li; T. Wang; B. Lei","School of Biomedical Engineering, Shenzhen University, National-Regional Key Technology Engineering Laboratory for Medical Ultrasound, Guangdong Key Laboratory for Biomedical Measurements and Ultrasound Imaging, Shenzhen, China","2016 38th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)","20161018","2016","","","627","630","The accurate recognition of fetal facial standard plane (FFSP) (i.e., axial, coronal and sagittal plane) from ultrasound (US) images is quite essential for routine US examination. Since the labor-intensive and subjective measurement is too time-consuming and unreliable, the development of the automatic FFSP recognition method is highly desirable. Different from the previous methods, we leverage a general framework to recognize the FFSP from US images automatically. Specifically, instead of using the previous hand-crafted visual features, we utilize the recent developed deep learning approach via very deep convolutional networks (DCNN) architecture to represent fine-grained details of US image. Also, very small (3×3) convolution filters are adopted to improve the performance. The evaluation of our FFSP dataset shows the superiority of our method over the previous studies and achieves the state-of-the-art FFSP recognition results.","1557-170X;1557170X","Electronic:978-1-4577-0220-4; POD:978-1-4577-0219-8","10.1109/EMBC.2016.7590780","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7590780","","Computer architecture;Convolution;Image recognition;Imaging;Standards;Training;Ultrasonic imaging","biomedical ultrasonics;face recognition;learning (artificial intelligence);medical image processing;neural nets;obstetrics","DCNN;FFSP dataset;US examination;automatic FFSP recognition method;convolution filters;deep learning approach;fetal facial standard plane recognition;hand-crafted visual features;ultrasound images;very deep convolutional networks","","","","","","","","16-20 Aug. 2016","","IEEE","IEEE Conference Publications"
"Learning a multiscale patch-based representation for image denoising in X-RAY fluoroscopy","Y. Matviychuk; B. Mailhé; X. Chen; Q. Wang; A. Kiraly; N. Strobel; M. Nadar","Siemens Healthcare, Medical Imaging Technologies, Princeton, NJ, USA","2016 IEEE International Conference on Image Processing (ICIP)","20160819","2016","","","2330","2334","Denoising is an indispensable step in processing low-dose X-ray fluoroscopic images that requires development of specialized high-quality algorithms able to operate in near real-time. We address this problem with an efficient deep learning approach based on the process-centric view of traditional iterative thresholding methods. We develop a novel trainable patch-based multiscale framework for sparse image representation. In a computationally efficient way, it allows us to accurately reconstruct important image features on multiple levels of decomposition with patch dictionaries of reduced size and complexity. The flexibility of the chosen machine learning approach allows us to tailor the learned basis for preserving important structural information in the image and noticeably minimize the amount of artifacts. Our denoising results obtained with real clinical data demonstrate significant quality improvement and are computed much faster in comparison with the BM3D algorithm.","","Electronic:978-1-4673-9961-6; POD:978-1-4673-9962-3","10.1109/ICIP.2016.7532775","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7532775","Radiography;iterative algorithms;neural networks","Approximation algorithms;Dictionaries;Image reconstruction;Image representation;Iterative methods;Neural networks;Noise reduction","diagnostic radiography;feature extraction;image denoising;image reconstruction;image representation;image segmentation;iterative methods;learning (artificial intelligence);medical image processing","BM3D algorithm;X-ray fluoroscopy;artifact minimization;clinical data;complexity;deep learning approach;image decomposition;image denoising;image feature reconstruction;iterative thresholding method;low-dose X-ray fluoroscopic image;machine learning;multiscale patch-based representation learning;patch dictionary;sparse image representation;structural information preservation;trainable patch-based multiscale framework","","1","","38","","","","25-28 Sept. 2016","","IEEE","IEEE Conference Publications"
"Real-time 2D/3D registration via CNN regression","S. Miao; Z. J. Wang; Y. Zheng; R. Liao","Electrical and Computer Engineering, University of British Columbia, Canada","2016 IEEE 13th International Symposium on Biomedical Imaging (ISBI)","20160616","2016","","","1430","1434","In this paper, we present a Convolutional Neural Network (CNN) regression approach for real-time 2-D/3-D registration. Different from optimization-based methods, which iteratively optimize the transformation parameters over a scalar-valued metric function representing the quality of the registration, the proposed method exploits the information embedded in the appearances of the Digitally Reconstructed Radiograph and X-ray images, and employs CNN regressors to directly estimate the transformation parameters. The CNN regressors are trained for local zones and applied in a hierarchical manner to break down the complex regression task into simpler sub-tasks that can be learned separately. Our experiment results demonstrate the advantage of the proposed method in computational efficiency with negligible degradation of registration accuracy compared to intensity-based methods.","","Electronic:978-1-4799-2349-6; POD:978-1-4799-2351-9","10.1109/ISBI.2016.7493536","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7493536","2-D/3-D Registration;Convolutional Neural Network;Deep Learning;Image Guided Intervention","Biomedical imaging;Feature extraction;Neural networks;Real-time systems;Solid modeling;Training;X-ray imaging","","","","","","18","","","","13-16 April 2016","","IEEE","IEEE Conference Publications"
"Marginal Space Deep Learning: Efficient Architecture for Volumetric Image Parsing","F. C. Ghesu; E. Krubasik; B. Georgescu; V. Singh; Y. Zheng; J. Hornegger; D. Comaniciu","Medical Imaging Technologies, Siemens Healthcare, Princeton, NJ, USA","IEEE Transactions on Medical Imaging","20160429","2016","35","5","1217","1228","Robust and fast solutions for anatomical object detection and segmentation support the entire clinical workflow from diagnosis, patient stratification, therapy planning, intervention and follow-up. Current state-of-the-art techniques for parsing volumetric medical image data are typically based on machine learning methods that exploit large annotated image databases. Two main challenges need to be addressed, these are the efficiency in scanning high-dimensional parametric spaces and the need for representative image features which require significant efforts of manual engineering. We propose a pipeline for object detection and segmentation in the context of volumetric image parsing, solving a two-step learning problem: anatomical pose estimation and boundary delineation. For this task we introduce Marginal Space Deep Learning (MSDL), a novel framework exploiting both the strengths of efficient object parametrization in hierarchical marginal spaces and the automated feature design of Deep Learning (DL) network architectures. In the 3D context, the application of deep learning systems is limited by the very high complexity of the parametrization. More specifically 9 parameters are necessary to describe a restricted affine transformation in 3D, resulting in a prohibitive amount of billions of scanning hypotheses. The mechanism of marginal space learning provides excellent run-time performance by learning classifiers in clustered, high-probability regions in spaces of gradually increasing dimensionality. To further increase computational efficiency and robustness, in our system we learn sparse adaptive data sampling patterns that automatically capture the structure of the input. Given the object localization, we propose a DL-based active shape model to estimate the non-rigid object boundary. Experimental results are presented on the aortic valve in ultrasound using an extensive dataset of 2891 volumes from 869 patients, showing significant improvements of up to 45.2% o- er the state-of-the-art. To our knowledge, this is the first successful demonstration of the DL potential to detection and segmentation in full 3D data with parametrized representations.","0278-0062;02780062","","10.1109/TMI.2016.2538802","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7426845","Deep learning;image parsing;marginal space learning;sparse representations;three-dimensional (3D) object detection and segmentation","Context;Feature extraction;Image segmentation;Machine learning;Robustness;Shape;Three-dimensional displays","biomedical ultrasonics;feature extraction;image classification;image sampling;image segmentation;learning (artificial intelligence);medical image processing;pattern clustering;probability;ultrasonic imaging","3D context;DL-based active shape model;anatomical object detection;anatomical pose estimation;annotated image databases;aortic valve;automated feature design;boundary delineation;clinical workflow;clustered high-probability regions;computational efficiency;deep learning network architectures;deep learning systems;diagnosis;extensive dataset;full 3D data detection;full 3D data segmentation;hierarchical marginal spaces;learning classifiers;machine learning methods;marginal space deep learning;nonrigid object boundary;object localization;object parametrization;parametrized representations;patient stratification;representative image features;restricted affine transformation;run-time performance;scanning high-dimensional parametric spaces;scanning hypotheses;segmentation support;sparse adaptive data sampling patterns;therapy planning;two-step learning problem;ultrasound;volumetric medical image data parsing","","9","","46","","","20160307","May 2016","","IEEE","IEEE Journals & Magazines"
"Multi-Instance Deep Learning: Discover Discriminative Local Anatomies for Bodypart Recognition","Z. Yan; Y. Zhan; Z. Peng; S. Liao; Y. Shinagawa; S. Zhang; D. N. Metaxas; X. S. Zhou","Department of Computer Science, Rutgers University, Piscataway, NJ, USA","IEEE Transactions on Medical Imaging","20160429","2016","35","5","1332","1343","In general image recognition problems, discriminative information often lies in local image patches. For example, most human identity information exists in the image patches containing human faces. The same situation stays in medical images as well. “Bodypart identity” of a transversal slice-which bodypart the slice comes from-is often indicated by local image information, e.g., a cardiac slice and an aorta arch slice are only differentiated by the mediastinum region. In this work, we design a multi-stage deep learning framework for image classification and apply it on bodypart recognition. Specifically, the proposed framework aims at: 1) discover the local regions that are discriminative and non-informative to the image classification problem, and 2) learn a image-level classifier based on these local regions. We achieve these two tasks by the two stages of learning scheme, respectively. In the pre-train stage, a convolutional neural network (CNN) is learned in a multi-instance learning fashion to extract the most discriminative and and non-informative local patches from the training slices. In the boosting stage, the pre-learned CNN is further boosted by these local patches for image classification. The CNN learned by exploiting the discriminative local appearances becomes more accurate than those learned from global image context. The key hallmark of our method is that it automatically discovers the discriminative and non-informative local patches through multi-instance deep learning. Thus, no manual annotation is required. Our method is validated on a synthetic dataset and a large scale CT dataset. It achieves better performances than state-of-the-art approaches, including the standard deep CNN.","0278-0062;02780062","","10.1109/TMI.2016.2524985","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7398101","CNN;discriminative local information discovery;multi-instance;multi-stage","Algorithm design and analysis;DICOM;Image analysis;Image recognition;Machine learning;Three-dimensional displays","cardiology;computerised tomography;face recognition;image classification;learning (artificial intelligence);medical image processing","aorta arch slice;body-part recognition;cardiac slice;convolutional neural network;discriminative information;discriminative local anatomies;discriminative local appearances;global image context;human faces;human identity information;image classification problem;image recognition problems;image-level classifier;large scale CT dataset;local image information;local image patches;mediastinum region;multiinstance deep learning;multiinstance learning fashion;multistage deep learning framework;prelearned CNN;pretrain stage;synthetic dataset;transversal slice","","10","","51","","","20160203","May 2016","","IEEE","IEEE Journals & Magazines"
"A CNN Regression Approach for Real-Time 2D/3D Registration","S. Miao; Z. J. Wang; R. Liao","Department of Electrical and Computer Engineering, University of British Columbia, Vancouver","IEEE Transactions on Medical Imaging","20160429","2016","35","5","1352","1363","In this paper, we present a Convolutional Neural Network (CNN) regression approach to address the two major limitations of existing intensity-based 2-D/3-D registration technology: 1) slow computation and 2) small capture range. Different from optimization-based methods, which iteratively optimize the transformation parameters over a scalar-valued metric function representing the quality of the registration, the proposed method exploits the information embedded in the appearances of the digitally reconstructed radiograph and X-ray images, and employs CNN regressors to directly estimate the transformation parameters. An automatic feature extraction step is introduced to calculate 3-D pose-indexed features that are sensitive to the variables to be regressed while robust to other factors. The CNN regressors are then trained for local zones and applied in a hierarchical manner to break down the complex regression task into multiple simpler sub-tasks that can be learned separately. Weight sharing is furthermore employed in the CNN regression model to reduce the memory footprint. The proposed approach has been quantitatively evaluated on 3 potential clinical applications, demonstrating its significant advantage in providing highly accurate real-time 2-D/3-D registration with a significantly enlarged capture range when compared to intensity-based methods.","0278-0062;02780062","","10.1109/TMI.2016.2521800","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7393571","2-D/3-D registration;convolutional neural network;deep learning;image guided intervention","Attenuation;Biomedical imaging;Computed tomography;Feature extraction;Real-time systems;X-ray imaging","diagnostic radiography;feature extraction;image reconstruction;image registration;iterative methods;medical image processing;neural nets;optimisation;regression analysis","3D pose-indexed features;CNN regression approach;CNN regressors;X-ray images;automatic feature extraction step;complex regression task;convolutional neural network regression approach;digitally reconstructed radiograph;formation parameters;intensity-based 2D-3D registration technology;intensity-based methods;iterative optimization;memory footprint;multiple simpler subtasks;optimization-based methods;real-time 2D-3D registration;scalar-valued metric function;transformation parameters","","4","","31","","","20160126","May 2016","","IEEE","IEEE Journals & Magazines"
"Temporal Pattern and Association Discovery of Diagnosis Codes Using Deep Learning","S. Mehrabi; S. Sohn; D. Li; J. J. Pankratz; T. Therneau; J. L. S. Sauver; H. Liu; M. Palakal","Dept. of Health Sci. Res., Mayo Clinic, Rochester, MN, USA","2015 International Conference on Healthcare Informatics","20151210","2015","","","408","416","Longitudinal health records contain data on patients' visits, condition, treatment, and test results representing progression of their health status over time. In poorly understood patient populations, such data are particularly helpful in characterizing disease progression and early detection. In this work we developed a deep learning algorithm for temporal pattern discovery over Rochester Epidemiology Project data. We modeled each patient's records as a matrix of temporal clinical events with ICD9 and HCUP CSS diagnosis codes as rows and years of diagnosis as columns. Patients aged 18 or younger at the time of diagnosis were selected. A deep Boltzmann machine network with three hidden layers was constructed with each patient's diagnosis matrix values as visible nodes. The final weights of the network model were analyzed as the common features among patients' records.","","Electronic:978-1-4673-9548-9; POD:978-1-4673-9549-6","10.1109/ICHI.2015.58","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7349719","Deep Learning;Rochester Epidemiology Project;Temporal Pattern Discovery","Cascading style sheets;Diseases;Machine learning;Medical diagnostic imaging;Sociology;Statistics","Boltzmann machines;data mining;electronic health records;learning (artificial intelligence);matrix algebra;patient diagnosis","HCUP CSS diagnosis;ICD9 diagnosis code;Rochester Epidemiology Project data;deep Boltzmann machine network;deep learning;deep learning algorithm;disease progression;longitudinal health record;patient diagnosis matrix value;temporal association discovery;temporal pattern discovery","","4","","45","","","","21-23 Oct. 2015","","IEEE","IEEE Conference Publications"
"Automation for individualization of Kinect-based quantitative progressive exercise regimen","S. k. Jun; S. Kumar; X. Zhou; D. K. Ramsey; V. N. Krovi","MAE Dept., SUNY Buffalo, Buffalo, NY, USA","2013 IEEE International Conference on Automation Science and Engineering (CASE)","20131107","2013","","","243","248","The Smart Health paradigm has opened up immense possibilities for designing cyber-physical systems with integrated sensing and analysis for data-driven healthcare decision-making. Clinical motor-rehabilitation has traditionally tended to entail labor-intensive approaches with limited quantitative methods and numerous logistics deployment challenges. We believe such labor-intensive rehabilitation procedures offer a fertile application field for robotics and automation technologies. We seek to concretize this Smart Health paradigm in the context of alleviating knee osteoarthritis (OA). Our long-term goal is the creation, analysis and validation of a low-cost cyber-physical framework for individualized but quantitative motor-rehabilitation. We seek build upon parameterized exercise-protocols, low-cost data-acquisition capabilities of the Kinect sensor and appropriate statistical data-processing to aid individualized-assessment and close the quantitative feedback-loop. Specifically, in this paper, we focus our attention on quantitative evaluation of a clinically-relevant deep-squatting exercise. Data for multiple trials with multiple of squatting motions were captured by Kinect system and examined to aid our individualization goals. Principal Component Analysis (PCA) approaches facilitated both dimension-reduction and filtering of the noisy-data while the K-Nearest Neighbors (K-NN) method was adapted for subject classification. Our preliminary deployment of this approach with 5 subjects achieved 95.6% classification accuracy.","2161-8070;21618070","Electronic:978-1-4799-1515-6; POD:978-1-4799-1513-2; USB:978-1-4799-1514-9","10.1109/CoASE.2013.6654038","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6654038","Human identification;Kinect;Nearest neighbors;PCA","Accuracy;Hip;Joints;Knee;Medical treatment;Monitoring;Principal component analysis","image sensors;learning (artificial intelligence);medical computing;patient rehabilitation;pattern classification;principal component analysis","K-NN method;Kinect sensor;Kinect-based quantitative progressive exercise regimen;PCA;automation technologies;classification accuracy;clinical motor-rehabilitation;clinically-relevant deep-squatting exercise;cyber-physical systems design;data-driven health care decision-making;dimension reduction;k-nearest neighbor method;knee osteoarthritis;labor-intensive rehabilitation procedures;low-cost cyber-physical framework;noisy-data filtering;principal component analysis;quantitative feedback-loop;quantitative motor-rehabilitation;robotics;smart health paradigm;squatting motions;statistical data-processing;subject classification","","2","","25","","","","17-20 Aug. 2013","","IEEE","IEEE Conference Publications"
"Knowledge-based classification of CZCS images and monitoring of red tides off the west Florida shelf","Mingrui Zhang; L. O. Hall; D. B. Goldgof","Dept. of Comput. Sci. & Eng., Univ. of South Florida, Tampa, FL, USA","Proceedings of 13th International Conference on Pattern Recognition","20020806","1996","2","","452","456 vol.2","Red tides on the west Florida shelf have significant economic and public health effects. Tracking the phytoplankton bloom, known as red tide, is important to understanding the phenomena. In this paper, a knowledge-based approach to automatic classification of Coastal Zone Color Scanner satellite images is developed. The Coastal Zone Color Scanner or CZCS images are initially segmented by the unsupervised mr-FCM algorithm then an expert system utilizes rules, and an iterative clustering process, to recognize case I (deep) water, case II (shallow) water and red tide by searching for expected features. The results show that this system is effective in recognizing images with red tide and segmenting the red tide","1051-4651;10514651","POD:0-8186-7282-X","10.1109/ICPR.1996.546866","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=546866","","Clustering algorithms;Color;Image recognition;Image segmentation;Iterative algorithms;Monitoring;Public healthcare;Satellites;Sea measurements;Tides","computerised monitoring;environmental science computing;expert systems;geophysics computing;image classification;image colour analysis;image segmentation;oceanography;tides;unsupervised learning","CZCS images;Coastal Zone Color Scanner satellite images;deep water;economic effects;expert system;image recognition;image segmentation;iterative clustering process;knowledge-based image classification;phytoplankton bloom tracking;public health effects;red tide monitoring;rules;shallow water;unsupervised mr-FCM algorithm;west Florida shelf","","3","","12","","","","25-29 Aug 1996","25 Aug 1996-29 Aug 1996","IEEE","IEEE Conference Publications"
"Reports on CBMI 16 and ICME 16","B. Ionescu; H. Müller; Y. Kompatsiaris; G. Gravier; A. Vetro","University Politehnica of Bucharest","IEEE MultiMedia","20161114","2016","23","4","88","93","This issue features not just one but two conference reports. The first covers the 14th International Workshop on Content-Based Multimedia Indexing (CBMI 16), while the second covers the 2016 IEEE International Conference on Multimedia and Expo (ICME 2016). For both, find out what hot topics and key themes were discussed, which submissions earned the Best Paper awards, and more.","1070-986X;1070986X","","10.1109/MMUL.2016.56","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7742776","CBMI;ICME;big data;content-based processing;deep learning;e-learning;graphics;healthcare;multimedia;multimedia indexing;multimedia retrieval;virtualization;visualization","","","","","","","","","","","Oct.-Dec. 2016","","IEEE","IEEE Journals & Magazines"
