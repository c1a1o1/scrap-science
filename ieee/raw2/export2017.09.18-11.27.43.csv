"http://ieeexplore.ieee.org/search/searchresult.jsp?bulkSetSize=2000&queryText%3Ddeep+learning+fundus",2017/09/18 11:27:43
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","License","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"Advanced deep learning for blood vessel segmentation in retinal fundus images","Lua Ngo; Jae-Ho Han","Dept. Brain and Cognitive Engineering, Korea University, Seoul, South Korea","2017 5th International Winter Conference on Brain-Computer Interface (BCI)","20170220","2017","","","91","92","Rising of deep learning methodologies draws huge attention to their application in image processing and classification. Catching up the trends, this study briefly presents state-of-the-art of deep learning applications in medical imaging interfered with achievements of blood vessel segmentation methods in neurosensory retinal fundus images. Successful segmentation based on deep learning offers advantage in diagnosing ophthalmological disease or pathology.","","Electronic:978-1-5090-5096-3; POD:978-1-5090-5097-0","10.1109/IWW-BCI.2017.7858169","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7858169","Biomedical optical imaging;blood vessels;fundus images;image segmentation;medical image processing","","blood vessels;image segmentation;learning (artificial intelligence);medical image processing","advanced deep learning methodologies;blood vessel segmentation methods;image classification;image processing;ophthalmological disease;pathology;retinal fundus images","","","","","","","","9-11 Jan. 2017","","IEEE","IEEE Conference Publications"
"A Deep Learning Method for Microaneurysm Detection in Fundus Images","J. Shan; L. Li","Dept. of Comput. Sci., Pace Univ. New York City, New York, NY, USA","2016 IEEE First International Conference on Connected Health: Applications, Systems and Engineering Technologies (CHASE)","20160818","2016","","","357","358","Diabetic Retinopathy (DR) is the leading cause of blindness in the working-age population. Microaneurysms (MAs), due to leakage from retina blood vessels, are the early signs of DR. However, automated MA detection is complicated because of the small size of MA lesions and the low contrast between the lesion and its retinal background. Recently deep learning (DL) strategies have been used for automatic feature extraction and classification problems, especially for image analysis. In this paper, a Stacked Sparse Autoencoder (SSAE), an instance of a DL strategy, is presented for MA detection in fundus images. Small image patches are generated from the original fundus images. The SSAE learns high-level features from pixel intensities alone in order to identify distinguishing features of MA. The high-level features learned by SSAE are fed into a classifier to categorize each image patch as MA or non-MA. The public benchmark DIARETDB is utilized to provide the training/testing data and ground truth. Among the 89 images, totally 2182 image patches with MA lesions, serve as positive data, and another 6230 image patches without MA lesions are generated by a randomly sliding window operation, to serve as negative data. Without any blood vessel removal or complicated preprocessing operations, SSAE learned directly from the raw image patches, and automatically extracted the distinguishing features to classify the patches using Softmax Classifier. By employing the fine-tuning operation, an improved F-measure 91.3% and an average area under the ROC curve (AUC) 96.2% were achieved using 10-fold cross-validation.","","Electronic:978-1-5090-0943-5; POD:978-1-5090-0944-2","10.1109/CHASE.2016.12","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7545864","automated microaneurysm detection;deep learning;diabetic retinopathy;feature representation;stacked sparse autoencoder","Biomedical image processing;Conferences;Feature extraction;Lesions;Machine learning","blood vessels;diseases;feature extraction;image classification;learning (artificial intelligence);medical image processing","10-fold cross-validation;DIARETDB public benchmark;DR;F-measure;SSAE;automated MA detection;automatic feature extraction;blindness;classification problems;deep learning method;diabetic retinopathy;fine-tuning operation;fundus images;image analysis;microaneurysm detection;microaneurysms;randomly sliding window operation;retina blood vessels;softmax classifier;stacked sparse autoencoder;working-age population","","1","","","","","","27-29 June 2016","","IEEE","IEEE Conference Publications"
"Deep neural network and random forest hybrid architecture for learning to detect retinal vessels in fundus images","D. Maji; A. Santara; S. Ghosh; D. Sheet; P. Mitra","Indian Institute of Technology Kharagpur, WB 721302, India","2015 37th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)","20151105","2015","","","3029","3032","Vision impairment due to pathological damage of the retina can largely be prevented through periodic screening using fundus color imaging. However the challenge with large-scale screening is the inability to exhaustively detect fine blood vessels crucial to disease diagnosis. In this work we present a computational imaging framework using deep and ensemble learning based hybrid architecture for reliable detection of blood vessels in fundus color images. A deep neural network (DNN) is used for unsupervised learning of vesselness dictionaries using sparse trained denoising auto-encoders (DAE), followed by supervised learning of the DNN response using a random forest for detecting vessels in color fundus images. In experimental evaluation with the DRIVE database, we achieve the objective of vessel detection with max. avg. accuracy of 0.9327 and area under ROC curve of 0.9195.","1094-687X;1094687X","DVD:978-1-4244-9270-1; Electronic:978-1-4244-9271-8; POD:978-1-4244-9269-5","10.1109/EMBC.2015.7319030","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7319030","Computational imaging;deep learning;denoising auto-encoder;random forests;vessel detection","Biomedical imaging;Image analysis;Radio frequency;Retinal vessels;Vegetation","biomedical optical imaging;blood vessels;diseases;eye;image denoising;learning (artificial intelligence);medical image processing;vision defects","DNN response;DRIVE database;ROC curve;blood vessels;computational imaging framework;deep network;deep neural network;disease diagnosis;fundus color imaging;large-scale screening;learning based hybrid architecture;pathological damage;periodic screening;random forest hybrid architecture;retinal vessel detection;sparse trained denoising autoencoders;unsupervised learning;vision impairment","","1","","16","","","","25-29 Aug. 2015","","IEEE","IEEE Conference Publications"
"Multi-stage segmentation of the fovea in retinal fundus images using fully Convolutional Neural Networks","S. Sedai; R. Tennakoon; P. Roy; K. Cao; R. Garnavi","IBM Research - Australia, Melbourne, VIC, Australia","2017 IEEE 14th International Symposium on Biomedical Imaging (ISBI 2017)","20170619","2017","","","1083","1086","The fovea is one of the most important anatomical landmarks in the eye and its localization is required in automated analysis of retinal diseases due to its role in sharp central vision. In this paper, we propose a two-stage deep learning framework for accurate segmentation of the fovea in retinal colour fundus images. In the first stage, coarse segmentation is performed to localize the fovea in the fundus image. The location information from the first stage is then used to perform fine-grained segmentation of the fovea region in the second stage. The proposed method performs end-to-end pixelwise segmentation by creating a deep learning model based on fully convolutional neural networks, which does not require the prior knowledge of the location of other retinal structures such as optic disc (OD) and vasculature geometry. We demonstrate the effectiveness of our method on a dataset with 400 retinal images with average localization error of 14 Â± 7 pixels.","","Electronic:978-1-5090-1172-8; POD:978-1-5090-1173-5","10.1109/ISBI.2017.7950704","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7950704","Convolution neural network;Fovea Segmentation;Retinal Imaging","Convolution;Image segmentation;Machine learning;Neural networks;Optical imaging;Retina;Training","biomedical optical imaging;eye;image segmentation;medical image processing;neural nets","end-to-end pixelwise segmentation;fovea;fully convolutional neural networks;multistage segmentation;optic disc;retinal colour fundus images;retinal structures;two-stage deep learning framework;vasculature geometry","","","","","","","","18-21 April 2017","","IEEE","IEEE Conference Publications"
"Automatic Feature Learning Method for Detection of Retinal Landmarks","B. Al-Bander; W. Al-Nuaimy; M. A. Al-Taee; A. Al-Ataby; Y. Zheng","","2016 9th International Conference on Developments in eSystems Engineering (DeSE)","20170518","2016","","","13","18","This paper presents an automatic deep learning method for location detection of important retinal landmarks, the fovea and optic disc (OD) in digital fundus retinal images with the potential for use in an automated screening and grading system. The proposed method is based on deep convolutional neural networks (CNN) and does not depend the visual appearance or anatomical features of the retinal landmarks. It comprises convolution, max-pooling, fully connected and dropout layers as well as an output layer. The CNN is trained using an existing dataset images along with their annotated locations of the foveal and OD centres. Performance of the network is evaluated using Root Mean Square Error (RMSE). The developed feature learning-based approach presents promising system for retinal landmarks detection.","","Electronic:978-1-5090-5487-9; POD:978-1-5090-5488-6","10.1109/DeSE.2016.4","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7930616","Automatic feature learning;automated grading;convolutional neural network;deep learning;retinal landmarks","Adaptive optics;Feature extraction;Neural networks;Optical filters;Optical imaging;Retina;Training","","","","","","","","","","Aug. 31 2016-Sept. 2 2016","","IEEE","IEEE Conference Publications"
"Augmenting data when training a CNN for retinal vessel segmentation: How to warp?","A. Oliveira; S. Pereira; C. A. Silva","CMEMS-UMinho Research Unit, University of Minho, Guimar&#x00E3;es, Portugal","2017 IEEE 5th Portuguese Meeting on Bioengineering (ENBENG)","20170330","2017","","","1","4","The retinal vascular condition is a trustworthy biomarker of several ophthalmologic and cardiovascular diseases, so automatic vessel segmentation is a crucial step to diagnose and monitor these problems. Deep Learning models have recently revolutionized the state-of-the-art in several fields, since they can learn features with multiple levels of abstraction from the data itself. However, these methods can easily fall into overfitting, since a huge number of parameters must be learned. Having bigger datasets may act as regularization and lead to better models. Yet, acquiring and manually annotating images, especially in the medical field, can be a long and costly procedure. Hence, when using regular datasets, people heavily need to apply artificial data augmentation. In this work, we use a fully convolutional neural network capable of reaching the state-of-the-art. Also, we investigate the benefits of augmenting data with new samples created by warping retinal fundus images with nonlinear transformations. Our results hint that may be possible to halve the amount of data, while maintaining the same performance.","","Electronic:978-1-5090-4801-4; POD:978-1-5090-4802-1","10.1109/ENBENG.2017.7889443","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7889443","Convolutional neural network;Data augmentation;Retinal blood vessel segmentation","Data mining;Image segmentation;Neural networks;Retinal vessels;Training;Two dimensional displays","biomedical optical imaging;blood vessels;cardiovascular system;diseases;eye;image segmentation;learning (artificial intelligence);medical image processing;neural nets;vision defects","CNN;artificial data augmentation;automatic vessel segmentation;biomarker;cardiovascular diseases;deep Learning models;fully convolutional neural network;medical field;nonlinear transformations;ophthalmologic diseases;regular datasets;retinal fundus images;retinal vascular condition;retinal vessel segmentation","","","","","","","","16-18 Feb. 2017","","IEEE","IEEE Conference Publications"
"Retinal vessel segmentation via deep learning network and fully-connected conditional random fields","H. Fu; Y. Xu; D. W. K. Wong; J. Liu","Ocular Imaging Department, Institute for Infocomm Research, Agency for Science, Technology and Research (A&#8727;STAR), Singapore","2016 IEEE 13th International Symposium on Biomedical Imaging (ISBI)","20160616","2016","","","698","701","Vessel segmentation is a key step for various medical applications. This paper introduces the deep learning architecture to improve the performance of retinal vessel segmentation. Deep learning architecture has been demonstrated having the powerful ability in automatically learning the rich hierarchical representations. In this paper, we formulate the vessel segmentation to a boundary detection problem, and utilize the fully convolutional neural networks (CNNs) to generate a vessel probability map. Our vessel probability map distinguishes the vessels and background in the inadequate contrast region, and has robustness to the pathological regions in the fundus image. Moreover, a fully-connected Conditional Random Fields (CRFs) is also employed to combine the discriminative vessel probability map and long-range interactions between pixels. Finally, a binary vessel segmentation result is obtained by our method. We show that our proposed method achieve a state-of-the-art vessel segmentation performance on the DRIVE and STARE datasets.","","Electronic:978-1-4799-2349-6; POD:978-1-4799-2351-9","10.1109/ISBI.2016.7493362","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7493362","Conditional Random Fields;Convolutional Neural Networks;Vessel segmentation","Computer architecture;Image segmentation;Machine learning;Neural networks;Pathology;Retinal vessels","blood vessels;eye;image segmentation;medical image processing;neural nets","DRIVE dataset;STARE dataset;binary vessel segmentation;boundary detection;convolutional neural networks;deep learning network;fully-connected conditional random fields;fundus image;pathological region;retinal vessel segmentation;vessel probability map","","3","","18","","","","13-16 April 2016","","IEEE","IEEE Conference Publications"
"Deep vessel tracking: A generalized probabilistic approach via deep learning","A. Wu; Z. Xu; M. Gao; M. Buty; D. J. Mollura","Department of Radiology and Imaging Sciences, National Institutes of Health, Bethesda, MD 20892","2016 IEEE 13th International Symposium on Biomedical Imaging (ISBI)","20160616","2016","","","1363","1367","Analysis of vascular geometry is important in many medical imaging applications, such as retinal, pulmonary, and cardiac investigations. In order to make reliable judgments for clinical usage, accurate and robust segmentation methods are needed. Due to the high complexity of biological vasculature trees, manual identification is often too time-consuming and tedious to be used in practice. To design an automated and computerized method, a major challenge is that the appearance of vasculatures in medical images has great variance across modalities and subjects. Therefore, most existing approaches are specially designed for a particular task, lacking the flexibility to be adapted to other circumstances. In this paper, we present a generic approach for vascular structure identification from medical images, which can be used for multiple purposes robustly. The proposed method uses the state-of-the-art deep convolutional neural network (CNN) to learn the appearance features of the target. A Principal Component Analysis (PCA)-based nearest neighbor search is then utilized to estimate the local structure distribution, which is further incorporated within the generalized probabilistic tracking framework to extract the entire connected tree. Qualitative and quantitative results over retinal fundus data demonstrate that the proposed framework achieves comparable accuracy as compared with state-of-the-art methods, while efficiently producing more information regarding the candidate tree structure.","","Electronic:978-1-4799-2349-6; POD:978-1-4799-2351-9","10.1109/ISBI.2016.7493520","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7493520","Deep Learning;Generalized Probabilistic Tracking;Nearest Neighbor Search;Principal Component Analysis;Vascular Structure","Biomedical imaging;Dictionaries;Image segmentation;Machine learning;Probabilistic logic;Robustness","","","","1","","10","","","","13-16 April 2016","","IEEE","IEEE Conference Publications"
"Fast Convolutional Neural Network Training Using Selective Data Sampling: Application to Hemorrhage Detection in Color Fundus Images","M. J. J. P. van Grinsven; B. van Ginneken; C. B. Hoyng; T. Theelen; C. I. SÃ¡nchez","Diagnostic Image Analysis Group, Department of Radiology and Nuclear Medicine, Radboud University Medical Center, Nijmegen, The Netherlands","IEEE Transactions on Medical Imaging","20160429","2016","35","5","1273","1284","Convolutional neural networks (CNNs) are deep learning network architectures that have pushed forward the state-of-the-art in a range of computer vision applications and are increasingly popular in medical image analysis. However, training of CNNs is time-consuming and challenging. In medical image analysis tasks, the majority of training examples are easy to classify and therefore contribute little to the CNN learning process. In this paper, we propose a method to improve and speed-up the CNN training for medical image analysis tasks by dynamically selecting misclassified negative samples during training. Training samples are heuristically sampled based on classification by the current status of the CNN. Weights are assigned to the training samples and informative samples are more likely to be included in the next CNN training iteration. We evaluated and compared our proposed method by training a CNN with (SeS) and without (NSeS) the selective sampling method. We focus on the detection of hemorrhages in color fundus images. A decreased training time from 170 epochs to 60 epochs with an increased performance-on par with two human experts-was achieved with areas under the receiver operating characteristics curve of 0.894 and 0.972 on two data sets. The SeS CNN statistically outperformed the NSeS CNN on an independent test set.","0278-0062;02780062","","10.1109/TMI.2016.2526689","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7401052","Convolutional neural network;deep learning;hemorrhage;selective sampling","Biomedical imaging;Databases;Hemorrhaging;Image analysis;Image color analysis;Observers;Training","biomedical optical imaging;blood;computer vision;image classification;image colour analysis;image sampling;learning (artificial intelligence);medical image processing;neural nets;sensitivity analysis","CNN learning process;CNN training iteration;color fundus images;computer vision applications;deep learning network architectures;dynamically selecting misclassified negative samples;fast convolutional neural network training;hemorrhage detection;independent test set;medical image analysis tasks;receiver operating characteristics curve;selective data sampling;selective sampling method","","7","","48","","","20160208","May 2016","","IEEE","IEEE Journals & Magazines"
"Detection of exudates in fundus photographs using convolutional neural networks","P. PrentaÅ¡iÄ; S. LonÄariÄ","University of Zagreb, Faculty of Electrical Engineering and Computing, Unska 3, Image Processing Group 10000, Croatia","2015 9th International Symposium on Image and Signal Processing and Analysis (ISPA)","20151026","2015","","","188","192","Diabetic retinopathy is one of the leading causes of preventable blindness in the developed world. Early diagnosis of diabetic retinopathy enables timely treatment and in order to achieve it a major effort will have to be invested into screening programs and especially into automated screening programs. Detection of exudates is very important for early diagnosis of diabetic retinopathy. Deep neural networks have proven to be a very promising machine learning technique, and have shown excellent results in different compute vision problems. In this paper we show that convolutional neural networks can be effectively used in order to detect exudates in color fundus photographs.","1845-5921;18455921","Electronic:978-1-4673-8032-4; POD:978-1-4673-8033-1","10.1109/ISPA.2015.7306056","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7306056","","Convolution;Diabetes;Neural networks;Optical imaging;Optical sensors;Retina;Retinopathy","biomedical optical imaging;colour photography;diseases;eye;image colour analysis;medical image processing;neural nets;object detection","color fundus photographs;convolutional neural networks;deep neural networks;diabetic retinopathy;early diagnosis;exudate detection;machine learning technique;preventable blindness","","","","31","","","","7-9 Sept. 2015","","IEEE","IEEE Conference Publications"
"Using deep learning for robustness to parapapillary atrophy in optic disc segmentation","R. Srivastava; J. Cheng; D. W. K. Wong; J. Liu","Institute for Infocomm Research, Singapore 138632","2015 IEEE 12th International Symposium on Biomedical Imaging (ISBI)","20150723","2015","","","768","771","Optic Disc (OD) segmentation from retinal fundus images is important for many applications such as detecting other optic structures and early detection of glaucoma. One of the major problems in segmenting OD is the presence of Para-papillary Atrophy (PPA) which in many cases looks similar to the OD. Researchers have used many different features to distinguish between PPA and OD, however each of these features has some limitation or the other. In this paper, we propose to use a deep neural network for OD segmentation which can learn features to distinguish PPA from OD. Using simple image intensity based features, the proposed method has the least mean overlapping error (9.7%) among the state-of-the-art works for OD segmentation in fundus images with PPA.","1945-7928;19457928","Electronic:978-1-4799-2374-8; POD:978-1-4673-9330-0","10.1109/ISBI.2015.7163985","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7163985","Optic Disc segmentation;deep learning;parapapillary atrophy;retinal fundus images","Adaptive optics;Atrophy;Feature extraction;Image segmentation;Optical imaging;Retina;Training","eye;feature extraction;image segmentation;learning (artificial intelligence);medical image processing;neural nets;neurophysiology","deep learning;deep neural network;glaucoma detection;image intensity based features;least mean overlapping error;optic disc segmentation;optic structures;parapapillary atrophy;retinal fundus images","","1","","10","","","","16-19 April 2015","","IEEE","IEEE Conference Publications"
"Image quality classification for DR screening using deep learning","F. Yu; J. Sun; A. Li; J. Cheng; C. Wan; J. Liu","Nanjing University of Aeronautics and Astronautics, China","2017 39th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)","20170914","2017","","","664","667","The quality of input images significantly affects the outcome of automated diabetic retinopathy (DR) screening systems. Unlike the previous methods that only consider simple low-level features such as hand-crafted geometric and structural features, in this paper we propose a novel method for retinal image quality classification (IQC) that performs computational algorithms imitating the working of the human visual system. The proposed algorithm combines unsupervised features from saliency map and supervised features coming from convolutional neural networks (CNN), which are fed to an SVM to automatically detect high quality vs poor quality retinal fundus images. We demonstrate the superior performance of our proposed algorithm on a large retinal fundus image dataset and the method could achieve higher accuracy than other methods. Although retinal images are used in this study, the methodology is applicable to the image quality assessment and enhancement of other types of medical images.","","Electronic:978-1-5090-2809-2; POD:978-1-5090-2810-8","10.1109/EMBC.2017.8036912","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8036912","convolutional neural networks;image quality classification;saliency map","","","","","","","","","","","11-15 July 2017","","IEEE","IEEE Conference Publications"
"Deep tessellated retinal image detection using Convolutional Neural Networks","X. Lyu; H. Li; Y. Zhen; X. Ji; S. Zhang","Computer Graphics and Imaging Lab, College of Computer Science and Technology, Zhejiang University, Hangzhou, China","2017 39th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)","20170914","2017","","","676","680","Tessellation in fundus is not only a visible feature for aged-related and myopic maculopathy but also confuse retinal vessel segmentation. The detection of tessellated images is an inevitable processing in retinal image analysis. In this work, we propose a model using convolutional neural network for detecting tessellated images. The input to the model is pre-processed fundus image, and the output indicate whether this photograph has tessellation or not. A database with 12,000 colour retinal images is collected to evaluate the classification performance. The best tessellation classifier achieves accuracy of 97.73% and AUC value of 0.9659 using pretrained GoogLeNet and transfer learning technique.","","Electronic:978-1-5090-2809-2; POD:978-1-5090-2810-8","10.1109/EMBC.2017.8036915","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8036915","Tessellated fundus;convolutional neural network;tessellation detection;transfer learning","","","","","","","","","","","11-15 July 2017","","IEEE","IEEE Conference Publications"
"PhD Forum Abstract: Non-intrusive Blood Glucose Monitor by Multi-task Deep Learning","W. Gu","","2017 16th ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)","20170612","2017","","","249","250","Blood glucose concentration plays an important role in personal health. Hyperglycemia results in diabetes, leading to health risks such as pancreatic function failure, immunity reduce and ocular fundus diseases [6]. Meanwhile, hypoglycemia also brings complications such as confusion, shakiness, anxiety, and if not treated in time, coma or death [2]. People with diabetes need tight control of their blood glucose concentration to avoid both short-term and longterm physiological complications. In this work, we design BGMonitor, the first personalized smartphone-based non-invasive blood glucose monitoring system that detects abnormal blood glucose events by jointly tracking meal, drugs and insulin intake, physical activity and sleep quality. When BGMonitor detects an abnormal blood glucose event, it reminds the user to double-check by finger pricking or using clinical CGM devices.","","Electronic:978-1-4503-4890-4; POD:978-1-4673-9147-4","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7944794","","Biomedical monitoring;Blood;Diabetes;Drugs;Fingers;Monitoring;Sugar","biology computing;blood;diseases;learning (artificial intelligence);sugar","Hyperglycemia;PhD forum abstract;abnormal blood glucose;blood glucose concentration;diabetes;health risks;multitask deep learning;non-invasive blood glucose monitoring system;nonintrusive blood glucose monitor;ocular fundus diseases;personal health;personalized smartphone;physiological complications","","","","","","","","18-21 April 2017","","IEEE","IEEE Conference Publications"
"Convolutional neural networks for deep feature learning in retinal vessel segmentation","A. F. Khalaf; I. A. Yassine; A. S. Fahmy","Systems and Biomedical Engineering Department, Faculty of Engineering, Cairo University","2016 IEEE International Conference on Image Processing (ICIP)","20161208","2016","","","385","388","Analysis of retinal vessels in fundus images provides a valuable tool for characterizing many retinal and systemic diseases. Accurate automatic segmentation of these vessels is usually required as an essential analysis step. In this work, we propose a new formulation of deep Convolutional Neural Networks that allows simple and accurate segmentation of the retinal vessels. A major modification in this work is to reduce the intra-class variance by formulating the problem as a Three-class problem that differentiates: large vessels, small vessels, and background areas. In addition, different sizes of the convolutional kernels have been studied and it was found that a combination of kernels with different sizes achieve the best sensitivity and specificity. The proposed method was tested using DRIVE dataset and it showed superior performance compared to several other state of the art methods. The segmentation sensitivity, specificity and accuracy were found to be 83.97%, 95.62% and 94.56% respectively.","","Electronic:978-1-4673-9961-6; POD:978-1-4673-9962-3","10.1109/ICIP.2016.7532384","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7532384","Convolutional Neural Networks;Deep Learning;Pattern Classification;Retinal Blood Vessel Segmentation","","diseases;image segmentation;medical image processing;neural nets","DRIVE dataset;convolutional neural networks;deep feature learning;fundus images;retinal blood vessel segmentation;retinal diseases;retinal vessel analysis;segmentation sensitivity;systemic diseases","","","","","","","","25-28 Sept. 2016","","IEEE","IEEE Conference Publications"
"Customizing CNNs for blood vessel segmentation from fundus images","S. K. Vengalil; N. Sinha; S. S. S. Kruthiventi; R. V. Babu","International Institute of Information Technology, Bangalore, India","2016 International Conference on Signal Processing and Communications (SPCOM)","20161117","2016","","","1","4","For automatic screening of eye diseases, it is very important to segment regions corresponding to the different eye-parts from the fundal images. A challenging task, in this context, is to segment the network of blood vessels. The blood vessel network runs all along the fundal image, varying in density and fineness of structure. Besides, changes in illumination, color and pathology also add to the difficulties in blood vessel segmentation. In this paper, we propose segmentation of blood vessels from fundal images in the deep learning framework, without any pre-processing. A deep convolutional network, consisting of 8 convolutional layers and 3 pooling layers in between, is used to achieve the segmentation. In this work, a Convolutional Neural Network currently in use for semantic image segmentation is customized for blood vessel segmentation by replacing the output layer with a convolutional layer of kernel size 1 Ã 1 which generates the final segmented image. The output of CNN is a gray scale image and is binarized by thresholding. The proposed method is applied on 2 publicly available databases DRIVE and HRF (capturing diversity in image resolution), consisting of healthy and diseased fundal images boosted by mirror versions of the originals. The method results in an accuracy of 93.94% and yields 0.894 as area under the ROC curve on the test data comprising of randomly selected 23 images from HRF dataset. The promising results illustrate generalizability of the proposed approach.","","Electronic:978-1-5090-1746-1; POD:978-1-5090-1747-8","10.1109/SPCOM.2016.7746702","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7746702","","Biomedical imaging;Blood vessels;Image resolution;Image segmentation;Pathology;Testing;Training","blood vessels;convolution;diseases;image colour analysis;image resolution;image segmentation;learning (artificial intelligence);medical image processing;neural nets","CNN;DRIVE database;HRF databases;ROC curve;automatic screening;blood vessel network;blood vessel segmentation;convolutional neural network;deep learning framework;eye diseases;fundal images;fundus images;gray scale image;image resolution;semantic image segmentation","","","","","","","","12-15 June 2016","","IEEE","IEEE Conference Publications"
"Segmenting Retinal Blood Vessels With Deep Neural Networks","P. Liskowski; K. Krawiec","Institute of Computing Science, Poznan University of Technology, Poland","IEEE Transactions on Medical Imaging","20161103","2016","35","11","2369","2380","The condition of the vascular network of human eye is an important diagnostic factor in ophthalmology. Its segmentation in fundus imaging is a nontrivial task due to variable size of vessels, relatively low contrast, and potential presence of pathologies like microaneurysms and hemorrhages. Many algorithms, both unsupervised and supervised, have been proposed for this purpose in the past. We propose a supervised segmentation technique that uses a deep neural network trained on a large (up to 400 \thinspace000) sample of examples preprocessed with global contrast normalization, zero-phase whitening, and augmented using geometric transformations and gamma corrections. Several variants of the method are considered, including structured prediction, where a network classifies multiple pixels simultaneously. When applied to standard benchmarks of fundus imaging, the DRIVE, STARE, and CHASE databases, the networks significantly outperform the previous algorithms on the area under ROC curve measure (up to > 0.99) and accuracy of classification (up to > 0.97). The method is also resistant to the phenomenon of central vessel reflex, sensitive in detection of fine vessels ( sensitivity > 0.87), and fares well on pathological cases.","0278-0062;02780062","","10.1109/TMI.2016.2546227","10.13039/501100005632 - Narodowe Centrum Bada? i Rozwoju; ","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7440871","Classification;deep learning;feature learning;fundus;neural networks;retina;retinopathy;structured prediction;vessel segmentation","Biomedical imaging;Blood vessels;Convolution;Databases;Image segmentation;Neural networks;Pathology","blood vessels;eye;image classification;image segmentation;medical image processing;neural nets;sensitivity analysis;unsupervised learning","CHASE databases;DRIVE databases;ROC curve;STARE databases;central vessel reflex;deep neural networks;diagnostic factor;fundus imaging;gamma corrections;geometric transformations;global contrast normalization;hemorrhages;human eye;image classification;microaneurysms;nontrivial task;ophthalmology;retinal blood vessel segmentation;structured prediction;supervised segmentation;vascular network;zero-phase whitening","","7","","","","","20160324","Nov. 2016","","IEEE","IEEE Journals & Magazines"
"Deep neural ensemble for retinal vessel segmentation in fundus images towards achieving label-free angiography","A. Lahiri; A. G. Roy; D. Sheet; P. K. Biswas","Dept. of Electronics and Electrical Communication Engineering, Indian Institute of Technology Kharagpur, India","2016 38th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)","20161018","2016","","","1340","1343","Automated segmentation of retinal blood vessels in label-free fundus images entails a pivotal role in computed aided diagnosis of ophthalmic pathologies, viz., diabetic retinopathy, hypertensive disorders and cardiovascular diseases. The challenge remains active in medical image analysis research due to varied distribution of blood vessels, which manifest variations in their dimensions of physical appearance against a noisy background. In this paper we formulate the segmentation challenge as a classification task. Specifically, we employ unsupervised hierarchical feature learning using ensemble of two level of sparsely trained denoised stacked autoencoder. First level training with bootstrap samples ensures decoupling and second level ensemble formed by different network architectures ensures architectural revision. We show that ensemble training of auto-encoders fosters diversity in learning dictionary of visual kernels for vessel segmentation. SoftMax classifier is used for fine tuning each member autoencoder and multiple strategies are explored for 2-level fusion of ensemble members. On DRIVE dataset, we achieve maximum average accuracy of 95.33% with an impressively low standard deviation of 0.003 and Kappa agreement coefficient of 0.708. Comparison with other major algorithms substantiates the high efficacy of our model.","1557-170X;1557170X","Electronic:978-1-4577-0220-4; POD:978-1-4577-0219-8","10.1109/EMBC.2016.7590955","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7590955","","Biomedical imaging;Feature extraction;Image segmentation;Kernel;Retinal vessels;Standards;Training","biomedical optical imaging;blood vessels;cardiovascular system;diseases;eye;feature extraction;image classification;image coding;image denoising;image segmentation;medical image processing;unsupervised learning","2-level fusion;DRIVE dataset;Kappa agreement coefficient;SoftMax classifier;architectural revision;autoencoders fosters diversity;automated segmentation;bootstrap samples;cardiovascular diseases;classification task;computed aided diagnosis;deep neural ensemble;diabetic retinopathy;first level training;hypertensive disorders;label-free angiography;label-free fundus images;learning dictionary;maximum average accuracy;medical image analysis;network architectures;noisy background;ophthalmic pathologies;physical appearance;retinal blood vessels;retinal vessel segmentation;sparsely trained denoised stacked autoencoder;standard deviation;unsupervised hierarchical feature learning;visual kernels","","","","","","","","16-20 Aug. 2016","","IEEE","IEEE Conference Publications"
