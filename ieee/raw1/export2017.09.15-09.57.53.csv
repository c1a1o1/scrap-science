"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=8014844,7934380",2017/09/15 09:57:53
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","License","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"Generative Adversarial Networks for Noise Reduction in Low-Dose CT","J. M. Wolterink; T. Leiner; M. A. Viergever; I. Isgum","","IEEE Transactions on Medical Imaging","","2017","PP","99","1","1","Noise is inherent to low-dose CT acquisition. We propose to train a convolutional neural network (CNN) jointly with an adversarial CNN to estimate routine-dose CT images from low-dose CT images and hence reduce noise. A generator CNN was trained to transform low-dose CT images into routine-dose CT images using voxel-wise loss minimization. An adversarial discriminator CNN was simultaneously trained to distinguish the output of the generator from routinedose CT images. The performance of this discriminator was used as an adversarial loss for the generator. Experiments were performed using CT images of an anthropomorphic phantom containing calcium inserts, as well as patient non-contrast-enhanced cardiac CT images. The phantom and patients were scanned at 20% and 100% routine clinical dose. Three training strategies were compared: the first used only voxel-wise loss, the second combined voxel-wise loss and adversarial loss, and the third used only adversarial loss. The results showed that training with only voxel-wise loss resulted in the highest peak signal-to-noise ratio with respect to reference routine-dose images. However, the CNNs trained with adversarial loss captured image statistics of routine-dose images better. Noise reduction improved quantification of low-density calcified inserts in phantom CT images and allowed coronary calcium scoring in low-dose patient CT images with high noise levels. Testing took less than 10 seconds per CT volume. CNN-based low-dose CT noise reduction in the image domain is feasible. Training with an adversarial network improves the CNNâ€™s ability to generate images with an appearance similar to that of reference routine-dose CT images.","0278-0062;02780062","","10.1109/TMI.2017.2708987","Netherlands Organization for Health Research and Development ZonMw; ","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7934380","Low-dose cardiac CT;coronary calcium scoring;deep learning,;generative adversarial networks;noise reduction","Calcium;Computed tomography;Convolution;Generators;Noise reduction;Training;Transforms","","","","","","","","","20170526","","","IEEE","IEEE Early Access Articles"
"Generative Adversarial Learning for Reducing Manual Annotation in Semantic Segmentation on Large Scale Miscroscopy Images: Automated Vessel Segmentation in Retinal Fundus Image as Test Case","A. Lahiri; K. Ayush; P. K. Biswas; P. Mitra","","2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)","20170824","2017","","","794","800","Convolutional Neural Network(CNN) based semantic segmentation require extensive pixel level manual annotation which is daunting for large microscopic images. The paper is aimed towards mitigating this labeling effort by leveraging the recent concept of generative adversarial network(GAN) wherein a generator maps latent noise space to realistic images while a discriminator differentiates between samples drawn from database and generator. We extend this concept to a multi task learning wherein a discriminator-classifier network differentiates between fake/real examples and also assigns correct class labels. Though our concept is generic, we applied it for the challenging task of vessel segmentation in fundus images. We show that proposed method is more data efficient than a CNN. Specifically, with 150K, 30K and 15K training examples, proposed method achieves mean AUC of 0.962, 0.945 and 0.931 respectively, whereas the simple CNN achieves AUC of 0.960, 0.921 and 0.916 respectively.","","Electronic:978-1-5386-0733-6; POD:978-1-5386-0734-3","10.1109/CVPRW.2017.110","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8014844","","Biomedical imaging;Gallium nitride;Generators;Image segmentation;Manuals;Semantics;Training","","","","","","","","","","21-26 July 2017","","IEEE","IEEE Conference Publications"
