"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=7950544,7918014,7493402,7163869,7961205,7949028,7966408,7954012,7950542,7950660,7950543,7576695,7883849,7844626,7841003,7727966,7727205,7163826,8005794,7862905,7950686,7950488,7950585,7950587,7947200,7934380,7776792,7926678,7872780,7555958,7493206,7404017,7426826,7422082,7401039,7393571,7422783",2017/09/15 09:40:09
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","License","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"Multi-Scale Rotation-Invariant Convolutional Neural Networks for Lung Texture Classification","Q. Wang; Y. Zheng; g. yang; W. Jin; X. Chen; y. yin","School of Computer Science and Technology, Shandong University, Jinan 250101, China.(email:shdyn2000@mail.sdu.edu.cn)","IEEE Journal of Biomedical and Health Informatics","","2017","PP","99","1","1","We propose a new Multi-scale Rotation-invariant Convolutional Neural Network (MRCNN) model for classifying various lung tissue types on high-resolution computed tomography (HRCT). MRCNN employs Gabor-local binary pattern (Gabor-LBP) which introduces a good property in image analysis - invariance to image scales and rotations. In addition, we offer an approach to deal with the problems caused by imbalanced number of samples between different classes in most of the existing works, accomplished by changing the overlapping size between the adjacent patches. Experimental results on a public Interstitial Lung Disease (ILD) database show a superior performance of the proposed method to state-of-the-art.","2168-2194;21682194","","10.1109/JBHI.2017.2685586","NSFC Joint Fund with Guangdong under Key Project; National Natural Science Foundation of China under Grant; the Fostering Project of Dominant Discipline and Talent Team of Shandong Province Higher Education Institutions; ","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7883849","Gabor filter;Interstitial Lung Disease (ILD) classification;convolutional neural network (CNN);local binary pattern (LBP);lung classification","Biomedical imaging;Computed tomography;Feature extraction;Informatics;Lungs;Neural networks;Support vector machines","","","","","","","","","20170321","","","IEEE","IEEE Early Access Articles"
"Adrenal lesions detection on low-contrast CT images using fully convolutional networks with multi-scale integration","L. Bi; J. Kim; T. Su; M. Fulham; D. Feng; G. Ning","School of Information Technologies, University of Sydney, Australia","2017 IEEE 14th International Symposium on Biomedical Imaging (ISBI 2017)","20170619","2017","","","895","898","Adrenal lesions include a wide variety of benign and malignant neoplasms of the adrenal gland, and are seen in up to 5% of computed tomography (CT) examinations of the abdomen. Better identification of these lesions is important for effective management and patient prognosis. Detection on low-contrast CT images, however, even for experienced physicians can be difficult and error-prone, because the lesions are often problematic to be separated from the normal surrounding structures. Existing lesion detection techniques have problems in identifying and differentiating low-contrast tumors, which is related to their use of low-level features rather than high level of semantics. Hence we propose an automated approach using fully convolutional networks (FCNs) and multi-scale integration to detect adrenal lesion on low-contrast CT scans. The architecture of FCNs includes deep, coarse, semantic information and shallow, fine, appearance information in a hierarchical manner and it enables the encoding of image-wide location and semantics, which are desirable characteristics for adrenal lesion detection. We also propose a multi-scale integration with a superpixel based random walk (MI-SRW) approach to refine the lesion boundaries on different scales. The MI-SRW technique enables us to constrain the spatial and appearance consistency and then use complementary information provided on different scales to detect adrenal lesions of various sizes and characteristics. We used 38 adrenal lesions detected on low-contrast CT and compared our approach to existing `state-of-the-art' methods and found that our approach had superior detection performance.","","Electronic:978-1-5090-1172-8; POD:978-1-5090-1173-5","10.1109/ISBI.2017.7950660","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7950660","Adrenal lesions;Detection;Fully Convolutional Networks (FCN)","Biomedical imaging;Computed tomography;Feature extraction;Lesions;Semantics;Support vector machines","biological organs;cancer;computerised tomography;feature extraction;image coding;medical image processing;tumours","MI-SRW approach;adrenal gland;adrenal lesion;adrenal lesion detection;adrenal lesions detection;appearance consistency;benign neoplasms;complementary information;computed tomography examinations;deep coarse semantic information;fully convolutional networks;hierarchical manner;image-wide location encoding;lesion boundaries;lesion detection techniques;low-contrast CT image detection;low-contrast CT images;low-contrast CT scans;low-contrast tumors;low-level features;malignant neoplasms;multiscale integration;normal surrounding structures;patient prognosis;semantics encoding;shallow fine appearance information;spatial consistency;superpixel based random walk","","","","","","","","18-21 April 2017","","IEEE","IEEE Conference Publications"
"Anatomy-specific classification of medical images using deep convolutional nets","H. R. Roth; C. T. Lee; H. C. Shin; A. Seff; L. Kim; J. Yao; L. Lu; R. M. Summers","Imaging Biomarkers and Computer-Aided Diagnosis Laboratory, Radiology and Imaging Sciences Department, National Institutes of Health Clinical Center, Bethesda, MD 20892, USA","2015 IEEE 12th International Symposium on Biomedical Imaging (ISBI)","20150723","2015","","","101","104","Automated classification of human anatomy is an important prerequisite for many computer-aided diagnosis systems. The spatial complexity and variability of anatomy throughout the human body makes classification difficult. “Deep learning” methods such as convolutional networks (ConvNets) outperform other state-of-the-art methods in image classification tasks. In this work, we present a method for organ- or body-part-specific anatomical classification of medical images acquired using computed tomography (CT) with ConvNets. We train a ConvNet, using 4,298 separate axial 2D key-images to learn 5 anatomical classes. Key-images were mined from a hospital PACS archive, using a set of 1,675 patients. We show that a data augmentation approach can help to enrich the data set and improve classification performance. Using ConvNets and data augmentation, we achieve anatomy-specific classification error of 5.9 % and area-under-the-curve (AUC) values of an average of 0.998 in testing. We demonstrate that deep learning can be used to train very reliable and accurate classifiers that could initialize further computer-aided diagnosis.","1945-7928;19457928","Electronic:978-1-4799-2374-8; POD:978-1-4673-9330-0","10.1109/ISBI.2015.7163826","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7163826","Computed tomography (CT);Convolutional Networks;Deep Learning;Image Classification","Computed tomography;Convolution;Lungs;Medical diagnostic imaging;Neural networks;Training","PACS;biological organs;computerised tomography;image classification;medical image processing","ConvNets;anatomy variability;anatomy-specific classification;anatomy-specific classification error;area-under-the-curve;automated classification;axial 2D key-images;body part-specific anatomical classification;computed tomography;computer-aided diagnosis systems;convolutional networks;data augmentation;data augmentation approach;deep convolutional nets;deep learning methods;hospital PACS archive;human anatomy;image classification;medical images;organ-specific anatomical classification;spatial complexity","","5","","16","","","","16-19 April 2015","","IEEE","IEEE Conference Publications"
"Deep Convolutional Neural Network for Inverse Problems in Imaging","K. H. Jin; M. T. McCann; E. Froustey; M. Unser","Biomedical Imaging Group, &#x00C9;cole Polytechnique F&#x00E9;d&#x00E9;rale de Lausanne, Lausanne, Switzerland","IEEE Transactions on Image Processing","20170711","2017","26","9","4509","4522","In this paper, we propose a novel deep convolutional neural network (CNN)-based algorithm for solving ill-posed inverse problems. Regularized iterative algorithms have emerged as the standard approach to ill-posed inverse problems in the past few decades. These methods produce excellent results, but can be challenging to deploy in practice due to factors including the high computational cost of the forward and adjoint operators and the difficulty of hyperparameter selection. The starting point of this paper is the observation that unrolled iterative methods have the form of a CNN (filtering followed by pointwise nonlinearity) when the normal operator (H*H, where H* is the adjoint of the forward imaging operator, H) of the forward model is a convolution. Based on this observation, we propose using direct inversion followed by a CNN to solve normal-convolutional inverse problems. The direct inversion encapsulates the physical model of the system, but leads to artifacts when the problem is ill posed; the CNN combines multiresolution decomposition and residual learning in order to learn to remove these artifacts while preserving image structure. We demonstrate the performance of the proposed network in sparse-view reconstruction (down to 50 views) on parallel beam X-ray computed tomography in synthetic phantoms as well as in real experimental sinograms. The proposed network outperforms total variation-regularized iterative reconstruction for the more realistic phantoms and requires less than a second to reconstruct a 512 × 512 image on the GPU.","1057-7149;10577149","","10.1109/TIP.2017.2713099","10.13039/100000070 - National Institute of Biomedical Imaging and Bioengineering; 10.13039/100010661 - European Union¿¿¿s Horizon 2020 Framework Programme for Research and Innovation (call 2015); 10.13039/501100000781 - European Research Council (H2020-ERC Project GlobalBioIm); 10.13039/501100006391 - Center for Biomedical Imaging of the Geneva-Lausanne Universities and EPFL; ","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7949028","Image restoration;biomedical imaging;biomedical signal processing;computed tomography;image reconstruction;magnetic resonance imaging;reconstruction algorithms;tomography","Computed tomography;Convolution;Image reconstruction;Inverse problems;Iterative methods;Neural networks","computerised tomography;feedforward neural nets;image resolution;iterative methods;learning (artificial intelligence);medical image processing","CNN;GPU;adjoint operators;deep convolutional neural network;direct inversion;forward model;forward operators;hyperparameter selection;ill-posed inverse problems;image structure;multiresolution decomposition;normal-convolutional inverse problems;parallel beam X-ray computed tomography;regularized iterative algorithms;residual learning;synthetic phantoms;total variation-regularized iterative reconstruction","","","","","","","20170615","Sept. 2017","","IEEE","IEEE Journals & Magazines"
"Convolutional Neural Networks for Medical Image Analysis: Full Training or Fine Tuning?","N. Tajbakhsh; J. Y. Shin; S. R. Gurudu; R. T. Hurst; C. B. Kendall; M. B. Gotway; J. Liang","Department of Biomedical Informatics, Arizona State University, Scottsdale, AZ, USA","IEEE Transactions on Medical Imaging","20160429","2016","35","5","1299","1312","Training a deep convolutional neural network (CNN) from scratch is difficult because it requires a large amount of labeled training data and a great deal of expertise to ensure proper convergence. A promising alternative is to fine-tune a CNN that has been pre-trained using, for instance, a large set of labeled natural images. However, the substantial differences between natural and medical images may advise against such knowledge transfer. In this paper, we seek to answer the following central question in the context of medical image analysis: Can the use of pre-trained deep CNNs with sufficient fine-tuning eliminate the need for training a deep CNN from scratch? To address this question, we considered four distinct medical imaging applications in three specialties (radiology, cardiology, and gastroenterology) involving classification, detection, and segmentation from three different imaging modalities, and investigated how the performance of deep CNNs trained from scratch compared with the pre-trained CNNs fine-tuned in a layer-wise manner. Our experiments consistently demonstrated that 1) the use of a pre-trained CNN with adequate fine-tuning outperformed or, in the worst case, performed as well as a CNN trained from scratch; 2) fine-tuned CNNs were more robust to the size of training sets than CNNs trained from scratch; 3) neither shallow tuning nor deep tuning was the optimal choice for a particular application; and 4) our layer-wise fine-tuning scheme could offer a practical way to reach the best performance for the application at hand based on the amount of available data.","0278-0062;02780062","","10.1109/TMI.2016.2535302","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7426826","Carotid intima-media thickness;computer-aided detection;convolutional neural networks;deep learning;fine-tuning;medical image analysis;polyp detection;pulmonary embolism detection;video quality assessment","Biomedical imaging;Computed tomography;Feature extraction;Image analysis;Image segmentation;Training;Tuning","biomedical optical imaging;endoscopes;image classification;image segmentation;medical image processing;neural nets","cardiology;classification;deep convolutional neural network;distinct medical imaging applications;gastroenterology;imaging modalities;labeled training data;layer-wise fine-tuning scheme;medical image analysis;radiology;segmentation","","34","","76","","","20160307","May 2016","","IEEE","IEEE Journals & Magazines"
"Size and Texture-Based Classification of Lung Tumors with 3D CNNs","Z. Luo; M. A. Brubaker; M. Brudno","","2017 IEEE Winter Conference on Applications of Computer Vision (WACV)","20170515","2017","","","806","814","In this paper, we explore the use of current deep learning methods in the field of computer-aided diagnosis (CAD). Specifically we propose the use of 3D convolutional neural nets (CNN) in classifying lung nodules based off of their appearance in CT scans. We explore the choices of network architectures, learning parameters and problem formulations. Comparing these results to other methods we show that the proposed method has close to perfect performance on the publicly available LIDC dataset, achieving an AUC of 0:9685 and a false positive rate of 0:46% with a true positive rate of 90% where the ground truth is the expert opinion of a radiologist.","","Electronic:978-1-5090-4822-9; POD:978-1-5090-4823-6","10.1109/WACV.2017.95","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7926678","","Biological neural networks;Cancer;Computed tomography;Lungs;Three-dimensional displays;Tumors","","","","","","","","","","24-31 March 2017","","IEEE","IEEE Conference Publications"
"Lung nodule detection in CT images using deep convolutional neural networks","R. Golan; C. Jacob; J. Denzinger","Dept. of Computer Science, University of Calgary, Alberta, Canada T2N 1N4","2016 International Joint Conference on Neural Networks (IJCNN)","20161103","2016","","","243","250","Early detection of lung nodules in thoracic Computed Tomography (CT) scans is of great importance for the successful diagnosis and treatment of lung cancer. Due to improvements in screening technologies, and an increased demand for their use, radiologists are required to analyze an ever increasing amount of image data, which can affect the quality of their diagnoses. Computer-Aided Detection (CADe) systems are designed to assist radiologists in this endeavor. Here, we present a CADe system for the detection of lung nodules in thoracic CT images. Our system is based on (1) the publicly available Lung Image Database Consortium (LIDC) and Image Database Resource Initiative (IDRI) database, which contains 1018 thoracic CT scans with nodules of different shape and size, and (2) a deep Convolutional Neural Network (CNN), which is trained, using the back-propagation algorithm, to extract valuable volumetric features from the input data and detect lung nodules in sub-volumes of CT images. Considering only those test nodules that have been annotated by four radiologists, our CADe system achieves a sensitivity (true positive rate) of 78.9% with 20 false positives (FPs) per scan, or a sensitivity of 71.2% with 10 FPs per scan. This is achieved without using any segmentation or additional FP reduction procedures, both of which are commonly used in other CADe systems. Furthermore, our CADe system is validated on a larger number of lung nodules compared to other studies, which increases the variation in their appearance, and therefore, makes their detection by a CADe system more challenging.","","","10.1109/IJCNN.2016.7727205","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7727205","","Biological neural networks;Biomedical imaging;Cancer;Computed tomography;Image databases;Lungs","backpropagation;cancer;computerised tomography;feature extraction;medical image processing;neural nets;object detection;patient diagnosis;patient treatment","CADe systems;CNN;IDRI database;LIDC database;backpropagation algorithm;computer-aided detection system;deep convolutional neural network;deep convolutional neural networks;image data;image database resource initiative database;lung cancer diagnosis;lung cancer treatment;lung image database consortium database;lung nodule detection;screening technology;thoracic CT images;thoracic computed tomography scans;valuable volumetric feature extraction","","","","","","","","24-29 July 2016","","IEEE","IEEE Conference Publications"
"Low-Dose CT with a Residual Encoder-Decoder Convolutional Neural Network (RED-CNN)","H. Chen; Y. Zhang; M. K. Kalra; F. Lin; Y. Chen; P. Liao; J. Zhou; G. Wang","College of Computer Science, Sichuan University, Chengdu 610065, China.","IEEE Transactions on Medical Imaging","","2017","PP","99","1","1","Given the potential risk of X-ray radiation to the patient, low-dose CT has attracted a considerable interest in the medical imaging field. Currently, the main stream low-dose CT methods include vendor-specific sinogram domain filtration and iterative reconstruction algorithms, but they need to access raw data whose formats are not transparent to most users. Due to the difficulty of modeling the statistical characteristics in the image domain, the existing methods for directly processing reconstructed images cannot eliminate image noise very well while keeping structural details. Inspired by the idea of deep learning, here we combine the autoencoder, deconvolution network, and shortcut connections into the residual encoder-decoder convolutional neural network (RED-CNN) for low-dose CT imaging. After patch-based training, the proposed RED-CNN achieves a competitive performance relative to the-state-of-art methods in both simulated and clinical cases. Especially, our method has been favorably evaluated in terms of noise suppression, structural preservation, and lesion detection.","0278-0062;02780062","","10.1109/TMI.2017.2715284","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7947200","Low-dose CT;auto-encoder;convolutional;deconvolutional;deep learning;residual neural network","Computed tomography;Convolution;Decoding;Feature extraction;Image reconstruction;X-ray imaging","","","","","","","","","20170613","","","IEEE","IEEE Early Access Articles"
"Automatic segmentation of the left ventricle in cardiac CT angiography using convolutional neural networks","M. Zreik; T. Leiner; B. D. de Vos; R. W. van Hamersvelt; M. A. Viergever; I. Išgum","Image Sciences Institute, University Medical Center Utrecht, The Netherlands","2016 IEEE 13th International Symposium on Biomedical Imaging (ISBI)","20160616","2016","","","40","43","Accurate delineation of the left ventricle (LV) is an important step in evaluation of cardiac function. In this paper, we present an automatic method for segmentation of the LV in cardiac CT angiography (CCTA) scans. Segmentation is performed in two stages. First, a bounding box around the LV is detected using a combination of three convolutional neural networks (CNNs). Subsequently, to obtain the segmentation of the LV, voxel classification is performed within the defined bounding box using a CNN. The study included CCTA scans of sixty patients, fifty scans were used to train the CNNs for the LV localization, five scans were used to train LV segmentation and the remaining five scans were used for testing the method. Automatic segmentation resulted in the average Dice coefficient of 0.85 and mean absolute surface distance of 1.1 mm. The results demonstrate that automatic segmentation of the LV in CCTA scans using voxel classification with convolutional neural networks is feasible.","","Electronic:978-1-4799-2349-6; POD:978-1-4799-2351-9","10.1109/ISBI.2016.7493206","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7493206","Cardiac CT Angiography;Classification;Convolutional Neural Network;Deep learning;Left ventricle segmentation","Biomedical imaging;Computed tomography;Heart;Image segmentation;Manuals;Neural networks;Observers","","","","","","16","","","","13-16 April 2016","","IEEE","IEEE Conference Publications"
"Classification of radiology reports using neural attention models","B. Shin; F. H. Chokshi; T. Lee; J. D. Choi","Mathematics and Computer Science, Emory University, Atlanta, GA 30322","2017 International Joint Conference on Neural Networks (IJCNN)","20170703","2017","","","4363","4370","The electronic health record (EHR) contains a large amount of multi-dimensional and unstructured clinical data of significant operational and research value. Distinguished from previous studies, our approach embraces a double-annotated dataset and strays away from obscure “black-box” models to comprehensive deep learning models. In this paper, we present a novel neural attention mechanism that not only classifies clinically important findings. Specifically, convolutional neural networks (CNN) with attention analysis are used to classify radiology head computed tomography reports based on five categories that radiologists would account for in assessing acute and communicable findings in daily practice. The experiments show that our CNN attention models outperform non-neural models, especially when trained on a larger dataset. Our attention analysis demonstrates the intuition behind the classifier's decision by generating a heatmap that highlights attended terms used by the CNN model; this is valuable when potential downstream medical decisions are to be performed by human experts or the classifier information is to be used in cohort construction such as for epidemiological studies.","","Electronic:978-1-5090-6182-2; POD:978-1-5090-6183-9","10.1109/IJCNN.2017.7966408","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7966408","","Computational modeling;Convolution;Machine learning;Neural networks;Radiology;Sentiment analysis;Support vector machines","computerised tomography;convolution;data analysis;electronic health records;neural nets;pattern classification;radiology","CNN;EHR;attention analysis;convolutional neural networks;double-annotated dataset;electronic health record;neural attention mechanism;neural attention models;radiology head computed tomography reports classification","","","","","","","","14-19 May 2017","","IEEE","IEEE Conference Publications"
"TumorNet: Lung nodule characterization using multi-view Convolutional Neural Network with Gaussian Process","S. Hussein; R. Gillies; K. Cao; Q. Song; U. Bagci","Center for Research in Computer Vision (CRCV) at University of Central Florida, Orlando, United States of America","2017 IEEE 14th International Symposium on Biomedical Imaging (ISBI 2017)","20170619","2017","","","1007","1010","Characterization of lung nodules as benign or malignant is one of the most important tasks in lung cancer diagnosis, staging and treatment planning. While the variation in the appearance of the nodules remains large, there is a need for a fast and robust computer aided system. In this work, we propose an end-to-end trainable multi-view deep Convolutional Neural Network (CNN) for nodule characterization. First, we use median intensity projection to obtain a 2D patch corresponding to each dimension. The three images are then concatenated to form a tensor, where the images serve as different channels of the input image. In order to increase the number of training samples, we perform data augmentation by scaling, rotating and adding noise to the input image. The trained network is used to extract features from the input image followed by a Gaussian Process (GP) regression to obtain the malignancy score. We also empirically establish the significance of different high level nodule attributes such as calcification, sphericity and others for malignancy determination. These attributes are found to be complementary to the deep multi-view CNN features and a significant improvement over other methods is obtained.","","Electronic:978-1-5090-1172-8; POD:978-1-5090-1173-5","10.1109/ISBI.2017.7950686","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7950686","Computer-aided diagnosis;computed tomography;deep learning;lung cancer;pulmonary nodule","Cancer;Computed tomography;Feature extraction;Lungs;Neural networks;Training","Gaussian processes;computerised tomography;feature extraction;neural nets;tumours","Gaussian process;TumorNet;calcification;computed tomography;feature extraction;lung nodule characterization;malignancy determination;multiview convolutional neural network;sphericity","","","","","","","","18-21 April 2017","","IEEE","IEEE Conference Publications"
"Ischemic stroke identification based on EEG and EOG using ID convolutional neural network and batch normalization","E. P. Giri; M. I. Fanany; A. M. Arymurthy; S. K. Wijaya","Computer Sciences Department, Faculty of Mathematics and Natural Sciences, Bogor Agricultural University, Bogor 16680, West Java, Indonesia","2016 International Conference on Advanced Computer Science and Information Systems (ICACSIS)","20170309","2016","","","484","491","In 2015, stroke was the number one cause of death in Indonesia. The majority type of stroke is ischemic. The standard tool for diagnosing stroke is CT-Scan. For developing countries like Indonesia, the availability of CT-Scan is very limited and still relatively expensive. Because of the availability, another device that potential to diagnose stroke in Indonesia is EEG. Ischemic stroke occurs because of obstruction that can make the cerebral blood flow (CBF) on a person with stroke has become lower than CBF on a normal person (control) so that the EEG signal have a deceleration. On this study, we perform the ability of ID Convolutional Neural Network (1DCNN) to construct classification model that can distinguish the EEG and EOG stroke data from EEG and EOG control data. To accelerate training process our model we use Batch Normalization. Involving 62 person data object and from leave one out the scenario with five times repetition of measurement we obtain the average of accuracy 0.86 (F-Score 0.861) only at 200 epoch. This result is better than all over shallow and popular classifiers as the comparator (the best result of accuracy 0.69 and F-Score 0.72). The feature used in our study were only 24 handcrafted feature with simple feature extraction process.","","Electronic:978-1-5090-4629-4; POD:978-1-5090-4630-0; USB:978-1-5090-4628-7","10.1109/ICACSIS.2016.7872780","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7872780","EEG;ID CNN;deep learning;ischemic;stroke","Brain modeling;Computed tomography;Convolution;Electroencephalography;Electrooculography;Feature extraction;Hospitals","blood;convolution;electro-oculography;electroencephalography;feature extraction;medical signal processing;neural nets;patient diagnosis","1D convolutional neural network;1DCNN;CBF;CT-Scan;EEG;EOG;batch normalization;cerebral blood flow;electroencephalography;electrooculography;feature extraction;ischemic stroke identification;stroke diagnosis","","","","","","","","15-16 Oct. 2016","","IEEE","IEEE Conference Publications"
"Lung nodule detection in CT using 3D convolutional neural networks","X. Huang; J. Shan; V. Vaidya","GE Global Research, Niskayuna, NY, United States of America","2017 IEEE 14th International Symposium on Biomedical Imaging (ISBI 2017)","20170619","2017","","","379","383","We propose a new computer-aided detection system that uses 3D convolutional neural networks (CNN) for detecting lung nodules in low dose computed tomography. The system leverages both a priori knowledge about lung nodules and confounding anatomical structures and data-driven machine-learned features and classifier. Specifically, we generate nodule candidates using a local geometric-model-based filter and further reduce the structure variability by estimating the local orientation. The nodule candidates in the form of 3D cubes are fed into a deep 3D convolutional neural network that is trained to differentiate nodule and non-nodule inputs. We use data augmentation techniques to generate a large number of training examples and apply regularization to avoid overfitting. On a set of 99 CT scans, the proposed system achieved state-of-the-art performance and significantly outperformed a similar hybrid system that uses conventional shallow learning. The experimental results showed benefits of using a priori models to reduce the problem space for data-driven machine learning of complex deep neural networks. The results also showed the advantages of 3D CNN over 2D CNN in volumetric medical image analysis.","","Electronic:978-1-5090-1172-8; POD:978-1-5090-1173-5","10.1109/ISBI.2017.7950542","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7950542","3D convolutional neural networks;CT;Lung nodule;computer-aided detection;deep learning","Computed tomography;Lungs;Neural networks;Solid modeling;Three-dimensional displays;Training;Two dimensional displays","computerised tomography;feature extraction;image classification;learning (artificial intelligence);lung;medical image processing;neural nets","3D CNN;CT scans;complex deep neural networks;computer-aided detection;conventional shallow learning;data augmentation;data-driven machine-learned classifier;data-driven machine-learned features;deep 3D convolutional neural networks;local geometric-model-based filter;low dose computed tomography;lung nodule detection;structure variability;volumetric medical image analysis","","","","","","","","18-21 April 2017","","IEEE","IEEE Conference Publications"
"Combining deep neural network and traditional image features to improve survival prediction accuracy for lung cancer patients from diagnostic CT","R. Paul; S. H. Hawkins; L. O. Hall; D. B. Goldgof; R. J. Gillies","Department of Computer Science and Engineering, University of South Florida, Tampa, USA","2016 IEEE International Conference on Systems, Man, and Cybernetics (SMC)","20170209","2016","","","002570","002575","Lung cancer is caused by abnormal and uncontrolled growth of cells in the lungs and the mortality rate of lung cancer is the highest among all types of cancer. It can be identified and treated with the help of computed tomography (CT) images. For an automated classifier, identifying good features from an image is a key concern. Deep feature extraction using pre-trained convolutional neural networks has been successful for some image domains recently. In our study, we apply a pre-trained convolutional neural network (CNN) to extract deep features from lung cancer CT images and then train classifiers to predict short and long term survivors. The best accuracy of 77.5% was with a cropping approach using a decision tree classifier in a leave one out cross validation with ten features chosen using symmetric uncertainty feature ranking. We mixed extracted deep neural network features along with quantitative (traditional image) features and obtained the best accuracy of 82.5% with a nearest neighbor classifier in a leave one out cross validation using the symmetric uncertainty feature ranking algorithm.","","Electronic:978-1-5090-1897-0; POD:978-1-5090-1898-7; USB:978-1-5090-1819-2","10.1109/SMC.2016.7844626","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7844626","CNN;Radiomics;computed tomography;deep features","Cancer;Classification algorithms;Computed tomography;Feature extraction;Lungs;Neural networks;Tumors","cancer;computerised tomography;convolution;decision trees;image classification;learning (artificial intelligence);lung;patient diagnosis","automated classifier;classifier training;computed tomography images;decision tree classifier;deep feature extraction;deep neural network;diagnostic CT;lung cancer patients;nearest neighbor classifier;pretrained convolutional neural networks;quantitative image features;survival prediction accuracy;symmetric uncertainty feature ranking","","","","","","","","9-12 Oct. 2016","","IEEE","IEEE Conference Publications"
"Application of big data analytics for automated estimation of CT image quality","M. D. Naeemi; J. Ren; N. Hollcroft; A. M. Alessio; S. Roychowdhury","Department of Electrical Engineering, University of Washington, Bothell WA","2016 IEEE International Conference on Big Data (Big Data)","20170206","2016","","","3422","3431","With the increasing applications of Big Data analytics in medical image processing systems, there has been a growing need for quantitative medical image quality assessment techniques. Specifically for computed tomography (CT) images, quantitative image assessment can allow for benchmarking image processing methods and optimization of image acquisition parameters. In this work, large volumes of CT images from phantoms and patients are analyzed using 3 data models that vary in their implementation time complexities. The goal here is to identify the optimal method that scales across data set variabilities for predictive modeling of CT image quality (CTIQ). The first two models rely on spatial segmentation of regions-of-interest (ROIs) and estimate CTIQs in terms of segmented pixel variabilities. The third, convolutional neural network (CNN) model relies on error back-propagation from the training set of images to learn the regions indicative of CTIQ. We observe that for 70/30 data split, the average multi-class classification accuracies for CTIQ prediction using the 3 data models range from 73.6-100% and 50-100% for the phantom and patient CT images, respectively. Using variance of pixels within the segmented ROIs as a CTIQ classification parameter, the spatial segmentation data models are found to be more generalizable that the CNN model. However, the CNN model is found to be more suitable for CT image texture classification in the absence of structural variabilities. Our analysis demonstrates that spatial ROI segmentation data models are consistent CTIQ estimators while the CNN models are consistent identifiers of structural similarities for CT image data sets.","","Electronic:978-1-4673-9005-7; POD:978-1-4673-9006-4","10.1109/BigData.2016.7841003","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7841003","CT image;Convolutional neural network;Image variability;Region of interest","Big data;Computed tomography;Data models;Image quality;Image segmentation;Lungs;Measurement","Big Data;backpropagation;computerised tomography;convolution;data analysis;image segmentation;medical image processing;neural nets","Big Data analytics;CNN model;CT image quality;CTIQ;ROI;automated estimation;computed tomography images;convolutional neural network;data models;data set variabilities;error back-propagation;image acquisition parameters;medical image processing systems;medical image quality assessment techniques;predictive modeling;quantitative image assessment;regions-of-interest;segmented pixel variabilities;spatial segmentation;time complexities","","","","","","","","5-8 Dec. 2016","","IEEE","IEEE Conference Publications"
"Multilevel Contextual 3-D CNNs for False Positive Reduction in Pulmonary Nodule Detection","Q. Dou; H. Chen; L. Yu; J. Qin; P. A. Heng","Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong","IEEE Transactions on Biomedical Engineering","20170615","2017","64","7","1558","1567","Objective: False positive reduction is one of the most crucial components in an automated pulmonary nodule detection system, which plays an important role in lung cancer diagnosis and early treatment. The objective of this paper is to effectively address the challenges in this task and therefore to accurately discriminate the true nodules from a large number of candidates. Methods: We propose a novel method employing three-dimensional (3-D) convolutional neural networks (CNNs) for false positive reduction in automated pulmonary nodule detection from volumetric computed tomography (CT) scans. Compared with its 2-D counterparts, the 3-D CNNs can encode richer spatial information and extract more representative features via their hierarchical architecture trained with 3-D samples. More importantly, we further propose a simple yet effective strategy to encode multilevel contextual information to meet the challenges coming with the large variations and hard mimics of pulmonary nodules. Results: The proposed framework has been extensively validated in the LUNA16 challenge held in conjunction with ISBI 2016, where we achieved the highest competition performance metric (CPM) score in the false positive reduction track. Conclusion: Experimental results demonstrated the importance and effectiveness of integrating multilevel contextual information into 3-D CNN framework for automated pulmonary nodule detection in volumetric CT data. Significance: While our method is tailored for pulmonary nodule detection, the proposed framework is general and can be easily extended to many other 3-D object detection tasks from volumetric medical images, where the targeting objects have large variations and are accompanied by a number of hard mimics.","0018-9294;00189294","","10.1109/TBME.2016.2613502","Shenzhen-Hong Kong Innovation Circle; The Hong Kong Special Administrative Region; 10.13039/501100001809 - National Natural Science Foundation of China; ","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7576695","3-D convolutional neural networks;Computer-aided diagnosis;deep learning;false positive reduction;pulmonary nodule detection","Cancer;Computed tomography;Feature extraction;Kernel;Lungs;Three-dimensional displays;Two dimensional displays","cancer;computerised tomography;feature extraction;lung;medical image processing;neural nets","3D convolutional neural network;3D object detection tasks;CPM score;ISBI 2016;LUNA16 challenge;automated pulmonary nodule detection system;competition performance metric score;contextual 3D CNN;false positive reduction track;feature extraction;lung cancer diagnosis;multilevel contextual information;volumetric CT scans;volumetric computed tomography;volumetric medical images","","","","","","","20160926","July 2017","","IEEE","IEEE Journals & Magazines"
"Low-dose CT denoising with convolutional neural network","H. Chen; Y. Zhang; W. Zhang; P. Liao; K. Li; J. Zhou; G. Wang","College of Computer Science, Sichuan University, Chengdu 610065, China","2017 IEEE 14th International Symposium on Biomedical Imaging (ISBI 2017)","20170619","2017","","","143","146","To reduce the potential radiation risk, low-dose CT has attracted much attention. However, simply lowering the radiation dose will lead to significant deterioration of the image quality. In this paper, we propose a noise reduction method for low-dose CT via deep neural network without accessing original projection data. A deep convolutional neural network is trained to transform low-dose CT images towards normal-dose CT images, patch by patch. Visual and quantitative evaluation demonstrates a competing performance of the proposed method.","","Electronic:978-1-5090-1172-8; POD:978-1-5090-1173-5","10.1109/ISBI.2017.7950488","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7950488","Low-dose CT;convolutional neural network;deep learning;noise reduction","Computed tomography;Dictionaries;Filtering;Image reconstruction;Neural networks;Noise reduction;Training","computerised tomography;image denoising;medical image processing;neural nets","deep convolutional neural network;image quality;low-dose CT denoising;low-dose CT images;noise reduction method;normal-dose CT images;original projection data;quantitative evaluation;radiation dose;visual evaluation","","","","","","","","18-21 April 2017","","IEEE","IEEE Conference Publications"
"ConvNet-Based Localization of Anatomical Structures in 3-D Medical Images","B. D. de Vos; J. M. Wolterink; P. A. de Jong; T. Leiner; M. A. Viergever; I. Išgum","Image Sciences Institute, University Medical Center Utrecht, Utrecht, The Netherlands","IEEE Transactions on Medical Imaging","20170630","2017","36","7","1470","1481","Localization of anatomical structures is a prerequisite for many tasks in a medical image analysis. We propose a method for automatic localization of one or more anatomical structures in 3-D medical images through detection of their presence in 2-D image slices using a convolutional neural network (ConvNet). A single ConvNet is trained to detect the presence of the anatomical structure of interest in axial, coronal, and sagittal slices extracted from a 3-D image. To allow the ConvNet to analyze slices of different sizes, spatial pyramid pooling is applied. After detection, 3-D bounding boxes are created by combining the output of the ConvNet in all slices. In the experiments, 200 chest CT, 100 cardiac CT angiography (CTA), and 100 abdomen CT scans were used. The heart, ascending aorta, aortic arch, and descending aorta were localized in chest CT scans, the left cardiac ventricle in cardiac CTA scans, and the liver in abdomen CT scans. Localization was evaluated using the distances between automatically and manually defined reference bounding box centroids and walls. The best results were achieved in the localization of structures with clearly defined boundaries (e.g., aortic arch) and the worst when the structure boundary was not clearly visible (e.g., liver). The method was more robust and accurate in localization multiple structures.","0278-0062;02780062","","10.1109/TMI.2017.2673121","10.13039/100007065 - NVIDIA Corporation with the donation of the Tesla K40 GPU used for this research; 10.13039/501100003958 - Netherlands Organization for Scientific Research Foundation for Technology Sciences Project 12726; ","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7862905","CT;Localization;convolutional neural networks;deep learning;detection","Abdomen;Anatomical structure;Computed tomography;Heart;Three-dimensional displays;Two dimensional displays","angiocardiography;computerised tomography;feature extraction;liver;medical image processing;neural nets;stereo image processing","3D medical images;ConvNet-based localization;abdomen CT scans;anatomical structure;aortic arch;ascending aorta;cardiac CT angiography;chest CT;convolutional neural network;descending aorta;heart;left cardiac ventricle;liver","","","","","","","20170223","July 2017","","IEEE","IEEE Journals & Magazines"
"Deep Convolutional Neural Networks for Computer-Aided Detection: CNN Architectures, Dataset Characteristics and Transfer Learning","H. C. Shin; H. R. Roth; M. Gao; L. Lu; Z. Xu; I. Nogues; J. Yao; D. Mollura; R. M. Summers","Imaging Biomarkers and Computer-Aided Diagnosis Laboratory","IEEE Transactions on Medical Imaging","20160503","2016","35","5","1285","1298","Remarkable progress has been made in image recognition, primarily due to the availability of large-scale annotated datasets and deep convolutional neural networks (CNNs). CNNs enable learning data-driven, highly representative, hierarchical image features from sufficient training data. However, obtaining datasets as comprehensively annotated as ImageNet in the medical imaging domain remains a challenge. There are currently three major techniques that successfully employ CNNs to medical image classification: training the CNN from scratch, using off-the-shelf pre-trained CNN features, and conducting unsupervised CNN pre-training with supervised fine-tuning. Another effective method is transfer learning, i.e., fine-tuning CNN models pre-trained from natural image dataset to medical image tasks. In this paper, we exploit three important, but previously understudied factors of employing deep convolutional neural networks to computer-aided detection problems. We first explore and evaluate different CNN architectures. The studied models contain 5 thousand to 160 million parameters, and vary in numbers of layers. We then evaluate the influence of dataset scale and spatial image context on performance. Finally, we examine when and why transfer learning from pre-trained ImageNet (via fine-tuning) can be useful. We study two specific computer-aided detection (CADe) problems, namely thoraco-abdominal lymph node (LN) detection and interstitial lung disease (ILD) classification. We achieve the state-of-the-art performance on the mediastinal LN detection, and report the first five-fold cross-validation classification results on predicting axial CT slices with ILD categories. Our extensive empirical evaluation, CNN model analysis and valuable insights can be extended to the design of high performance CAD systems for other medical imaging tasks.","0278-0062;02780062","","10.1109/TMI.2016.2528162","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7404017","Biomedical imaging;computer aided diagnosis;image analysis;machine learning;neural networks","Biomedical imaging;Computational modeling;Computed tomography;Diseases;Lungs;Lymph nodes;Solid modeling","computerised tomography;diseases;image classification;image representation;learning (artificial intelligence);lung;medical image processing;neurophysiology;reviews","CNN architectures;CNN model analysis;axial CT slices;computer-aided detection;computer-aided detection problems;dataset characteristics;deep convolutional neural networks;fine-tuning CNN models;five-fold cross-validation classification;high performance CAD systems;highly representative hierarchical image features;image recognition;interstitial lung disease classification;learning data-driven;mediastinal LN detection;medical image classification;medical image tasks;medical imaging domain;natural image dataset;off-the-shelf pretrained CNN features;pretrained imagenet;spatial image context;state-of-the-art performance;supervised fine-tuning;thoraco-abdominal lymph node detection;transfer learning;unsupervised CNN pretraining","","35","","73","","","20160211","May 2016","","IEEE","IEEE Journals & Magazines"
"Generative Adversarial Networks for Noise Reduction in Low-Dose CT","J. M. Wolterink; T. Leiner; M. A. Viergever; I. Isgum","","IEEE Transactions on Medical Imaging","","2017","PP","99","1","1","Noise is inherent to low-dose CT acquisition. We propose to train a convolutional neural network (CNN) jointly with an adversarial CNN to estimate routine-dose CT images from low-dose CT images and hence reduce noise. A generator CNN was trained to transform low-dose CT images into routine-dose CT images using voxel-wise loss minimization. An adversarial discriminator CNN was simultaneously trained to distinguish the output of the generator from routinedose CT images. The performance of this discriminator was used as an adversarial loss for the generator. Experiments were performed using CT images of an anthropomorphic phantom containing calcium inserts, as well as patient non-contrast-enhanced cardiac CT images. The phantom and patients were scanned at 20% and 100% routine clinical dose. Three training strategies were compared: the first used only voxel-wise loss, the second combined voxel-wise loss and adversarial loss, and the third used only adversarial loss. The results showed that training with only voxel-wise loss resulted in the highest peak signal-to-noise ratio with respect to reference routine-dose images. However, the CNNs trained with adversarial loss captured image statistics of routine-dose images better. Noise reduction improved quantification of low-density calcified inserts in phantom CT images and allowed coronary calcium scoring in low-dose patient CT images with high noise levels. Testing took less than 10 seconds per CT volume. CNN-based low-dose CT noise reduction in the image domain is feasible. Training with an adversarial network improves the CNN’s ability to generate images with an appearance similar to that of reference routine-dose CT images.","0278-0062;02780062","","10.1109/TMI.2017.2708987","Netherlands Organization for Health Research and Development ZonMw; ","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7934380","Low-dose cardiac CT;coronary calcium scoring;deep learning,;generative adversarial networks;noise reduction","Calcium;Computed tomography;Convolution;Generators;Noise reduction;Training;Transforms","","","","","","","","","20170526","","","IEEE","IEEE Early Access Articles"
"A deep learning based approach to classification of CT brain images","X. W. Gao; R. Hui","Department of Computer Science, Middlesex University, London NW4 4BT, UK","2016 SAI Computing Conference (SAI)","20160901","2016","","","28","31","This study explores the applicability of the state of the art of deep learning convolutional neural network (CNN) to the classification of CT brain images, aiming at bring images into clinical applications. Towards this end, three categories are clustered, which contains subjects' data with either Alzheimer's disease (AD) or lesion (e.g. tumour) or normal ageing. Specifically, due to the characteristics of CT brain images with larger thickness along depth (z) direction (~5mm), both 2D and 3D CNN are employed in this research. The fusion is therefore conducted based on both 2D CT images along axial direction and 3D segmented blocks with the accuracy rates are 88.8%, 76.7% and 95% for classes of AD, lesion and normal respectively, leading to an average of 86.8%.","","Electronic:978-1-4673-8460-5; POD:978-1-4673-8461-2","10.1109/SAI.2016.7555958","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7555958","3D CNN;CT brain images;Classification;convolutional neural network","Alzheimer's disease;Brain;Computed tomography;Kernel;Lesions;Three-dimensional displays;Two dimensional displays","computerised tomography;diseases;image classification;learning (artificial intelligence);medical image processing;neural nets","2D CNN;2D CT images;3D CNN;3D segmented blocks;AD;Alzheimer's disease;CT brain image classification;axial direction;clinical applications;deep learning based approach;deep learning convolutional neural network;lesion;normal ageing","","","","","","","","13-15 July 2016","","IEEE","IEEE Conference Publications"
"Lung Pattern Classification for Interstitial Lung Diseases Using a Deep Convolutional Neural Network","M. Anthimopoulos; S. Christodoulidis; L. Ebner; A. Christe; S. Mougiakakou","ARTORG Center for Biomedical Engineering Research, University of Bern, Switzerland","IEEE Transactions on Medical Imaging","20160429","2016","35","5","1207","1216","Automated tissue characterization is one of the most crucial components of a computer aided diagnosis (CAD) system for interstitial lung diseases (ILDs). Although much research has been conducted in this field, the problem remains challenging. Deep learning techniques have recently achieved impressive results in a variety of computer vision problems, raising expectations that they might be applied in other domains, such as medical image analysis. In this paper, we propose and evaluate a convolutional neural network (CNN), designed for the classification of ILD patterns. The proposed network consists of 5 convolutional layers with 2 × 2 kernels and LeakyReLU activations, followed by average pooling with size equal to the size of the final feature maps and three dense layers. The last dense layer has 7 outputs, equivalent to the classes considered: healthy, ground glass opacity (GGO), micronodules, consolidation, reticulation, honeycombing and a combination of GGO/reticulation. To train and evaluate the CNN, we used a dataset of 14696 image patches, derived by 120 CT scans from different scanners and hospitals. To the best of our knowledge, this is the first deep CNN designed for the specific problem. A comparative analysis proved the effectiveness of the proposed CNN against previous methods in a challenging dataset. The classification performance ( ~ 85.5%) demonstrated the potential of CNNs in analyzing lung patterns. Future work includes, extending the CNN to three-dimensional data provided by CT volume scans and integrating the proposed method into a CAD system that aims to provide differential diagnosis for ILDs as a supportive tool for radiologists.","0278-0062;02780062","","10.1109/TMI.2016.2535865","Bern University hospital Inselspital; Swiss National Science Foundation SNSF; ","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7422082","Convolutional neural networks;interstitial lung diseases;texture classification","Computed tomography;Convolution;Design automation;Diseases;Feature extraction;Lungs;Neural networks","biological tissues;computerised tomography;convolution;diseases;feature extraction;image classification;learning (artificial intelligence);lung;medical image processing;neural nets","CT volume scans;ILD pattern classification;automated tissue characterization;computer aided diagnosis system;computer vision problems;consolidation;deep convolutional neural network;deep learning techniques;feature maps;ground glass opacity;honeycombing;interstitial lung diseases;lung pattern classification;medical image analysis;micronodules;reticulation","","17","","42","","","20160229","May 2016","","IEEE","IEEE Journals & Magazines"
"Segmentation of Pulmonary CT Image by Using Convolutional Neural Network Based on Membership Function","J. Xu; H. Liu","Sch. of Comput. Sci. & Technol., Shandong Univ. of Finance & Econ., Jinan, China","2017 IEEE International Conference on Computational Science and Engineering (CSE) and IEEE International Conference on Embedded and Ubiquitous Computing (EUC)","20170810","2017","1","","198","203","The accurate segmentation of pulmonary CT images is of great significance to clinical computer-aided diagnosis and treatment. In order to avoid the explicit extraction of image features and improve the efficiency of image segmentation and reduce the influence of human factors on the segmentation results, this paper proposes a method of segmenting pulmonary CT image based on membership function convolution neural network (MFCNN). First, the method uses pulmonary CT image filtered by the Gaussian as the input data of the convolution neural network. Then, that uses the improved convolution neural network to achieve the initial segmentation of the image. Finally, the final segmentation result is obtained by setting the threshold based on this paper method. After experimental comparison, this paper demonstrates the feasibility and effectiveness of convolution neural network in the segmentation of pulmonary CT images.","","Electronic:978-1-5386-3221-5; POD:978-1-5386-3222-2; Paper:978-1-5386-3220-8","10.1109/CSE-EUC.2017.42","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8005794","convolutional neural network;image segmentation;membership function;pulmonary CT images","Computed tomography;Convolution;Feature extraction;Image segmentation;Medical diagnostic imaging;Neural networks","Gaussian processes;computerised tomography;feature extraction;feedforward neural nets;image filtering;image segmentation;medical image processing","Gaussian process;clinical computer-aided diagnosis;clinical computer-aided treatment;image feature extraction;input data;membership function convolution neural network;pulmonary CT image filtering;pulmonary CT image segmentation","","","","","","","","21-24 July 2017","","IEEE","IEEE Conference Publications"
"Multisource Transfer Learning With Convolutional Neural Networks for Lung Pattern Analysis","S. Christodoulidis; M. Anthimopoulos; L. Ebner; A. Christe; S. Mougiakakou","ARTORG Center for Biomedical Engineering Research, University of Bern, Bern, Switzerland","IEEE Journal of Biomedical and Health Informatics","20170520","2017","21","1","76","84","Early diagnosis of interstitial lung diseases is crucial for their treatment, but even experienced physicians find it difficult, as their clinical manifestations are similar. In order to assist with the diagnosis, computer-aided diagnosis systems have been developed. These commonly rely on a fixed scale classifier that scans CT images, recognizes textural lung patterns, and generates a map of pathologies. In a previous study, we proposed a method for classifying lung tissue patterns using a deep convolutional neural network (CNN), with an architecture designed for the specific problem. In this study, we present an improved method for training the proposed network by transferring knowledge from the similar domain of general texture classification. Six publicly available texture databases are used to pretrain networks with the proposed architecture, which are then fine-tuned on the lung tissue data. The resulting CNNs are combined in an ensemble and their fused knowledge is compressed back to a network with the original architecture. The proposed approach resulted in an absolute increase of about 2% in the performance of the proposed CNN. The results demonstrate the potential of transfer learning in the field of medical image analysis, indicate the textural nature of the problem and show that the method used for training a network can be as important as designing its architecture.","2168-2194;21682194","","10.1109/JBHI.2016.2636929","Bern University Hospital; 10.13039/501100001711 - Swiss National Science Foundation (SNSF); ","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7776792","Convolutional neural networks (CNNs);interstitial lung diseases (ILDs);knowledge distillation;model compression;model ensemble;texture classification;transfer learning","Biomedical imaging;Computed tomography;Databases;Knowledge engineering;Lungs;Machine learning;Training","biological tissues;computerised tomography;diseases;image classification;image texture;learning (artificial intelligence);lung;medical image processing;neural nets","CT images;computed tomography;computer-aided diagnosis;convolutional neural networks;fused knowledge compression;interstitial lung disease diagnosis;lung pattern analysis;lung tissue data;medical image analysis;multisource transfer learning;texture classification;texture databases","","","","","","","20161207","Jan. 2017","","IEEE","IEEE Journals & Magazines"
"Deep-learning strategy for pulmonary artery-vein classification of non-contrast CT images","P. Nardelli; D. Jimenez-Carretero; D. Bermejo-Peláez; M. J. Ledesma-Carbayo; F. N. Rahaghi; R. S. J. Estépar","Applied Chest Imaging Laboratory, Brigham and Women's Hospital, Boston, MA, USA","2017 IEEE 14th International Symposium on Biomedical Imaging (ISBI 2017)","20170619","2017","","","384","387","Artery-vein classification on pulmonary computed tomography (CT) images is becoming of high interest in the scientific community due to the prevalence of pulmonary vascular disease that affects arteries and veins through different mechanisms. In this work, we present a novel approach to automatically segment and classify vessels from chest CT images. We use a scale-space particle segmentation to isolate vessels, and combine a convolutional neural network (CNN) to graph-cut (GC) to classify the single particles. Information about proximity of arteries to airways is learned by the network by means of a bronchus enhanced image. The methodology is evaluated on the superior and inferior lobes of the right lung of twenty clinical cases. Comparison with manual classification and a Random Forests (RF) classifier is performed. The algorithm achieves an overall accuracy of 87% when compared to manual reference, which is higher than the 73% accuracy achieved by RF.","","Electronic:978-1-5090-1172-8; POD:978-1-5090-1173-5","10.1109/ISBI.2017.7950543","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7950543","Artery-vein segmentation;Frangi filter;convolutional neural networks;lung","Arteries;Computed tomography;Image segmentation;Lungs;Manuals;Radio frequency;Veins","blood vessels;computerised tomography;image classification;image segmentation;learning (artificial intelligence);neural nets","computed tomography;convolutional neural network;deep-learning strategy;noncontrast CT images;pulmonary artery-vein classification;random forests classifier;scale-space particle segmentation","","","","","","","","18-21 April 2017","","IEEE","IEEE Conference Publications"
"Combining Generative and Discriminative Representation Learning for Lung CT Analysis With Convolutional Restricted Boltzmann Machines","G. van Tulder; M. de Bruijne","Biomedical Imaging Group, Erasmus MC, Rotterdam, The Netherlands","IEEE Transactions on Medical Imaging","20160429","2016","35","5","1262","1272","The choice of features greatly influences the performance of a tissue classification system. Despite this, many systems are built with standard, predefined filter banks that are not optimized for that particular application. Representation learning methods such as restricted Boltzmann machines may outperform these standard filter banks because they learn a feature description directly from the training data. Like many other representation learning methods, restricted Boltzmann machines are unsupervised and are trained with a generative learning objective; this allows them to learn representations from unlabeled data, but does not necessarily produce features that are optimal for classification. In this paper we propose the convolutional classification restricted Boltzmann machine, which combines a generative and a discriminative learning objective. This allows it to learn filters that are good both for describing the training data and for classification. We present experiments with feature learning for lung texture classification and airway detection in CT images. In both applications, a combination of learning objectives outperformed purely discriminative or generative learning, increasing, for instance, the lung tissue classification accuracy by 1 to 8 percentage points. This shows that discriminative learning can help an otherwise unsupervised feature learner to learn filters that are optimized for classification.","0278-0062;02780062","","10.1109/TMI.2016.2526687","10.13039/501100003246 - Nederlandse Organisatie voor Wetenschappelijk Onderzoek; ","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7401039","Deep learning;X-ray imaging and computed tomography;lung;machine learning;neural network;pattern recognition and classification;representation learning;restricted Boltzmann machine;segmentation","Computed tomography;Feature extraction;Learning systems;Lungs;Neural networks;Standards;Training data","Boltzmann machines;biological tissues;channel bank filters;computerised tomography;feature extraction;image classification;image filtering;image texture;lung;medical image processing;pneumodynamics","airway detection;convolutional restricted Boltzmann machines;discriminative representation learning;feature description;generative learning objective;generative representation learning;lung CT analysis;lung texture classification;lung tissue classification accuracy;standard predefined filter banks;tissue classification system;training data;unlabeled data representations","","5","","47","","","20160208","May 2016","","IEEE","IEEE Journals & Magazines"
"Off-the-shelf convolutional neural network features for pulmonary nodule detection in computed tomography scans","B. van Ginneken; A. A. A. Setio; C. Jacobs; F. Ciompi","Diagnostic Image Analysis Group, Radboud University Medical Center, Nijmegen, The Netherlands","2015 IEEE 12th International Symposium on Biomedical Imaging (ISBI)","20150723","2015","","","286","289","Convolutional neural networks (CNNs) have emerged as the most powerful technique for a range of different tasks in computer vision. Recent work suggested that CNN features are generic and can be used for classification tasks outside the exact domain for which the networks were trained. In this work we use the features from one such network, OverFeat, trained for object detection in natural images, for nodule detection in computed tomography scans. We use 865 scans from the publicly available LIDC data set, read by four thoracic radiologists. Nodule candidates are generated by a state-of-the-art nodule detection system. We extract 2D sagittal, coronal and axial patches for each nodule candidate and extract 4096 features from the penultimate layer of OverFeat and classify these with linear support vector machines. We show for various configurations that the off-the-shelf CNN features perform surprisingly well, but not as good as the dedicated detection system. When both approaches are combined, significantly better results are obtained than either approach alone. We conclude that CNN features have great potential to be used for detection tasks in volumetric medical data.","1945-7928;19457928","Electronic:978-1-4799-2374-8; POD:978-1-4673-9330-0","10.1109/ISBI.2015.7163869","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7163869","Nodule detection;computed tomography;convolutional neural networks","Biomedical imaging;Cancer;Computed tomography;Design automation;Feature extraction;Lesions;Lungs","computerised tomography;feature extraction;image classification;medical image processing;neural nets;support vector machines","2D sagittal;CNN features;LIDC data set;OverFeat features;axial patches;computed tomography scans;coronal patches;feature extraction;image classification;linear support vector machines;object detection;off-the-shelf convolutional neural network features;pulmonary nodule detection;thoracic radiologists;volumetric medical data","","12","","11","","","","16-19 April 2015","","IEEE","IEEE Conference Publications"
"Atherosclerotic vascular calcification detection and segmentation on low dose computed tomography scans using convolutional neural networks","K. Chellamuthu; J. Liu; J. Yao; M. Bagheri; L. Lu; V. Sandfort; R. M. Summers","Imaging Biomarkers and Computer-aided Diagnosis Laboratory, Radiology and Imaging Sciences, National Institutes of Health Clinical Center, Building 10 Room 1C224 MSC 1182, Bethesda, MD 20892-1182, United States of America","2017 IEEE 14th International Symposium on Biomedical Imaging (ISBI 2017)","20170619","2017","","","388","391","We propose an automated platform for extra-coronary calcification detection on low dose CT scans. We utilize faster regional convolutional neural networks (R-CNN) to directly detect calcifications at the lesion-level without performing vessel extraction. To segment detected calcifications at the voxel-level, we employ holistically nested edge detection (HED). CT scans of 112 vasculitis patients and 3219 images with labeled calcifications were used to develop and evaluate our method. By employing a two-class faster R-CNN, the average precision (AP) increased from 49.2% to 84.4% for calcification detection. In addition, sensitivity of 85.0% at 1 false positive per image was observed. The Dice Similarity Coefficient (DSC) for calcification segmentation using HED (0.83±0.08) was significantly better (p≪0.01) than the traditional threshold-based method (0.59±0.26).","","Electronic:978-1-5090-1172-8; POD:978-1-5090-1173-5","10.1109/ISBI.2017.7950544","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7950544","CNNs;Calcification;HED;plaque;region proposal","Atherosclerosis;Computed tomography;Computer vision;Image edge detection;Image segmentation;Proposals","blood vessels;computerised tomography;diseases;feature extraction;image segmentation;medical image processing;neural nets","Dice similarity coefficient;atherosclerotic vascular calcification detection;average precision;convolutional neural networks;extracoronary calcification detection;holistically nested edge detection;low dose CT scans;low dose computed tomography scans;segmentation method;threshold-based method;vasculitis patients;vessel extraction;voxel-level","","","","","","","","18-21 April 2017","","IEEE","IEEE Conference Publications"
"Convolutional neural networks for lung cancer screening in computed tomography (CT) scans","P. Rao; N. A. Pereira; R. Srinivasan","Department of Electronics and Communication Engineering, M. S. Ramaiah Institute of Technology, Bengaluru 560054, India","2016 2nd International Conference on Contemporary Computing and Informatics (IC3I)","20170504","2016","","","489","493","Diagnosis and cure of cancer has been one of the biggest challenges faced by mankind in the last few decades. Early detection of cancer would facilitate in saving millions of lives across the globe every year. This paper presents an approach which uses a Convolutional Neural Network (CNNs) to classify tumours seen in lung cancer screening computed tomography scans as malignant or benign. CNNs have special properties such as spatial invariance, and allow for multiple feature extraction. When such layers are cascaded, leading to Deep CNNs, it has been shown widely that the accuracy of prediction increases dramatically. In this work, we have designed a CNN suitable for the analysis of CT scans with tumours, using domain knowledge from both medicine and neural networks. The results show that the accuracy of classification for our network performs better than both the traidtional neural networks, and also existing CNNs built for image classification purposes.","","Electronic:978-1-5090-5256-1; POD:978-1-5090-5257-8; USB:978-1-5090-5255-4","10.1109/IC3I.2016.7918014","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7918014","","Cancer;Computed tomography;Computer architecture;Convolution;Feature extraction;Neural networks;Tumors","cancer;computerised tomography;feature extraction;feedforward neural nets;image classification;lung;medical image processing","CT scan analysis;cancer detection;cancer diagnosis;computed tomography scans;convolutional neural networks;deep CNN;feature extraction;image classification purposes;lung cancer screening;tumour classification","","","","","","","","14-17 Dec. 2016","","IEEE","IEEE Conference Publications"
"Deep Features Learning for Medical Image Analysis with Convolutional Autoencoder Neural Network","M. Chen; X. Shi; Y. Zhang; D. Wu; M. Guizani","School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, HuBei China (e-mail: minchen@ieee.org)","IEEE Transactions on Big Data","","2017","PP","99","1","1","At present, computed tomography (CT) are widely used to assist diagnosis. Especially, computer aided diagnosis (CAD) based on artificial intelligence (AI) is an extremely important research field in intelligent healthcare. However, it is a great challenge to establish an adequate labeled dataset for CT analysis assistance, due to the privacy and security issues. Therefore, this paper proposes a convolutional autoencoder deep learning framework to support unsupervised image features learning for lung nodule through unlabeled data, which only needs a small amount of labeled data for efficient feature learning. Through comprehensive experiments, it evaluates that the proposed scheme is superior to other approaches, which effectively solves the intrinsic labor-intensive problem during of artificial image labeling. Moreover, it verifies that the proposed convolutional autoencoder approach can be extended for similarity measurement of lung nodules images. Especially, the features extracted through unsupervised learning are also applicable in other related scenarios.","","","10.1109/TBDATA.2017.2717439","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7954012","Convolutional autoencoder neural network;Feature learning;Hand-craft feature;Lung nodule;Unsupervised learning","Biomedical imaging;Computed tomography;Convolutional codes;Feature extraction;Image analysis;Lungs;Training","","","","","","","","","20170620","","","IEEE","IEEE Early Access Articles"
"Colitis detection on computed tomography using regional convolutional neural networks","J. Liu; D. Wang; Z. Wei; L. Lu; L. Kim; E. Turkbey; R. M. Summers","Imaging Biomarkers and Computer-aided Diagnosis Laboratory, Radiology and Imaging Sciences, National Institutes of Health Clinical Center, Building 10 Room 1C224 MSC 1182, Bethesda, MD 20892-1182","2016 IEEE 13th International Symposium on Biomedical Imaging (ISBI)","20160616","2016","","","863","866","Colitis is inflammation of the colon that is frequently associated with infection and immune compromise. The wall of a colon afflicted with colitis is much thicker than normal. Colitis can be debilitating or life threatening, and early detection is essential to initiate proper treatment. In this work, we apply high-capacity convolutional neural net-works (CNNs) to bottom-up region proposals to detect potential colitis on CT scans. Our method first generates around 3000 category-independent region proposals for each slice of the input CT scan using selective search. Then, a fixed-length feature vector is extracted from each region proposal using a CNN. Finally, each region proposal is classified and assigned a confidence score with a linear SVM. We applied the detection method to 448 images from 56 CT scans of patients with colitis for evaluation. The detection system achieved 85% sensitivity at 1 false positive per image.","","Electronic:978-1-4799-2349-6; POD:978-1-4799-2351-9","10.1109/ISBI.2016.7493402","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7493402","CNNs;Colitis;Region proposal;SVM","Biological neural networks;Colon;Computed tomography;Feature extraction;Image segmentation;Proposals;Support vector machines","computerised tomography;diseases;feature extraction;image classification;medical image processing;support vector machines","CT scans;bottom-up region;category-independent region;classification;colitis detection;colon inflammation;computed tomography;detection method;early detection;fixed-length feature vector;high-capacity convolutional neural networks;immune compromise;infection;life threatening;linear SVM;potential colitis;regional convolutional neural networks","","","","20","","","","13-16 April 2016","","IEEE","IEEE Conference Publications"
"Detecting Anatomical Landmarks From Limited Medical Imaging Data Using Two-Stage Task-Oriented Deep Neural Networks","J. Zhang; M. Liu; D. Shen","Department of Radiology and the Biomedical Research Imaging Center, University of North Carolina at Chapel Hill, Chapel Hill, NC, USA","IEEE Transactions on Image Processing","20170718","2017","26","10","4753","4764","One of the major challenges in anatomical landmark detection, based on deep neural networks, is the limited availability of medical imaging data for network learning. To address this problem, we present a two-stage task-oriented deep learning method to detect large-scale anatomical landmarks simultaneously in real time, using limited training data. Specifically, our method consists of two deep convolutional neural networks (CNN), with each focusing on one specific task. Specifically, to alleviate the problem of limited training data, in the first stage, we propose a CNN based regression model using millions of image patches as input, aiming to learn inherent associations between local image patches and target anatomical landmarks. To further model the correlations among image patches, in the second stage, we develop another CNN model, which includes a) a fully convolutional network that shares the same architecture and network weights as the CNN used in the first stage and also b) several extra layers to jointly predict coordinates of multiple anatomical landmarks. Importantly, our method can jointly detect large-scale (e.g., thousands of) landmarks in real time. We have conducted various experiments for detecting 1200 brain landmarks from the 3D T1-weighted magnetic resonance images of 700 subjects, and also 7 prostate landmarks from the 3D computed tomography images of 73 subjects. The experimental results show the effectiveness of our method regarding both accuracy and efficiency in the anatomical landmark detection.","1057-7149;10577149","","10.1109/TIP.2017.2721106","10.13039/100000002 - NIH; ","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7961205","Anatomical landmark detection;deep convolutional neural networks;limited medical imaging data;real-time;task-oriented","Biological neural networks;Biomedical imaging;Machine learning;Testing;Three-dimensional displays;Training;Training data","biomedical MRI;computerised tomography;feedforward neural nets;learning (artificial intelligence);medical image processing;object detection;regression analysis","3D T1-weighted magnetic resonance images;3D computed tomography images;CNN based regression model;anatomical landmark coordinate prediction;anatomical landmark detection;brain landmarks;deep convolutional neural networks;fully convolutional network;local image patches;medical imaging data;network learning;prostate landmarks;training data;two-stage task-oriented deep learning method;two-stage task-oriented deep neural networks","","","","","","","20170628","Oct. 2017","","IEEE","IEEE Journals & Magazines"
"A CNN Regression Approach for Real-Time 2D/3D Registration","S. Miao; Z. J. Wang; R. Liao","Department of Electrical and Computer Engineering, University of British Columbia, Vancouver","IEEE Transactions on Medical Imaging","20160429","2016","35","5","1352","1363","In this paper, we present a Convolutional Neural Network (CNN) regression approach to address the two major limitations of existing intensity-based 2-D/3-D registration technology: 1) slow computation and 2) small capture range. Different from optimization-based methods, which iteratively optimize the transformation parameters over a scalar-valued metric function representing the quality of the registration, the proposed method exploits the information embedded in the appearances of the digitally reconstructed radiograph and X-ray images, and employs CNN regressors to directly estimate the transformation parameters. An automatic feature extraction step is introduced to calculate 3-D pose-indexed features that are sensitive to the variables to be regressed while robust to other factors. The CNN regressors are then trained for local zones and applied in a hierarchical manner to break down the complex regression task into multiple simpler sub-tasks that can be learned separately. Weight sharing is furthermore employed in the CNN regression model to reduce the memory footprint. The proposed approach has been quantitatively evaluated on 3 potential clinical applications, demonstrating its significant advantage in providing highly accurate real-time 2-D/3-D registration with a significantly enlarged capture range when compared to intensity-based methods.","0278-0062;02780062","","10.1109/TMI.2016.2521800","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7393571","2-D/3-D registration;convolutional neural network;deep learning;image guided intervention","Attenuation;Biomedical imaging;Computed tomography;Feature extraction;Real-time systems;X-ray imaging","diagnostic radiography;feature extraction;image reconstruction;image registration;iterative methods;medical image processing;neural nets;optimisation;regression analysis","3D pose-indexed features;CNN regression approach;CNN regressors;X-ray images;automatic feature extraction step;complex regression task;convolutional neural network regression approach;digitally reconstructed radiograph;formation parameters;intensity-based 2D-3D registration technology;intensity-based methods;iterative optimization;memory footprint;multiple simpler subtasks;optimization-based methods;real-time 2D-3D registration;scalar-valued metric function;transformation parameters","","4","","31","","","20160126","May 2016","","IEEE","IEEE Journals & Magazines"
"Convolutional neural networks for predicting molecular profiles of non-small cell lung cancer","D. Yu; M. Zhou; F. Yang; D. Dong; O. Gevaert; Z. Liu; J. Shi; J. Tian","The Key Laboratory of Molecular Imaging, Institute of Automation, Chinese Academy of Sciences, China","2017 IEEE 14th International Symposium on Biomedical Imaging (ISBI 2017)","20170619","2017","","","569","572","Quantitative imaging biomarkers identification has become a powerful tool for predictive diagnosis given increasingly available clinical imaging data. In parallel, molecular profiles have been well documented in non-small cell lung cancers (NSCLCs). However, there has been limited studies on leveraging the two major sources for improving lung cancer computer-aided diagnosis. In this paper, we investigate the problem of predicting molecular profiles with CT imaging arrays in NSCLC. In particular, we formulate a discriminative convolutional neural network to learn deep features for predicting epidermal growth factor receptor (EGFR) mutation states that are associated with cancer cell growth. We evaluated our approach on two independent datasets including a discovery set with 595 patients (Datset1) and a validation set with 89 patients (Dataset2). Extensive experimental results demonstrated that the learned CNN-based features are effective in predicting EGFR mutation states (AUC=0.828, ACC=76.16%) on Dataset1, and it further demonstrated generalized predictive performance (AUC=0.668, ACC=67.55%) on Dataset2.","","Electronic:978-1-5090-1172-8; POD:978-1-5090-1173-5","10.1109/ISBI.2017.7950585","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7950585","Computed tomography;Computed-aided diagnosis;Convolutional neural networks;Non-Small Cell Lung Carcinoma","Cancer;Computed tomography;Convolution;Feature extraction;Lungs;Neural networks","cancer;cellular biophysics;computerised tomography;feature extraction;lung;medical image processing;molecular biophysics;neural nets;proteins","CT imaging arrays;EGFR mutation state prediction;biomarker identification;cancer cell growth;clinical imaging data;discriminative convolutional neural network;epidermal growth factor receptor;learned CNN-based feature;lung cancer computer-aided diagnosis;molecular profile;nonsmall cell lung cancer;quantitative imaging","","","","","","","","18-21 April 2017","","IEEE","IEEE Conference Publications"
"Pulmonary Nodule Detection in CT Images: False Positive Reduction Using Multi-View Convolutional Networks","A. A. A. Setio; F. Ciompi; G. Litjens; P. Gerke; C. Jacobs; S. J. van Riel; M. M. W. Wille; M. Naqibullah; C. I. Sánchez; B. van Ginneken","Diagnostic Image Analysis Group at the Department of Radiology and Nuclear Medicine, Radboud University Medical Center, Nijmegen, The Netherlands","IEEE Transactions on Medical Imaging","20160429","2016","35","5","1160","1169","We propose a novel Computer-Aided Detection (CAD) system for pulmonary nodules using multi-view convolutional networks (ConvNets), for which discriminative features are automatically learnt from the training data. The network is fed with nodule candidates obtained by combining three candidate detectors specifically designed for solid, subsolid, and large nodules. For each candidate, a set of 2-D patches from differently oriented planes is extracted. The proposed architecture comprises multiple streams of 2-D ConvNets, for which the outputs are combined using a dedicated fusion method to get the final classification. Data augmentation and dropout are applied to avoid overfitting. On 888 scans of the publicly available LIDC-IDRI dataset, our method reaches high detection sensitivities of 85.4% and 90.1% at 1 and 4 false positives per scan, respectively. An additional evaluation on independent datasets from the ANODE09 challenge and DLCST is performed. We showed that the proposed multi-view ConvNets is highly suited to be used for false positive reduction of a CAD system.","0278-0062;02780062","","10.1109/TMI.2016.2536809","The Netherlands Organization for Scientific Research; ","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7422783","Computed tomography;computer-aided detection;convolutional networks;deep learning;lung cancer;pulmonary nodule","Cancer;Computed tomography;Design automation;Feature extraction;Lesions;Lungs;Solids","cancer;computerised tomography;feature extraction;image classification;image fusion;medical image processing;tumours","2D ConvNets;2D patches;ANODE09 challenge;CAD system;CT images;computer-aided detection system;data augmentation;dedicated fusion method;differently oriented planes;discriminative features;false positive reduction;final classification;multiple streams;multiview ConvNets;multiview convolutional networks;nodule candidates;publicly available LIDC-IDRI dataset;pulmonary nodule detection;training data","","10","1","47","","","20160301","May 2016","","IEEE","IEEE Journals & Magazines"
"A Bottom-Up Approach for Pancreas Segmentation Using Cascaded Superpixels and (Deep) Image Patch Labeling","A. Farag; L. Lu; H. R. Roth; J. Liu; E. Turkbey; R. M. Summers","Department of Radiology and Imaging Sciences, Imaging Biomarkers and Computer-Aided Diagnosis Laboratory, National Institutes of Health Clinical Center, Bethesda, MD, USA","IEEE Transactions on Image Processing","20161124","2017","26","1","386","399","Robust organ segmentation is a prerequisite for computer-aided diagnosis, quantitative imaging analysis, pathology detection, and surgical assistance. For organs with high anatomical variability (e.g., the pancreas), previous segmentation approaches report low accuracies, compared with well-studied organs, such as the liver or heart. We present an automated bottom-up approach for pancreas segmentation in abdominal computed tomography (CT) scans. The method generates a hierarchical cascade of information propagation by classifying image patches at different resolutions and cascading (segments) superpixels. The system contains four steps: 1) decomposition of CT slice images into a set of disjoint boundary-preserving superpixels; 2) computation of pancreas class probability maps via dense patch labeling; 3) superpixel classification by pooling both intensity and probability features to form empirical statistics in cascaded random forest frameworks; and 4) simple connectivity based post-processing. Dense image patch labeling is conducted using two methods: efficient random forest classification on image histogram, location and texture features; and more expensive (but more accurate) deep convolutional neural network classification, on larger image windows (i.e., with more spatial contexts). Over-segmented 2-D CT slices by the simple linear iterative clustering approach are adopted through model/parameter calibration and labeled at the superpixel level for positive (pancreas) or negative (non-pancreas or background) classes. The proposed method is evaluated on a data set of 80 manually segmented CT volumes, using six-fold cross-validation. Its performance equals or surpasses other state-of-the-art methods (evaluated by “leave-one-patient-out”), with a dice coefficient of 70.7% and Jaccard index of 57.9%. In addition, the computational efficiency has improved significantly, requiring a - ere 6 ~ 8 min per testing case, versus ≥ 10 h for other methods. The segmentation framework using deep patch labeling confidences is also more numerically stable, as reflected in the smaller performance metric standard deviations. Finally, we implement a multi-atlas label fusion (MALF) approach for pancreas segmentation using the same data set. Under six-fold cross-validation, our bottom-up segmentation method significantly outperforms its MALF counterpart: 70.7±13.0% versus 52.51±20.84% in dice coefficients.","1057-7149;10577149","","10.1109/TIP.2016.2624198","10.13039/100000098 - Intramural Research Program of the National Institutes of Health Clinical Center; ","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7727966","Abdominal computed tomography (CT);cascaded random forest;deep convolutional neural networks;dense image patch labeling;pancreas segmentation","Computed tomography;Image segmentation;Labeling;Liver;Pancreas;Shape","biological organs;computerised tomography;image segmentation;iterative methods;learning (artificial intelligence);medical image processing;neural nets;probability","CT slice image decomposition;abdominal computed tomography scans;bottom-up approach;cascaded superpixels;computer-aided diagnosis;deep convolutional neural network classification;deep image patch labeling;dense patch labeling;disjoint boundary-preserving superpixels;image histogram;image location;linear iterative clustering approach;model-parameter calibration;multiatlas label fusion approach;pancreas class probability maps;pancreas segmentation;pathology detection;probability features;quantitative imaging analysis;random forest classification;superpixel classification;surgical assistance;texture features","","","","","","","20161101","Jan. 2017","","IEEE","IEEE Journals & Magazines"
"Self supervised deep representation learning for fine-grained body part recognition","P. Zhang; F. Wang; Y. Zheng","Medical Imaging Technologies, Siemens Medical Solutions USA Inc., Princeton, NJ 08540, USA","2017 IEEE 14th International Symposium on Biomedical Imaging (ISBI 2017)","20170619","2017","","","578","582","Difficulty on collecting annotated medical images leads to lack of enough supervision and makes discrimination tasks challenging. However, raw data, e.g., spatial context information from 3D CT images, even without annotation, may contain rich useful information. In this paper, we exploit spatial context information as a source of supervision to solve discrimination tasks for fine-grained body part recognition with conventional 3D CT and MR volumes. The proposed pipeline consists of two steps: 1) pre-train a convolutional network for an auxiliary task of 2D slices ordering in a self-supervised manner; 2) transfer and fine-tune the pre-trained network for fine-grained body part recognition. Without any use of human annotation in the first stage, the pre-trained network can still outperform CNN trained from scratch on CT as well as M-R data. Moreover, by comparing with pre-trained CNN from ImageNet, we discover that the distance between source and target tasks plays a crucial role in transfer learning. Our experiments demonstrate that our approach can achieve high accuracy with a slice location estimation error of only a few slices on CT and MR data. To the best of our knowledge, our work is the first attempt studying the problem of robust body part recognition at a continuous level.","","Electronic:978-1-5090-1172-8; POD:978-1-5090-1173-5","10.1109/ISBI.2017.7950587","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7950587","Body Part Recognition;Self Supervised Learning;Slice Ordering","Biomedical imaging;Computed tomography;Context;Image recognition;Three-dimensional displays;Training;Two dimensional displays","biomedical MRI;computerised tomography;image recognition;learning (artificial intelligence);medical image processing","3D CT;MR volumes;fine-grained body part recognition;self supervised deep representation learning;spatial context information;transfer learning","","","","","","","","18-21 April 2017","","IEEE","IEEE Conference Publications"
