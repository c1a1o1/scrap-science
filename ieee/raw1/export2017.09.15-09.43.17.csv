"http://ieeexplore.ieee.org/search/searchresult.jsp?bulkSetSize=2000&rowsPerPage%3D75%26queryText%3DConvolutional+mri",2017/09/15 09:43:17
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","License","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"Residual and plain convolutional neural networks for 3D brain MRI classification","S. Korolev; A. Safiullin; M. Belyaev; Y. Dodonova","Skolkovo Institute of Science and Technology, Russia","2017 IEEE 14th International Symposium on Biomedical Imaging (ISBI 2017)","20170619","2017","","","835","838","In the recent years there have been a number of studies that applied deep learning algorithms to neuroimaging data. Pipelines used in those studies mostly require multiple processing steps for feature extraction, although modern advancements in deep learning for image classification can provide a powerful framework for automatic feature generation and more straightforward analysis. In this paper, we show how similar performance can be achieved skipping these feature extraction steps with the residual and plain 3D convolutional neural network architectures. We demonstrate the performance of the proposed approach for classification of Alzheimer's disease versus mild cognitive impairment and normal controls on the Alzheimers Disease National Initiative (ADNI) dataset of 3D structural MRI brain scans.","","Electronic:978-1-5090-1172-8; POD:978-1-5090-1173-5","10.1109/ISBI.2017.7950647","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7950647","Alzheimer's Disease;Convolutional Neural Network;Deep Learning;MRI;Residual Neural Network","Alzheimer's disease;Biological neural networks;Feature extraction;Machine learning;Magnetic resonance imaging;Three-dimensional displays","biomedical MRI;brain;cognition;diseases;feature extraction;image classification;learning (artificial intelligence);medical image processing;neural net architecture","3D brain MRI classification;3D plain convolutional neural network architecture;3D residual convolutional neural network architecture;3D structural MRI brain scans;ADNI dataset;Alzheimers disease national initiative dataset;cognitive impairment;deep learning algorithms;feature extraction;feature generation;image classification;neuroimaging data","","","","","","","","18-21 April 2017","","IEEE","IEEE Conference Publications"
"Brain MRI super-resolution using deep 3D convolutional networks","C. H. Pham; A. Ducournau; R. Fablet; F. Rousseau","Institut Mines T&#x00E9;l&#x00E9;com Atlantique, LaTIM U1101 INSERM, France","2017 IEEE 14th International Symposium on Biomedical Imaging (ISBI 2017)","20170619","2017","","","197","200","Example-based single image super-resolution (SR) has recently shown outcomes with high reconstruction performance. Several methods based on neural networks have successfully introduced techniques into SR problem. In this paper, we propose a three-dimensional (3D) convolutional neural network to generate high-resolution (HR) brain image from its input low-resolution (LR) with the help of patches of other HR brain images. Our work demonstrates the need of fitting data and network parameters for 3D brain MRI.","","Electronic:978-1-5090-1172-8; POD:978-1-5090-1173-5","10.1109/ISBI.2017.7950500","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7950500","3D convolutional neural network;Super-resolution;brain MRI","Biological neural networks;Image resolution;Image restoration;Magnetic resonance imaging;Three-dimensional displays;Training;Two dimensional displays","biomedical MRI;brain;image reconstruction;image resolution;medical image processing;neural nets;neurophysiology","3D brain MRI;HR brain images;SR problem;brain MRI super-resolution;data fitting;deep 3D convolutional networks;example-based single image super-resolution;high reconstruction performance;high-resolution brain image;input low-resolution;network parameters;neural networks;three-dimensional convolutional neural network","","","","","","","","18-21 April 2017","","IEEE","IEEE Conference Publications"
"Biopsy-guided learning with deep convolutional neural networks for Prostate Cancer detection on multiparametric MRI","Y. Tsehay; N. Lay; X. Wang; J. T. Kwak; B. Turkbey; P. Choyke; P. Pinto; B. Wood; R. M. Summers","Imaging Biomarkers and Computer-Aided Diagnosis Laboratory, Department of Radiology and Imaging Science, National Institute of Health, Clinical Center, Bethesda, MD 20892, United States of America","2017 IEEE 14th International Symposium on Biomedical Imaging (ISBI 2017)","20170619","2017","","","642","645","Prostate Cancer (PCa) is highly prevalent and is the second most common cause of cancer-related deaths in men. Multiparametric MRI (mpMRI) is robust in detecting PCa. We developed a weakly supervised computer-aided detection (CAD) system that uses biopsy points to learn to identify PCa on mpMRI. Our CAD system, which is based on a deep convolutional neural network architecture, yielded an area under the curve (AUC) of 0.903±0.009 on a receiver operation characteristic (ROC) curve computed on 10 different models in a 10 fold cross-validation. 9 of the 10 ROCs were statistically significantly different from a competing support vector machine based CAD, which yielded a 0.86 AUC when tested on the same dataset (α = 0.05). Furthermore, our CAD system proved to be more robust in detecting high-grade transition zone lesions.","","Electronic:978-1-5090-1172-8; POD:978-1-5090-1173-5","10.1109/ISBI.2017.7950602","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7950602","Biopsy Database;Computer-Aided Detection;Holistically-nested Edge Detection;Prostate;Prostate-CAD;Radiology","Biopsy;Databases;Lesions;Principal component analysis;Solid modeling;Training","biomedical MRI;cancer;learning (artificial intelligence);medical image processing;neural nets;sensitivity analysis;support vector machines","biopsy-guided learning;computer-aided detection;deep convolutional neural network;multiparametric MRI;prostate cancer detection;receiver operation characteristic curve;support vector machine","","","","","","","","18-21 April 2017","","IEEE","IEEE Conference Publications"
"Identifying Carotid Plaque Composition in MRI with Convolutional Neural Networks","Y. Dong; Y. Pan; X. Zhao; R. Li; C. Yuan; W. Xu","Inst. for Interdiscipl. Inf. Sci., Tsinghua Univ., Beijing, China","2017 IEEE International Conference on Smart Computing (SMARTCOMP)","20170615","2017","","","1","8","Carotid plaques may cause strokes. The composition of the plaque helps assessing the risk. Magnetic resonance imaging (MRI) is a powerful technology for analyzing the composition. It is both tedious and error-prone for a human radiologist to review such images. Traditional computer-aided diagnosis tools use manually crafted features that lack both generality and accuracy. We propose a novel approach using Deep convolutional neural networks (CNN) to classify these plaque tissues. In order to accommodate the multi-contrast MRI images, we modify state-of-the-art CNN models to support different number of input channels, and also adapt the models to do pixel- wise predictions. On a dataset with 1,098 human subjects, we show that we achieve significantly better accuracy than previous models. Our result also indicates interesting relations between contrast weightings and tissue types.","","Electronic:978-1-5090-6517-2; POD:978-1-5090-6518-9","10.1109/SMARTCOMP.2017.7947015","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7947015","","Adaptation models;Atherosclerosis;Biomedical imaging;Hemorrhaging;Magnetic resonance imaging;Neural networks","biomedical MRI;feedforward neural nets;medical image processing","CNN;carotid plaque composition;contrast weightings;deep convolutional neural networks;human radiologist;magnetic resonance imaging;multicontrast MRI images;plaque tissues;tissue types","","","","","","","","29-31 May 2017","","IEEE","IEEE Conference Publications"
"On hierarchical brain tumor segmentation in MRI using fully convolutional neural networks: A preliminary study","S. Pereira; A. Oliveira; V. Alves; C. A. Silva","CMEMS-UMinho Research Unit, University of Minho, Guimar&#x00E3;es, Portugal","2017 IEEE 5th Portuguese Meeting on Bioengineering (ENBENG)","20170330","2017","","","1","4","Magnetic Resonance Imaging is the preferred imaging modality for assessing brain tumors, and segmentation is necessary for diagnosis and treatment planning. Thus, robust automatic segmentation methods are required. Machine learning proposals where the model is learned from data are quite successful. Hierarchical segmentation approaches firstly segment the whole tumor, followed by intra-tumor tissue identification. However, results comparing it with single stages approaches are needed, as state of the art results are also achieved by all-at-once strategies. Currently, fully convolutional networks approaches for segmentation are very efficient. In this paper, a hierarchical approach for brain tumor segmentation using a fully convolutional network is studied. The evaluation is performed on the Brain Tumor Segmentation Challenge 2013 dataset, and we report the metrics Dice Score Coefficient, Positive Predictive Value, and Sensitivity. Results show benefits from segmenting the complete tumor first, over all tissues in one stage. Moreover, the tumor core also benefits from such approach. This behavior may be justified by the high data imbalance observed between tumor and normal tissues, which is mitigated by considering the tumor as a whole.","","Electronic:978-1-5090-4801-4; POD:978-1-5090-4802-1","10.1109/ENBENG.2017.7889452","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7889452","Brain tumor segmentation;Convolutional neural network;Magnetic Resonance Imaging","Image segmentation;Magnetic resonance imaging;Neural networks;Sensitivity;Training;Tumors","biomedical MRI;brain;image segmentation;medical image processing;neural nets;tumours","MRI;hierarchical brain tumor segmentation;machine learning;magnetic resonance imaging;neural networks","","","","","","","","16-18 Feb. 2017","","IEEE","IEEE Conference Publications"
"Mental Disease Feature Extraction with MRI by 3D Convolutional Neural Network with Multi-channel Input","L. Cao; Z. Liu; X. He; Y. Cao; K. Li","Sch. of Inf. Sci. & Eng., Shandong Univ., Jinan, China","2016 IEEE International Conference on Smart Cloud (SmartCloud)","20161226","2016","","","224","227","Magnetic resonance imaging (MRI) plays an important role in early diagnosis, which can accurately capture the disease variations of the anatomical brain structure. We propose a novel method for improving feature extraction performance from magnetic resonance images (MRI). This study presents a combination of multi-channel input and 3D convolutional neural network architecture which can reduce the feature dimensionality. Multi-channel input scheme is devised to apply prior knowledge on MRI original inputs in order to overcame possibly uncertainty and unsteadiness on the final features. While, the 3D-CNN model can simultaneously extract features from spatial and temporal dimensions for purpose of capturing the variations of constructive information.","","Electronic:978-1-5090-5263-9; POD:978-1-5090-5264-6","10.1109/SmartCloud.2016.38","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7796178","3D convolutional neural network;MRI;Multi-channel input;feature extraction","Convolution;Feature extraction;Kernel;Magnetic resonance imaging;Three-dimensional displays;Wavelet transforms","biomedical MRI;brain;convolution;diseases;feature extraction;medical image processing;neural nets;patient diagnosis;stereo image processing","3D convolutional neural network;MRI;anatomical brain structure;diagnosis;magnetic resonance imaging;mental disease feature extraction;multichannel input","","","","","","","","18-20 Nov. 2016","","IEEE","IEEE Conference Publications"
"MRI image segmentation by fully convolutional networks","Y. Wang; Z. Sun; C. Liu; W. Peng; J. Zhang","Key Laboratory of Convergence Medical Engineering System and Healthcare Technology, the Ministry of Industry and Information Technology, School of Life Science, Beijing Institute of Technology, Beijing, China","2016 IEEE International Conference on Mechatronics and Automation","20160905","2016","","","1697","1702","With the development of various imaging technologies, medical imaging has been playing more important roles on providing scientific proof for doctors to make decisions on clinical diagnosis. At the same time, it is very important to excavate valuable information hidden in those images and take over some auxiliary medical works from doctors by the computer. Therefore, a large number of image segmentation methods, including some classic algorithms have been proposed and some of them perform well. In this paper, we built a deep convolutional neural network to segment the MRI brain images. Results show that the network has a good performance on segmentation of the gray and white matter of brains, it also had a good generalization ability.","","CD-ROM:978-1-5090-2394-3; Electronic:978-1-5090-2396-7; POD:978-1-5090-2397-4","10.1109/ICMA.2016.7558819","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7558819","MRI brain imaging;deep convolutional network;fully convolutional network;image segmentation","Agriculture;Brain;Image segmentation;Magnetic resonance imaging;Medical diagnostic imaging;Medical services","biomedical MRI;image segmentation;medical image processing;neural nets","MRI brain images;MRI image segmentation;deep convolutional neural network;magnetic resonance imaging","","","","","","","","7-10 Aug. 2016","","IEEE","IEEE Conference Publications"
"Compressed sensing reconstruction of dynamic contrast enhanced MRI using GPU-accelerated convolutional sparse coding","T. M. Quan; W. K. Jeong","School of Electrical and Computer Engineering, Ulsan National Institute of Science and Technology (UNIST), Ulsan, South Korea","2016 IEEE 13th International Symposium on Biomedical Imaging (ISBI)","20160616","2016","","","518","521","In this paper, we propose a data-driven image reconstruction algorithm that specifically aims to reconstruct undersampled dynamic contrast enhanced (DCE) MRI data. The proposed method is based on the convolutional sparse coding algorithm, which leverages the Fourier convolution theorem to accelerate the process of learning a collections of filters and iteratively refines the reconstruction result using the sparse codes found during the reconstruction process. We introduce a novel energy formation based on the learning over time-varing DCE-MRI images, and propose an extension of Alternating Direction Method of Multiplier (ADMM) method to solve the constrained optimization problem efficiently using the GPU. We assess the performance of the proposed method by comparing with the state-of-the-art dictionary-based compressed sensing (CS) MRI method.","","Electronic:978-1-4799-2349-6; POD:978-1-4799-2351-9","10.1109/ISBI.2016.7493321","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7493321","Compressed Sensing;Convolutional Sparse Coding;GPU;MRI","Convolution;Convolutional codes;Dictionaries;Encoding;Fourier transforms;Image reconstruction;Magnetic resonance imaging","","","","","","7","","","","13-16 April 2016","","IEEE","IEEE Conference Publications"
"Brain Tumor Segmentation Using Convolutional Neural Networks in MRI Images","S. Pereira; A. Pinto; V. Alves; C. A. Silva","CMEMS-UMinho Research Unit, University of Minho, Guimar&#x00E3;es, Portugal","IEEE Transactions on Medical Imaging","20160429","2016","35","5","1240","1251","Among brain tumors, gliomas are the most common and aggressive, leading to a very short life expectancy in their highest grade. Thus, treatment planning is a key stage to improve the quality of life of oncological patients. Magnetic resonance imaging (MRI) is a widely used imaging technique to assess these tumors, but the large amount of data produced by MRI prevents manual segmentation in a reasonable time, limiting the use of precise quantitative measurements in the clinical practice. So, automatic and reliable segmentation methods are required; however, the large spatial and structural variability among brain tumors make automatic segmentation a challenging problem. In this paper, we propose an automatic segmentation method based on Convolutional Neural Networks (CNN), exploring small 3 ×3 kernels. The use of small kernels allows designing a deeper architecture, besides having a positive effect against overfitting, given the fewer number of weights in the network. We also investigated the use of intensity normalization as a pre-processing step, which though not common in CNN-based segmentation methods, proved together with data augmentation to be very effective for brain tumor segmentation in MRI images. Our proposal was validated in the Brain Tumor Segmentation Challenge 2013 database (BRATS 2013), obtaining simultaneously the first position for the complete, core, and enhancing regions in Dice Similarity Coefficient metric (0.88, 0.83, 0.77) for the Challenge data set. Also, it obtained the overall first position by the online evaluation platform. We also participated in the on-site BRATS 2015 Challenge using the same model, obtaining the second place, with Dice Similarity Coefficient metric of 0.78, 0.65, and 0.75 for the complete, core, and enhancing regions, respectively.","0278-0062;02780062","","10.1109/TMI.2016.2538465","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7426413","Brain tumor;brain tumor segmentation;convolutional neural networks;deep learning;glioma;magnetic resonance imaging","Brain modeling;Context;Image segmentation;Kernel;Magnetic resonance imaging;Training;Tumors","biomedical MRI;brain;cancer;image segmentation;medical image processing;neurophysiology;tumours","CNN-based segmentation methods;Dice similarity coefficient metrics;MRI images;automatic segmentation;automatic segmentation methods;brain tumor segmentation;clinical practice;convolutional neural networks;data augmentation;gliomas;imaging technique;intensity normalization;kernels;magnetic resonance imaging;manual segmentation;on-site BRATS 2015 Challenge;oncological patients;online evaluation platform;precise quantitative measurements;preprocessing step;quality-of-life;reliable segmentation methods;spatial variability;structural variability","","15","","52","","","20160304","May 2016","","IEEE","IEEE Journals & Magazines"
"Deep Convolutional Neural Networks for left ventricle segmentation","S. Molaei; M. Shiri; K. Horan; D. Kahrobaei; B. Nallamothu; K. Najarian","Department of Emergency Medicine, University of Michigan, Ann Arbor, USA","2017 39th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)","20170914","2017","","","668","671","Left ventricle (LV) segmentation is crucial for quantitative cardiac function analysis. Manual segmentation of the endocardium and epicardium is highly cumbersome; physicians limit delineation to the end-diastolic and end-systolic phases. A fully automated system could provide an analysis of cardiac morphology for all phases in a much shorter time. Most of the current LV segmentation methods are semi-automated and require error prone manual initialization. A fully-automated LV segmentation method would expedite the functional analysis of the LV, reduce subjectivity and improve patient experience. We automatically segment the LV wall in cardiac MRI images with a Deep Convolutional Neural Network (DCNN). This algorithm first calculates the probability of a pixel belonging to the LV wall or background and then generates a label based on those probabilities without manual initialization. We then compare these results to the results obtained with another DCNN initialization method using Gabor filters. With Gabor DCNN we obtain an accuracy of 0.97, specificity of 0.984, sensitivity of 0.841 and mean accuracy of 0.902. This shows that Gabor filters perform better than random filters in the DCNN for LV segmentation.","","Electronic:978-1-5090-2809-2; POD:978-1-5090-2810-8","10.1109/EMBC.2017.8036913","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8036913","","","","","","","","","","","","11-15 July 2017","","IEEE","IEEE Conference Publications"
"Constrained Deep Weak Supervision for Histopathology Image Segmentation","Z. Jia; X. Huang; E. I. C. Chang; Y. Xu","Microsoft Research, Beijing 100080, China and Institute for Interdisciplinary Information Sciences, Tsinghua University, Beijing 100084, China.","IEEE Transactions on Medical Imaging","","2017","PP","99","1","1","In this paper, we develop a new weakly-supervised learning algorithm to learn to segment cancerous regions in histopathology images. Our work is under a multiple instance learning framework (MIL) with a new formulation, deep weak supervision (DWS); we also propose an effective way to introduce constraints to our neural networks to assist the learning process. The contributions of our algorithm are threefold: (1) We build an end-to-end learning system that segments cancerous regions with fully convolutional networks (FCN) in which image-toimage weakly-supervised learning is performed. (2) We develop a deep week supervision formulation to exploit multi-scale learning under weak supervision within fully convolutional networks. (3) Constraints about positive instances are introduced in our approach to effectively explore additional weakly-supervised information that is easy to obtain and enjoys a significant boost to the learning process. The proposed algorithm, abbreviated as DWS-MIL, is easy to implement and can be trained efficiently. Our system demonstrates state-of-the-art results on large-scale histopathology image datasets and can be applied to various applications in medical imaging beyond histopathology images such as MRI, CT, and ultrasound images.","0278-0062;02780062","","10.1109/TMI.2017.2724070","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7971941","Convolutional neural networks;fully convolutional networks;histopathology image segmentation;multiple instance learning;weakly supervised learning","Biomedical imaging;Cancer;Image segmentation;Neural networks;Prediction algorithms;Supervised learning;Training","","","","","","","","","20170707","","","IEEE","IEEE Early Access Articles"
"End-to-end learning of brain tissue segmentation from imperfect labeling","A. Fedorov; J. Johnson; E. Damaraju; A. Ozerin; V. Calhoun; S. Plis","The Mind Research Network, Albuquerque, USA","2017 International Joint Conference on Neural Networks (IJCNN)","20170703","2017","","","3785","3792","Segmenting a structural magnetic resonance imaging (MRI) scan is an important pre-processing step for analytic procedures and subsequent inferences about longitudinal tissue changes. Manual segmentation defines the current gold standard in quality but is prohibitively expensive. Automatic approaches are computationally intensive, incredibly slow at scale, and error prone due to usually involving many potentially faulty intermediate steps. In order to streamline the segmentation, we introduce a deep learning model that is based on volumetric dilated convolutions, subsequently reducing both processing time and errors. Compared to its competitors, the model has a reduced set of parameters and thus is easier to train and much faster to execute. The contrast in performance between the dilated network and its competitors becomes obvious when both are tested on a large dataset of unprocessed human brain volumes. The dilated network consistently outperforms not only another state-of-the-art deep learning approach, the up convolutional network, but also the ground truth on which it was trained. Not only can the incredible speed of our model make large scale analyses much easier but we also believe it has great potential in a clinical setting where, with little to no substantial delay, a patient and provider can go over test results.","","Electronic:978-1-5090-6182-2; POD:978-1-5090-6183-9","10.1109/IJCNN.2017.7966333","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7966333","","Brain modeling;Image segmentation;Kernel;Magnetic resonance imaging;Mathematical model;Training","biological tissues;biomedical MRI;brain;image segmentation;learning (artificial intelligence);medical image processing","MRI scan;brain tissue segmentation;deep learning model;dilated network;end-to-end learning;gold standard;imperfect labeling;longitudinal tissue changes;preprocessing step;structural magnetic resonance imaging scan;subsequent inferences;unprocessed human brain volumes;volumetric dilated convolutions","","","","","","","","14-19 May 2017","","IEEE","IEEE Conference Publications"
"Auto-context Convolutional Neural Network (Auto-Net) for Brain Extraction in Magnetic Resonance Imaging","S. S. M. Salehi; D. Erdogmus; A. Gholipour","Electrical and Computer Engineering Department, Northeastern University, Boston, MA, 02115 and Radiology Department, Boston Children&#x2019;s Hospital and Harvard Medical School, Boston MA 02115.","IEEE Transactions on Medical Imaging","","2017","PP","99","1","1","Brain extraction or whole brain segmentation is an important first step in many of the neuroimage analysis pipelines. The accuracy and robustness of brain extraction, therefore, is crucial for the accuracy of the entire brain analysis process. State-of-the-art brain extraction techniques rely heavily on the accuracy of alignment or registration between brain atlases and query brain anatomy, and/or make assumptions about the image geometry; therefore have limited success when these assumptions do not hold or image registration fails. With the aim of designing an accurate, learning-based, geometry-independent and registration-free brain extraction tool in this study, we present a technique based on an auto-context convolutional neural network (CNN), in which intrinsic local and global image features are learned through 2D patches of different window sizes. We consider two different architectures: 1) a voxelwise approach based on three parallel 2D convolutional pathways for three different directions (axial, coronal, and sagittal) that implicitly learn 3D image information without the need for computationally expensive 3D convolutions, and 2) a fully convolutional network based on the U-net architecture. Posterior probability maps generated by the networks are used iteratively as context information along with the original image patches to learn the local shape and connectedness of the brain to extract it from non-brain tissue. The brain extraction results we have obtained from our CNNs are superior to the recently reported results in the literature on two publicly available benchmark datasets, namely LPBA40 and OASIS, in which we obtained Dice overlap coefficients of 97.73% and 97.62%, respectively. Significant improvement was achieved via our auto-context algorithm. Furthermore, we evaluated the performance of our algorithm in the challenging problem of extracting arbitrarily-oriented fetal brains in reconstructed fe- al brain magnetic resonance imaging (MRI) datasets. In this application our voxelwise auto-context CNN performed much better than the other methods (Dice coefficient: 95.97%), where the other methods performed poorly due to the non-standard orientation and geometry of the fetal brain in MRI. Through training, our method can provide accurate brain extraction in challenging applications. This in-turn may reduce the problems associated with image registration in segmentation tasks.","0278-0062;02780062","","10.1109/TMI.2017.2721362","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7961201","Auto-Context;Brain extraction;CNN;Convolutional neural network;MRI;U-net;Whole brain segmentation","Computer architecture;Context;Feature extraction;Image segmentation;Magnetic resonance imaging;Three-dimensional displays;Two dimensional displays","","","","","","","","","20170628","","","IEEE","IEEE Early Access Articles"
"Hippocampus segmentation through multi-view ensemble ConvNets","Y. Chen; B. Shi; Z. Wang; P. Zhang; C. D. Smith; J. Liu","School of EECS, Ohio University, Athens, 45701, United States of America","2017 IEEE 14th International Symposium on Biomedical Imaging (ISBI 2017)","20170619","2017","","","192","196","Automated segmentation of brain structures from MR images is an important practice in many neuroimage studies. In this paper, we explore the utilization of a multi-view ensemble approach that relies on neural networks (NN) to combine multiple decision maps in achieving accurate hippocampus segmentation. Constructed under a general convolutional NN structure, our Ensemble-Net networks explore different convolution configurations to capture the complementary information residing in the multiple label probabilities produced by our U-Seg-Net (a modified U-Net) segmentation neural network. T1-weighted MRI scans and the associated Hippocampal masks of 110 healthy subjects from the ADNI project were used as the training and testing data. The combined U-Seg-Net + Ensemble-Net framework achieves over 89% Dice ratio on the test dataset.","","Electronic:978-1-5090-1172-8; POD:978-1-5090-1173-5","10.1109/ISBI.2017.7950499","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7950499","ADNI;Alzheimer's Disease;Convolutional Neural Networks;Hippocampal Segmentation","Convolution;Hippocampus;Image segmentation;Solid modeling;Three-dimensional displays;Training;Two dimensional displays","biomedical MRI;brain;diseases;image segmentation;neurophysiology;probability","ADNI project;Dice ratio;MR images;T1-weighted MRI scans;U-Seg-Net;associated hippocampal masks;automated segmentation;brain structures;complementary information;convolution configurations;ensemble-net framework;ensemble-net networks;general convolutional NN structure;hippocampus segmentation;modified U-Net;multiple decision maps;multiple label probabilities;multiview ensemble convnets;neural networks;neuroimage;test dataset;testing data;training data","","","","","","","","18-21 April 2017","","IEEE","IEEE Conference Publications"
"M-net: A Convolutional Neural Network for deep brain structure segmentation","R. Mehta; J. Sivaswamy","Center for Visual Information Technology (CVIT), IIIT-Hyderabad, India","2017 IEEE 14th International Symposium on Biomedical Imaging (ISBI 2017)","20170619","2017","","","437","440","In this paper, we propose an end-to-end trainable Convolutional Neural Network (CNN) architecture called the M-net, for segmenting deep (human) brain structures from Magnetic Resonance Images (MRI). A novel scheme is used to learn to combine and represent 3D context information of a given slice in a 2D slice. Consequently, the M-net utilizes only 2D convolution though it operates on 3D data, which makes M-net memory efficient. The segmentation method is evaluated on two publicly available datasets and is compared against publicly available model based segmentation algorithms as well as other classification based algorithms such as Random Forrest and 2D CNN based approaches. Experiment results show that the M-net outperforms all these methods in terms of dice coefficient and is at least 3 times faster than other methods in segmenting a new volume which is attractive for clinical use.","","Electronic:978-1-5090-1172-8; POD:978-1-5090-1173-5","10.1109/ISBI.2017.7950555","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7950555","Convolutional Neural Networks;Deep Brain Structures;Magnetic Resonance Images;Segmentation","Brain;Convolution;Image segmentation;Magnetic resonance imaging;Three-dimensional displays;Training;Two dimensional displays","biomedical MRI;brain;convolution;image segmentation;medical image processing;neural nets","2D convolution;M-net;convolutional neural network;deep brain structure segmentation;magnetic resonance images","","","","","","","","18-21 April 2017","","IEEE","IEEE Conference Publications"
"L-CNN: Exploiting labeling latency in a CNN learning framework","M. J. Afridi; A. Ross; E. M. Shapiro","Department of Computer Science and Engineering, Michigan State University, United States of America","2016 23rd International Conference on Pattern Recognition (ICPR)","20170424","2016","","","2156","2161","A supervised learning system requires labeled data during the training phase. Obtaining labels can be an expensive process, especially in medical imaging applications where a qualified expert may be needed to carefully analyze images and annotate them. This constrains the amount of labeled data available. This study explores the possibility of incorporating labeling behavior (viz., labeling latency) in a supervised convolutional neural network (CNN) framework in order to improve its performance in the presence of limited labeled data. The problem of “spot” detection in MRI scans is considered in this work. In this two-class problem, (a) labeling behavior is available only during the training phase unlike traditional features that are available both during training and testing; and (b) the labeling behavior is associated with only one class (the positive samples) unlike other side information that is available for all classes. To address these issues, a new CNN architecture referred to as L-CNN is designed. The proposed method utilizes the labeling behavior of the expert to cluster the labeled data into multiple categories; a source CNN is then trained to distinguish between these categories. Next, a transfer learning paradigm is used where a target CNN is initialized using this source CNN and its weights updated with the limited labeled data that is available. Experimental results on an existing MRI database show that the proposed L-CNN performs better than a conventional CNN and, further, significantly outperforms the previous state-of-the-art, thereby establishing a new baseline for “spot” detection in MRI.","","Electronic:978-1-5090-4847-2; POD:978-1-5090-4848-9","10.1109/ICPR.2016.7899955","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7899955","","Biomedical imaging;Computer architecture;Labeling;Magnetic resonance imaging;Microprocessors;Testing;Training","biomedical MRI;learning (artificial intelligence);medical image processing;neural nets","L-CNN;MRI scans;labeling behavior;supervised convolutional neural network learning framework;supervised learning system;transfer learning paradigm;two-class problem","","","","","","","","4-8 Dec. 2016","","IEEE","IEEE Conference Publications"
"A deep learning network for right ventricle segmentation in short-axis MRI","G. Luo; R. An; K. Wang; S. Dong; H. Zhang","Harbin Institute of Technology, Harbin, China","2016 Computing in Cardiology Conference (CinC)","20170302","2016","","","485","488","The segmentation of the right ventricle (RV) myocardium on MRI is a prerequisite step for the evaluation of RV structure and function, which is of great importance in the diagnose of most cardiac diseases, such as pulmonary hypertension, congenital heart disease, coronary heart disease, and dysplasia. However, RV segmentation is considered challenging, mainly because of the complex crescent shape of the RV across slices and phases. Hence this study aims to propose a new approach to segment RV endocardium and epicardium based on deep learning. The proposed method contains two subtasks: (1) localizing the region of interest (ROI), the biventricular region which contains more meaningful features and can facilitate the RV segmentation, and (2) segmenting the RV myocardium based on the localization. The two subtasks are integrated into a joint task learning framework, in which each task is solved via two multilayer convolutional neural networks. The experiments results show that the proposed method has big potential to be further researched and applied in clinical diagnosis.","","Electronic:978-1-5090-0895-7; POD:978-1-5090-0896-4","10.23919/CIC.2016.7868785","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7868785","","Cardiac disease;Heart;Image segmentation;Machine learning;Magnetic resonance imaging;Neural networks;Training","biomedical MRI;cardiology;diseases;image segmentation;learning (artificial intelligence);medical image processing;neural nets","RV endocardium;RV epicardium;RV function;RV structure;biventricular region;cardiac diseases;clinical diagnosis;congenital heart disease;convolutional neural networks;coronary heart disease;deep learning network;dysplasia;pulmonary hypertension;region-of-interest;right ventricle segmentation;short-axis MRI","","","","","","","","11-14 Sept. 2016","","IEEE","IEEE Conference Publications"
"Adaptive Estimation of Active Contour Parameters Using Convolutional Neural Networks and Texture Analysis","A. Hoogi; A. Subramaniam; R. Veerapaneni; D. L. Rubin","Departments of Biomedical Data Science, Radiology, and Medicine (Biomedical Informatics Research), Stanford University, Stanford, CA, USA","IEEE Transactions on Medical Imaging","20170301","2017","36","3","781","791","In this paper, we propose a generalization of the level set segmentation approach by supplying a novel method for adaptive estimation of active contour parameters. The presented segmentation method is fully automatic once the lesion has been detected. First, the location of the level set contour relative to the lesion is estimated using a convolutional neural network (CNN). The CNN has two convolutional layers for feature extraction, which lead into dense layers for classification. Second, the output CNN probabilities are then used to adaptively calculate the parameters of the active contour functional during the segmentation process. Finally, the adaptive window size surrounding each contour point is re-estimated by an iterative process that considers lesion size and spatial texture. We demonstrate the capabilities of our method on a dataset of 164 MRI and 112 CT images of liver lesions that includes low contrast and heterogeneous lesions as well as noisy images. To illustrate the strength of our method, we evaluated it against state of the art CNN-based and active contour techniques. For all cases, our method, as assessed by Dice similarity coefficients, performed significantly better than currently available methods. An average Dice improvement of 0.27 was found across the entire dataset over all comparisons. We also analyzed two challenging subsets of lesions and obtained a significant Dice improvement of 0.24 with our method (p <;0.001, Wilcoxon).","0278-0062;02780062","","10.1109/TMI.2016.2628084","10.13039/100000054 - National Cancer Institute, National Institutes of Health; ","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7742396","Active contours;adaptive parameters;convolutional neural network;image segmentation","Active contours;Adaptation models;Adaptive estimation;Image segmentation;Lesions;Level set;Neural networks","biomedical MRI;computerised tomography;feature extraction;image classification;image segmentation;image texture;iterative methods;liver;medical image processing;neural nets;probability","CNN-based techniques;CT images;Dice similarity coefficients;MRI images;active contour functional;active contour parameters;active contour techniques;adaptive estimation;adaptive window size;average Dice improvement;contour point;convolutional neural networks;feature extraction;heterogeneous lesions;image classification;iterative process;lesion size;level set contour location;level set segmentation;liver lesions;low contrast lesions;noisy images;output CNN probability;segmentation method;spatial texture;texture analysis","","","","","","","20161111","March 2017","","IEEE","IEEE Journals & Magazines"
"Automatic segmentation of the left atrium from MR images via semantic information","Chunhua Deng; Xiaolong Zhang","College of Computer Science and Technology Wuhan University of Science and Technology, 430065, China","2016 IEEE International Conference on Systems, Man, and Cybernetics (SMC)","20170209","2016","","","003312","003316","Magnetic resonance imaging (MRI) can aid in assessing post-ablation scar formation. Automatic segmentation of left atrium (LA) offers great benefits for an accurate statistical assessment of LA region. However, how to robustly segment LA is still remaining as a challenging task for its high anatomical variability. In this paper, a robust segmentation method that exploits semantic information from different parts is proposed. The semantic correlation is exploited by the K Nearest Neighbor (KNN) search from corpus images with Convolutional Neural Network (CNN) features, which can be regarded as our main contribution. We propose a graph model to fuse semantic cues and eliminate accidental factors. Meanwhile, to optimize segmentation results, a super pixel voting method is also proposed. Experiments on public datasets of MRI image demonstrate the validity and accuracy of our semantic segmentation.","","Electronic:978-1-5090-1897-0; POD:978-1-5090-1898-7; USB:978-1-5090-1819-2","10.1109/SMC.2016.7844745","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7844745","Convolutional Neural Network (CNN);K Nearest Neighbor (KNN);Magnetic resonance images;Semantic segmentation;left atrium","Conferences;Cybernetics;Heart;Image segmentation;Magnetic resonance imaging;Semantics;Three-dimensional displays","biomedical MRI;graph theory;image segmentation;medical image processing;neural nets;search problems;statistical analysis","CNN;K nearest neighbor search;KNN search;MRI;automatic segmentation;convolutional neural network;corpus images;graph model;high anatomical variability;left atrium;magnetic resonance imaging;semantic information;statistical assessment;super pixel voting method","","","","","","","","9-12 Oct. 2016","","IEEE","IEEE Conference Publications"
"DemNet: A Convolutional Neural Network for the detection of Alzheimer's Disease and Mild Cognitive Impairment","C. D. Billones; O. J. L. D. Demetria; D. E. D. Hostallero; P. C. Naval","Computer Vision & Machine Intelligence Group, Department of Computer Science, College of Engineering, University of the Philippines-Diliman, Philippines","2016 IEEE Region 10 Conference (TENCON)","20170209","2016","","","3724","3727","The early diagnosis of Alzheimer's Disease (AD) and its prodromal form, Mild Cognitive Impairment (MCI), has been the subject of extensive research in recent years. Some recent studies have shown promising results in the diagnosis of AD and MCI using structural Magnetic Resonance Imaging (MRI) scans. In this paper, we propose the use of a Convolutional Neural Network (CNN) in the detection of AD and MCI. In particular, we modified the 16-layered VGGNet for the 3-way classification of AD, MCI and Healthy Controls (HC) on the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset achieving an overall accuracy of 91.85% and outperforming several classifiers from other studies.","","Electronic:978-1-5090-2597-8; POD:978-1-5090-2598-5; USB:978-1-5090-2596-1","10.1109/TENCON.2016.7848755","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7848755","","Alzheimer's disease;Biological neural networks;Feature extraction;Kernel;Magnetic resonance imaging;Neurons","biomedical MRI;convolution;data analysis;medical image processing;neural nets","16-layered VGGNet;3-way classification;AD;ADNI dataset;Alzheimer disease neuroimaging initiative dataset;CNN;DemNet;HC;MCI;MRI scans;convolutional neural network;healthy controls;magnetic resonance imaging scans;mild cognitive impairment detection;prodromal form;structural magnetic resonance imaging","","","","","","","","22-25 Nov. 2016","","IEEE","IEEE Conference Publications"
"Cardiac left ventricle segmentation using convolutional neural network regression","L. K. Tan; Y. M. Liew; E. Lim; R. A. McLaughlin","Faculty of Medicine, University of Malaya, Kuala Lumpur, Malaysia","2016 IEEE EMBS Conference on Biomedical Engineering and Sciences (IECBES)","20170206","2016","","","490","493","Cardiac MRI is important for the diagnosis and assessment of various cardiovascular diseases. Automated segmentation of the left ventricular (LV) endocardium at end-diastole (ED) and end-systole (ES) enables automated quantification of various clinical parameters including ejection fraction. Neural networks have been used for general image segmentation, usually via per-pixel categorization e.g. “foreground” and “background”. In this paper we propose that the generally circular LV endocardium can be parameterized and the endocardial contour determined via neural network regression. We designed two convolutional neural networks (CNN), one for localization of the LV, and the other for determining the endocardial radius. We trained the networks against 100 datasets from the Medical Image Computing and Computer Assisted Intervention (MICCAI) 2011 challenge, and tested the networks against 45 datasets from the MICCAI 2009 challenge. The networks achieved 0.88 average Dice metric, 2.30 mm average perpendicular distance, and 97.9% good contours, the latter being the highest published result to date. These results demonstrate that CNN regression is a viable and highly promising method for automated LV endocardial segmentation at ED and ES phases, and is capable of generalizing learning between highly distinct training and testing data sets.","","Electronic:978-1-4673-7791-1; POD:978-1-4673-7792-8","10.1109/IECBES.2016.7843499","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7843499","cardiac MRI;left ventricle;neural network regression;segmentation","Blood;Image segmentation;Magnetic resonance imaging;Measurement;Neural networks;Standards;Training","biomedical MRI;cardiology;diseases;image segmentation;medical image processing;neural nets;regression analysis","Medical Image Computing and Computer Assisted Intervention;automated segmentation;cardiac MRI;cardiac left ventricle segmentation;cardiovascular disease assessment;cardiovascular disease diagnosis;circular left ventricular endocardium;convolutional neural network regression;ejection fraction;endocardial contour;general image segmentation","","","","","","","","4-8 Dec. 2016","","IEEE","IEEE Conference Publications"
"Deep learning-based pipeline to recognize Alzheimer's disease using fMRI data","S. Sarraf; G. Tofighi","Department of Electrical and Computer Engineering, McMaster University Hamilton, ON, L8S 4L8, Canada, Rotman Research Institue at Baycrest, University of Toronto","2016 Future Technologies Conference (FTC)","20170119","2016","","","816","820","Over the past decade, machine learning techniques and in particular predictive modeling and pattern recognition in biomedical sciences, from drug delivery systems to medical imaging, have become one of the most important methods of assisting researchers in gaining a deeper understanding of issues in their entirety and solving complex medical problems. Deep learning is a powerful machine learning algorithm in classification that extracts low-to high-level features. In this paper, we employ a convolutional neural network to distinguish an Alzheimers brain from a normal, healthy brain. The importance of classifying this type of medical data lies in its potential to develop a predictive model or system in order to recognize the symptoms of Alzheimers disease when compared with normal subjects and to estimate the stages of the disease. Classification of clinical data for medical conditions such as Alzheimers disease has always been challenging, and the most problematic aspect has always been selecting the strongest discriminative features. Using the Convolutional Neural Network (CNN) and the famous architecture LeNet-5, we successfully classified functional MRI data of Alzheimers subjects from normal controls, where the accuracy of testing data reached 96.85%. This experiment suggests that the shift and scale invariant features extracted by CNN followed by deep learning classification represents the most powerful method of distinguishing clinical data from healthy data in fMRI. This approach also allows for expansion of the methodology to predict more complicated systems.","","Electronic:978-1-5090-4171-8; POD:978-1-5090-4172-5","10.1109/FTC.2016.7821697","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7821697","Alzheimer's Disease;Deep learning;fMRI","Alzheimer's disease;Biological neural networks;Biomedical imaging;Feature extraction;Machine learning;Neurons","biomedical MRI;convolution;diseases;feature extraction;learning (artificial intelligence);medical computing;neural nets;pattern classification","Alzheimer disease;Alzheimers brain;CNN;LeNet-5 architecture;biomedical sciences;clinical data classification;convolutional neural network;deep learning-based pipeline;drug delivery systems;functional MRI data classification;machine learning;medical imaging;pattern recognition;predictive modeling;scale invariant features extraction","","","","","","","","6-7 Dec. 2016","","IEEE","IEEE Conference Publications"
"V-Net: Fully Convolutional Neural Networks for Volumetric Medical Image Segmentation","F. Milletari; N. Navab; S. A. Ahmadi","","2016 Fourth International Conference on 3D Vision (3DV)","20161219","2016","","","565","571","Convolutional Neural Networks (CNNs) have been recently employed to solve problems from both the computer vision and medical image analysis fields. Despite their popularity, most approaches are only able to process 2D images while most medical data used in clinical practice consists of 3D volumes. In this work we propose an approach to 3D image segmentation based on a volumetric, fully convolutional, neural network. Our CNN is trained end-to-end on MRI volumes depicting prostate, and learns to predict segmentation for the whole volume at once. We introduce a novel objective function, that we optimise during training, based on Dice coefficient. In this way we can deal with situations where there is a strong imbalance between the number of foreground and background voxels. To cope with the limited number of annotated volumes available for training, we augment the data applying random non-linear transformations and histogram matching. We show in our experimental evaluation that our approach achieves good performances on challenging test data while requiring only a fraction of the processing time needed by other previous methods.","","Electronic:978-1-5090-5407-7; POD:978-1-5090-5408-4","10.1109/3DV.2016.79","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7785132","Deep learning;convolutional neural networks;machine learning;prostate;segmentation","Biomedical imaging;Feature extraction;Image segmentation;Magnetic resonance imaging;Neural networks;Three-dimensional displays;Two dimensional displays","biomedical MRI;image segmentation;medical image processing;neural nets","3D image segmentation;CNN;Dice coefficient;MRI volumes;V-Net;background voxel;clinical practice;computer vision;foreground voxel;fully convolutional neural networks;histogram matching;magnetic resonance imaging;medical image analysis;random nonlinear transformations;volumetric medical image segmentation","","1","","","","","","25-28 Oct. 2016","","IEEE","IEEE Conference Publications"
"Brain MRI segmentation with patch-based CNN approach","Z. Cui; J. Yang; Y. Qiao","Institute of Image Processing and Pattern Recognition, Shanghai Jiao Tong University, China","2016 35th Chinese Control Conference (CCC)","20160829","2016","","","7026","7031","Brain Magnetic Resonance Image (MRI) plays a non-substitutive role in clinical diagnosis. The symptom of many diseases corresponds to the structural variants of brain. Automatic structure segmentation in brain MRI is of great importance in modern medical research. Some methods were developed for automatic segmenting of brain MRI but failed to achieve desired accuracy. In this paper, we proposed a new patch-based approach for automatic segmentation of brain MRI using convolutional neural network (CNN). Each brain MRI acquired from a small portion of public dataset is firstly divided into patches. All of these patches are then used for training CNN, which is used for automatic segmentation of brain MRI. Experimental results showed that our approach achieved better segmentation accuracy compared with other deep learning methods.","","Electronic:978-9-8815-6391-0; POD:978-1-5090-0910-7","10.1109/ChiCC.2016.7554465","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7554465","Brain MRI Segmentation;CNN;Deep Learning;Patch-based","Biology;Biomedical imaging;Computer architecture;Image segmentation;Magnetic resonance imaging;Visualization","biomedical MRI;brain;diseases;image segmentation;learning (artificial intelligence);medical image processing;neural nets","CNN training;automatic brain MRI segmentation;automatic structure segmentation;brain magnetic resonance image;clinical diagnosis;convolutional neural network;disease symptoms;patch-based CNN approach;public dataset;segmentation accuracy;structural variants","","","","","","","","27-29 July 2016","","IEEE","IEEE Conference Publications"
"A deep symmetry convnet for stroke lesion segmentation","Y. Wang; A. K. Katsaggelos; X. Wang; T. B. Parrish","Northwestern University, Department of EECS, Evanston, IL, USA","2016 IEEE International Conference on Image Processing (ICIP)","20160819","2016","","","111","115","Stroke is one of the leading causes of death and disability. Clinically, to establish stroke patient prognosis, an accurate delineation of brain lesion is essential, which is time consuming and prone to subjective errors. In this paper, we propose a novel method call Deep Lesion Symmetry ConvNet to automatically segment chronic stroke lesions using MRI. An 8-layer 3D convolutional neural network is constructed to handle the MRI voxels. An additional CNN stream using the corresponding symmetric MRI voxels is combined, leading to a significant improvement in system performance. The high average dice coefficient achieved on our dataset based on data collected from three research labs demonstrates the effectiveness of our method.","","Electronic:978-1-4673-9961-6; POD:978-1-4673-9962-3","10.1109/ICIP.2016.7532329","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7532329","Brain Quasi-symmetry;Deep Learning;Image Segmentation;MRI;Stroke","Biological neural networks;Brain modeling;Image segmentation;Lesions;Magnetic resonance imaging;Pipelines;Three-dimensional displays","biomedical MRI;brain;image segmentation;medical image processing;neural nets;patient treatment","3D convolutional neural network;MRI voxels;brain lesion;death;deep symmetry ConvNet;disability;stroke lesion segmentation;stroke patient prognosis","","","","13","","","","25-28 Sept. 2016","","IEEE","IEEE Conference Publications"
"Alzheimer's disease diagnostics by adaptation of 3D convolutional network","E. Hosseini-Asl; R. Keynton; A. El-Baz","Electrical and Computer Engineering Department, University of Louisville, Louisville, KY, USA","2016 IEEE International Conference on Image Processing (ICIP)","20160819","2016","","","126","130","Early diagnosis, playing an important role in preventing progress and treating the Alzheimer's disease (AD), is based on classification of features extracted from brain images. The features have to accurately capture main AD-related variations of anatomical brain structures, such as, e.g., ventricles size, hippocampus shape, cortical thickness, and brain volume. This paper proposed to predict the AD with a deep 3D convolutional neural network (3D-CNN), which can learn generic features capturing AD biomarkers and adapt to different domain datasets. The 3D-CNN is built upon a 3D convolutional autoencoder, which is pre-trained to capture anatomical shape variations in structural brain MRI scans. Fully connected upper layers of the 3D-CNN are then fine-tuned for each task-specific AD classification. Experiments on the CADDementia MRI dataset with no skull-stripping preprocessing have shown our 3D-CNN outperforms several conventional classifiers by accuracy. Abilities of the 3D-CNN to generalize the features learnt and adapt to other domains have been validated on the ADNI dataset.","","Electronic:978-1-4673-9961-6; POD:978-1-4673-9962-3","10.1109/ICIP.2016.7532332","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7532332","3D convolutional neural network;Alzheimer's disease;autoencoder;brain MRI;deep learning","Convolution;Feature extraction;Hippocampus;Magnetic resonance imaging;Positron emission tomography;Three-dimensional displays;Training","biomedical MRI;brain;diseases;feature extraction;generalisation (artificial intelligence);image classification;learning (artificial intelligence);medical image processing;neural nets;neurophysiology","3D convolutional autoencoder;3D-CNN;AD biomarkers;ADNI dataset;Alzheimer's disease diagnostics;Alzheimer's disease progress prevention;Alzheimer's disease treatment;CADDementia MRI dataset;anatomical brain structures;anatomical shape variation;brain image;brain volume;cortical thickness;deep 3D convolutional neural network;early diagnosis;feature classification;feature extraction;feature generalization;generic feature learning;hippocampus shape;structural brain MRI scan;ventricles size","","","","38","","","","25-28 Sept. 2016","","IEEE","IEEE Conference Publications"
"Non-uniform patch sampling with deep convolutional neural networks for white matter hyperintensity segmentation","M. Ghafoorian; N. Karssemeijer; T. Heskes; I. W. M. van Uder; F. E. de Leeuw; E. Marchiori; B. van Ginneken; B. Platel","Diagnostic Image Analysis Group, Radboud University Medical Center, Nijmegen, the Netherlands","2016 IEEE 13th International Symposium on Biomedical Imaging (ISBI)","20160616","2016","","","1414","1417","Convolutional neural networks (CNN) have been widely used for visual recognition tasks including semantic segmentation of images. While the existing methods consider uniformly sampled single-or multi-scale patches from the neighborhood of each voxel, this approach might be sub-optimal as it captures and processes unnecessary details far away from the center of the patch. We instead propose to train CNNs with non-uniformly sampled patches that allow a wider extent for the sampled patches. This results in more captured contextual information, which is in particular of interest for biomedical image analysis, where the anatomical location of imaging features are often crucial. We evaluate and compare this strategy for white matter hyperintensity segmentation on a test set of 46 MRI scans. We show that the proposed method not only outperforms identical CNNs with uniform patches of the same size (0.780 Dice coefficient compared to 0.736), but also gets very close to the performance of an independent human expert (0.796 Dice coefficient).","","Electronic:978-1-4799-2349-6; POD:978-1-4799-2351-9","10.1109/ISBI.2016.7493532","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7493532","convolutional neural network;deep learning;non-uniform patch;white matter hyperintensity","Biological neural networks;Biomedical imaging;Convolution;Image segmentation;Sampling methods;Training;Visualization","biomedical MRI;brain;feature extraction;image sampling;image segmentation;medical image processing;neural nets;neurophysiology","Dice coefficient;MRI scans;anatomical location;biomedical image analysis;captured contextual information;deep convolutional neural networks;identical CNNs;imaging features;independent human expert;nonuniform patch sampling;sampled multiscale patches;sampled single-scale patches;semantic image segmentation;visual recognition tasks;white matter hyperintensity segmentation","","1","","9","","","","13-16 April 2016","","IEEE","IEEE Conference Publications"
"Accelerating magnetic resonance imaging via deep learning","S. Wang; Z. Su; L. Ying; X. Peng; S. Zhu; F. Liang; D. Feng; D. Liang","Paul C. Lauterbur Research Center for Biomedical Imaging, SIAT, CAS, Shenzhen, P.R. China","2016 IEEE 13th International Symposium on Biomedical Imaging (ISBI)","20160616","2016","","","514","517","This paper proposes a deep learning approach for accelerating magnetic resonance imaging (MRI) using a large number of existing high quality MR images as the training datasets. An off-line convolutional neural network is designed and trained to identify the mapping relationship between the MR images obtained from zero-filled and fully-sampled k-space data. The network is not only capable of restoring fine structures and details but is also compatible with online constrained reconstruction methods. Experimental results on real MR data have shown encouraging performance of the proposed method for efficient and accurate imaging.","","Electronic:978-1-4799-2349-6; POD:978-1-4799-2351-9","10.1109/ISBI.2016.7493320","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7493320","Deep learning;convolutional neural network;magnetic resonance imaging;prior knowledge","Acceleration;Convolution;Image reconstruction;Magnetic resonance imaging;Neural networks;Training","","","","1","","9","","","","13-16 April 2016","","IEEE","IEEE Conference Publications"
"Sub-cortical brain structure segmentation using F-CNN'S","M. Shakeri; S. Tsogkas; E. Ferrante; S. Lippe; S. Kadoury; N. Paragios; I. Kokkinos","Polytechnique Montreal","2016 IEEE 13th International Symposium on Biomedical Imaging (ISBI)","20160616","2016","","","269","272","In this paper we propose a deep learning approach for segmenting sub-cortical structures of the human brain in Magnetic Resonance (MR) image data. We draw inspiration from a state-of-the-art Fully-Convolutional Neural Network (F-CNN) architecture for semantic segmentation of objects in natural images, and adapt it to our task. Unlike previous CNN-based methods that operate on image patches, our model is applied on a full blown 2D image, without any alignment or registration steps at testing time. We further improve segmentation results by interpreting the CNN output as potentials of a Markov Random Field (MRF), whose topology corresponds to a volumetric grid. Alpha-expansion is used to perform approximate inference imposing spatial volumetric homogeneity to the CNN priors. We compare the performance of the proposed pipeline with a similar system using Random Forest-based priors, as well as state-of-art segmentation algorithms, and show promising results on two different brain MRI datasets.","","Electronic:978-1-4799-2349-6; POD:978-1-4799-2351-9","10.1109/ISBI.2016.7493261","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7493261","Convolutional neural networks;Magnetic Resonance Imaging;Markov Random Fields;semantic segmentation;sub-cortical structures","Brain;Image segmentation;Magnetic resonance imaging;Markov random fields;Semantics;Three-dimensional displays;Training","Markov processes;biomedical MRI;brain;image segmentation;medical image processing;neural nets","F-CNN architecture;Markov random field;brain MRI dataset;deep learning approach;fully-convolutional neural network;human brain;image patch;image registration;image segmentation;magnetic resonance image data;random forest-based prior;semantic segmentation;subcortical brain structure segmentation","","","","12","","","","13-16 April 2016","","IEEE","IEEE Conference Publications"
"Deep Feature Learning with Discrimination Mechanism for Brain Tumor Segmentation and Diagnosis","L. Zhao; K. Jia","Multimedia Inf. Process. Group, Beijing Univ. of Technol., Beijing, China","2015 International Conference on Intelligent Information Hiding and Multimedia Signal Processing (IIH-MSP)","20160225","2015","","","306","309","Brain tumor segmentation is one of the main challenging problems in computer vision and its early diagnosis is critical to clinics. Segmentation needs to be accurate, efficient and robust to avoid influences caused by various large and complex biases added to images. This paper proposes a multiple convolutional neural network (CNNs) framework with discrimination mechanism which is effective to achieve these goals. First of all, this paper proposes to construct different triplanar 2D CNNs architecture for 3D voxel classification, greatly reducing segmentation time. Experiment is conducted on images provided by Multimodal Brain Tumor Image Segmentation Benchmark (BRATS) organized by MICCAI 2013 for both training and testing. As T1, T1-enhanced, T2 and FLAIR MRI images are utilized, multimodal features are combined. As a result, accuracy, sensitivity and specificity are comparable in comparison with manual gold standard images and better than state-of-the-art segmentation methods.","","CD-ROM:978-1-5090-0187-3; Electronic:978-1-5090-0188-0; POD:978-1-5090-0189-7","10.1109/IIH-MSP.2015.41","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7415818","CNNs;brain tumor segmentation;voting strategy","Cancer;Computer architecture;Feature extraction;Image segmentation;Magnetic resonance imaging;Three-dimensional displays;Tumors","biomedical MRI;brain;computational geometry;computer vision;feedforward neural nets;image classification;image segmentation;learning (artificial intelligence);medical image processing;tumours","3D voxel classification;BRATS;FLAIR MRI image utilization;MICCAI 2013;T1 image utilization;T1-enhanced image utilization;T2 image utilization;brain tumor diagnosis;brain tumor segmentation;computer vision;deep feature learning;discrimination mechanism;multimodal brain tumor image segmentation benchmark;multiple convolutional neural network framework;segmentation time reduction;triplanar 2D CNN architecture","","","","14","","","","23-25 Sept. 2015","","IEEE","IEEE Conference Publications"
"Brain tumor grading based on Neural Networks and Convolutional Neural Networks","Y. Pan; W. Huang; Z. Lin; W. Zhu; J. Zhou; J. Wong; Z. Ding","School of EEE, Nanyang Technological University, Singapore","2015 37th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)","20151105","2015","","","699","702","This paper studies brain tumor grading using multiphase MRI images and compares the results with various configurations of deep learning structure and baseline Neural Networks. The MRI images are used directly into the learning machine, with some combination operations between multiphase MRIs. Compared to other researches, which involve additional effort to design and choose feature sets, the approach used in this paper leverages the learning capability of deep learning machine. We present the grading performance on the testing data measured by the sensitivity and specificity. The results show a maximum improvement of 18% on grading performance of Convolutional Neural Networks based on sensitivity and specificity compared to Neural Networks. We also visualize the kernels trained in different layers and display some self-learned features obtained from Convolutional Neural Networks.","1094-687X;1094687X","DVD:978-1-4244-9270-1; Electronic:978-1-4244-9271-8; POD:978-1-4244-9269-5","10.1109/EMBC.2015.7318458","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7318458","","Artificial neural networks;Biological neural networks;Image segmentation;Kernel;Sensitivity and specificity;Training;Tumors","biomedical MRI;brain;image classification;learning (artificial intelligence);medical disorders;medical image processing;neurophysiology;tumours","baseline neural networks;brain tumor grading;convolutional neural networks;deep learning machine;deep learning structure;grading performance;multiphase MRI imaging;self-learned features;testing data","","","","8","","","","25-29 Aug. 2015","","IEEE","IEEE Conference Publications"
"Automatic localization of the left ventricle in cardiac MRI images using deep learning","O. Emad; I. A. Yassine; A. S. Fahmy","Center for Informatics Science, Nile University, Giza, Egypt","2015 37th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)","20151105","2015","","","683","686","Automatic localization of the left ventricle (LV) in cardiac MRI images is an essential step for automatic segmentation, functional analysis, and content based retrieval of cardiac images. In this paper, we introduce a new approach based on deep Convolutional Neural Network (CNN) to localize the LV in cardiac MRI in short axis views. A six-layer CNN with different kernel sizes was employed for feature extraction, followed by Softmax fully connected layer for classification. The pyramids of scales analysis was introduced in order to take account of the different sizes of the heart. A publically-available database of 33 patients was used for learning and testing. The proposed method was able it localize the LV with 98.66%, 83.91% and 99.07% for accuracy, sensitivity and specificity respectively.","1094-687X;1094687X","DVD:978-1-4244-9270-1; Electronic:978-1-4244-9271-8; POD:978-1-4244-9269-5","10.1109/EMBC.2015.7318454","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7318454","","Biomedical imaging;Convolution;Feature extraction;Heart;Image segmentation;Magnetic resonance imaging;Sensitivity","biomedical MRI;cardiology;feature extraction;image classification;image segmentation;medical image processing;neural nets","Softmax;automatic segmentation;cardiac MRI images;deep convolutional neural network;deep learning;feature extraction;image classification;left ventricle automatic localization","","2","","21","","","","25-29 Aug. 2015","","IEEE","IEEE Conference Publications"
"GSURS: Generalized sparse uniform resampling with application to MRI","A. Kiperwas; D. Rosenfeld; Y. C. Eldar","Department of Electrical Engineering Technion, Israel Institute of Technology","2015 International Conference on Sampling Theory and Applications (SampTA)","20150709","2015","","","538","542","We present an algorithm for resampling data from a non-uniform grid onto a uniform grid. Our algorithm termed generalized sparse uniform resampling (GSURS) uses methods from modern sampling theory. Selection of an intermediate subspace generated by integer translations of a compactly supported generating kernel produces a sparse system of equations representing the relation between the nonuniformly spaced samples and a series of generalized samples. This sparse system of equations can be solved efficiently using a sparse equation solver. A correction filter is subsequently applied to the result in order to attain the uniformly spaced samples of the signal. We demonstrate the application of the new method for reconstructing MRI data from nonuniformly spaced k-space samples. In this scenario, the algorithm is first used to calculate uniformly spaced k-space samples, and subsequently an inverse FFT is applied to these samples in order to obtain the reconstructed image. Simulations using a numerical phantom are used to compare the performance of GSURS with other reconstruction methods, in particular convolutional gridding and the nonuniform FFT.","","Electronic:978-1-4673-7353-1; POD:978-1-4673-7354-8; USB:978-1-4673-7352-4","10.1109/SAMPTA.2015.7148949","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7148949","","Approximation methods;Image reconstruction;Magnetic resonance imaging;Mathematical model;Phantoms;Sparse matrices;Trajectory","biomedical MRI;compressed sensing;convolution;fast Fourier transforms;image filtering;image reconstruction;image sampling;inverse transforms;phantoms","GSURS;MRI data;convolutional gridding;correction filter;fast Fourier transforms;generalized sparse uniform resampling;inverse FFT;k-space samples;nonuniform FFT;nonuniform grid;numerical phantom;reconstructed image;reconstruction methods;resampling data;sampling theory;sparse equation solver;sparse system","","0","","18","","","","25-29 May 2015","","IEEE","IEEE Conference Publications"
"High spatial resolution reconstruction technique for SPECT using a fan-beam collimator","T. Ichihara; K. Nambu; N. Motomura","Toshiba, Tochigi, Japan","IEEE Transactions on Nuclear Science","20020806","1993","40","4","1149","1157","The physical characteristics of the collimator cause degradation of resolution with increasing distance from the collimator surface. A convolutional backprojection algorithm is derived for fan beam single-photon-emission computed tomography (SPECT) data without rebinding into parallel beam geometry. The projections are filtered and then backprojected into the area within an isosceles triangle whose vertex is the focal point of the fan-beam and whose base is the fan-beam collimator face, and outside of the circle whose center is located midway between the focal point and the center of rotation and whose diameter is the distance between the focal point and the center of rotation. Consequently, the backprojected area is close to the collimator surface. This algorithm, implemented on a GCA-9300A SPECT system, shows good results with phantom and patient studies. The SPECT transaxial resolution is 4.6 mm FWHM (reconstructed image matrix size of 256×256) at the center of SPECT field of view using ultra-high-resolution fan beam collimators for brain study. Clinically, Tc-99m HMPAO and Tc-99m ECD brain data are reconstructed using this algorithm. The reconstruction results are compared with MRI images of the same slice position and show significant improvement over results obtained with standard reconstruction algorithms","0018-9499;00189499","","10.1109/23.256727","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=256727","","Collimators;Computational geometry;Computed tomography;Degradation;Image reconstruction;Image resolution;Imaging phantoms;Magnetic resonance imaging;Spatial resolution;Surface reconstruction","computerised tomography;image reconstruction;medical image processing;patient diagnosis;radioisotope scanning and imaging","(SPECT);GCA-9300A SPECT system;brain study;collimator;convolutional backprojection algorithm;fan beam single-photon-emission computed tomography;transaxial resolution","","1","","5","","","","Aug 1993","","IEEE","IEEE Journals & Magazines"
"List of papers","","","2014 International Conference on Digital Image Computing: Techniques and Applications (DICTA)","20150115","2014","","","1","4","The following topics are dealt with: Gaussian mixture model; depth map coding; high-precision image registration; quantization based watermarking approach; DCE-MRI prostate sequences; rank minimization; nuclear-norm minimization; CT reconstruction; medical image retrieval; sensor data fusion; moving object recognition; image-set based face recognition; image fusion; hyperspherical clustering; crowd event detection; video watermarking scheme; 3D planar patch reconstruction; distant object detection; pedestrian lane detection; reflective feature detection; image sequences; partial fingerprint matching; railway level crossing event detection; human action recognition; breast cancer magnetic resonance imaging; HEVC video coding; target detection; image registration; low-contrast infrared ship image segmentation; fuzzy inference system; 2D human pose tracking; skeleton representation; crowd behavior recognition; convolutional neural network; automatic aerial imagery analysis; regression Web testing; landmark detector system; multiresolution frontal faces; automatic building footprint extraction; LIDAR point cloud data; image quality evaluation index; supervised latent Dirichlet allocation models; activity representation; nonrigid 3D multimodal image registration algorithm; discriminative key pose extraction; multiple feature distance preserving model; saliency detection; automatic UAV forced landing site detection; machine learning; HEp-2 cell image clustering; robust visual tracking; infrared ship target image smoothing; and unsupervised image classification.","","Electronic:978-1-4799-5409-4; POD:978-1-4799-5410-0","10.1109/DICTA.2014.7008079","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7008079","","","Gaussian processes;biomedical MRI;cancer;computerised tomography;face recognition;feature extraction;fingerprint identification;fuzzy reasoning;image classification;image enhancement;image fusion;image matching;image motion analysis;image reconstruction;image registration;image representation;image resolution;image retrieval;image segmentation;image sequences;image watermarking;infrared imaging;learning (artificial intelligence);medical image processing;minimisation;mixture models;neural nets;object detection;object tracking;optical radar;pattern clustering;pedestrians;program testing;railway engineering;video coding;video watermarking","2D human pose tracking;3D planar patch reconstruction;CT reconstruction;DCE-MRI prostate sequences;Gaussian mixture model;HEVC video coding;HEp-2 cell image clustering;LIDAR point cloud data;activity representation;automatic UAV forced landing site detection;automatic aerial imagery analysis;automatic building footprint extraction;breast cancer magnetic resonance imaging;convolutional neural network;crowd behavior recognition;crowd event detection;depth map coding;discriminative key pose extraction;distant object detection;fuzzy inference system;high-precision image registration;human action recognition;hyperspherical clustering;image fusion;image quality evaluation index;image sequences;image-set based face recognition;infrared ship target image smoothing;landmark detector system;low-contrast infrared ship image segmentation;machine learning;medical image retrieval;moving object recognition;multiple feature distance preserving model;multiresolution frontal faces;nonrigid 3D multimodal image registration algorithm;nuclear-norm minimization;partial fingerprint matching;pedestrian lane detection;quantization based watermarking approach;railway level crossing event detection;rank minimization;reflective feature detection;regression Web testing;robust visual tracking;saliency detection;sensor data fusion;skeleton representation;supervised latent Dirichlet allocation models;target detection;unsupervised image classification;video watermarking scheme","","0","","","","","","25-27 Nov. 2014","","IEEE","IEEE Conference Publications"
"Deep Learning with Edge Computing for Localization of Epileptogenicity Using Multimodal rs-fMRI and EEG Big Data","M. P. Hosseini; T. X. Tran; D. Pompili; K. Elisevich; H. Soltanian-Zadeh","Dept. of Electr. & Comput. Eng., Rutgers Univ.-New Brunswick, New Brunswick, NJ, USA","2017 IEEE International Conference on Autonomic Computing (ICAC)","20170810","2017","","","83","92","Epilepsy is a chronic brain disorder characterized by the occurrence of spontaneous seizures of which about 30 percent of patients remain medically intractable and may undergo surgical intervention; despite the latter, some may still fail to attain a seizure-free outcome. Functional changes may precede structural ones in the epileptic brain and may be detectable using existing noninvasive modalities. Functional connectivity analysis through electroencephalography (EEG) and resting state-functional magnetic resonance imaging (rs-fMRI), complemented by diffusion tensor imaging (DTI), has provided such meaningful input in cases of temporal lobe epilepsy (TLE). Recently, the emergence of edge computing has provided competent solutions enabling context-aware and real-time response services for users. By leveraging the potential of autonomic edge computing in epilepsy, we develop and deploy both noninvasive and invasive methods for the monitoring, evaluation and regulation of the epileptic brain, with responsive neurostimulation (RNS; Neuropace). First, an autonomic edge computing framework is proposed for processing of big data as part of a decision support system for surgical candidacy. Second, an optimized model for estimation of the epileptogenic network using independently acquired EEG and rs-fMRI is presented. Third, an unsupervised feature extraction model is developed based on a convolutional deep learning structure for distinguishing interictal epileptic discharge (IED) periods from nonIED periods using electrographic signals from electrocorticography (ECoG). Experimental and simulation results from actual patient data validate the effectiveness of the proposed methods.","","Electronic:978-1-5386-1762-5; POD:978-1-5386-1763-2; USB:978-1-5386-1761-8","10.1109/ICAC.2017.41","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8005336","Autonomic Computing;Deep Learning;EEG;Edge Computing;Epilepsy Seizure Localization;Health Monitoring and Treatment;Medical Big Data;rs-fMRI","Big Data;Cloud computing;Edge computing;Electroencephalography;Epilepsy;Feature extraction;Logic gates","Big Data;biomedical MRI;decision support systems;electroencephalography;feature extraction;learning (artificial intelligence);medical image processing;unsupervised learning","DTI;ECoG;EEG big data;IED periods;RNS;TLE;autonomic edge computing;chronic brain disorder;convolutional deep learning structure;decision support system;diffusion tensor imaging;electrocorticography;electroencephalography;electrographic signals;epileptogenicity;interictal epileptic discharge;multimodal rs-fMRI;responsive neurostimulation;state-functional magnetic resonance imaging;temporal lobe epilepsy;unsupervised feature extraction model","","","","","","","","17-21 July 2017","","IEEE","IEEE Conference Publications"
"Super-resolution of Magnetic Resonance Images using deep Convolutional Neural Networks","K. Srinivasan; A. Ankur; A. Sharma","Department of Computer Science & Information Engineering, National Ilan University, China","2017 IEEE International Conference on Consumer Electronics - Taiwan (ICCE-TW)","20170727","2017","","","41","42","This research focuses on developing a Super-resolution magnetic resonance (MR) Image restoration method using Convolutional Neural Networks (CNN). The main aim is to train an end to end mapping that takes low-resolution image as input and returns a high-resolution output. Low overhead and a state of the art reconstruction makes the model perform efficiently.","","Electronic:978-1-5090-4017-9; POD:978-1-5090-4018-6","10.1109/ICCE-China.2017.7990985","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7990985","","Conferences;Image reconstruction;Image resolution;Image restoration;Interpolation;Magnetic resonance;Neural networks","biomedical MRI;feedforward neural nets;image resolution;image restoration;medical image processing","CNN;MR;deep convolutional neural networks;end-to-end mapping;high-resolution output;image restoration method;low-resolution image;magnetic resonance images;super-resolution","","","","","","","","12-14 June 2017","","IEEE","IEEE Conference Publications"
"Computer-aided classification of multi-types of dementia via convolutional neural networks","E. M. Alkabawi; A. R. Hilal; O. A. Basir","Department of Electrical and Computer Engineering, University of Waterloo, Ontario, Canada","2017 IEEE International Symposium on Medical Measurements and Applications (MeMeA)","20170720","2017","","","45","50","With millions of people suffering from dementia worldwide, the global prevalence of dementia has a significant impact on the patients' lives, their caregivers' physical and emotional states, and the global economy. Early diagnosis of dementia helps in finding suitable therapies that reduce or even prevent further deterioration of patients' cognitive abilities. In recent years, state-of-the-art literature has proposed various computer-aided diagnosis systems based on 3-dimensional brain imagery analysis to identify early symptoms of dementia. These systems aim to assist radiologists in increasing the accuracy of diagnoses and reducing false positives. However, the early diagnosis of dementia is a challenging task due to the image quality, noise, and human brain irregularities. The state-of-the-art has focused on differentiating multi-stages of Alzheimer's disease, however, the diagnosis of various types of dementia is still a gap. This paper proposes a deep learning-based computer-aided diagnosis approach for the early detection of multi-type of dementia. To show the performance of the proposed CAD algorithm, three conventional CAD methods are implemented for comparison. The proposed algorithm yields a 74.93% accuracy in early diagnosis of multi-type of dementia and outperforms the state of the art CAD methods.","","Electronic:978-1-5090-2984-6; POD:978-1-5090-2985-3","10.1109/MeMeA.2017.7985847","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7985847","Alzheimer's disease;Brain imaging;Computer-Aided Diagnosis;Convolutional Neural Networks;Dementia;Early diagnosis;Magnetic Resonance Imaging","Brain;Dementia;Feature extraction;Image edge detection;Image segmentation;Magnetic resonance imaging","biomedical MRI;cognition;convolution;diseases;learning (artificial intelligence);medical disorders;medical image processing;neural nets;neurophysiology","Alzheimer disease;caregiver physical states;caregiveremotional states;convolutional neural networks;deep learning-based computer-aided diagnosis approach;dementia;image quality;magnetic resonance imaging;patient cognitive abilities;three-dimensional brain imagery analysis","","","","","","","","7-10 May 2017","","IEEE","IEEE Conference Publications"
"Detecting Anatomical Landmarks From Limited Medical Imaging Data Using Two-Stage Task-Oriented Deep Neural Networks","J. Zhang; M. Liu; D. Shen","Department of Radiology and the Biomedical Research Imaging Center, University of North Carolina at Chapel Hill, Chapel Hill, NC, USA","IEEE Transactions on Image Processing","20170718","2017","26","10","4753","4764","One of the major challenges in anatomical landmark detection, based on deep neural networks, is the limited availability of medical imaging data for network learning. To address this problem, we present a two-stage task-oriented deep learning method to detect large-scale anatomical landmarks simultaneously in real time, using limited training data. Specifically, our method consists of two deep convolutional neural networks (CNN), with each focusing on one specific task. Specifically, to alleviate the problem of limited training data, in the first stage, we propose a CNN based regression model using millions of image patches as input, aiming to learn inherent associations between local image patches and target anatomical landmarks. To further model the correlations among image patches, in the second stage, we develop another CNN model, which includes a) a fully convolutional network that shares the same architecture and network weights as the CNN used in the first stage and also b) several extra layers to jointly predict coordinates of multiple anatomical landmarks. Importantly, our method can jointly detect large-scale (e.g., thousands of) landmarks in real time. We have conducted various experiments for detecting 1200 brain landmarks from the 3D T1-weighted magnetic resonance images of 700 subjects, and also 7 prostate landmarks from the 3D computed tomography images of 73 subjects. The experimental results show the effectiveness of our method regarding both accuracy and efficiency in the anatomical landmark detection.","1057-7149;10577149","","10.1109/TIP.2017.2721106","10.13039/100000002 - NIH; ","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7961205","Anatomical landmark detection;deep convolutional neural networks;limited medical imaging data;real-time;task-oriented","Biological neural networks;Biomedical imaging;Machine learning;Testing;Three-dimensional displays;Training;Training data","biomedical MRI;computerised tomography;feedforward neural nets;learning (artificial intelligence);medical image processing;object detection;regression analysis","3D T1-weighted magnetic resonance images;3D computed tomography images;CNN based regression model;anatomical landmark coordinate prediction;anatomical landmark detection;brain landmarks;deep convolutional neural networks;fully convolutional network;local image patches;medical imaging data;network learning;prostate landmarks;training data;two-stage task-oriented deep learning method;two-stage task-oriented deep neural networks","","","","","","","20170628","Oct. 2017","","IEEE","IEEE Journals & Magazines"
"Deeply-supervised CNN for prostate segmentation","Q. Zhu; B. Du; B. Turkbey; P. L. Choyke; P. Yan","School of Computer, Wuhan University, WuHan, China, 430079","2017 International Joint Conference on Neural Networks (IJCNN)","20170703","2017","","","178","184","Prostate segmentation from Magnetic Resonance (MR) images plays an important role in image guided intervention. However, the lack of clear boundary specifically at the apex and base, and huge variation of shape and texture between the images from different patients make the task very challenging. To overcome these problems, in this paper, we propose a deeply supervised convolutional neural network (CNN) utilizing the convolutional information to accurately segment the prostate from MR images. The proposed model can effectively detect the prostate region with additional deeply supervised layers compared with other approaches. Since some information will be abandoned after convolution, it is necessary to pass the features extracted from early stages to later stages. The experimental results show that significant segmentation accuracy improvement has been achieved by our proposed method compared to other reported approaches.","","Electronic:978-1-5090-6182-2; POD:978-1-5090-6183-9","10.1109/IJCNN.2017.7965852","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7965852","","Convolution;Feature extraction;Image segmentation;Machine learning;Medical diagnostic imaging;Training","biomedical MRI;feature extraction;feedforward neural nets;image segmentation;medical image processing","MR images;convolutional information;deeply supervised convolutional neural network;deeply supervised layers;deeply-supervised CNN;feature extraction;image guided intervention;magnetic resonance images;prostate region detection;prostate segmentation","","","","","","","","14-19 May 2017","","IEEE","IEEE Conference Publications"
"A Fast Algorithm for Convolutional Structured Low-Rank Matrix Recovery","G. Ongie; M. Jacob","Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, Michigan United States (e-mail: gregongie@gmail.com)","IEEE Transactions on Computational Imaging","","2017","PP","99","1","1","Fourier domain structured low-rank matrix priors are emerging as powerful alternatives to traditional image recovery methods such as total variation (TV) and wavelet regularization. These priors specify that a convolutional structured matrix, i.e., Toeplitz, Hankel, or their multi-level generalizations, built from Fourier data of the image should be low-rank. The main challenge in applying these schemes to large-scale problems is the computational complexity and memory demand resulting from lifting the image data to a large scale matrix. We introduce a fast and memory efficient approach called the Generic Iterative Reweighted Annihilation Filter (GIRAF) algorithm that exploits the convolutional structure of the lifted matrix to work in the original un-lifted domain, thus considerably reducing the complexity. Our experiments on the recovery of images from undersampled Fourier measurements show that the resulting algorithm is considerably faster than previously proposed algorithms, and can accommodate much larger problem sizes than previously studied.","2333-9403;23339403","","10.1109/TCI.2017.2721819","American Cancer Society; National Institutes of Health; National Science Foundation; Office of Naval Research; ","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7964698","Annihilating Filter;Compressed Sensing;Finite Rate of Innovation;MRI Reconstruction;Multilevel Toeplitz Matrices;Structured Low-Rank Matrix Recovery","Approximation algorithms;Convolution;Image reconstruction;Jacobian matrices;Magnetic resonance imaging;Transmission line matrix methods","","","","","","","","","20170630","","","IEEE","IEEE Early Access Articles"
"Cerebral vessel classification with convolutional neural networks","Y. H. Şahin; G. Ünal","Bilgisayar M&#x00FC;hendisli&#x011F;i B&#x00F6;l&#x00FC;m&#x00FC;, &#x0130;stanbul Teknik &#x00DC;niversitesi, &#x0130;stanbul, T&#x00FC;rkiye","2017 25th Signal Processing and Communications Applications Conference (SIU)","20170629","2017","","","1","4","Analysing brain magnetic resonance angiography (MRA) images is important for detecting arteriovenous malformations and aneurysms. To detect these diseases, extracting the vessel structure in the image can be seen as a first step. In this paper, it was aimed to classify the cubic image parts obtained from brain MRA images according to whether they belong to vein structure or not. For this purpose, a 9 layers deep convolutional neural network (CNN) architecture is designed. With the model trained using this architecture, 85% accuracy was obtained in the classification performed on the test data.","","Electronic:978-1-5090-6494-6; POD:978-1-5090-6495-3","10.1109/SIU.2017.7960697","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7960697","cerebral vessel classification;convolutional neural networks;deep learning;magnetic resonance angiography (MRA)","Biological neural networks;Biomedical imaging;Brain modeling;Dogs;Image segmentation;Magnetic resonance;Nanoelectromechanical systems","biomedical MRI;diseases;feature extraction;feedforward neural nets;image classification;medical image processing;object detection","CNN architecture;aneurysm detection;arteriovenous malformation detection;brain MRA images;brain magnetic resonance angiography image analysis;cerebral vessel classification;cubic image part classification;deep convolutional neural network architecture;disease detection;vein structure;vessel structure extraction","","","","","","","","15-18 May 2017","","IEEE","IEEE Conference Publications"
"Classification of brain tissues as lesion or healthy by 3D convolutional neural networks","C. Y. Aydoğdu; E. Albay; G. Ünal","Bilgisayar ve Bili&#x015F;im Fak&#x00FC;ltesi, &#x0130;stanbul Teknik &#x00DC;niversitesi, &#x0130;stanbul, T&#x00FC;rkiye","2017 25th Signal Processing and Communications Applications Conference (SIU)","20170629","2017","","","1","4","In this paper, a three dimensional convolutional neural network based solution is proposed for classification of brain tissues as lesion or healthy in terms of ischemic stroke disease. Three dimensional data used in this work are obtained by magnetic resonance imaging technique. Proposed method is compared with traditional methods that are in the same category, via K-fold cross validation technique in terms of sensitivity, specificity and accuracy measures. In conclusion, it is obtained nearly 89% accuracy using our proposed method. Comparing this method with others, our proposed method is the best method.","","Electronic:978-1-5090-6494-6; POD:978-1-5090-6495-3","10.1109/SIU.2017.7960524","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7960524","3D;classification;convolution;cross validation;ischemic stroke;magnetic resonance;neural networks","Biological neural networks;Biomedical imaging;Dogs;Image segmentation;Lesions;Magnetic resonance imaging;Three-dimensional displays","biological tissues;biomedical MRI;brain;convolution;diseases;image classification;medical image processing;neural nets","3D convolutional neural networks;brain tissues classification;healthy brain tissues;ischemic stroke disease;k-fold cross validation;lesion brain tissues;magnetic resonance imaging","","","","","","","","15-18 May 2017","","IEEE","IEEE Conference Publications"
"SurvivalNet: Predicting patient survival from diffusion weighted magnetic resonance images using cascaded fully convolutional and 3D Convolutional Neural Networks","P. Ferdinand Christ; F. Ettlinger; G. Kaissis; S. Schlecht; F. Ahmaddy; F. Grün; A. Valentinitsch; S. A. Ahmadi; R. Braren; B. Menze","Technische Universit&#x00E4;t M&#x00FC;nchen, Image-Based Biomedical Modeling Group, Arccisstrasse 21, 80333 Munich, Germany","2017 IEEE 14th International Symposium on Biomedical Imaging (ISBI 2017)","20170619","2017","","","839","843","Automatic non-invasive assessment of hepatocellular carcinoma (HCC) malignancy has the potential to substantially enhance tumor treatment strategies for HCC patients. In this work we present a novel framework to automatically characterize the malignancy of HCC lesions from DWI images. We predict HCC malignancy in two steps: As a first step we automatically segment HCC tumor lesions using cascaded fully convolutional neural networks (CFCN). A 3D neural network (SurvivalNet) then predicts the HCC lesions' malignancy from the HCC tumor segmentation. We formulate this task as a classification problem with classes being “low risk” and “high risk” represented by longer or shorter survival times than the median survival. We evaluated our method on DWI of 31 HCC patients. Our proposed framework achieves an end-to-end accuracy of 65% with a Dice score for the automatic lesion segmentation of 69% and an accuracy of 68% for tumor malignancy classification based on expert annotations. We compared the SurvivalNet to classical handcrafted features such as Histogram and Haralick and show experimentally that SurvivalNet outperforms the handcrafted features in HCC malignancy classification. End-to-end assessment of tumor malignancy based on our proposed fully automatic framework corresponds to assessment based on expert annotations with high significance (p > 0.95).","","Electronic:978-1-5090-1172-8; POD:978-1-5090-1173-5","10.1109/ISBI.2017.7950648","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7950648","3D Neural Network;Fully Convolutional Neural Networks;MRI;Survival Prediction","Cancer;Feature extraction;Image segmentation;Imaging;Lesions;Three-dimensional displays","biomedical MRI;cancer;image classification;image segmentation;medical image processing;neural nets;tumours","3D convolutional neural networks;DWI images;Dice score;HCC lesion malignancy classification;HCC tumor lesions;HCC tumor segmentation;Haralick;Histogram;SurvivalNet;automatic lesion segmentation;diffusion weighted magnetic resonance images;fully convolutional neural network;hepatocellular carcinoma;patient survival;tumor malignancy classification;tumor treatment strategies","","","","","","","","18-21 April 2017","","IEEE","IEEE Conference Publications"
"Deep residual learning for compressed sensing MRI","D. Lee; J. Yoo; J. C. Ye","Bio Imaging and Signal Processing Lab., Dep. of Bio and Brain Engineering, KAIST, South Korea","2017 IEEE 14th International Symposium on Biomedical Imaging (ISBI 2017)","20170619","2017","","","15","18","Compressed sensing (CS) enables significant reduction of MR acquisition time with performance guarantee. However, computational complexity of CS is usually expensive. To address this, here we propose a novel deep residual learning algorithm to reconstruct MR images from sparsely sampled k-space data. In particular, based on the observation that coherent aliasing artifacts from downsampled data has topologically simpler structure than the original image data, we formulate a CS problem as a residual regression problem and propose a deep convolutional neural network (CNN) to learn the aliasing artifacts. Experimental results using single channel and multi channel MR data demonstrate that the proposed deep residual learning outperforms the existing CS and parallel imaging algorithms. Moreover, the computational time is faster in several orders of magnitude.","","Electronic:978-1-5090-1172-8; POD:978-1-5090-1173-5","10.1109/ISBI.2017.7950457","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7950457","CNN;Compressed sensing MRI;deep learning;residual learning","Complexity theory;Image reconstruction;Machine learning;Magnetic resonance imaging;Manifolds;Topology","biomedical MRI;compressed sensing;data acquisition;image reconstruction;learning (artificial intelligence);medical image processing;neural nets;regression analysis","MR acquisition time;MR image reconstruction;compressed sensing MRI;deep convolutional neural network;deep residual learning algorithm;residual regression problem;sparsely sampled k-space data","","","","","","","","18-21 April 2017","","IEEE","IEEE Conference Publications"
"Aneurysm detection in 3D cerebral angiograms based on intra-vascular distance mapping and convolutional neural networks","T. Jerman; F. Pernus; B. Likar; Ž. Špiclin","University of Ljubljana, Faculty of Electrical Engineering, Tr&#x017E;a&#x0161;ka cesta 25, SI-1000, Slovenia","2017 IEEE 14th International Symposium on Biomedical Imaging (ISBI 2017)","20170619","2017","","","612","615","Early and more sensitive detection of small aneurysms in 3D cerebral angiograms is required to prevent potentially fatal rupture events. Herein, we propose a novel method that entails structure enhancement filtering to highlight potential aneurysm locations, intra-vascular distance mapping for regional vascular shape encoding and dimensionality reduction and a convolutional neural network to automatically determine optimal features and classification rules for aneurysm detection. Evaluation on 15 3D digital subtraction angiograms showed better performance of the proposed method compared to enhancement filtering and random forest based methods, as it achieved a 100% detection sensitivity at a low number of false positives (2.4 per dataset). The proposed method is also applicable to other angiographic modalities.","","Electronic:978-1-5090-1172-8; POD:978-1-5090-1173-5","10.1109/ISBI.2017.7950595","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7950595","aneurysms;convolutional neural networks;detection;intravascular ray-casting","Aneurysm;Image edge detection;Sensitivity;Three-dimensional displays;Training;Two dimensional displays;Visualization","biomedical MRI;brain;image recognition;medical disorders;medical image processing;neural nets","3D cerebral angiograms;3D digital subtraction angiograms;aneurysm detection;convolutional neural networks;dimensionality reduction;intra-vascular distance mapping;potentially fatal rupture events;random forest based methods;regional vascular shape encoding;structure enhancement filtering","","","","","","","","18-21 April 2017","","IEEE","IEEE Conference Publications"
"Classification of MRI data using deep learning and Gaussian process-based model selection","H. Bertrand; M. Perrot; R. Ardon; I. Bloch","LTCI, T&#x00E9;l&#x00E9;com ParisTech, Universit&#x00E9; Paris-Saclay, France","2017 IEEE 14th International Symposium on Biomedical Imaging (ISBI 2017)","20170619","2017","","","745","748","The classification of MRI images according to the anatomical field of view is a necessary task to solve when faced with the increasing quantity of medical images. In parallel, advances in deep learning makes it a suitable tool for computer vision problems. Using a common architecture (such as AlexNet) provides quite good results, but not sufficient for clinical use. Improving the model is not an easy task, due to the large number of hyper-parameters governing both the architecture and the training of the network, and to the limited understanding of their relevance. Since an exhaustive search is not tractable, we propose to optimize the network first by random search, and then by an adaptive search based on Gaussian Processes and Probability of Improvement. Applying this method on a large and varied MRI dataset, we show a substantial improvement between the baseline network and the final one (up to 20% for the most difficult classes).","","Electronic:978-1-5090-1172-8; POD:978-1-5090-1173-5","10.1109/ISBI.2017.7950626","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7950626","Classification;Convolutional Neural Networks;Deep Learning;Gaussian Process;MRI;Model Selection","Abdomen;Biomedical imaging;Machine learning;Magnetic resonance imaging;Optimization;Pelvis;Training","Gaussian processes;biomedical MRI;computer vision;image classification;learning (artificial intelligence);medical image processing","Gaussian process-based model selection;MRI image classification;adaptive search;anatomical field of view;computer vision problems;deep learning;random search","","","","","","","","18-21 April 2017","","IEEE","IEEE Conference Publications"
"Automatic detection of motion artifacts in MR images using CNNS","K. Meding; A. Loktyushin; M. Hirsch","Max Planck Institute for Intelligent Systems, Department of Empirical Inference, Germany","2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","20170619","2017","","","811","815","Considerable practical interest exists in being able to automatically determine whether a recorded magnetic resonance image is affected by motion artifacts caused by patient movements during scanning. Existing approaches usually rely on the use of navigators or external sensors to detect and track patient motion during image acquisition. In this work, we present an algorithm based on convolutional neural networks that enables fully automated detection of motion artifacts in MR scans without special hardware requirements. The approach is data driven and uses the magnitude of MR images in the spatial domain as input. We evaluate the performance of our algorithm on both synthetic and real data and observe adequate performance in terms of accuracy and generalization to different types of data. Our proposed approach could potentially be used in clinical practice to tag an MR image as motion-free or motion-corrupted immediately after a scan is finished. This process would facilitate the acquisition of high-quality MR images that are often indispensable for accurate medical diagnosis.","","Electronic:978-1-5090-4117-6; POD:978-1-5090-4118-3; USB:978-1-5090-4116-9","10.1109/ICASSP.2017.7952268","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7952268","Convolutional Neural Networks;Deep Learning;MRI;Motion Artifacts;Quality Assessment","Brain;Kernel;Magnetic resonance imaging;Motion artifacts;Testing;Three-dimensional displays;Training","biomedical MRI;convolution;feature extraction;image motion analysis;neural nets;patient diagnosis","CNNS;MR images;MR scans;automatic motion artifacts detection;clinical practice;convolutional neural networks;data accuracy;data driven;data generalization;image acquisition;magnetic resonance image;medical diagnosis;motion-corrupted MR image;motion-free MR image;patient motion;patient movements","","","","","","","","5-9 March 2017","","IEEE","IEEE Conference Publications"
"Fast predictive multimodal image registration","X. Yang; R. Kwitt; M. Styner; M. Niethammer","Department of Computer Science, UNC Chapel Hill, USA","2017 IEEE 14th International Symposium on Biomedical Imaging (ISBI 2017)","20170619","2017","","","858","862","We introduce a deep encoder-decoder architecture for image deformation prediction from multimodal images. Specifically, we design an image-patch-based deep network that jointly (i) learns an image similarity measure and (ii) the relationship between image patches and deformation parameters. While our method can be applied to general image registration formulations, we focus on the Large Deformation Diffeomorphic Metric Mapping (LDDMM) registration model. By predicting the initial momentum of the shooting formulation of LDDMM, we preserve its mathematical properties and drastically reduce the computation time, compared to optimization-based approaches. Furthermore, we create a Bayesian probabilistic version of the network that allows evaluation of registration uncertainty via sampling of the network at test time. We evaluate our method on a 3D brain MRI dataset using both T1- and T2-weighted images. Our experiments show that our method generates accurate predictions and that learning the similarity measure leads to more consistent registrations than relying on generic multimodal image similarity measures, such as mutual information. Our approach is an order of magnitude faster than optimization-based LDDMM.","","Electronic:978-1-5090-1172-8; POD:978-1-5090-1173-5","10.1109/ISBI.2017.7950652","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7950652","deep learning;deformation prediction;multimodal image similarity","Bayes methods;Convolutional codes;Deformable models;Image registration;Optimization;Three-dimensional displays;Training","Bayes methods;biomedical MRI;biomedical measurement;brain;image registration;learning (artificial intelligence);medical image processing;neural nets;optimisation","3D brain MRI dataset;Bayesian probabilistic version;LDDMM registration model;T1-weighted images;T2-weighted images;deep encoder-decoder architecture;image deformation prediction;image registration formulations;image-patch-based deep network;large deformation diffeomorphic metric mapping;multimodal image registration;multimodal image similarity measurement;multimodal images;optimization-based LDDMM","","","","","","","","18-21 April 2017","","IEEE","IEEE Conference Publications"
"3-D functional brain network classification using Convolutional Neural Networks","D. Ren; Y. Zhao; H. Chen; Q. Dong; J. Lv; T. Liu","College of Computer Science and Information Engineering, Tianjin University of Science and Technology, 300222, China","2017 IEEE 14th International Symposium on Biomedical Imaging (ISBI 2017)","20170619","2017","","","1217","1221","Several recent studies have shown that dictionary learning and sparse representation can effectively reconstruct hundreds of interacting functional brain networks simultaneously from whole-brain fMRI data. However, accurate classification and recognition of those hundreds of functional networks from an individual or a population of many subjects is still a challenging and open problem due to the intrinsic variability of functional networks and other noise sources. To tackle this problem, this paper presents an effective deep learning framework to train convolutional neural networks from a large dataset of hundreds of thousands of available brain network volume maps, which was then applied on testing samples for network classification and recognition. We effectively applied computer-labeled data as training set so the whole process can be automated. Experimental results showed that the proposed method is quite robust in handling noisy patterns in the dataset, which suggests that our work offers a new computational framework for modeling functional connectomes from fMRI big data in the future.","","Electronic:978-1-5090-1172-8; POD:978-1-5090-1173-5","10.1109/ISBI.2017.7950736","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7950736","3D convolutional neural networks;classification;deep learning;functional brain networks","Biological neural networks;Machine learning;Noise measurement;Testing;Three-dimensional displays;Training;Visualization","Big Data;biomedical MRI;brain;image classification;image denoising;learning (artificial intelligence);neural nets;neurophysiology","3-D functional brain network classification;brain network volume maps;computational framework;computer-labeled data;convolutional neural networks;deep learning framework;dictionary learning;fMRI big data;functional connectomes;functional networks;intrinsic variability;network recognition;noise sources;noisy patterns;sparse representation;training set;whole-brain fMRI data","","","","","","","","18-21 April 2017","","IEEE","IEEE Conference Publications"
"Prostate segmentation in MR images using ensemble deep convolutional neural networks","H. Jia; Y. Xia; W. Cai; M. Fulham; D. D. Feng","Shaanxi Key Lab of Speech & Image Information Processing (SAIIP), School of Computer Science, Northwestern Polytechnical University, Xi'an 710072, China","2017 IEEE 14th International Symposium on Biomedical Imaging (ISBI 2017)","20170619","2017","","","762","765","The automated segmentation of the prostate gland from MR images is increasingly used for clinical diagnosis. Since deep learning demonstrates superior performance in computer vision applications, we propose a coarse-to-fine segmentation strategy using ensemble deep convolutional neural networks (DCNNs) to address prostate segmentation in MR images. First, we use registration-based coarse segmentation on pre-processed prostate MR images to define the potential boundary region. We then train four DCNNs as voxel-based classifiers and classify the voxel in the potential region is a prostate voxel when at least three DCNNs made that decision. Finally, we use boundary refinement to eliminate the outliers and smooth the boundary. We evaluated our approach on the MICCAI PROMIS12 challenge dataset and our experimental results verify the effectiveness of the proposed algorithms.","","Electronic:978-1-5090-1172-8; POD:978-1-5090-1173-5","10.1109/ISBI.2017.7950630","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7950630","MR prostate segmentation;deep convolutional neural network;voxel classification","Biomedical imaging;Convolution;Glands;Image segmentation;Magnetic resonance imaging;Probabilistic logic;Training","biomedical MRI;image registration;image segmentation;learning (artificial intelligence);medical image processing;neural nets;pattern classification","MICCAI PROMIS12 challenge dataset;MR images;automated prostate gland segmentation;computer vision applications;deep learning;ensemble deep convolutional neural networks;prostate MR image preprocessing;prostate voxel;registration-based coarse segmentation;voxel-based classifiers","","","","","","","","18-21 April 2017","","IEEE","IEEE Conference Publications"
"Self supervised deep representation learning for fine-grained body part recognition","P. Zhang; F. Wang; Y. Zheng","Medical Imaging Technologies, Siemens Medical Solutions USA Inc., Princeton, NJ 08540, USA","2017 IEEE 14th International Symposium on Biomedical Imaging (ISBI 2017)","20170619","2017","","","578","582","Difficulty on collecting annotated medical images leads to lack of enough supervision and makes discrimination tasks challenging. However, raw data, e.g., spatial context information from 3D CT images, even without annotation, may contain rich useful information. In this paper, we exploit spatial context information as a source of supervision to solve discrimination tasks for fine-grained body part recognition with conventional 3D CT and MR volumes. The proposed pipeline consists of two steps: 1) pre-train a convolutional network for an auxiliary task of 2D slices ordering in a self-supervised manner; 2) transfer and fine-tune the pre-trained network for fine-grained body part recognition. Without any use of human annotation in the first stage, the pre-trained network can still outperform CNN trained from scratch on CT as well as M-R data. Moreover, by comparing with pre-trained CNN from ImageNet, we discover that the distance between source and target tasks plays a crucial role in transfer learning. Our experiments demonstrate that our approach can achieve high accuracy with a slice location estimation error of only a few slices on CT and MR data. To the best of our knowledge, our work is the first attempt studying the problem of robust body part recognition at a continuous level.","","Electronic:978-1-5090-1172-8; POD:978-1-5090-1173-5","10.1109/ISBI.2017.7950587","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7950587","Body Part Recognition;Self Supervised Learning;Slice Ordering","Biomedical imaging;Computed tomography;Context;Image recognition;Three-dimensional displays;Training;Two dimensional displays","biomedical MRI;computerised tomography;image recognition;learning (artificial intelligence);medical image processing","3D CT;MR volumes;fine-grained body part recognition;self supervised deep representation learning;spatial context information;transfer learning","","","","","","","","18-21 April 2017","","IEEE","IEEE Conference Publications"
"Fast Fully Automatic Segmentation of the Severely Abnormal Human Right Ventricle from Cardiovascular Magnetic Resonance Images Using a Multi-Scale 3D Convolutional Neural Network","A. Giannakidis; K. Kamnitsas; V. Spadotto; J. Keegan; G. Smith; B. Glocker; D. Rueckert; S. Ernst; M. A. Gatzoulis; D. J. Pennell; S. Babu-Narayan; D. N. Firmin","NIHR Cardiovascular Biomed. Res. Unit, R. Brompton Hosp., London, UK","2016 12th International Conference on Signal-Image Technology & Internet-Based Systems (SITIS)","20170424","2016","","","42","46","Cardiac magnetic resonance (CMR) is regarded as the reference examination for cardiac morphology in tetralogy of Fallot (ToF) patients allowing images of high spatial resolution and high contrast. The detailed knowledge of the right ventricular anatomy is critical in ToF management. The segmentation of the right ventricle (RV) in CMR images from ToF patients is a challenging task due to the high shape and image quality variability. In this paper we propose a fully automatic deep learning-based framework to segment the RV from CMR anatomical images of the whole heart. We adopt a 3D multi-scale deep convolutional neural network to identify pixels that belong to the RV. Our robust segmentation framework was tested on 26 ToF patients achieving a Dice similarity coefficient of 0.8281±0.1010 with reference to manual annotations performed by expert cardiologists. The proposed technique is also computationally efficient, which may further facilitate its adoption in the clinical routine.","","Electronic:978-1-5090-5698-9; POD:978-1-5090-5699-6","10.1109/SITIS.2016.16","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7907443","3D convolutional neural network;cardiavascular magnetic resonance;deep learning;right ventricle;segmentation;tetralogy of Fallot","Heart;Image segmentation;Magnetic resonance;Manuals;Neurons;Three-dimensional displays;Training","biomedical MRI;image segmentation;learning (artificial intelligence);medical image processing;neural nets","CMR;Dice similarity coefficient;ToF patients;cardiovascular magnetic resonance images;deep learning-based framework;fast fully automatic segmentation;human right ventricle;image quality variability;multiscale 3D convolutional neural network;right ventricle;tetralogy of Fallot patients","","","","","","","","Nov. 28 2016-Dec. 1 2016","","IEEE","IEEE Conference Publications"
"A temporal deep learning approach for MR perfusion parameter estimation in stroke","K. C. Ho; F. Scalzo; K. V. Sarma; S. El-Saden; C. W. Arnold","Medical Imaging Informatics Group, Department of Radiological Sciences, University of California Los Angeles, 90024, USA","2016 23rd International Conference on Pattern Recognition (ICPR)","20170424","2016","","","1315","1320","Perfusion magnetic resonance (MR) images are often used in the assessment of acute ischemic stroke to distinguish between salvageable tissue and infarcted core. Deconvolution methods such as singular value decomposition have been used to approximate model-based perfusion parameters from these images. However, studies have shown that these existing deconvolution algorithms can introduce distortions that may negatively influence the utility of these parameter maps. There is limited previous work on utilizing machine learning algorithms to estimate perfusion parameters. In this work, we present a novel bi-input convolutional neural network (bi-CNN) to approximate four perfusion parameters without using an explicit deconvolution method. These bi-CNNs produced good approximations for all four parameters, with relative average root-mean-square errors (ARMSEs) ≤ 5% of the maximum values. We further demonstrate the utility of the estimated perfusion maps for quantifying the salvageable tissue volume in stroke, with more than 80% agreement with the ground truth. These results show that deep learning techniques are a promising tool for perfusion parameter estimation without requiring a standard deconvolution process.","","Electronic:978-1-5090-4847-2; POD:978-1-5090-4848-9","10.1109/ICPR.2016.7899819","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7899819","","Biological neural networks;Biological tissues;Convolution;Deconvolution;Estimation;Imaging;Parameter estimation","approximation theory;biological tissues;biomedical MRI;deconvolution;feedforward neural nets;haemorheology;learning (artificial intelligence);medical signal processing;parameter estimation;singular value decomposition","MR perfusion parameter estimation;acute ischemic stroke assessment;bi-CNN;bi-input convolutional neural network;infarcted core;model-based perfusion parameters;perfusion magnetic resonance images;perfusion parameter approximation;relative average root-mean-square errors;salvageable tissue volume;singular value decomposition;temporal deep learning","","","","","","","","4-8 Dec. 2016","","IEEE","IEEE Conference Publications"
"Multimodal learning using convolution neural network and Sparse Autoencoder","Tien Duong Vu; Hyung-Jeong Yang; V. Q. Nguyen; A-Ran Oh; Mi-Sun Kim","Department of Electronics and Computer Engineering, Chonnam National University, Gwangju, South Korea","2017 IEEE International Conference on Big Data and Smart Computing (BigComp)","20170320","2017","","","309","312","In the last decade, pattern recognition methods using neuroimaging data for the diagnosis of Alzheimer's disease (AD) have been the subject of extensive research. Deep learning has recently been a great interest in AD classification. Previous works had done almost on single modality dataset, such as Magnetic Resonance Imaging (MRI) or Positron Emission Tomography (PET), shown high performances. However, identifying the distinctions between Alzheimer's brain data and healthy brain data in older adults (age > 75) is challenging due to highly similar brain patterns and image intensities. The corporation of multimodalities can solve this issue since it discovers and uses the further complementary of hidden biomarkers from other modalities instead of only one, which itself cannot provide. We therefore propose a deep learning method on fusion multimodalities. In details, our approach includes Sparse Autoencoder (SAE) and convolution neural network (CNN) train and test on combined PET-MRI data to diagnose the disease status of a patient. We focus on advantages of multimodalities to help providing complementary information than only one, lead to improve classification accuracy. We conducted experiments in a dataset of 1272 scans from ADNI study, the proposed method can achieve a classification accuracy of 90% between AD patients and healthy controls, demonstrate the improvement than using only one modality.","","Electronic:978-1-5090-3015-6; POD:978-1-5090-3016-3; USB:978-1-5090-3014-9","10.1109/BIGCOMP.2017.7881683","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7881683","Alzheimer's disease;MRI;PET;autoencoder;convolutional neural network;deep learning","Biological neural networks;Convolution;Feature extraction;Magnetic resonance imaging;Positron emission tomography;Support vector machines;Three-dimensional displays","biomedical MRI;brain;convolution;diseases;image classification;image coding;image fusion;learning (artificial intelligence);medical image processing;neural nets;positron emission tomography","Alzheimer disease diagnosis;convolution neural network;deep learning method;image fusion multimodalities;magnetic resonance imaging;multimodal learning method;neuroimaging data;pattern recognition methods;positron emission tomography;sparse autoencoder","","","","","","","","13-16 Feb. 2017","","IEEE","IEEE Conference Publications"
"Automatic segmentation of left ventricular myocardium by deep convolutional and de-convolutional neural networks","X. L. Yang; L. Gobeawan; S. Y. Yeo; W. T. Tang; Z. Z. Wu; Y. Su","Institute of High Performance Computing, A&#x2217;STAR, Singapore","2016 Computing in Cardiology Conference (CinC)","20170302","2016","","","81","84","Deep learning has been integrated into several existing left ventricle (LV) endocardium segmentation methods to yield impressive accuracy improvements. However, challenges remain for segmentation of LV epicardium due to its fuzzier appearance and complications from the right ventricular insertion points. Segmenting the myocardium collectively (i.e., endocardium and epicardium together) confers the potential for better segmentation results. In this work, we develop a computational platform based on deep learning to segment the whole LV myocardium simultaneously from a cardiac magnetic resonance (CMR) image. The deep convolutional network is constructed using Caffe platform, which consists of 6 convolutional layers, 2 pooling layers, and 1 de-convolutional layer. A preliminary result with Dice metric of 0.75±0.04 is reported on York MR dataset. While in its current form, our proposed one-step deep learning method cannot compete with state-of-art myocardium segmentation methods, it delivers promising first pass segmentation results.","","Electronic:978-1-5090-0895-7; POD:978-1-5090-0896-4","10.23919/CIC.2016.7868684","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7868684","","Image segmentation;Machine learning;Magnetic resonance;Magnetic resonance imaging;Measurement;Myocardium;Neural networks","biomedical MRI;cardiology;image segmentation;medical image processing;neural nets","Caffe platform;automatic left ventricular myocardium segmentation;cardiac magnetic resonance image;deconvolutional neural network;deep convolutional neural network;deep learning;left ventricle endocardium segmentation method;right ventricular insertion","","","","","","","","11-14 Sept. 2016","","IEEE","IEEE Conference Publications"
"DeepCut: Object Segmentation From Bounding Box Annotations Using Convolutional Neural Networks","M. Rajchl; M. C. H. Lee; O. Oktay; K. Kamnitsas; J. Passerat-Palmbach; W. Bai; M. Damodaram; M. A. Rutherford; J. V. Hajnal; B. Kainz; D. Rueckert","Department of Computing, Imperial College London, SW7 2AZ, London, U.K","IEEE Transactions on Medical Imaging","20170201","2017","36","2","674","683","In this paper, we propose DeepCut, a method to obtain pixelwise object segmentations given an image dataset labelled weak annotations, in our case bounding boxes. It extends the approach of the well-known GrabCut[1] method to include machine learning by training a neural network classifier from bounding box annotations. We formulate the problem as an energy minimisation problem over a densely-connected conditional random field and iteratively update the training targets to obtain pixelwise object segmentations. Additionally, we propose variants of the DeepCut method and compare those to a naïve approach to CNN training under weak supervision. We test its applicability to solve brain and lung segmentation problems on a challenging fetal magnetic resonance dataset and obtain encouraging results in terms of accuracy.","0278-0062;02780062","","10.1109/TMI.2016.2621185","Developing Human Connectome Project; iFIND project; 10.13039/501100000266 - Wellcome Trust and EPSRC IEH; 10.13039/501100000272 - National Institute for Health Research (NIHR) Biomedical Research Centre based at Guy¿s and St Thomas¿ NHS Foundation Trust and King¿s College London; 10.13039/501100000781 - ERC; 10.13039/501100000781 - Synergy Grant by the European Research Council (ERC); 10.13039/501100004963 - European Union¿s Seventh Framework Programme; ","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7739993","Bounding box;DeepCut;convolutional neural networks;image segmentation;machine learning;weak annotations","Biological neural networks;Computational modeling;Image segmentation;Imaging;Object segmentation;Optimization;Training","biomedical MRI;brain;image segmentation;learning (artificial intelligence);lung;medical image processing;neural nets","DeepCut;GrabCut;bounding box annotations;brain segmentation;convolutional neural networks;densely connected conditional random field;fetal magnetic resonance dataset;lung segmentation;machine learning;pixelwise object segmentation","","","","","","","20161109","Feb. 2017","","IEEE","IEEE Journals & Magazines"
"Moving from detection to pre-detection of Alzheimer's Disease from MRI data","K. A. N. N. P. Gunawardena; R. N. Rajapakse; N. D. Kodikara; I. U. K. Mudalige","University of Colombo School of Computing, Sri Lanka","2016 Sixteenth International Conference on Advances in ICT for Emerging Regions (ICTer)","20170126","2016","","","324","324","Alzheimer's Disease (AD) is the most common form of dementia, affecting approximately 10% of individuals under 65 years of age, with the prevalence doubling every 5 years up to age 80, above which the prevalence exceeds 40%. Currently diagnosis of AD is largely based on the examination of clinical history and tests such as MMSE (Mini-mental state examination) and PAL (Paired Associates Learning). However many present studies have highlighted the inaccuracies and limitations of such tests. Thus medical officers are now moving to the more accurate neuroimaging data (Magnetic Resonance Imaging- MRI) based diagnosis for these types of diseases where brain atrophy transpires. However it is a considerable challenge to analyse large numbers of images manually to get the most accurate diagnosis at present.","","CD:978-1-5090-6076-4; Electronic:978-1-5090-6078-8; POD:978-1-5090-6079-5; Paper:978-1-5090-6077-1","10.1109/ICTER.2016.7829940","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7829940","Alzheimer's disease;Convolutional neural network;Image Processing;MRI","Alzheimer's disease;Atrophy;MATLAB;Magnetic resonance imaging;Neuroimaging;Support vector machines","biomedical MRI;brain;diseases;medical image processing","AD diagnosis;Alzheimer's disease detection;Alzheimer's disease predetection;MRI data;brain;dementia;magnetic resonance imaging;neuroimaging data","","","","","","","","1-3 Sept. 2016","","IEEE","IEEE Conference Publications"
"Cardiac left ventricular volumes prediction method based on atlas location and deep learning","G. Luo; S. Dong; K. Wang; H. Zhang","School of Computer Science and Technology, Harbin Institute of Technology, China","2016 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)","20170119","2016","","","1604","1610","In this paper, we proposed a novel left ventricular volumes prediction method. This method is a cascade architecture which is based on multi-scale LV atlas location and deep convolutional neural networks (CNN). Firstly, we adopted LV atlas mapping method to achieve accurate location of LV region in cardiac magnetic resonance (CMR) images. And then, the CNN were used to train an end-to-end LV volumes prediction model to achieve the direct prediction. What's more, the large number of CMR images data (1140 subjects, more than 1026000 images) make the proposed deep CNN have relatively better feature representation and robust prediction ability. The experiment results on the large-scale CMR datasets prove that the proposed method has higher accuracy than the state-of-the-art prediction methods in terms of the end-diastole volumes (EDV), the end-systole volumes (ESV), and the ejection fraction (EF). Besides, we make the proposed method open accessible to public for wide application in other biomedical image processing fields.","","Electronic:978-1-5090-1611-2; POD:978-1-5090-1612-9","10.1109/BIBM.2016.7822759","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7822759","CMR images;LV atlas;deep convolutional neural networks;volumes prediction","Fitting;Image segmentation;Kernel;Manuals","biomedical MRI;cardiology;convolution;feature extraction;image representation;learning (artificial intelligence);medical image processing;neural nets","biomedical image processing fields;cardiac left ventricular volume prediction method;cardiac magnetic resonance images;deep convolutional neural networks;deep learning;end-diastole volumes;end-systole volumes;feature representation;multiscale LV atlas mapping method","","","","","","","","15-18 Dec. 2016","","IEEE","IEEE Conference Publications"
"Exploring deep features from brain tumor magnetic resonance images via transfer learning","Renhao Liu; L. O. Hall; D. B. Goldgof; Mu Zhou; R. A. Gatenby; K. B. Ahmed","Department of Computer Science and Engineering, University of South Florida, Tampa, USA","2016 International Joint Conference on Neural Networks (IJCNN)","20161103","2016","","","235","242","Finding appropriate feature representations from radiological images is a vital task for prediction and diagnosis. Deep convolutional neural networks have recently achieved state-of-the-art performance in classification problems from several different domains. Research has also shown the feasibility of using a pre-trained deep neural network as a feature extractor when only a small dataset is available. This paper proposes a novel image feature extraction method for predicting survival time from brain tumor magnetic resonance images using pretrained deep neural networks. Since all tumors are different sizes, we also explore different image resizing methods in the paper. We demonstrate that deep features can result in better survival time prediction with the highest accuracy of 95.45% versus conventional feature extraction methods from magnetic resonance images of the brain.","","","10.1109/IJCNN.2016.7727204","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7727204","","Histograms;Magnetic resonance imaging","biomedical MRI;brain;feature extraction;image representation;learning (artificial intelligence);medical image processing;neural nets;tumours","brain tumor magnetic resonance images;deep features;feature representations;image resizing methods;novel image feature extraction method;pretrained deep convolutional neural networks;survival time prediction;transfer learning","","","","","","","","24-29 July 2016","","IEEE","IEEE Conference Publications"
"Label inference encoded with local and global patch priors","S. Bao; A. C. S. Chung","Lo Kwee-Seong Medical Image Analysis Laboratory, Department of Computer Science and Engineering, The Hong Kong University of Science and Technology, Hong Kong","2016 IEEE International Conference on Image Processing (ICIP)","20160819","2016","","","3374","3378","In this paper, a novel label inference method encoded with local and global patch priors is introduced for the segmentation of subcortical structures in brain MR images. Due to the serious overlap of intensity profiles among different tissues in brain MR images, the conventional patch prior estimated with similarity measurement can be adversely impacted and become misleading during the final label inference procedure. As such, to obtain a more discriminative patch representation, we propose to capture local patch prior using sparse learning. Besides the local and low-level patch prior, the high-level structural properties of each subcortical structure are also taken into consideration and global patch prior is extracted with Convolutional Neural Networks. Experiments have been carried out on two publicly available datasets and results indicate that the proposed method can obtain the best performance as compared with other state-of-the-art methods.","","Electronic:978-1-4673-9961-6; POD:978-1-4673-9962-3","10.1109/ICIP.2016.7532985","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7532985","CNN;Segmentation;brain MR image;sparse learning","Biomedical imaging;Feature extraction;Hippocampus;Image edge detection;Image segmentation;Labeling;Lattices","biomedical MRI;feature extraction;image coding;image segmentation;inference mechanisms;learning (artificial intelligence);medical image processing;neural net architecture","brain MR image tissues;convolutional neural networks;global patch priors;high-level structural properties;intensity profile overlap;label inference encoding;publicly available datasets;sparse learning;sparse local low-level patch prior;subcortical structure segmentation","","","","17","","","","25-28 Sept. 2016","","IEEE","IEEE Conference Publications"
"Modality Classification for Searching Figures in Biomedical Literature","Z. Xue; M. M. Rahman; S. Antani; L. R. Long; D. Demner-Fushman; G. R. Thoma","Lister Hill Nat. Center for Biomed. Commun., Nat. Libr. of Med., Bethesda, MD, USA","2016 IEEE 29th International Symposium on Computer-Based Medical Systems (CBMS)","20160818","2016","","","152","157","Image modality classification categorizes images according to their type. It is an important module in the Open-iSM multimodal (text+image) search engine that retrieves figures from biomedical articles. It is a hierarchical classification where on the top level the input figures are classified into two general categories: regular images (X-ray, CT, MRI, photographs, etc.) vs. illustration images (cartoon sketch, charts, graphs, etc.). This binary classification task is challenged by the vast diversity of visual material (image type), and the way it is organized (simple or compound figures). We present two methods for this binary classification: (i) Support Vector Machines (SVM) with manually-selected features, including a feature based on semantic concepts, and, (ii) Deep Learning method which avoids the process of feature handcrafting. Both methods were tested and compared on a dataset of 16400 figures. Both methods achieved good performance (above 95% accuracy). The slightly better performance of the feature-based method demonstrates the effectiveness of the features we chose.","","Electronic:978-1-4673-9036-1; POD:978-1-4673-9037-8","10.1109/CBMS.2016.29","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7545975","Modality classification;concept feature;convolutional neural networks;deep learning;figure searching;support vector machine","Biomedical imaging;Image color analysis;Image edge detection;Neural networks;Semantics;Support vector machines;Visualization","image classification;image retrieval;learning (artificial intelligence);medical image processing;search engines;support vector machines","Open-iSM multimodal search engine;SVM;binary classification task;biomedical literature;deep learning;figure retrieval;figure searching;hierarchical classification;illustration images;image modality classification;regular images;support vector machines","","","","","","","","20-24 June 2016","","IEEE","IEEE Conference Publications"
"Deep 3D Convolutional Encoder Networks With Shortcuts for Multiscale Feature Integration Applied to Multiple Sclerosis Lesion Segmentation","T. Brosch; L. Y. W. Tang; Y. Yoo; D. K. B. Li; A. Traboulsee; R. Tam","Multiple Sclerosis/Magnetic Resonance Imaging Research Group, Division of Neurology, The University of British Columbia, Vancouver, Canada","IEEE Transactions on Medical Imaging","20160429","2016","35","5","1229","1239","We propose a novel segmentation approach based on deep 3D convolutional encoder networks with shortcut connections and apply it to the segmentation of multiple sclerosis (MS) lesions in magnetic resonance images. Our model is a neural network that consists of two interconnected pathways, a convolutional pathway, which learns increasingly more abstract and higher-level image features, and a deconvolutional pathway, which predicts the final segmentation at the voxel level. The joint training of the feature extraction and prediction pathways allows for the automatic learning of features at different scales that are optimized for accuracy for any given combination of image types and segmentation task. In addition, shortcut connections between the two pathways allow high- and low-level features to be integrated, which enables the segmentation of lesions across a wide range of sizes. We have evaluated our method on two publicly available data sets (MICCAI 2008 and ISBI 2015 challenges) with the results showing that our method performs comparably to the top-ranked state-of-the-art methods, even when only relatively small data sets are available for training. In addition, we have compared our method with five freely available and widely used MS lesion segmentation methods (EMS, LST-LPA, LST-LGA, Lesion-TOADS, and SLS) on a large data set from an MS clinical trial. The results show that our method consistently outperforms these other methods across a wide range of lesion sizes.","0278-0062;02780062","","10.1109/TMI.2016.2528821","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7404285","Convolutional neural networks;deep learning;machine learning;magnetic resonance imaging (MRI);multiple sclerosis lesions;segmentation","Convolution;Feature extraction;Image segmentation;Imaging;Lesions;Neural networks;Training","biomedical MRI;feature extraction;image segmentation;medical image processing;neural nets","EMS;ISBI 2015 challenges;LST-LGA;LST-LPA;Lesion-TOADS;MICCAI 2008 challenges;MS clinical trial;MS lesion segmentation methods;SLS;automatic feature learning;convolutional pathway;deconvolutional pathway;deep 3D convolutional encoder networks;feature extraction;higher-level image features;interconnected pathways;low-level features;magnetic resonance images;multiple sclerosis lesion segmentation;multiscale feature integration;neural network;prediction pathways;publicly available data sets;segmentation task;shortcut connections;top-ranked state-of-the-art methods;voxel level","","14","","47","","","20160211","May 2016","","IEEE","IEEE Journals & Magazines"
"Automatic Segmentation of MR Brain Images With a Convolutional Neural Network","P. Moeskops; M. A. Viergever; A. M. Mendrik; L. S. de Vries; M. J. N. L. Benders; I. Išgum","Image Sciences Institute, University Medical Center Utrecht, The Netherlands","IEEE Transactions on Medical Imaging","20160429","2016","35","5","1252","1261","Automatic segmentation in MR brain images is important for quantitative analysis in large-scale studies with images acquired at all ages. This paper presents a method for the automatic segmentation of MR brain images into a number of tissue classes using a convolutional neural network. To ensure that the method obtains accurate segmentation details as well as spatial consistency, the network uses multiple patch sizes and multiple convolution kernel sizes to acquire multi-scale information about each voxel. The method is not dependent on explicit features, but learns to recognise the information that is important for the classification based on training data. The method requires a single anatomical MR image only. The segmentation method is applied to five different data sets: coronal T<sub>2</sub>-weighted images of preterm infants acquired at 30 weeks postmenstrual age (PMA) and 40 weeks PMA, axial T<sub>2</sub>-weighted images of preterm infants acquired at 40 weeks PMA, axial T<sub>1</sub>-weighted images of ageing adults acquired at an average age of 70 years, and T<sub>1</sub>-weighted images of young adults acquired at an average age of 23 years. The method obtained the following average Dice coefficients over all segmented tissue classes for each data set, respectively: 0.87, 0.82, 0.84, 0.86, and 0.91. The results demonstrate that the method obtains accurate segmentations in all five sets, and hence demonstrates its robustness to differences in age and acquisition protocol.","0278-0062;02780062","","10.1109/TMI.2016.2548501","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7444155","Adult brain;MRI;automatic image segmentation;convolutional neural networks;deep learning;preterm neonatal brain","Aging;Biomedical imaging;Brain;Convolution;Image segmentation;Kernel;Pediatrics","biological tissues;biomedical MRI;brain;image segmentation;medical image processing;neural nets;neurophysiology;paediatrics","acquisition protocol;ageing adults;automatic MR brain image segmentation;average Dice coefficients;axial T<sub>2</sub>-weighted images;convolutional neural network;coronal T<sub>2</sub>-weighted images;multiple convolution kernel sizes;multiple patch sizes;multiscale information;postmenstrual age;preterm infants;quantitative analysis;segmented tissue classes;spatial consistency;training data","","11","","46","","","20160330","May 2016","","IEEE","IEEE Journals & Magazines"
"Automatic Detection of Cerebral Microbleeds From MR Images via 3D Convolutional Neural Networks","Q. Dou; H. Chen; L. Yu; L. Zhao; J. Qin; D. Wang; V. C. Mok; L. Shi; P. A. Heng","Department of Computer Science and Engineering, The Chinese University of Hong Kong, HK, China","IEEE Transactions on Medical Imaging","20160429","2016","35","5","1182","1195","Cerebral microbleeds (CMBs) are small haemorrhages nearby blood vessels. They have been recognized as important diagnostic biomarkers for many cerebrovascular diseases and cognitive dysfunctions. In current clinical routine, CMBs are manually labelled by radiologists but this procedure is laborious, time-consuming, and error prone. In this paper, we propose a novel automatic method to detect CMBs from magnetic resonance (MR) images by exploiting the 3D convolutional neural network (CNN). Compared with previous methods that employed either low-level hand-crafted descriptors or 2D CNNs, our method can take full advantage of spatial contextual information in MR volumes to extract more representative high-level features for CMBs, and hence achieve a much better detection accuracy. To further improve the detection performance while reducing the computational cost, we propose a cascaded framework under 3D CNNs for the task of CMB detection. We first exploit a 3D fully convolutional network (FCN) strategy to retrieve the candidates with high probabilities of being CMBs, and then apply a well-trained 3D CNN discrimination model to distinguish CMBs from hard mimics. Compared with traditional sliding window strategy, the proposed 3D FCN strategy can remove massive redundant computations and dramatically speed up the detection process. We constructed a large dataset with 320 volumetric MR scans and performed extensive experiments to validate the proposed method, which achieved a high sensitivity of 93.16% with an average number of 2.74 false positives per subject, outperforming previous methods using low-level descriptors or 2D CNNs by a significant margin. The proposed method, in principle, can be adapted to other biomarker detection tasks from volumetric medical data.","0278-0062;02780062","","10.1109/TMI.2016.2528129","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7403984","3D convolutional neural networks;biomarker detection;cerebral microbleeds;deep learning;susceptibility-weighted imaging","Biomarkers;Feature extraction;Kernel;MIMICs;Medical diagnostic imaging;Three-dimensional displays","biomedical MRI;blood;blood vessels;brain;cognition;diseases;feature extraction;haemodynamics;medical image processing;neurophysiology;probability","3D FCN strategy;3D convolutional neural networks;3D fully convolutional network strategy;CMB detection;MR volume extraction;MRI;automatic cerebral microbleed detection;blood vessels;cerebrovascular diseases;cognitive dysfunctions;current clinical routine;diagnostic biomarkers;haemorrhages;low-level hand-crafted descriptors;magnetic resonance images;massive redundant computations;probabilities;radiologists;representative high-level features;spatial contextual information;traditional sliding window strategy;well-trained 3D CNN discrimination","","15","","52","","","20160211","May 2016","","IEEE","IEEE Journals & Magazines"
"Anatomical Landmark Detection in Medical Applications Driven by Synthetic Data","G. Riegler; M. Urschler; M. Rüther; H. Bischof; D. Stern","Graz Univ. of Technol., Graz, Austria","2015 IEEE International Conference on Computer Vision Workshop (ICCVW)","20160215","2015","","","85","89","An important initial step in many medical image analysis applications is the accurate detection of anatomical landmarks. Most successful methods for this task rely on data-driven machine learning algorithms. However, modern machine learning techniques, e.g. convolutional neural networks, need a large corpus of training data, which is often an unrealistic setting for medical datasets. In this work, we investigate how to adapt synthetic image datasets from other computer vision tasks to overcome the under-representation of the anatomical pose and shape variations in medical image datasets. We transform both data domains to a common one in such a way that a convolutional neural network can be trained on the larger synthetic image dataset and fine-tuned on the smaller medical image dataset. Our evaluations on data of MR hand and whole body CT images demonstrate that this approach improves the detection results compared to training a convolutional neural network only on the medical data. The proposed approach may also be usable in other medical applications, where training data is scarce.","","Electronic:978-1-4673-9711-7; POD:978-1-4673-9712-4","10.1109/ICCVW.2015.21","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7406370","","Biomedical imaging;Computed tomography;Shape;Three-dimensional displays;Training;Training data","biomedical MRI;computer vision;computerised tomography;learning (artificial intelligence);medical image processing;neural nets;object detection","MR hand;anatomical landmark detection;computer tomography;computer vision;convolutional neural network;magnetic resonance;medical image analysis;neural network training;whole body CT images","","","","20","","","","7-13 Dec. 2015","","IEEE","IEEE Conference Publications"
"Automatic cerebral microbleeds detection from MR images via Independent Subspace Analysis based hierarchical features","Q. Dou; H. Chen; L. Yu; L. Shi; D. Wang; V. C. Mok; P. A. Heng","Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong","2015 37th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)","20151105","2015","","","7933","7936","With the development of susceptibility weighted imaging (SWI) technology, cerebral microbleed (CMB) detection is increasingly essential in cerebrovascular diseases diagnosis and cognitive impairment assessment. Clinical CMB detection is based on manual rating which is subjective and time-consuming with limited reproducibility. In this paper, we propose a computer-aided system for automatic detection of CMBs from brain SWI images. Our approach detects the CMBs within three stages: (i) candidates screening based on intensity values (ii) compact 3D hierarchical features extraction via a stacked convolutional Independent Subspace Analysis (ISA) network (iii) false positive candidates removal with a support vector machine (SVM) classifier based on the learned representation features from ISA. Experimental results on 19 subjects (161 CMBs) achieve a high sensitivity of 89.44% with an average of 7.7 and 0.9 false positives per subject and per CMB, respectively, which validate the efficacy of our approach.","1094-687X;1094687X","DVD:978-1-4244-9270-1; Electronic:978-1-4244-9271-8; POD:978-1-4244-9269-5","10.1109/EMBC.2015.7320232","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7320232","Cerebral microbleed;brain SWI;computer aided diagnosis;feature representation","Feature extraction;Imaging;Radio frequency;Sensitivity;Support vector machines;Three-dimensional displays;Training","biomedical MRI;brain;diseases;feature extraction;medical image processing;support vector machines","CMB automatic detection;MR images;automatic cerebral microbleeds detection;brain SWI images;cerebrovascular diseases diagnosis;clinical CMB detection;cognitive impairment assessment;compact 3D hierarchical feature extraction;computer-aided system;stacked convolutional independent subspace analysis network;subspace analysis-based hierarchical features;support vector machine classifier;susceptibility weighted imaging technology","","","","14","","","","25-29 Aug. 2015","","IEEE","IEEE Conference Publications"
"Automated anatomical landmark detection ondistal femur surface using convolutional neural network","D. Yang; S. Zhang; Z. Yan; C. Tan; K. Li; D. Metaxas","CBIM, Rutgers University, Piscataway, NJ, US","2015 IEEE 12th International Symposium on Biomedical Imaging (ISBI)","20150723","2015","","","17","21","Accurate localization of the anatomical landmarks on distal femur bone in the 3D medical images is very important for knee surgery planning and biomechanics analysis. However, the landmark identification process is often conducted manually or by using the inserted auxiliaries, which is time-consuming and lacks of accuracy. In this paper, an automatic localization method is proposed to determine positions of initial geometric landmarks on femur surface in the 3D MR images. Based on the results from the convolutional neural network (CNN) classifiers and shape statistics, we use the narrow-band graph cut optimization to achieve the 3D segmentation of femur surface. Finally, the anatomical landmarks are located on the femur according to the geometric cues of surface mesh. Experiments demonstrate that the proposed method is effective, efficient, and reliable to segment femur and locate the anatomical landmarks.","1945-7928;19457928","Electronic:978-1-4799-2374-8; POD:978-1-4673-9330-0","10.1109/ISBI.2015.7163806","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7163806","Deep learning;anatomical landmark detection;convolutional neural network;graph cut;mesh curvature","Biomedical imaging;Bones;Image segmentation;Neural networks;Shape;Three-dimensional displays;Training","biomechanics;biomedical MRI;bone;graph theory;image classification;medical image processing;neural nets;optimisation;surgery","3D MR images;3D medical images;3D segmentation;CNN classifiers;automated anatomical landmark detection;automatic localization method;biomechanics analysis;convolutional neural network;distal femur bone;distal femur surface;knee surgery planning;landmark identification process;magnetic resonance images;narrow-band graph cut optimization;shape statistics;surface mesh","","0","","20","","","","16-19 April 2015","","IEEE","IEEE Conference Publications"
"MR Image Reconstruction with Convolutional Characteristic Constraint (CoCCo)","X. Peng; D. Liang","Paul C. Lauterbur Research Center for Biomedical Imaging, Shenzhen Institutes of Advanced Technology, Shenzhen, China","IEEE Signal Processing Letters","20150120","2015","22","8","1184","1188","The problem of recovering an image from limited or sparsely sampled Fourier measurements occurs in the application of magnetic resonance imaging. To address this problem, we propose a novel MR image reconstruction method with convolutional characteristic constraints. We first estimate the convolutional characteristics using standard compressed sensing method in a parallel fashion. Then we use the recovered image characteristics to constrain the target image function. The image characteristics should either be sparser or of higher SNR than the original image to enable superior performance. In this work, we studied using thirteen kernels and experiments based on a brain data set were conducted. It is demonstrated that the proposed method outperforms the existing methods in terms of high quality imaging due to multiple characteristic constraints and the robustness to measurement noise.","1070-9908;10709908","","10.1109/LSP.2014.2376699","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6971076","Compressed sensing (CS);constrained imaging;convolutional characteristic;magnetic resonance imaging (MRI)","Biomedical measurement;Convolution;Image reconstruction;Kernel;Magnetic resonance imaging;Noise;Standards","biomedical MRI;compressed sensing;convolution;image reconstruction;medical image processing","CoCCo;MR image reconstruction method;SNR;brain data set;convolutional characteristic constraint;image recovery;magnetic resonance imaging;measurement noise;sparsely sampled Fourier measurements;standard compressed sensing method;target image function","","4","","19","","","20141202","Aug. 2015","","IEEE","IEEE Journals & Magazines"
"Modeling latency and shape changes in trial based neuroimaging data","M. Mørup; L. K. Hansen; K. H. Madsen","Section for Cogntive Systems, DTU Informatics, Technical University of Denmark, Denmark","2011 Conference Record of the Forty Fifth Asilomar Conference on Signals, Systems and Computers (ASILOMAR)","20120426","2011","","","439","443","To overcome poor signal-to-noise ratios in neuroimaging, data sets are often acquired over repeated trials that form a three-way array of space×time×trials. As neuroimaging data contain multiple inter-mixed signal components blind signal separation and decomposition methods are frequently invoked for exploratory analysis and as a preprocessing step for signal detection. Most previous component analyses have avoided working directly with the tri-linear structure, but resorted to bi-linear models such as ICA, PCA, and NMF. Multi-linear decomposition can exploit consistency over trials and contrary to bi-linear decomposition render unique representations without additional constraints. However, they can degenerate if data does not comply with the given multi-linear structure, e.g., due to time-delays. Here we extend multi-linear decomposition to account for general temporal modeling within a convolutional representation. We demonstrate how this alleviates degeneracy and helps to extract physiologically plausible components. The resulting convolutive multi-linear decomposition can model realistic trial variability as demonstrated in EEG and fMRI data.","1058-6393;10586393","Electronic:978-1-4673-0323-1; POD:978-1-4673-0321-7","10.1109/ACSSC.2011.6190037","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6190037","","Analytical models;Brain models;Data models;Delay;Electroencephalography;Visualization","biomedical MRI;blind source separation;convolution;electroencephalography;medical signal detection;neurophysiology","EEG data;bilinear decomposition;blind signal separation;convolutional representation;convolutive multilinear decomposition;electroencephalography;fMRI data;functional magnetic resonance imaging;multiple intermixed signal component;signal decomposition methods;signal detection;temporal modeling;trial based neuroimaging data;trial variability;trilinear structure","","2","","29","","","","6-9 Nov. 2011","","IEEE","IEEE Conference Publications"
"Theoretical Quality Assessment of Myocardial Elastography with In Vivo Validation","W. n. Lee; C. M. Ingrassia; S. D. Fung-kee-fung; K. D. Costa; J. W. Holmes; E. E. Konofagou","Columbia Univ., New York","IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control","20071210","2007","54","11","2233","2245","Myocardial elastography (ME), a radio frequency (RF)-based speckle tracking technique with one-dimensional (1-D) cross correlation and novel recorrelation methods in a 2-D search was proposed to estimate and fully image 2-1) transmural deformation field and to detect abnormal cardiac function. A theoretical framework was first developed in order to evaluate the performance of 2-D myocardial elastography based on a previously developed 3-D finite-element model of the canine left ventricle. A normal (control) and an ischemic (left-circumflex, LCx) model, which more completely represented myocardial deformation than a kinematic model, were considered. A 2-D convolu-tional image formation model was first used to generate RF signals for quality assessment of ME in the normal and ischemic cases. A 3-D image formation model was further developed to investigate the effect of the out-of-plane motion on the 2-D, in-plane motion estimation. Both orthogonal, in-plane displacement components (i.e., lateral and axial) between consecutive RF frames were iteratively estimated. All the estimated incremental 2-D displacements from end-diastole (ED) to end-systole (ES) were then accumulated to acquire the cumulative 2-D displacements, which were further used to calculate the cumulative 2-D systolic finite strains. Furthermore, the cumulative systolic radial and circumferential strains, which were angle-and frame-rate independent, were obtained from the 2-D finite-strain components and imaged in full view to detect the ischemic region. We also explored the theoretical understanding of the limitations of our technique for the accurate depiction of disease and validated it in vivo against tagged magnetic resonance imaging (tMRI) in the case of a normal human myocardium in a 2-D short-axis (SA) echocardiographic view. The theoretical framework succeeded in demonstrating that the 2-D myocardial elastography technique was a reliable tool for the complete estimation and depiction of the in-p- - lane myocardial deformation field as well as for accurate identification of pathological mechanical function using established finite-element, left-ventricular canine models. In a preliminary study, the 2-D myocardial elastography was shown capable of imaging myocardial deformation comparable to equivalent tMRI estimates in a clinical setting.","0885-3010;08853010","","10.1109/TUFFC.2007.528","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4399698","","Deformable models;Finite element methods;Frequency estimation;In vivo;Kinematics;Myocardium;Quality assessment;Radio frequency;Signal generators;Speckle","biomedical MRI;deformation;diseases;echocardiography;finite element analysis;haemodynamics;iterative methods;medical image processing;motion estimation;muscle","2-D convolutional image formation model;2-D systolic finite strains;3-D finite-element model;abnormal cardiac function;canine left ventricle;disease;echocardiography;end-diastole;end-systole;in-plane displacement;in-plane motion estimation;iterative estimation;left-ventricular canine models;magnetic resonance imaging;myocardial elastography;myocardium;one-dimensional cross correlation;out-of-plane motion;radio frequency-based speckle tracking technique;recorrelation methods;schemia;transmural deformation","Algorithms;Echocardiography, Three-Dimensional;Elasticity;Elasticity Imaging Techniques;Humans;Image Enhancement;Image Interpretation, Computer-Assisted;Models, Cardiovascular;Myocardial Ischemia;Quality Assurance, Health Care;Reproducibility of Results;Sensitivity and Specificity;Stress, Mechanical;Ventricular Dysfunction, Left","53","7","1","","","","Nov. 2007","","IEEE","IEEE Journals & Magazines"
