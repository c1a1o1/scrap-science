"http://ieeexplore.ieee.org/search/searchresult.jsp?bulkSetSize=2000&queryText%3Dcnn+medical",2017/09/15 10:02:56
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","License","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"Variational computing based segmentation methods for medical imaging by using CNN","A. Gacsádi; P. Szolgay","Electronics Department, University of Oradea, Oradea, Romania","2010 12th International Workshop on Cellular Nanoscale Networks and their Applications (CNNA 2010)","20100329","2010","","","1","6","The paper presents a new variational computing based medical image segmentation method by using Cellular Neural Networks (CNN). By implementing the proposed algorithm on FPGA (Field Programmable Gate Array) with an emulated digital CNN-UM (CNN-Universal Machine) there is the possibility to meet the requirements for medical image segmentation.","2165-0144;21650144","Electronic:978-1-4244-6680-1; POD:978-1-4244-6679-5","10.1109/CNNA.2010.5430256","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5430256","cellular neural networks;medical imaging;segmentation;variational computing","Application software;Biomedical imaging;Cellular networks;Cellular neural networks;Computed tomography;Computer networks;Image segmentation;Magnetic resonance imaging;Medical diagnostic imaging;Optimization methods","cellular neural nets;field programmable gate arrays;image segmentation;medical image processing;variational techniques","cellular neural networks;digital CNN-universal machine;field programmable gate array;medical image segmentation;medical imaging;variational computing","","3","","20","","","","3-5 Feb. 2010","","IEEE","IEEE Conference Publications"
"Design of complex-valued CNN filters for medical image enhancement","K. Kondo; M. Iguchi; H. Ishigaki; Y. Konishi; K. Mabuchi","Fac. of Eng., Himeji Inst. of Technol., Hyogo, Japan","Proceedings Joint 9th IFSA World Congress and 20th NAFIPS International Conference (Cat. No. 01TH8569)","20020807","2001","3","","1642","1646 vol.3","In this paper, we present a new image enhancement technique, using cellular neural network (CNN) filters with complex weighting factors, that is applicable to medical images. Since CNN-type filters have only spatially local interconnections and the number of connections between neurons is relatively low, the required computation in the learning phase is a reasonable amount. However, the output/input behavior is restrictive. The proposed CNN filters are designed as complex-coefficient filters which can improve the output SNR and process the 2D analytic signals of input images. The filter parameters are determined by applying a complex domain backpropagation algorithm. Through several simulations, it is shown that the proposed filters are robust and noise-tolerant for medical images","","POD:0-7803-7078-3","10.1109/NAFIPS.2001.943797","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=943797","","Backpropagation algorithms;Biomedical imaging;Cellular neural networks;Filters;Image analysis;Image enhancement;Neurons;Signal analysis;Signal design;Signal processing","backpropagation;cellular neural nets;filtering theory;image enhancement;medical image processing","2D analytic signal processing;complex domain backpropagation algorithm;complex weighting factors;complex-coefficient filters;complex-valued cellular neural network filters;computational requirements;filter parameters;learning phase;medical image enhancement;noise tolerance;output/input behavior;robustness;signal-to-noise ratio;simulations;spatially local neuron interconnections","","0","","6","","","","25-28 July 2001","25 Jul 2001-28 Jul 2001","IEEE","IEEE Conference Publications"
"Medical Concept Normalization for Online User-Generated Texts","K. Lee; S. A. Hasan; O. Farri; A. Choudhary; A. Agrawal","","2017 IEEE International Conference on Healthcare Informatics (ICHI)","20170914","2017","","","462","469","Social media has become an important tool for sharing content in the last decade. People often talk about their experiences and opinions on different health-related issues e.g. they write reviews on medications, describe symptoms and ask informal questions about various health concerns. Due to the colloquial nature of the languages used in the social media, it is often difficult for an automated system to accurately interpret them for appropriate clinical understanding. To address this challenge, this paper proposes a novel approach for medical concept normalization of user-generated texts to map a health condition described in the colloquial language to a medical concept defined in standard clinical terminologies. We use multiple deep learning architectures such as convolutional neural networks (CNN) and recurrent neural networks (RNN) with input word embeddings trained on various clinical domain-specific knowledge sources. Extensive experiments on two benchmark datasets demonstrate that the proposed models can achieve up to 21.28% accuracy improvements over the existing models when we use the combination of all knowledge sources to learn neural embeddings.","","Electronic:978-1-5090-4881-6; POD:978-1-5090-4882-3","10.1109/ICHI.2017.59","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8031195","deep learning;medical concept normalization;social media","Drugs;Hair;Hidden Markov models;Medical diagnostic imaging;Pain;Recurrent neural networks;Social network services","","","","","","","","","","23-26 Aug. 2017","","IEEE","IEEE Conference Publications"
"Image quality classification for DR screening using deep learning","F. Yu; J. Sun; A. Li; J. Cheng; C. Wan; J. Liu","Nanjing University of Aeronautics and Astronautics, China","2017 39th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)","20170914","2017","","","664","667","The quality of input images significantly affects the outcome of automated diabetic retinopathy (DR) screening systems. Unlike the previous methods that only consider simple low-level features such as hand-crafted geometric and structural features, in this paper we propose a novel method for retinal image quality classification (IQC) that performs computational algorithms imitating the working of the human visual system. The proposed algorithm combines unsupervised features from saliency map and supervised features coming from convolutional neural networks (CNN), which are fed to an SVM to automatically detect high quality vs poor quality retinal fundus images. We demonstrate the superior performance of our proposed algorithm on a large retinal fundus image dataset and the method could achieve higher accuracy than other methods. Although retinal images are used in this study, the methodology is applicable to the image quality assessment and enhancement of other types of medical images.","","Electronic:978-1-5090-2809-2; POD:978-1-5090-2810-8","10.1109/EMBC.2017.8036912","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8036912","convolutional neural networks;image quality classification;saliency map","","","","","","","","","","","11-15 July 2017","","IEEE","IEEE Conference Publications"
"Fine-grained image recognition via weakly supervised click data guided bilinear CNN model","G. Zheng; M. Tan; J. Yu; Q. Wu; J. Fan","Key Laboratory of Complex Systems Modeling and Simulation, School of Computer Science and Technology, Hangzhou Dianzi University","2017 IEEE International Conference on Multimedia and Expo (ICME)","20170831","2017","","","661","666","Bilinear convolutional neural networks (BCNN) model, the state-of-the-art in fine-grained image recognition, fails in distinguishing the categories with subtle visual differences. We design a novel BCNN model guided by user click data (C-BCNN) to improve the performance via capturing both the visual and semantical content in images. Specially, to deal with the heavy noise in large-scale click data, we propose a weakly supervised learning approach to learn the C-BCNN, namely W-C-BCNN. It can automatically weight the training images based on their reliability. Extensive experiments are conducted on the public Clickture-Dog dataset. It shows that: (1) integrating CNN with click feature largely improves the performance; (2) both the click data and visual consistency can help to model image reliability. Moreover, the method can be easily customized to medical image recognition. Our model performs much better than conventional BCNN models on both the Clickture-Dog and medical image dataset.","","Electronic:978-1-5090-6067-2; POD:978-1-5090-6068-9; USB:978-1-5090-6066-5","10.1109/ICME.2017.8019407","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8019407","Bilinear CNN;Fine-grained Image Recognition;User Click Data;Weakly Supervised Learning","Computational modeling;Data models;Feature extraction;Image recognition;Reliability;Training;Visualization","","","","","","","","","","10-14 July 2017","","IEEE","IEEE Conference Publications"
"Analysis of Disfluencies for automatic detection of Mild Cognitive Impartment: a deep learning approach","K. Lopez-de-Ipina; U. Martinez-de-Lizarduy; P. M. Calvo; B. Beitia; J. Garcia-Melero; M. Ecay-Torres; A. Estanga; M. Faundez-Zanuy","Faculty of Engineering 20018, Donostia-San Sebastian Spain Universidad del Pais Vasco/Euskal Herriko Unibertsitatea (UPV/EHU) {karmele.ipina, unai.martinezdelizarduy, pilarmaria.calvo, mariablanca.beitia","2017 International Conference and Workshop on Bioinspired Intelligence (IWOBI)","20170724","2017","","","1","4","The so-called Mild Cognitive Impairment (MCI) or cognitive loss appears in a previous stage before Alzheimer's Disease (AD), but it does not seem sufficiently severe to interfere in independent abilities of daily life, so it usually does not receive an appropriate diagnosis. Its detection is a challenging issue to be addressed by medical specialists. This work presents a novel proposal based on automatic analysis of speech and disfluencies aimed at supporting MCI diagnosis. The approach includes deep learning by means of Convolutional Neural Networks (CNN) and non-linear multifeature modelling. Moreover, to select the most relevant features non-parametric Mann-Whitney U-testt and Support Vector Machine Attribute (SVM) evaluation are used.","","Electronic:978-1-5386-0850-0; POD:978-1-5386-0851-7","10.1109/IWOBI.2017.7985526","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7985526","Automatic speechanalysis;Convolutional Neural Networks;Deep Learning;Disfluencies;Mild Cognitive Impairment;Nonlinearfeatures","Dementia;Frequency modulation;Machine learning;Neurons;Speech;Support vector machines","cognition;diseases;learning (artificial intelligence);medical signal detection;neural nets;speech;speech processing;support vector machines","Alzheimer disease;MCI diagnosis;automatic mild cognitive impartment detection;convolutional neural networks;deep learning approach;disfluencies analysis;nonlinear multifeature modelling;nonparametric Mann-Whitney U-test;speech analysis;support vector machine attribute evaluation","","","","","","","","10-12 July 2017","","IEEE","IEEE Conference Publications"
"Cell classification using convolutional neural networks in medical hyperspectral imagery","Xiang Li; W. Li; Xiaodong Xu; Wei Hu","College of Information Science & Technology, Beijing University of Chemical Technology, China","2017 2nd International Conference on Image, Vision and Computing (ICIVC)","20170720","2017","","","501","504","Hyperspectral imaging is a rising imaging modality in the field of medical applications, and the combination of both spectral and spatial information provides wealth information for cell classification. In this paper, deep convolutional neural network (CNN) is employed to achieve blood cell discrimination in medical hyperspectral images (MHSI). As a deep learning architecture, CNNs are expected to get more discriminative and semantic features, which effect classification accuracy to a certain extent. Experimental results based on two real medical hyperspectral image data sets demonstrate that cell classification using CNNs is effective. In addition, compared to traditional support vector machine (SVM), the proposed method, which jointly exploits spatial and spectral features, can achieve better classification performance, showcasing the CNN-based methods' tremendous potential for accurate medical hyperspectral data classification.","","DVD:978-1-5090-6236-2; Electronic:978-1-5090-6238-6; POD:978-1-5090-6239-3","10.1109/ICIVC.2017.7984606","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7984606","blood cell classification;convolutional neural network;deep learning;medical hyperspectral imagery","Blood;Computer architecture;Hyperspectral imaging;Medical diagnostic imaging;Microprocessors;Support vector machines","blood;cellular biophysics;feature extraction;hyperspectral imaging;image classification;learning (artificial intelligence);medical image processing;neural nets","CNN;blood cell discrimination;cell classification;deep convolutional neural network;deep learning architecture;discriminative features;hyperspectral imaging;medical applications;medical hyperspectral data classification;medical hyperspectral imagery;semantic features;spatial features;spatial information;spectral features;spectral information","","","","","","","","2-4 June 2017","","IEEE","IEEE Conference Publications"
"Fast medical image segmentation based on patch sharing","Jinjin Hai; Jian Chen; Kai Qiao; Lei Zeng; Jingbo Xu; Bin Yan","National Digital Switching System Engineering & Technological Research Centre, Zhengzhou, China","2017 2nd International Conference on Image, Vision and Computing (ICIVC)","20170720","2017","","","336","340","The lack of labeled medical data is a severe challenge of applying CNNs in medical image segmentation. The common method to solve this problem is employing patches extracted from every pixel of the entire image as train samples. But classifying every pixel in the image is time-consuming, which is not appropriate in practical medical application. This paper proposed a fast segmentation algorithm based on trained network model to reduce test time. Transforming the fully-connected layer of trained network into convolutional layer is used as the test network and the entire image is the input of test network. However, due to the convolutional and pooling operation of CNN, some pixel classification results are missed. To obtain corresponding segmentation, different size of original image are cropped as the input of test network, and interpolation is taken to supply the final image segmentation, according to the offset rule of the input images. The numerical simulation experiments indicated that the proposed algorithm show prominent performance in segmentation time and remain unchanged in the final segmentation result compared with initial train network architecture.","","DVD:978-1-5090-6236-2; Electronic:978-1-5090-6238-6; POD:978-1-5090-6239-3","10.1109/ICIVC.2017.7984573","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7984573","convolutional neural network;medical image segmentation;patch sharing","Art;Convolution;Image segmentation;Knowledge engineering;Magnetic resonance imaging;Medical diagnostic imaging","convolution;feature extraction;image classification;image segmentation;learning (artificial intelligence);medical image processing","CNNs;convolutional layer;fast medical image segmentation;image cropping;medical data;patch extraction;patch sharing;pixel classification;trained network model","","","","","","","","2-4 June 2017","","IEEE","IEEE Conference Publications"
"A Unified Deep Learning Model for Protein Structure Prediction","L. Bai; L. Yang","Sch. of Comput., Electron. & Inf. Guangxi Univ., Nanning, China","2017 3rd IEEE International Conference on Cybernetics (CYBCONF)","20170720","2017","","","1","6","Predicting protein tertiary structure from its primary amino acid sequence is one of the most challenging problems in bioinformatics, which makes an important impact in the field of medical science. The mainly difficult is how to learn the most useful and suitable protein features to improve the prediction. In this paper, we propose a novel unified deep learning model for improving protein tertiary structure prediction. The core contribution of this work is the group of deep convolution neural networks (deep CNNs) that can directly learn the high-level relational features from a pair of the query and target protein sequences. The deep CNN can learn high-level relational features from the pairwise protein sequences in a hierarchy by progressively integrating convergent protein property representations from lower levels. Multiple deep CNNs are designed to achieve robust protein structure similarities from different aspects. These relational features are fully connected to the top two Restricted Boltzmann Machines (RBMS) layer to further extract global relational features, which significantly improve the protein structure prediction. Experiments conducted on a well-known benchmark, SCOPe dataset, show that our model significantly outperforms the state-of-the-art methods in various statistical measurements. The results also demonstrate that our deep learning model can improve the learning of protein properties.","","Electronic:978-1-5386-2201-8; POD:978-1-5386-2202-5","10.1109/CYBConf.2017.7985752","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7985752","","Convolution;Feature extraction;Hidden Markov models;Machine learning;Predictive models;Protein sequence","Boltzmann machines;bioinformatics;feedforward neural nets;learning (artificial intelligence);proteins;statistical analysis","RBMS layer;SCOPe dataset benchmark;bioinformatics;convergent protein property representations;deep CNN;deep-convolution neural networks;global relational feature extraction;high-level relational feature learning;pairwise protein sequences;primary amino acid sequence;protein feature learning;protein tertiary structure prediction;query protein sequences;restricted Boltzmann machine layer;robust protein structure similarities;statistical measurements;target protein sequences;unified deep-learning model","","","","","","","","21-23 June 2017","","IEEE","IEEE Conference Publications"
"Detecting Anatomical Landmarks From Limited Medical Imaging Data Using Two-Stage Task-Oriented Deep Neural Networks","J. Zhang; M. Liu; D. Shen","Department of Radiology and the Biomedical Research Imaging Center, University of North Carolina at Chapel Hill, Chapel Hill, NC, USA","IEEE Transactions on Image Processing","20170718","2017","26","10","4753","4764","One of the major challenges in anatomical landmark detection, based on deep neural networks, is the limited availability of medical imaging data for network learning. To address this problem, we present a two-stage task-oriented deep learning method to detect large-scale anatomical landmarks simultaneously in real time, using limited training data. Specifically, our method consists of two deep convolutional neural networks (CNN), with each focusing on one specific task. Specifically, to alleviate the problem of limited training data, in the first stage, we propose a CNN based regression model using millions of image patches as input, aiming to learn inherent associations between local image patches and target anatomical landmarks. To further model the correlations among image patches, in the second stage, we develop another CNN model, which includes a) a fully convolutional network that shares the same architecture and network weights as the CNN used in the first stage and also b) several extra layers to jointly predict coordinates of multiple anatomical landmarks. Importantly, our method can jointly detect large-scale (e.g., thousands of) landmarks in real time. We have conducted various experiments for detecting 1200 brain landmarks from the 3D T1-weighted magnetic resonance images of 700 subjects, and also 7 prostate landmarks from the 3D computed tomography images of 73 subjects. The experimental results show the effectiveness of our method regarding both accuracy and efficiency in the anatomical landmark detection.","1057-7149;10577149","","10.1109/TIP.2017.2721106","10.13039/100000002 - NIH; ","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7961205","Anatomical landmark detection;deep convolutional neural networks;limited medical imaging data;real-time;task-oriented","Biological neural networks;Biomedical imaging;Machine learning;Testing;Three-dimensional displays;Training;Training data","biomedical MRI;computerised tomography;feedforward neural nets;learning (artificial intelligence);medical image processing;object detection;regression analysis","3D T1-weighted magnetic resonance images;3D computed tomography images;CNN based regression model;anatomical landmark coordinate prediction;anatomical landmark detection;brain landmarks;deep convolutional neural networks;fully convolutional network;local image patches;medical imaging data;network learning;prostate landmarks;training data;two-stage task-oriented deep learning method;two-stage task-oriented deep neural networks","","","","","","","20170628","Oct. 2017","","IEEE","IEEE Journals & Magazines"
"An Automatic Detection System of Lung Nodule Based on Multi-Group Patch-Based Deep Learning Network","H. Jiang; H. Ma; W. Qian; M. Gao; Y. Li","shenyang China (e-mail: hongyang1020@126.com)","IEEE Journal of Biomedical and Health Informatics","","2017","PP","99","1","1","High-efficiency lung nodule detection dramatically contributes to the risk assessment of lung cancer. It is a significant and challenging task to quickly locate the exact positions of lung nodules. Extensive work has been done by researchers around this domain for approximately two decades. However, previous computer aided detection (CADe) schemes are mostly intricate and time-consuming since they may require more image processing modules, such as the computed tomography (CT) image transformation, the lung nodule segmentation and the feature extraction, to construct a whole CADe system. It is difficult for those schemes to process and analyze enormous data when the medical images continue to increase. Besides, some state of the art deep learning schemes may be strict in the standard of database. This study proposes an effective lung nodule detection scheme based on multi-group patches cut out from the lung images, which are enhanced by the Frangi filter. Through combining two groups of images, a four-channel convolution neural networks (CNN) model is designed to learn the knowledge of radiologists for detecting nodules of four levels. This CADe scheme can acquire the sensitivity of 80.06% with 4.7 false positives per scan and the sensitivity of 94% with 15.1 false positives per scan. The results demonstrate that the multi-group patch-based learning system is efficient to improve the performance of lung nodule detection and greatly reduce the false positives under a huge amount of image data.","2168-2194;21682194","","10.1109/JBHI.2017.2725903","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7981333","Frangi filter;computed tomography (CT) images;computer aided detection (CADe);deep learning network;lung nodule detection","Biomedical imaging;Cancer;Computed tomography;Databases;Feature extraction;Image segmentation;Lungs","","","","","","","","","20170714","","","IEEE","IEEE Early Access Articles"
"Classification of radiology reports using neural attention models","B. Shin; F. H. Chokshi; T. Lee; J. D. Choi","Mathematics and Computer Science, Emory University, Atlanta, GA 30322","2017 International Joint Conference on Neural Networks (IJCNN)","20170703","2017","","","4363","4370","The electronic health record (EHR) contains a large amount of multi-dimensional and unstructured clinical data of significant operational and research value. Distinguished from previous studies, our approach embraces a double-annotated dataset and strays away from obscure “black-box” models to comprehensive deep learning models. In this paper, we present a novel neural attention mechanism that not only classifies clinically important findings. Specifically, convolutional neural networks (CNN) with attention analysis are used to classify radiology head computed tomography reports based on five categories that radiologists would account for in assessing acute and communicable findings in daily practice. The experiments show that our CNN attention models outperform non-neural models, especially when trained on a larger dataset. Our attention analysis demonstrates the intuition behind the classifier's decision by generating a heatmap that highlights attended terms used by the CNN model; this is valuable when potential downstream medical decisions are to be performed by human experts or the classifier information is to be used in cohort construction such as for epidemiological studies.","","Electronic:978-1-5090-6182-2; POD:978-1-5090-6183-9","10.1109/IJCNN.2017.7966408","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7966408","","Computational modeling;Convolution;Machine learning;Neural networks;Radiology;Sentiment analysis;Support vector machines","computerised tomography;convolution;data analysis;electronic health records;neural nets;pattern classification;radiology","CNN;EHR;attention analysis;convolutional neural networks;double-annotated dataset;electronic health record;neural attention mechanism;neural attention models;radiology head computed tomography reports classification","","","","","","","","14-19 May 2017","","IEEE","IEEE Conference Publications"
"Modeling medical texts for distributed representations based on Skip-Gram model","Z. Zhou; B. Fu; H. Qiu; Y. Zhang; X. Liu","Dept. Big Data Research Center, School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, P. R. China","2017 3rd International Conference on Information Management (ICIM)","20170619","2017","","","279","283","Medical text is complex while its semantic expression is variable. Producing a vector for each medical word to encode its semantic information, as the cornerstone of medical semantic understanding, is quite different from the tasks of natural language processing. In this paper, we focus on the vectorization of Chinese medical text words. To recognize Chinese medical entities, a framework is constructed for Chinese word segmentations by jointly using a built medical dictionary and a trained hidden Markov model. Then, each medical text word is learned by Skip-Gram model into a 128 dimension vector for the distributed representation, and the robustness of the vectorization model is strengthened by negative sampling. Comparing with the one-hot method, the word vectorization method based on Skip-Gram model can improve the performance of the CNN classifier significantly due to the data sparsity and vector dimension decreased. The accuracy is also improved about 15% than that of the one-hot method.","","Electronic:978-1-5090-6306-2; POD:978-1-5090-6307-9; Paper:978-1-5090-6304-8; USB:978-1-5090-6305-5","10.1109/INFOMAN.2017.7950392","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7950392","deep learning;negative sampling;neural network;word vector","Convolution;Dictionaries;Hidden Markov models;Medical diagnostic imaging;Neural networks;Semantics;Vocabulary","hidden Markov models;learning (artificial intelligence);medical information systems;sampling methods;text analysis","CNN classifier;Chinese medical entity recognition;Chinese medical text words;Skip-Gram model;built medical dictionary;distributed representation;hidden Markov model;medical text modeling;medical word;natural language processing;negative sampling;one-hot method;semantic expression;word vectorization method","","","","","","","","21-23 April 2017","","IEEE","IEEE Conference Publications"
"Disease Prediction by Machine Learning Over Big Data From Healthcare Communities","M. Chen; Y. Hao; K. Hwang; L. Wang; L. Wang","School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, China","IEEE Access","20170619","2017","5","","8869","8879","With big data growth in biomedical and healthcare communities, accurate analysis of medical data benefits early disease detection, patient care, and community services. However, the analysis accuracy is reduced when the quality of medical data is incomplete. Moreover, different regions exhibit unique characteristics of certain regional diseases, which may weaken the prediction of disease outbreaks. In this paper, we streamline machine learning algorithms for effective prediction of chronic disease outbreak in disease-frequent communities. We experiment the modified prediction models over real-life hospital data collected from central China in 2013-2015. To overcome the difficulty of incomplete data, we use a latent factor model to reconstruct the missing data. We experiment on a regional chronic disease of cerebral infarction. We propose a new convolutional neural network (CNN)-based multimodal disease risk prediction algorithm using structured and unstructured data from hospital. To the best of our knowledge, none of the existing work focused on both data types in the area of medical big data analytics. Compared with several typical prediction algorithms, the prediction accuracy of our proposed algorithm reaches 94.8% with a convergence speed, which is faster than that of the CNN-based unimodal disease risk prediction algorithm.","","","10.1109/ACCESS.2017.2694446","International Science and Technology Corporation Program of Chinese Ministry of Science and Technology; 10.13039/501100001809 - National Natural Science Foundation of China; ","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7912315","Big data analytics;healthcare;machine learning","Big Data;Data models;Diseases;Hospitals;Machine learning algorithms;Prediction algorithms","Big Data;health care;learning (artificial intelligence);neural nets","CNN-based multimodal disease risk prediction algorithm;convolutional neural network-based multimodal disease risk prediction algorithm;disease prediction;healthcare communities;machine learning algorithms;medical big data analytics;real-life hospital data","","","","","","Traditional","20170426","2017","","IEEE","IEEE Journals & Magazines"
"Domain specific convolutional neural nets for detection of architectural distortion in mammograms","R. Ben-Ari; A. Akselrod-Ballin; L. Karlinsky; S. Hashoul","IBM Research - Haifa, Israel","2017 IEEE 14th International Symposium on Biomedical Imaging (ISBI 2017)","20170619","2017","","","552","556","Detection of Architectural distortion (AD) is important for ruling out possible pre-malignant lesions in breast, but due to its subtlety, it is often missed on the screening mammograms. In this work we suggest a novel AD detection method based on region proposal convolution neural nets (R-CNN). When the data is scarce, as typically the case in medical domain, R-CNN yields poor results. In this study, we suggest a new R-CNN method addressing this shortcoming by using a pretrained network on a candidate region guided by clinical observations. We test our method on the publicly available DDSM data set, with comparison to the latest faster R-CNN and previous works. Our detection accuracy allows binary image classification (normal vs. containing AD) with over 80% sensitivity and specificity, and yields 0.46 false-positives per image at 83% true-positive rate, for localization accuracy. These measures significantly improve the best results in the literature.","","Electronic:978-1-5090-1172-8; POD:978-1-5090-1173-5","10.1109/ISBI.2017.7950581","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7950581","Architectural Distortion;Breast Mammography;Computer-Aided Diagnosis;Convolution Neural Net;Deep Learning;Region Proposal","Breast;Convolution;Mammography;Neural networks;Proposals;Sensitivity;Training","cancer;image classification;mammography;medical image processing;neural nets","AD detection method;R-CNN method;architectural distortion detection;image classification;mammograms;region proposal convolution neural nets","","","","","","","","18-21 April 2017","","IEEE","IEEE Conference Publications"
"Lung nodule detection in CT using 3D convolutional neural networks","X. Huang; J. Shan; V. Vaidya","GE Global Research, Niskayuna, NY, United States of America","2017 IEEE 14th International Symposium on Biomedical Imaging (ISBI 2017)","20170619","2017","","","379","383","We propose a new computer-aided detection system that uses 3D convolutional neural networks (CNN) for detecting lung nodules in low dose computed tomography. The system leverages both a priori knowledge about lung nodules and confounding anatomical structures and data-driven machine-learned features and classifier. Specifically, we generate nodule candidates using a local geometric-model-based filter and further reduce the structure variability by estimating the local orientation. The nodule candidates in the form of 3D cubes are fed into a deep 3D convolutional neural network that is trained to differentiate nodule and non-nodule inputs. We use data augmentation techniques to generate a large number of training examples and apply regularization to avoid overfitting. On a set of 99 CT scans, the proposed system achieved state-of-the-art performance and significantly outperformed a similar hybrid system that uses conventional shallow learning. The experimental results showed benefits of using a priori models to reduce the problem space for data-driven machine learning of complex deep neural networks. The results also showed the advantages of 3D CNN over 2D CNN in volumetric medical image analysis.","","Electronic:978-1-5090-1172-8; POD:978-1-5090-1173-5","10.1109/ISBI.2017.7950542","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7950542","3D convolutional neural networks;CT;Lung nodule;computer-aided detection;deep learning","Computed tomography;Lungs;Neural networks;Solid modeling;Three-dimensional displays;Training;Two dimensional displays","computerised tomography;feature extraction;image classification;learning (artificial intelligence);lung;medical image processing;neural nets","3D CNN;CT scans;complex deep neural networks;computer-aided detection;conventional shallow learning;data augmentation;data-driven machine-learned classifier;data-driven machine-learned features;deep 3D convolutional neural networks;local geometric-model-based filter;low dose computed tomography;lung nodule detection;structure variability;volumetric medical image analysis","","","","","","","","18-21 April 2017","","IEEE","IEEE Conference Publications"
"Self supervised deep representation learning for fine-grained body part recognition","P. Zhang; F. Wang; Y. Zheng","Medical Imaging Technologies, Siemens Medical Solutions USA Inc., Princeton, NJ 08540, USA","2017 IEEE 14th International Symposium on Biomedical Imaging (ISBI 2017)","20170619","2017","","","578","582","Difficulty on collecting annotated medical images leads to lack of enough supervision and makes discrimination tasks challenging. However, raw data, e.g., spatial context information from 3D CT images, even without annotation, may contain rich useful information. In this paper, we exploit spatial context information as a source of supervision to solve discrimination tasks for fine-grained body part recognition with conventional 3D CT and MR volumes. The proposed pipeline consists of two steps: 1) pre-train a convolutional network for an auxiliary task of 2D slices ordering in a self-supervised manner; 2) transfer and fine-tune the pre-trained network for fine-grained body part recognition. Without any use of human annotation in the first stage, the pre-trained network can still outperform CNN trained from scratch on CT as well as M-R data. Moreover, by comparing with pre-trained CNN from ImageNet, we discover that the distance between source and target tasks plays a crucial role in transfer learning. Our experiments demonstrate that our approach can achieve high accuracy with a slice location estimation error of only a few slices on CT and MR data. To the best of our knowledge, our work is the first attempt studying the problem of robust body part recognition at a continuous level.","","Electronic:978-1-5090-1172-8; POD:978-1-5090-1173-5","10.1109/ISBI.2017.7950587","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7950587","Body Part Recognition;Self Supervised Learning;Slice Ordering","Biomedical imaging;Computed tomography;Context;Image recognition;Three-dimensional displays;Training;Two dimensional displays","biomedical MRI;computerised tomography;image recognition;learning (artificial intelligence);medical image processing","3D CT;MR volumes;fine-grained body part recognition;self supervised deep representation learning;spatial context information;transfer learning","","","","","","","","18-21 April 2017","","IEEE","IEEE Conference Publications"
"HEp-2 cell classification based on a Deep Autoencoding-Classification convolutional neural network","J. Liu; B. Xu; L. Shen; J. Garibaldi; G. Qiu","The Universiy of Nottingham Ningbo China, China","2017 IEEE 14th International Symposium on Biomedical Imaging (ISBI 2017)","20170619","2017","","","1019","1023","In this paper, we present a novel deep learning model termed Deep Autoencoding-Classification Network (DACN) for HEp-2 cell classification. The DACN consists of an autoencoder and a normal classification convolutional neural network (CNN), while the two architectures shares the same encoding pipeline. The DACN model is jointly optimized for the classification error and the image reconstruction error based on a multi-task learning procedure. We evaluate the proposed model using the publicly available ICPR2012 benchmark dataset. We show that this architecture is particularly effective when the training dataset is small which is often the case in medical imaging applications. We present experimental results to show that the proposed approach outperforms all known state of the art HEp-2 cell classification methods.","","Electronic:978-1-5090-1172-8; POD:978-1-5090-1173-5","10.1109/ISBI.2017.7950689","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7950689","HEp2 cells;autoencoder;classification;convolutional neural networks;indirect immunofluorescence","Benchmark testing;Computer architecture;Image reconstruction;Machine learning;Microprocessors;Solid modeling;Training","cellular biophysics;image classification;image coding;image reconstruction;learning (artificial intelligence);medical image processing;neural nets","HEp-2 cell classification methods;deep autoencoding-classification convolutional neural network;image reconstruction error;medical imaging applications;multitask learning procedure","","","","","","","","18-21 April 2017","","IEEE","IEEE Conference Publications"
"A convolutional neural network approach for abnormality detection in Wireless Capsule Endoscopy","A. K. Sekuboyina; S. T. Devarakonda; C. S. Seelamantula","Klinikum rechts der Isar der Technische Universit&#x00E4;t M&#x00FC;nchen, 81675, Germany","2017 IEEE 14th International Symposium on Biomedical Imaging (ISBI 2017)","20170619","2017","","","1057","1060","In wireless capsule endoscopy (WCE), a swallowable miniature optical endoscope is used to transmit color images of the gastrointestinal tract. However, the number of images transmitted is large, taking a significant amount of the medical expert's time to review the scan. In this paper, we propose a technique to automate the abnormality detection in WCE images. We split the image into several patches and extract features pertaining to each block using a convolutional neural network (CNN) to increase their generality while overcoming the drawbacks of manually crafted features. We intend to exploit the importance of color information for the task. Experiments are performed to determine the optimal color space components for feature extraction and classifier design. We obtained an area under receiver-operating-characteristic (ROC) curve of approximately 0.8 on a dataset containing multiple abnormalities.","","Electronic:978-1-5090-1172-8; POD:978-1-5090-1173-5","10.1109/ISBI.2017.7950698","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7950698","Classification;Convolutional neural networks;Gastrointestinal tract;Wireless capsule endoscopy","Endoscopes;Feature extraction;Hemorrhaging;Image color analysis;Lesions;Neural networks;Training","biomedical optical imaging;endoscopes;feature extraction;medical image processing;neural nets;sensitivity analysis","abnormality detection;convolutional neural network;feature extraction;receiver-operating-characteristic curve;wireless capsule endoscopy","","","","","","","","18-21 April 2017","","IEEE","IEEE Conference Publications"
"Multilevel Contextual 3-D CNNs for False Positive Reduction in Pulmonary Nodule Detection","Q. Dou; H. Chen; L. Yu; J. Qin; P. A. Heng","Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong","IEEE Transactions on Biomedical Engineering","20170615","2017","64","7","1558","1567","Objective: False positive reduction is one of the most crucial components in an automated pulmonary nodule detection system, which plays an important role in lung cancer diagnosis and early treatment. The objective of this paper is to effectively address the challenges in this task and therefore to accurately discriminate the true nodules from a large number of candidates. Methods: We propose a novel method employing three-dimensional (3-D) convolutional neural networks (CNNs) for false positive reduction in automated pulmonary nodule detection from volumetric computed tomography (CT) scans. Compared with its 2-D counterparts, the 3-D CNNs can encode richer spatial information and extract more representative features via their hierarchical architecture trained with 3-D samples. More importantly, we further propose a simple yet effective strategy to encode multilevel contextual information to meet the challenges coming with the large variations and hard mimics of pulmonary nodules. Results: The proposed framework has been extensively validated in the LUNA16 challenge held in conjunction with ISBI 2016, where we achieved the highest competition performance metric (CPM) score in the false positive reduction track. Conclusion: Experimental results demonstrated the importance and effectiveness of integrating multilevel contextual information into 3-D CNN framework for automated pulmonary nodule detection in volumetric CT data. Significance: While our method is tailored for pulmonary nodule detection, the proposed framework is general and can be easily extended to many other 3-D object detection tasks from volumetric medical images, where the targeting objects have large variations and are accompanied by a number of hard mimics.","0018-9294;00189294","","10.1109/TBME.2016.2613502","Shenzhen-Hong Kong Innovation Circle; The Hong Kong Special Administrative Region; 10.13039/501100001809 - National Natural Science Foundation of China; ","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7576695","3-D convolutional neural networks;Computer-aided diagnosis;deep learning;false positive reduction;pulmonary nodule detection","Cancer;Computed tomography;Feature extraction;Kernel;Lungs;Three-dimensional displays;Two dimensional displays","cancer;computerised tomography;feature extraction;lung;medical image processing;neural nets","3D convolutional neural network;3D object detection tasks;CPM score;ISBI 2016;LUNA16 challenge;automated pulmonary nodule detection system;competition performance metric score;contextual 3D CNN;false positive reduction track;feature extraction;lung cancer diagnosis;multilevel contextual information;volumetric CT scans;volumetric computed tomography;volumetric medical images","","","","","","","20160926","July 2017","","IEEE","IEEE Journals & Magazines"
"Low-Dose CT with a Residual Encoder-Decoder Convolutional Neural Network (RED-CNN)","H. Chen; Y. Zhang; M. K. Kalra; F. Lin; Y. Chen; P. Liao; J. Zhou; G. Wang","College of Computer Science, Sichuan University, Chengdu 610065, China.","IEEE Transactions on Medical Imaging","","2017","PP","99","1","1","Given the potential risk of X-ray radiation to the patient, low-dose CT has attracted a considerable interest in the medical imaging field. Currently, the main stream low-dose CT methods include vendor-specific sinogram domain filtration and iterative reconstruction algorithms, but they need to access raw data whose formats are not transparent to most users. Due to the difficulty of modeling the statistical characteristics in the image domain, the existing methods for directly processing reconstructed images cannot eliminate image noise very well while keeping structural details. Inspired by the idea of deep learning, here we combine the autoencoder, deconvolution network, and shortcut connections into the residual encoder-decoder convolutional neural network (RED-CNN) for low-dose CT imaging. After patch-based training, the proposed RED-CNN achieves a competitive performance relative to the-state-of-art methods in both simulated and clinical cases. Especially, our method has been favorably evaluated in terms of noise suppression, structural preservation, and lesion detection.","0278-0062;02780062","","10.1109/TMI.2017.2715284","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7947200","Low-dose CT;auto-encoder;convolutional;deconvolutional;deep learning;residual neural network","Computed tomography;Convolution;Decoding;Feature extraction;Image reconstruction;X-ray imaging","","","","","","","","","20170613","","","IEEE","IEEE Early Access Articles"
"FUIQA: Fetal Ultrasound Image Quality Assessment With Deep Convolutional Networks","L. Wu; J. Z. Cheng; S. Li; B. Lei; T. Wang; D. Ni","National-Regional Key Technology Engineering Laboratory for Medical Ultrasound, Guangdong Key Laboratory for Biomedical Measurements and Ultrasound Imaging, School of Biomedical Engineering, Shenzhen University, Shenzhen, China","IEEE Transactions on Cybernetics","20170520","2017","47","5","1336","1349","The quality of ultrasound (US) images for the obstetric examination is crucial for accurate biometric measurement. However, manual quality control is a labor intensive process and often impractical in a clinical setting. To improve the efficiency of examination and alleviate the measurement error caused by improper US scanning operation and slice selection, a computerized fetal US image quality assessment (FUIQA) scheme is proposed to assist the implementation of US image quality control in the clinical obstetric examination. The proposed FUIQA is realized with two deep convolutional neural network models, which are denoted as L-CNN and C-CNN, respectively. The L-CNN aims to find the region of interest (ROI) of the fetal abdominal region in the US image. Based on the ROI found by the L-CNN, the C-CNN evaluates the image quality by assessing the goodness of depiction for the key structures of stomach bubble and umbilical vein. To further boost the performance of the L-CNN, we augment the input sources of the neural network with the local phase features along with the original US data. It will be shown that the heterogeneous input sources will help to improve the performance of the L-CNN. The performance of the proposed FUIQA is compared with the subjective image quality evaluation results from three medical doctors. With comprehensive experiments, it will be illustrated that the computerized assessment with our FUIQA scheme can be comparable to the subjective ratings from medical doctors.","2168-2267;21682267","","10.1109/TCYB.2017.2671898","National Key Research and Development Program of China; Natural Science Foundation of SZU; Open Fund Project of Fujian Provincial Key Laboratory of Information Processing and Intelligent Control (Minjiang University); Shenzhen Basic Research Project; 10.13039/501100001809 - National Natural Science Foundation of China; ","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7875138","Deep convolutional neural network (DCNN);fetal ultrasound (US);local phase;quality control","Biomedical imaging;Biomedical measurement;Image quality;Quality assessment;Quality control;Standards;Ultrasonic imaging","biomedical ultrasonics;feedforward neural nets;medical image processing;obstetrics;ultrasonic imaging","C-CNN;FUIQA;L-CNN;ROI;clinical obstetric examination;deep convolutional neural network;fetal US image quality assessment;fetal ultrasound image quality assessment;region of interest","","","","","","","20170309","May 2017","","IEEE","IEEE Journals & Magazines"
"An Ensemble of Fine-Tuned Convolutional Neural Networks for Medical Image Classification","A. Kumar; J. Kim; D. Lyndon; M. Fulham; D. Feng","Biomedical and Multimedia Information Technology Research Group, School of Information Technologies, The University of Sydney, Camperdown, NSW, Australia","IEEE Journal of Biomedical and Health Informatics","20170520","2017","21","1","31","40","The availability of medical imaging data from clinical archives, research literature, and clinical manuals, coupled with recent advances in computer vision offer the opportunity for image-based diagnosis, teaching, and biomedical research. However, the content and semantics of an image can vary depending on its modality and as such the identification of image modality is an important preliminary step. The key challenge for automatically classifying the modality of a medical image is due to the visual characteristics of different modalities: some are visually distinct while others may have only subtle differences. This challenge is compounded by variations in the appearance of images based on the diseases depicted and a lack of sufficient training data for some modalities. In this paper, we introduce a new method for classifying medical images that uses an ensemble of different convolutional neural network (CNN) architectures. CNNs are a state-of-the-art image classification technique that learns the optimal image features for a given classification task. We hypothesise that different CNN architectures learn different levels of semantic image representation and thus an ensemble of CNNs will enable higher quality features to be extracted. Our method develops a new feature extractor by fine-tuning CNNs that have been initialized on a large dataset of natural images. The fine-tuning process leverages the generic image features from natural images that are fundamental for all images and optimizes them for the variety of medical imaging modalities. These features are used to train numerous multiclass classifiers whose posterior probabilities are fused to predict the modalities of unseen images. Our experiments on the ImageCLEF 2016 medical image public dataset (30 modalities; 6776 training images, and 4166 test images) show that our ensemble of fine-tuned CNNs achieves a higher accuracy than established CNNs. Our ensemble also achieves a higher accuracy than - ethods in the literature evaluated on the same benchmark dataset and is only overtaken by those methods that source additional training data.","2168-2194;21682194","","10.1109/JBHI.2016.2635663","10.13039/100000163 - ARC; ","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7769199","Convolutional neural network (CNN);deep learning;ensembles;fine-tuning;image classification","Biomedical imaging;Computer architecture;Feature extraction;Informatics;Neural networks;Training;Training data","feature extraction;image classification;image representation;medical image processing;neural nets;probability","ImageCLEF 2016 medical image public dataset;feature extraction;fine-tuned convolutional neural networks;image features;medical image classification;natural image dataset;posterior probability;semantic image representation","","","","","","","20161205","Jan. 2017","","IEEE","IEEE Journals & Magazines"
"Standard Plane Localization in Fetal Ultrasound via Domain Transferred Deep Neural Networks","H. Chen; D. Ni; J. Qin; S. Li; X. Yang; T. Wang; P. A. Heng","Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong","IEEE Journal of Biomedical and Health Informatics","20170520","2015","19","5","1627","1636","Automatic localization of the standard plane containing complicated anatomical structures in ultrasound (US) videos remains a challenging problem. In this paper, we present a learning-based approach to locate the fetal abdominal standard plane (FASP) in US videos by constructing a domain transferred deep convolutional neural network (CNN). Compared with previous works based on low-level features, our approach is able to represent the complicated appearance of the FASP and hence achieve better classification performance. More importantly, in order to reduce the overfitting problem caused by the small amount of training samples, we propose a transfer learning strategy, which transfers the knowledge in the low layers of a base CNN trained from a large database of natural images to our task-specific CNN. Extensive experiments demonstrate that our approach outperforms the state-of-the-art method for the FASP localization as well as the CNN only trained on the limited US training samples. The proposed approach can be easily extended to other similar medical image computing problems, which often suffer from the insufficient training samples when exploiting the deep CNN to represent high-level features.","2168-2194;21682194","","10.1109/JBHI.2015.2425041","Hong Kong Innovation and Technology Fund; Research Grants Council of Hong Kong; Shenzhen Key Basic Research Project; Shenzhen-Hong Kong Innovation Circle Funding Program; 10.13039/501100001809 - National Natural Science Foundation of China; ","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7090943","Convolutional neural network (CNN);Ultrasound;convolutional neural network;deep learning;domain transfer;knowledge transfer;standard plane;ultrasound (US)","Biomedical imaging;Dictionaries;Feature extraction;Informatics;Standards;Training;Videos","biomedical ultrasonics;image classification;learning (artificial intelligence);medical image processing;neural nets;object detection;obstetrics","FASP localization;US videos;automatic standard plane localization;classification performance;domain transferred deep convolutional neural network;fetal abdominal standard plane;fetal ultrasound;high-level features;learning-based approach;low-level features;medical image computing problems;natural images;overfitting problem;task-specific CNN;transfer learning strategy;ultrasound videos","0;Abdomen;Female;Fetus;Humans;Image Processing, Computer-Assisted;Neural Networks (Computer);Pregnancy;ROC Curve;Ultrasonography, Prenatal","32","","37","","","20150421","Sept. 2015","","IEEE","IEEE Journals & Magazines"
"Multisource Transfer Learning With Convolutional Neural Networks for Lung Pattern Analysis","S. Christodoulidis; M. Anthimopoulos; L. Ebner; A. Christe; S. Mougiakakou","ARTORG Center for Biomedical Engineering Research, University of Bern, Bern, Switzerland","IEEE Journal of Biomedical and Health Informatics","20170520","2017","21","1","76","84","Early diagnosis of interstitial lung diseases is crucial for their treatment, but even experienced physicians find it difficult, as their clinical manifestations are similar. In order to assist with the diagnosis, computer-aided diagnosis systems have been developed. These commonly rely on a fixed scale classifier that scans CT images, recognizes textural lung patterns, and generates a map of pathologies. In a previous study, we proposed a method for classifying lung tissue patterns using a deep convolutional neural network (CNN), with an architecture designed for the specific problem. In this study, we present an improved method for training the proposed network by transferring knowledge from the similar domain of general texture classification. Six publicly available texture databases are used to pretrain networks with the proposed architecture, which are then fine-tuned on the lung tissue data. The resulting CNNs are combined in an ensemble and their fused knowledge is compressed back to a network with the original architecture. The proposed approach resulted in an absolute increase of about 2% in the performance of the proposed CNN. The results demonstrate the potential of transfer learning in the field of medical image analysis, indicate the textural nature of the problem and show that the method used for training a network can be as important as designing its architecture.","2168-2194;21682194","","10.1109/JBHI.2016.2636929","Bern University Hospital; 10.13039/501100001711 - Swiss National Science Foundation (SNSF); ","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7776792","Convolutional neural networks (CNNs);interstitial lung diseases (ILDs);knowledge distillation;model compression;model ensemble;texture classification;transfer learning","Biomedical imaging;Computed tomography;Databases;Knowledge engineering;Lungs;Machine learning;Training","biological tissues;computerised tomography;diseases;image classification;image texture;learning (artificial intelligence);lung;medical image processing;neural nets","CT images;computed tomography;computer-aided diagnosis;convolutional neural networks;fused knowledge compression;interstitial lung disease diagnosis;lung pattern analysis;lung tissue data;medical image analysis;multisource transfer learning;texture classification;texture databases","","","","","","","20161207","Jan. 2017","","IEEE","IEEE Journals & Magazines"
"Unsupervised Joint Mining of Deep Features and Image Labels for Large-Scale Radiology Image Categorization and Scene Recognition","X. Wang; L. Lu; H. C. Shin; L. Kim; M. Bagheri; I. Nogues; J. Yao; R. M. Summers","","2017 IEEE Winter Conference on Applications of Computer Vision (WACV)","20170515","2017","","","998","1007","The recent rapid and tremendous success of deep convolutional neural networks (CNN) on many challenging computer vision tasks largely derives from the accessibility of the well-annotated ImageNet and PASCAL VOC datasets. Nevertheless, unsupervised image categorization (i.e., without the ground-truth labeling) is much less investigated, yet critically important and difficult when annotations are extremely hard to obtain in the conventional way of ""Google Search"" and crowd sourcing. We address this problem by presenting a looped deep pseudo-task optimization (LDPO) framework for joint mining of deep CNN features and image labels. Our method is conceptually simple and rests upon the hypothesized ""convergence"" of better labels leading to better trained CNN models which in turn feed more discriminative image representations to facilitate more meaningful clusters/labels. Our proposed method is validated in tackling two important applications: 1) Large-scale medical image annotation has always been a prohibitively expensive and easily-biased task even for well-trained radiologists. Significantly better image categorization results are achieved via our proposed approach compared to the previous state-of-the-art method. 2) Unsupervised scene recognition on representative and publicly available datasets with our proposed technique is examined. The LDPO achieves excellent quantitative scene classification results. On the MIT indoor scene dataset, it attains a clustering accuracy of 75:3%, compared to the state-of-the-art supervised classification accuracy of 81:0% (when both are based on the VGG-VD model).","","Electronic:978-1-5090-4822-9; POD:978-1-5090-4823-6","10.1109/WACV.2017.116","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7926699","","Biomedical imaging;Computational modeling;Feature extraction;Image recognition;Image representation;Optimization;Radiology","","","","","","","","","","24-31 March 2017","","IEEE","IEEE Conference Publications"
"L-CNN: Exploiting labeling latency in a CNN learning framework","M. J. Afridi; A. Ross; E. M. Shapiro","Department of Computer Science and Engineering, Michigan State University, United States of America","2016 23rd International Conference on Pattern Recognition (ICPR)","20170424","2016","","","2156","2161","A supervised learning system requires labeled data during the training phase. Obtaining labels can be an expensive process, especially in medical imaging applications where a qualified expert may be needed to carefully analyze images and annotate them. This constrains the amount of labeled data available. This study explores the possibility of incorporating labeling behavior (viz., labeling latency) in a supervised convolutional neural network (CNN) framework in order to improve its performance in the presence of limited labeled data. The problem of “spot” detection in MRI scans is considered in this work. In this two-class problem, (a) labeling behavior is available only during the training phase unlike traditional features that are available both during training and testing; and (b) the labeling behavior is associated with only one class (the positive samples) unlike other side information that is available for all classes. To address these issues, a new CNN architecture referred to as L-CNN is designed. The proposed method utilizes the labeling behavior of the expert to cluster the labeled data into multiple categories; a source CNN is then trained to distinguish between these categories. Next, a transfer learning paradigm is used where a target CNN is initialized using this source CNN and its weights updated with the limited labeled data that is available. Experimental results on an existing MRI database show that the proposed L-CNN performs better than a conventional CNN and, further, significantly outperforms the previous state-of-the-art, thereby establishing a new baseline for “spot” detection in MRI.","","Electronic:978-1-5090-4847-2; POD:978-1-5090-4848-9","10.1109/ICPR.2016.7899955","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7899955","","Biomedical imaging;Computer architecture;Labeling;Magnetic resonance imaging;Microprocessors;Testing;Training","biomedical MRI;learning (artificial intelligence);medical image processing;neural nets","L-CNN;MRI scans;labeling behavior;supervised convolutional neural network learning framework;supervised learning system;transfer learning paradigm;two-class problem","","","","","","","","4-8 Dec. 2016","","IEEE","IEEE Conference Publications"
"An efficient radiographic Image Retrieval system using Convolutional Neural Network","M. Chowdhury; S. R. Bulò; R. Moreno; M. K. Kundu; Ö. Smedby","KTH, School of Technology and Health, H&#x00E4;lsov&#x00E4;gen 11c, SE-141 57 Huddinge, Sweden","2016 23rd International Conference on Pattern Recognition (ICPR)","20170424","2016","","","3134","3139","Content-Based Medical Image Retrieval (CBMIR) is an important research field in the context of medical data management. In this paper we propose a novel CBMIR system for the automatic retrieval of radiographic images. Our approach employs a Convolutional Neural Network (CNN) to obtain high-level image representations that enable a coarse retrieval of images that are in correspondence to a query image. The retrieved set of images is refined via a non-parametric estimation of putative classes for the query image, which are used to filter out potential outliers in favour of more relevant images belonging to those classes. The refined set of images is finally re-ranked using Edge Histogram Descriptor, i.e. a low-level edge-based image descriptor that allows to capture finer similarities between the retrieved set of images and the query image. To improve the computational efficiency of the system, we employ dimensionality reduction via Principal Component Analysis (PCA). Experiments were carried out to evaluate the effectiveness of the proposed system on medical data from the “Image Retrieval in Medical Applications” (IRMA) benchmark database. The obtained results show the effectiveness of the proposed CBMIR system in the field of medical image retrieval.","","Electronic:978-1-5090-4847-2; POD:978-1-5090-4848-9","10.1109/ICPR.2016.7900116","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7900116","","Histograms;Image edge detection;Image retrieval;Medical diagnostic imaging;Principal component analysis;Radiography","diagnostic radiography;image retrieval;medical image processing;neural nets;principal component analysis;query processing;set theory","CBMIR system;CNN;IRMA;PCA;content-based medical image retrieval;convolutional neural network;edge histogram descriptor;efficient radiographic image retrieval system;high-level image representations;image retrieval-in-medical applications;medical data management;nonparametric estimation;principal component analysis;query image","","","","","","","","4-8 Dec. 2016","","IEEE","IEEE Conference Publications"
"Automatic Scoring of Multiple Semantic Attributes With Multi-Task Feature Leverage: A Study on Pulmonary Nodules in CT Images","S. Chen; J. Qin; X. Ji; B. Lei; T. Wang; D. Ni; J. Z. Cheng","Department of Biomedical Engineering, National-Regional Key Technology Engineering Laboratory for Medical Ultrasound, Guangdong Key Laboratory for Biomedical Measurements and Ultrasound Imaging, School of Medicine, Shenzhen University, Shenzhen, China","IEEE Transactions on Medical Imaging","20170301","2017","36","3","802","814","The gap between the computational and semantic features is the one of major factors that bottlenecks the computer-aided diagnosis (CAD) performance from clinical usage. To bridge this gap, we exploit three multi-task learning (MTL) schemes to leverage heterogeneous computational features derived from deep learning models of stacked denoising autoencoder (SDAE) and convolutional neural network (CNN), as well as hand-crafted Haar-like and HoG features, for the description of 9 semantic features for lung nodules in CT images. We regard that there may exist relations among the semantic features of “spiculation”, “texture”, “margin”, etc., that can be explored with the MTL. The Lung Image Database Consortium (LIDC) data is adopted in this study for the rich annotation resources. The LIDC nodules were quantitatively scored w.r.t. 9 semantic features from 12 radiologists of several institutes in U.S.A. By treating each semantic feature as an individual task, the MTL schemes select and map the heterogeneous computational features toward the radiologists' ratings with cross validation evaluation schemes on the randomly selected 2400 nodules from the LIDC dataset. The experimental results suggest that the predicted semantic scores from the three MTL schemes are closer to the radiologists' ratings than the scores from single-task LASSO and elastic net regression methods. The proposed semantic attribute scoring scheme may provide richer quantitative assessments of nodules for better support of diagnostic decision and management. Meanwhile, the capability of the automatic association of medical image contents with the clinical semantic terms by our method may also assist the development of medical search engine.","0278-0062;02780062","","10.1109/TMI.2016.2629462","(Key) Project of Department of Education of Guangdong Province; Natural Science Foundation of SZU; Shenzhen Key Basic Research Project; Shenzhen-Hong Kong Innovation Circle Funding Program; 10.13039/501100001809 - National Natural Science Foundation of China; ","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7745891","Computer-aided diagnosis (CAD);computed tomography (CT);deep learning;feature learning;lung nodule;multi-task learning","Computational modeling;Computed tomography;Lungs;Machine learning;Medical diagnostic imaging;Semantics","computerised tomography;feature extraction;lung;medical image processing;pneumodynamics;regression analysis","CT images;HoG features;Lung Image Database Consortium data;clinical semantic terms;computer-aided diagnosis performance;convolutional neural network;deep learning models;elastic net regression methods;heterogeneous computational features;lung nodules;medical image;medical search engine;multitask learning schemes;pulmonary nodules;semantic features;single-task LASSO;stacked denoising autoencoder","","1","","","","","20161116","March 2017","","IEEE","IEEE Journals & Magazines"
"Application of big data analytics for automated estimation of CT image quality","M. D. Naeemi; J. Ren; N. Hollcroft; A. M. Alessio; S. Roychowdhury","Department of Electrical Engineering, University of Washington, Bothell WA","2016 IEEE International Conference on Big Data (Big Data)","20170206","2016","","","3422","3431","With the increasing applications of Big Data analytics in medical image processing systems, there has been a growing need for quantitative medical image quality assessment techniques. Specifically for computed tomography (CT) images, quantitative image assessment can allow for benchmarking image processing methods and optimization of image acquisition parameters. In this work, large volumes of CT images from phantoms and patients are analyzed using 3 data models that vary in their implementation time complexities. The goal here is to identify the optimal method that scales across data set variabilities for predictive modeling of CT image quality (CTIQ). The first two models rely on spatial segmentation of regions-of-interest (ROIs) and estimate CTIQs in terms of segmented pixel variabilities. The third, convolutional neural network (CNN) model relies on error back-propagation from the training set of images to learn the regions indicative of CTIQ. We observe that for 70/30 data split, the average multi-class classification accuracies for CTIQ prediction using the 3 data models range from 73.6-100% and 50-100% for the phantom and patient CT images, respectively. Using variance of pixels within the segmented ROIs as a CTIQ classification parameter, the spatial segmentation data models are found to be more generalizable that the CNN model. However, the CNN model is found to be more suitable for CT image texture classification in the absence of structural variabilities. Our analysis demonstrates that spatial ROI segmentation data models are consistent CTIQ estimators while the CNN models are consistent identifiers of structural similarities for CT image data sets.","","Electronic:978-1-4673-9005-7; POD:978-1-4673-9006-4","10.1109/BigData.2016.7841003","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7841003","CT image;Convolutional neural network;Image variability;Region of interest","Big data;Computed tomography;Data models;Image quality;Image segmentation;Lungs;Measurement","Big Data;backpropagation;computerised tomography;convolution;data analysis;image segmentation;medical image processing;neural nets","Big Data analytics;CNN model;CT image quality;CTIQ;ROI;automated estimation;computed tomography images;convolutional neural network;data models;data set variabilities;error back-propagation;image acquisition parameters;medical image processing systems;medical image quality assessment techniques;predictive modeling;quantitative image assessment;regions-of-interest;segmented pixel variabilities;spatial segmentation;time complexities","","","","","","","","5-8 Dec. 2016","","IEEE","IEEE Conference Publications"
"Cardiac left ventricle segmentation using convolutional neural network regression","L. K. Tan; Y. M. Liew; E. Lim; R. A. McLaughlin","Faculty of Medicine, University of Malaya, Kuala Lumpur, Malaysia","2016 IEEE EMBS Conference on Biomedical Engineering and Sciences (IECBES)","20170206","2016","","","490","493","Cardiac MRI is important for the diagnosis and assessment of various cardiovascular diseases. Automated segmentation of the left ventricular (LV) endocardium at end-diastole (ED) and end-systole (ES) enables automated quantification of various clinical parameters including ejection fraction. Neural networks have been used for general image segmentation, usually via per-pixel categorization e.g. “foreground” and “background”. In this paper we propose that the generally circular LV endocardium can be parameterized and the endocardial contour determined via neural network regression. We designed two convolutional neural networks (CNN), one for localization of the LV, and the other for determining the endocardial radius. We trained the networks against 100 datasets from the Medical Image Computing and Computer Assisted Intervention (MICCAI) 2011 challenge, and tested the networks against 45 datasets from the MICCAI 2009 challenge. The networks achieved 0.88 average Dice metric, 2.30 mm average perpendicular distance, and 97.9% good contours, the latter being the highest published result to date. These results demonstrate that CNN regression is a viable and highly promising method for automated LV endocardial segmentation at ED and ES phases, and is capable of generalizing learning between highly distinct training and testing data sets.","","Electronic:978-1-4673-7791-1; POD:978-1-4673-7792-8","10.1109/IECBES.2016.7843499","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7843499","cardiac MRI;left ventricle;neural network regression;segmentation","Blood;Image segmentation;Magnetic resonance imaging;Measurement;Neural networks;Standards;Training","biomedical MRI;cardiology;diseases;image segmentation;medical image processing;neural nets;regression analysis","Medical Image Computing and Computer Assisted Intervention;automated segmentation;cardiac MRI;cardiac left ventricle segmentation;cardiovascular disease assessment;cardiovascular disease diagnosis;circular left ventricular endocardium;convolutional neural network regression;ejection fraction;endocardial contour;general image segmentation","","","","","","","","4-8 Dec. 2016","","IEEE","IEEE Conference Publications"
"Wrist pulse detection and analysis using three in-line sensors and linear actuators","N. Spulak; S. Foeldi; M. Koller; M. Niemier; J. Schmiedeler; G. Cserey","","CNNA 2016; 15th International Workshop on Cellular Nanoscale Networks and their Applications","20170123","2016","","","1","2","The arterial blood pressure (ABP) pulse at the wrist can be used for medical diagnostic purposes. In Traditional Chinese Medicine (TCM), the practitioner uses three fingers to detect the pulse at three in-line locations on the wrist, pressing each finger into the wrist at varying depths. In this paper, a way to investigate and quantify this procedure is proposed by the use of a device containing three in-line force sensors controlled by linear actuators to detect wrist pulse waveforms. The resulting signals can then be processed, and individual pulse waveforms can be collected and examined. CNN was then used to process the individual pulse waves to detect the peaks. Incorporating CNN could increase the processing speed of the signals for immediate signal filtering and real time patient monitoring.","","Paper:978-3-8007-4252-3","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7827948","","","","","","","","","","","","23-25 Aug. 2016","","VDE","VDE Conference Publications"
"Dependency-based convolutional neural network for drug-drug interaction extraction","S. Liu; Kai Chen; Q. Chen; B. Tang","Intelligent Computing Research Center, Harbin Institute of Technology Shenzhen Graduate School, 518055, China","2016 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)","20170119","2016","","","1074","1080","Drug-drug interactions (DDIs) are crucial for healthcare. Besides DDIs reported in medical knowledge bases such as DrugBank, a large number of latest DDI findings are also reported in unstructured biomedical literature. Extracting DDIs from unstructured biomedical literature is a worthy addition to the existing knowledge bases. Currently, convolutional neural network (CNN) is a state-of-the-art method for DDI extraction. One limitation of CNN is that it neglects long distance dependencies between words in candidate DDI instances, which may be helpful for DDI extraction. In order to incorporate the long distance dependencies between words in candidate DDI instances, in this work, we propose a dependency-based convolutional neural network (DCNN) for DDI extraction. Experiments conducted on the DDIExtraction 2013 corpus show that DCNN using a public state-of-the-art dependency parser achieves an F-score of 70.19%, outperforming CNN by 0.44%. By analyzing errors of DCNN, we find that errors from dependency parsers are propagated into DCNN and affect the performance of DCNN. To reduce error propagation, we design a simple rule to combine CNN with DCNN, that is, using DCNN to extract DDIs in short sentences and CNN to extract DDIs in long distances as most dependency parsers work well for short sentences but bad for long sentences. Finally, our system that combines CNN and DCNN achieves an F-score of 70.81%, outperforming CNN by 1.06% and DNN by 0.62% on the DDIExtraction 2013 corpus.","","Electronic:978-1-5090-1611-2; POD:978-1-5090-1612-9","10.1109/BIBM.2016.7822671","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7822671","Biomedical literature;Dependency-based convolutional neural network;Drug-drug interaction","Drugs;Neural networks;TV","drugs;feature extraction;health care;medical computing;neural nets","DDIExtraction 2013 corpus;DrugBank;F-score;dependency-based convolutional neural network;drug-drug interaction extraction;healthcare;medical knowledge bases;public state-of-the-art dependency parser;unstructured biomedical literature","","","","","","","","15-18 Dec. 2016","","IEEE","IEEE Conference Publications"
"Deep learning-based pipeline to recognize Alzheimer's disease using fMRI data","S. Sarraf; G. Tofighi","Department of Electrical and Computer Engineering, McMaster University Hamilton, ON, L8S 4L8, Canada, Rotman Research Institue at Baycrest, University of Toronto","2016 Future Technologies Conference (FTC)","20170119","2016","","","816","820","Over the past decade, machine learning techniques and in particular predictive modeling and pattern recognition in biomedical sciences, from drug delivery systems to medical imaging, have become one of the most important methods of assisting researchers in gaining a deeper understanding of issues in their entirety and solving complex medical problems. Deep learning is a powerful machine learning algorithm in classification that extracts low-to high-level features. In this paper, we employ a convolutional neural network to distinguish an Alzheimers brain from a normal, healthy brain. The importance of classifying this type of medical data lies in its potential to develop a predictive model or system in order to recognize the symptoms of Alzheimers disease when compared with normal subjects and to estimate the stages of the disease. Classification of clinical data for medical conditions such as Alzheimers disease has always been challenging, and the most problematic aspect has always been selecting the strongest discriminative features. Using the Convolutional Neural Network (CNN) and the famous architecture LeNet-5, we successfully classified functional MRI data of Alzheimers subjects from normal controls, where the accuracy of testing data reached 96.85%. This experiment suggests that the shift and scale invariant features extracted by CNN followed by deep learning classification represents the most powerful method of distinguishing clinical data from healthy data in fMRI. This approach also allows for expansion of the methodology to predict more complicated systems.","","Electronic:978-1-5090-4171-8; POD:978-1-5090-4172-5","10.1109/FTC.2016.7821697","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7821697","Alzheimer's Disease;Deep learning;fMRI","Alzheimer's disease;Biological neural networks;Biomedical imaging;Feature extraction;Machine learning;Neurons","biomedical MRI;convolution;diseases;feature extraction;learning (artificial intelligence);medical computing;neural nets;pattern classification","Alzheimer disease;Alzheimers brain;CNN;LeNet-5 architecture;biomedical sciences;clinical data classification;convolutional neural network;deep learning-based pipeline;drug delivery systems;functional MRI data classification;machine learning;medical imaging;pattern recognition;predictive modeling;scale invariant features extraction","","","","","","","","6-7 Dec. 2016","","IEEE","IEEE Conference Publications"
"A deep tongue image features analysis model for medical application","Dan Meng; Guitao Cao; Y. Duan; Minghua Zhu; Liping Tu; Jiatuo Xu; D. Xu","School of Computer Scinence and Software Engineering, East China Normal University, Shanghai, China 200062","2016 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)","20170119","2016","","","1918","1922","With the improvement of people's living standards, there is no doubt that people are paying more and more attention to their health. However, shortage of medical resources is a critical global problem. As a result, an intelligent prognostics system has a great potential to play important roles in computer aided diagnosis. Numerous papers reported that tongue features have been closely related to a human's state. Among them, the majority of the existing tongue image analyses and classification methods are based on the low-level features, which may not provide a holistic view of the tongue. Inspired by a deep convolutional neural network (CNN), we propose a deep tongue image feature analysis system to extract unbiased features and reduce human labor for tongue diagnosis. With the unbalanced sample distribution, it is hard to form a balanced classification model based on feature representations obtained by existing low-level and high-level methods. Our proposed deep tongue image feature analysis model learns high-level features and provide more classification information during training time, which may result in higher accuracy when predicting testing samples. We tested the proposed system on a set of 267 gastritis patients, and a control group of 48 healthy volunteers (labeled according to Western medical practices). Test results show that the proposed deep tongue image feature analysis model can classify a given tongue image into healthy and diseased state with an average accuracy of 91.49%, which demonstrates the relationship between human body's state and its deep tongue image features.","","Electronic:978-1-5090-1611-2; POD:978-1-5090-1612-9","10.1109/BIBM.2016.7822815","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7822815","Tongue image;deep model;feature analysis;weighted SVM","Analytical models;Biomedical imaging;Computational modeling;Radio frequency;Sensitivity;Shape;Support vector machines","convolution;feature extraction;image classification;medical image processing;neural nets","computer aided diagnosis;deep convolutional neural network;deep tongue image classification methods;deep tongue image feature analysis model;intelligent prognostic system;medical application","","","","","","","","15-18 Dec. 2016","","IEEE","IEEE Conference Publications"
"EndoNet: A Deep Architecture for Recognition Tasks on Laparoscopic Videos","A. P. Twinanda; S. Shehata; D. Mutter; J. Marescaux; M. de Mathelin; N. Padoy","ICube, University of Strasbourg, CNRS, IHU, Strasbourg, France","IEEE Transactions on Medical Imaging","20161230","2017","36","1","86","97","Surgical workflow recognition has numerous potential medical applications, such as the automatic indexing of surgical video databases and the optimization of real-time operating room scheduling, among others. As a result, surgical phase recognition has been studied in the context of several kinds of surgeries, such as cataract, neurological, and laparoscopic surgeries. In the literature, two types of features are typically used to perform this task: visual features and tool usage signals. However, the used visual features are mostly handcrafted. Furthermore, the tool usage signals are usually collected via a manual annotation process or by using additional equipment. In this paper, we propose a novel method for phase recognition that uses a convolutional neural network (CNN) to automatically learn features from cholecystectomy videos and that relies uniquely on visual information. In previous studies, it has been shown that the tool usage signals can provide valuable information in performing the phase recognition task. Thus, we present a novel CNN architecture, called EndoNet, that is designed to carry out the phase recognition and tool presence detection tasks in a multi-task manner. To the best of our knowledge, this is the first work proposing to use a CNN for multiple recognition tasks on laparoscopic videos. Experimental comparisons to other methods show that EndoNet yields state-of-the-art results for both tasks.","0278-0062;02780062","","10.1109/TMI.2016.2593957","French state funds managed by the ANR within the Investissements d¿Avenir program; ","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7519080","Laparoscopic videos;cholecystectomy;convolutional neural network;phase recognition;tool presence detection","Computer architecture;Feature extraction;Image recognition;Laparoscopes;Surgery;Videos;Visualization","biomedical optical imaging;endoscopes;feature extraction;medical image processing;neural nets;optimisation;surgery","CNN architecture;EndoNet;automatic indexing;cataract surgeries;cholecystectomy videos;convolutional neural network;deep architecture;laparoscopic surgeries;laparoscopic videos;manual annotation process;medical applications;neurological surgeries;optimization;phase recognition task;real-time operating room scheduling;recognition tasks;surgical phase recognition;surgical video databases;surgical workflow recognition;tool presence detection tasks;tool usage signals;visual features","","1","","","","","20160722","Jan. 2017","","IEEE","IEEE Journals & Magazines"
"V-Net: Fully Convolutional Neural Networks for Volumetric Medical Image Segmentation","F. Milletari; N. Navab; S. A. Ahmadi","","2016 Fourth International Conference on 3D Vision (3DV)","20161219","2016","","","565","571","Convolutional Neural Networks (CNNs) have been recently employed to solve problems from both the computer vision and medical image analysis fields. Despite their popularity, most approaches are only able to process 2D images while most medical data used in clinical practice consists of 3D volumes. In this work we propose an approach to 3D image segmentation based on a volumetric, fully convolutional, neural network. Our CNN is trained end-to-end on MRI volumes depicting prostate, and learns to predict segmentation for the whole volume at once. We introduce a novel objective function, that we optimise during training, based on Dice coefficient. In this way we can deal with situations where there is a strong imbalance between the number of foreground and background voxels. To cope with the limited number of annotated volumes available for training, we augment the data applying random non-linear transformations and histogram matching. We show in our experimental evaluation that our approach achieves good performances on challenging test data while requiring only a fraction of the processing time needed by other previous methods.","","Electronic:978-1-5090-5407-7; POD:978-1-5090-5408-4","10.1109/3DV.2016.79","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7785132","Deep learning;convolutional neural networks;machine learning;prostate;segmentation","Biomedical imaging;Feature extraction;Image segmentation;Magnetic resonance imaging;Neural networks;Three-dimensional displays;Two dimensional displays","biomedical MRI;image segmentation;medical image processing;neural nets","3D image segmentation;CNN;Dice coefficient;MRI volumes;V-Net;background voxel;clinical practice;computer vision;foreground voxel;fully convolutional neural networks;histogram matching;magnetic resonance imaging;medical image analysis;random nonlinear transformations;volumetric medical image segmentation","","1","","","","","","25-28 Oct. 2016","","IEEE","IEEE Conference Publications"
"Lesion border detection using deep learning","P. Sabouri; H. GholamHosseini","Department of Electrical and Electronics Engineering, School of Engineering, Computer and Mathematical Sciences, Auckland University of Technology, Private bag 92006, Auckland 1142, New Zealand","2016 IEEE Congress on Evolutionary Computation (CEC)","20161121","2016","","","1416","1421","Computer aided diagnosis of medical images can result in (better) detection in addition to early diagnosis of many symptoms to assist health physicians and therefore reducing the mortality rate. Realization of an efficient mobile device for automatic diagnosis of melanoma would greatly enhance the applicability of medical image classification scheme and make it useful in clinical contexts. In this paper, a deep learning method using convolutional neural networks (CNN) is proposed for border detection of skin lesions based on clinical images. Prepossessing of clinical and dermoscopy images has been common and necessary in the lesion segmentation realm; however, the result of the study shows that CNN can be used with relatively much less prepossessing algorithm compared with previous methods.","","Electronic:978-1-5090-0623-6; POD:978-1-5090-0624-3; USB:978-1-5090-0622-9","10.1109/CEC.2016.7743955","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7743955","Deep learning;border detection;convolutional neural networks;lesion segmentation;melanoma detection","Feature extraction;Hair;Image color analysis;Image segmentation;Lesions;Malignant tumors;Skin","cancer;image classification;image segmentation;learning (artificial intelligence);medical image processing;mobile computing;neural nets;skin","CNN;automatic melanoma diagnosis;clinical image prepossessing;computer aided diagnosis;convolutional neural networks;deep learning;dermoscopy image prepossessing;lesion segmentation realm;medical image classification;mobile device;skin lesion border detection","","","","","","","","24-29 July 2016","","IEEE","IEEE Conference Publications"
"A multiclass classification method based on deep learning for named entity recognition in electronic medical records","X. Dong; L. Qian; Y. Guan; L. Huang; Q. Yu; J. Yang","Center of Excellence in Research and Education for Big Military Data Intelligence (CREDIT), Department of Electrical and Computer Engineering, Prairie View A&M University Houston, USA","2016 New York Scientific Data Summit (NYSDS)","20161121","2016","","","1","10","Research of named entity recognition (NER) on electrical medical records (EMRs) focuses on verifying whether methods to NER in traditional texts are effective for that in EMRs, and there is no model proposed for enhancing performance of NER via deep learning from the perspective of multiclass classification. In this paper, we annotate a real EMR corpus to accomplish the model training and evaluation. And, then, we present a Convolutional Neural Network (CNN) based multiclass classification method for mining named entities from EMRs. The method consists of two phases. In the phase 1, EMRs are pre-processed for representing samples with word embedding. In the phase 2, the method is built by segmenting training data into many subsets and training a CNN binary classification model on each of subset. Experimental results showed the effectiveness of our method.","","Electronic:978-1-4673-9051-4; POD:978-1-4673-9052-1","10.1109/NYSDS.2016.7747810","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7747810","convolutional neural network;electrical medical records;machine learning;named entity recognition;natural language processing","Diseases;Feature extraction;Medical diagnostic imaging;Support vector machines;Unified modeling language","data mining;electronic health records;learning (artificial intelligence);neural nets;pattern classification","CNN based multiclass classification method;CNN binary classification model;EMR corpus;NER;convolutional neural network based multiclass classification method;deep learning;electronic medical records;named entity mining;named entity recognition;training data segmentation","","","","","","","","14-17 Aug. 2016","","IEEE","IEEE Conference Publications"
"Weakly-supervised Convolutional learning for detection of inflammatory gastrointestinal lesions","S. V. Georgakopoulos; D. K. Iakovidis; M. Vasilakakis; V. P. Plagianakos; A. Koulaouzidis","Dept. of Computer Science and Biomedical Informatics, University of Thessaly, Lamia, Greece","2016 IEEE International Conference on Imaging Systems and Techniques (IST)","20161110","2016","","","510","514","Graphic image annotations provide the necessary ground truth information for supervised machine learning in image-based computer-aided medical diagnosis. Performing such annotations is usually a time-consuming and cost-inefficient process requiring knowledge from domain experts. To cope with this problem we propose a novel weakly-supervised learning method based on a Convolutional Neural Network (CNN) architecture. The advantage of the proposed method over conventional supervised approaches is that only image-level semantic annotations are used in the training process, instead of pixel-level graphic annotations. This can drastically reduce the required annotation effort. Its advantage over the few state-of-the-art weakly-supervised CNN architectures is its simplicity. The performance of the proposed method is evaluated in the context of computer-aided detection of inflammatory gastrointestinal lesions in wireless capsule endoscopy videos. This is a broad category of lesions, for which early detection and treatment can be of vital importance. The results show that the proposed weakly-supervised learning method can be more effective than the conventional supervised learning, with an accuracy of 90%.","","Electronic:978-1-5090-1817-8; POD:978-1-5090-1818-5","10.1109/IST.2016.7738279","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7738279","convolutional neural networks;inflammatory lesions;lesion detection;medical image analysis;weakly supervised learning","Biomedical imaging;Computer architecture;Graphics;Lesions;Support vector machines;Training;Videos","endoscopes;learning (artificial intelligence);medical image processing;neural nets;object detection;patient diagnosis","convolutional neural network;graphic image annotations;image-based computer-aided medical diagnosis;image-level semantic annotations;inflammatory gastrointestinal lesion detection;supervised machine learning;training process;weakly-supervised CNN architectures;weakly-supervised convolutional learning;wireless capsule endoscopy videos","","","","","","","","4-6 Oct. 2016","","IEEE","IEEE Conference Publications"
"Generating binary tags for fast medical image retrieval based on convolutional nets and Radon Transform","X. Liu; H. R. Tizhoosh; J. Kofman","Department of Systems Design Engineering, University of Waterloo, ON, Canada N2L 3G1","2016 International Joint Conference on Neural Networks (IJCNN)","20161103","2016","","","2872","2878","Content-based image retrieval (CBIR) in large medical image archives is a challenging and necessary task. Generally, different feature extraction methods are used to assign expressive and invariant features to each image such that the search for similar images comes down to feature classification and/or matching. The present work introduces a new image retrieval method for medical applications that employs a convolutional neural network (CNN) with recently introduced Radon barcodes. We combine neural codes for global classification with Radon barcodes for the final retrieval. We also examine image search based on regions of interest (ROI) matching after image retrieval. The IRMA dataset with more than 14,000 x-rays images is used to evaluate the performance of our method. Experimental results show that our approach is superior to many published works.","","","10.1109/IJCNN.2016.7727562","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7727562","","Biomedical imaging;Convolutional codes;Feature extraction;Image retrieval;Neural networks;Radon;Training","Radon transforms;bar codes;content-based retrieval;image classification;image matching;image retrieval;medical image processing;neural nets","CBIR;CNN;IRMA dataset;ROI matching;Radon barcodes;Radon transform;X-ray images;binary tag generation;content-based image retrieval;convolutional neural network;fast medical image retrieval;feature classification;feature extraction;feature matching;image search;neural codes;regions of interest","","1","","","","","","24-29 July 2016","","IEEE","IEEE Conference Publications"
"An Improved Cellular Nonlinear Network Architecture for Binary and Greyscale Image Processing","J. Muller; R. Wittig; J. Muller; R. Tetzlaff","TU Dresden, Dresden, 01062, Germany.(Email: jens.mueller1@tu-dresden.de)","IEEE Transactions on Circuits and Systems II: Express Briefs","","2016","PP","99","1","1","Cellular Nonlinear Networks (CNN) constitute a very powerful paradigm for single instruction/multiple data computers with fine granularity. Analogue and mixed-signal implementations have proved to be suitable for applications in high-speed image processing, robot control, medical signal processing, and many more. Especially digital emulations on fieldprogrammable gate arrays (FPGAs) allow the development of general-purpose computers based on the CNN Universal Machine (CNN-UM) [1] with an inherently parallel structure, a high degree of flexibility and a superior computational precision. However, these emulations turn out to be inefficient for the execution of binary operations which account for more than twothirds of all processing steps in a typical CNN algorithm. In this contribution we present an architecture for the emulation of CNNs that supports both a fast and efficient processing of binary images, and a high computational accuracy when needed. With the FPGA implementation of this architecture, a speed-up factor of up to 5 is achieved for binary-data operations.","1549-7747;15497747","","10.1109/TCSII.2016.2621773","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7707398","Cellular Nonlinear Network;Embedded System;FPGA;Image Processing;System-on-Chip","Computer architecture;Computers;Couplings;Field programmable gate arrays;Image processing;Mathematical model","","","","","","","","","20161026","","","IEEE","IEEE Early Access Articles"
"Brain MRI segmentation with patch-based CNN approach","Z. Cui; J. Yang; Y. Qiao","Institute of Image Processing and Pattern Recognition, Shanghai Jiao Tong University, China","2016 35th Chinese Control Conference (CCC)","20160829","2016","","","7026","7031","Brain Magnetic Resonance Image (MRI) plays a non-substitutive role in clinical diagnosis. The symptom of many diseases corresponds to the structural variants of brain. Automatic structure segmentation in brain MRI is of great importance in modern medical research. Some methods were developed for automatic segmenting of brain MRI but failed to achieve desired accuracy. In this paper, we proposed a new patch-based approach for automatic segmentation of brain MRI using convolutional neural network (CNN). Each brain MRI acquired from a small portion of public dataset is firstly divided into patches. All of these patches are then used for training CNN, which is used for automatic segmentation of brain MRI. Experimental results showed that our approach achieved better segmentation accuracy compared with other deep learning methods.","","Electronic:978-9-8815-6391-0; POD:978-1-5090-0910-7","10.1109/ChiCC.2016.7554465","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7554465","Brain MRI Segmentation;CNN;Deep Learning;Patch-based","Biology;Biomedical imaging;Computer architecture;Image segmentation;Magnetic resonance imaging;Visualization","biomedical MRI;brain;diseases;image segmentation;learning (artificial intelligence);medical image processing;neural nets","CNN training;automatic brain MRI segmentation;automatic structure segmentation;brain magnetic resonance image;clinical diagnosis;convolutional neural network;disease symptoms;patch-based CNN approach;public dataset;segmentation accuracy;structural variants","","","","","","","","27-29 July 2016","","IEEE","IEEE Conference Publications"
"On the generality of neural image features","R. Venkatesan; V. Gatupalli; B. Li","School of Computing Informatics and Decision Systems Engineering, Arizona State University, Tempe, AZ, USA","2016 IEEE International Conference on Image Processing (ICIP)","20160819","2016","","","41","45","Often the filters learned by Convolutional Neural Networks (CNNs) from different image datasets appear similar. This similarity of filters is often exploited for the purposes of transfer learning. This is also being used as an initialization technique for different tasks in the same dataset or for the same task in similar datasets. Off-the-shelf CNN features have capitalized on this idea to promote their networks as best transferable and most general and are used in a cavalier manner in day-to-day computer vision tasks. While the filters learned by these CNNs are related to the atomic structures of the images from which they are learnt, all datasets learn similar looking low-level filters. With the understanding that a dataset that contains many such atomic structures learn general filters and are therefore useful to initialize other networks with, we propose a way to analyse and quantify generality. We applied this metric on several popular character recognition, natural image and a medical image dataset, and arrive at some interesting conclusions. On further experimentation we also discovered that particular classes in a dataset themselves are more general than others.","","Electronic:978-1-4673-9961-6; POD:978-1-4673-9962-3","10.1109/ICIP.2016.7532315","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7532315","","Atomic layer deposition;Colonoscopy;Computer vision;Detectors;Feature extraction;Image edge detection;Training","feature extraction;image processing;learning (artificial intelligence);neural nets","CNN;convolutional neural networks;image datasets;initialization technique;low-level filters;medical image dataset;neural image features;transfer learning","","","","16","","","","25-28 Sept. 2016","","IEEE","IEEE Conference Publications"
"Colonic Polyp Classification with Convolutional Neural Networks","E. Ribeiro; A. Uhl; M. Häfner","Dept. of Comput. Sci., Univ. of Salzburg, Salzburg, Austria","2016 IEEE 29th International Symposium on Computer-Based Medical Systems (CBMS)","20160818","2016","","","253","258","Texture patch classification is an important task in many different computer-aided medical systems. Convolutional Neural Networks (CNN's) have become state-of-the-art for many computer vision tasks in recent years. In this paper, we propose the use of CNN's for the automated classification of colonic mucosa for colon polyp staging in the context of colon cancer screening. This deep learning approach has the property of extracting features and classifying images in the same architecture by exploiting directly the input image pixels being successful in handling distortions such as different light conditions, presence of partial occlusions, etc. For this type of deep learning approach it is common to require that the database contains large amounts of data, which is quite rare in the medical field. The method proposed allows the use of small patches (subimages) to increase the size of the database as well to classify different regions in the same image. We show experimentally that this model is more efficient than some of the commonly used features for colonic polyp classification.","","Electronic:978-1-4673-9036-1; POD:978-1-4673-9037-8","10.1109/CBMS.2016.39","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7545996","Colonic Polyp Classification;Convolutional Neural Networks;Deep Learning","Biological neural networks;Cancer;Colonic polyps;Endoscopes;Feature extraction;Training","biological organs;cancer;computer vision;feature extraction;image classification;image texture;learning (artificial intelligence);medical image processing;neural nets","CNN;automated colonic mucosa classification;colon cancer screening;colon polyp staging;colonic polyp classification;computer vision;computer-aided medical system;convolutional neural networks;deep learning;distortion handling;feature extraction;image classification;image pixels;partial occlusion;texture patch classification","","1","","","","","","20-24 June 2016","","IEEE","IEEE Conference Publications"
"Deep vessel tracking: A generalized probabilistic approach via deep learning","A. Wu; Z. Xu; M. Gao; M. Buty; D. J. Mollura","Department of Radiology and Imaging Sciences, National Institutes of Health, Bethesda, MD 20892","2016 IEEE 13th International Symposium on Biomedical Imaging (ISBI)","20160616","2016","","","1363","1367","Analysis of vascular geometry is important in many medical imaging applications, such as retinal, pulmonary, and cardiac investigations. In order to make reliable judgments for clinical usage, accurate and robust segmentation methods are needed. Due to the high complexity of biological vasculature trees, manual identification is often too time-consuming and tedious to be used in practice. To design an automated and computerized method, a major challenge is that the appearance of vasculatures in medical images has great variance across modalities and subjects. Therefore, most existing approaches are specially designed for a particular task, lacking the flexibility to be adapted to other circumstances. In this paper, we present a generic approach for vascular structure identification from medical images, which can be used for multiple purposes robustly. The proposed method uses the state-of-the-art deep convolutional neural network (CNN) to learn the appearance features of the target. A Principal Component Analysis (PCA)-based nearest neighbor search is then utilized to estimate the local structure distribution, which is further incorporated within the generalized probabilistic tracking framework to extract the entire connected tree. Qualitative and quantitative results over retinal fundus data demonstrate that the proposed framework achieves comparable accuracy as compared with state-of-the-art methods, while efficiently producing more information regarding the candidate tree structure.","","Electronic:978-1-4799-2349-6; POD:978-1-4799-2351-9","10.1109/ISBI.2016.7493520","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7493520","Deep Learning;Generalized Probabilistic Tracking;Nearest Neighbor Search;Principal Component Analysis;Vascular Structure","Biomedical imaging;Dictionaries;Image segmentation;Machine learning;Probabilistic logic;Robustness","","","","1","","10","","","","13-16 April 2016","","IEEE","IEEE Conference Publications"
"A hybrid learning approach for semantic labeling of cardiac CT slices and recognition of body position","M. Moradi; Y. Gur; H. Wang; P. Prasanna; T. Syeda-Mahmood","IBM Research - Almaden Research Center, San Jose, CA","2016 IEEE 13th International Symposium on Biomedical Imaging (ISBI)","20160616","2016","","","1418","1421","We work towards efficient methods of categorizing visual content in medical images as a precursor step to segmentation and anatomy recognition. In this paper, we address the problem of automatic detection of level/position for a given cardiac CT slice. Specifically, we divide the body area depicted in chest CT into nine semantic categories each representing an area most relevant to the study of a disease and/or key anatomic cardiovascular feature. Using a set of handcrafted image features together with features derived form a deep convolutional neural network (CNN), we build a classification scheme to map a given CT slice to the relevant level. Each feature group is used to train a separate support vector machine classifier. The resulting labels are then combined in a linear model, also learned from training data. We report margin zero and margin one accuracy of 91.7% and 98.8% and show that this hybrid approach is a very effective methodology for assigning a given CT image to a relatively narrow anatomic window.","","Electronic:978-1-4799-2349-6; POD:978-1-4799-2351-9","10.1109/ISBI.2016.7493533","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7493533","cardiac CT;image category classification;slice level recognition","Biomedical imaging;Computed tomography;Convolution;Feature extraction;Image recognition;Semantics;Support vector machines","cardiovascular system;computerised tomography;diseases;feature extraction;image classification;image segmentation;learning (artificial intelligence);medical image processing;neural nets;support vector machines","anatomic cardiovascular feature;anatomy recognition;automatic detection;body area;body position recognition;cardiac CT slices;chest CT;classification scheme;deep convolutional neural network;disease;handcrafted image features;hybrid learning approach;medical images;narrow anatomic window;segmentation;semantic categories;semantic labeling;separate support vector machine classifier;training data;visual content","","1","","13","","","","13-16 April 2016","","IEEE","IEEE Conference Publications"
"Discriminative feature extraction from X-ray images using deep convolutional neural networks","M. Srinivas; D. Roy; C. K. Mohan","VIsual learninG and InteLligence (VIGIL) group, Dept. of Computer Science and Engineering, Indian Institute of Technology Hyderabad","2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","20160519","2016","","","917","921","Feature extraction is one of the most important phases of medical image classification which requires extensive domain knowledge. Convolutional Neural Networks (CNN) have been successfully used for feature extraction in images from different domains involving a lot of classes. In this paper, CNNs are exploited to extract a hierarchical and discriminative representation of X-ray images. This representation is then used for classification of the X-ray images as various parts of the body. Visualization of the feature maps in the hidden layers show that features learnt by the CNN resemble the essential features which help discern the discrimination among different body parts. A comparison on the standard IRMA X-ray image dataset demonstrates that the CNNs easily outperform classifiers with hand-engineered features.","","Electronic:978-1-4799-9988-0; POD:978-1-4799-9989-7; USB:978-1-4799-9987-3","10.1109/ICASSP.2016.7471809","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7471809","Convolutional Neural Networks (CNN);Feature Extraction;X-ray image","Biomedical imaging;Convolution;Feature extraction;Support vector machines;Training;Visualization;X-ray imaging","X-ray imaging;feature extraction;image classification;image representation;medical image processing;neural nets","CNN;X-ray image classification;deep convolutional neural networks;discriminative feature extraction;discriminative representation;feature map visualization;hierarchical representation;medical image classification;standard IRMA X-ray image dataset","","","","25","","","","20-25 March 2016","","IEEE","IEEE Conference Publications"
"Deep Convolutional Neural Networks for Computer-Aided Detection: CNN Architectures, Dataset Characteristics and Transfer Learning","H. C. Shin; H. R. Roth; M. Gao; L. Lu; Z. Xu; I. Nogues; J. Yao; D. Mollura; R. M. Summers","Imaging Biomarkers and Computer-Aided Diagnosis Laboratory","IEEE Transactions on Medical Imaging","20160503","2016","35","5","1285","1298","Remarkable progress has been made in image recognition, primarily due to the availability of large-scale annotated datasets and deep convolutional neural networks (CNNs). CNNs enable learning data-driven, highly representative, hierarchical image features from sufficient training data. However, obtaining datasets as comprehensively annotated as ImageNet in the medical imaging domain remains a challenge. There are currently three major techniques that successfully employ CNNs to medical image classification: training the CNN from scratch, using off-the-shelf pre-trained CNN features, and conducting unsupervised CNN pre-training with supervised fine-tuning. Another effective method is transfer learning, i.e., fine-tuning CNN models pre-trained from natural image dataset to medical image tasks. In this paper, we exploit three important, but previously understudied factors of employing deep convolutional neural networks to computer-aided detection problems. We first explore and evaluate different CNN architectures. The studied models contain 5 thousand to 160 million parameters, and vary in numbers of layers. We then evaluate the influence of dataset scale and spatial image context on performance. Finally, we examine when and why transfer learning from pre-trained ImageNet (via fine-tuning) can be useful. We study two specific computer-aided detection (CADe) problems, namely thoraco-abdominal lymph node (LN) detection and interstitial lung disease (ILD) classification. We achieve the state-of-the-art performance on the mediastinal LN detection, and report the first five-fold cross-validation classification results on predicting axial CT slices with ILD categories. Our extensive empirical evaluation, CNN model analysis and valuable insights can be extended to the design of high performance CAD systems for other medical imaging tasks.","0278-0062;02780062","","10.1109/TMI.2016.2528162","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7404017","Biomedical imaging;computer aided diagnosis;image analysis;machine learning;neural networks","Biomedical imaging;Computational modeling;Computed tomography;Diseases;Lungs;Lymph nodes;Solid modeling","computerised tomography;diseases;image classification;image representation;learning (artificial intelligence);lung;medical image processing;neurophysiology;reviews","CNN architectures;CNN model analysis;axial CT slices;computer-aided detection;computer-aided detection problems;dataset characteristics;deep convolutional neural networks;fine-tuning CNN models;five-fold cross-validation classification;high performance CAD systems;highly representative hierarchical image features;image recognition;interstitial lung disease classification;learning data-driven;mediastinal LN detection;medical image classification;medical image tasks;medical imaging domain;natural image dataset;off-the-shelf pretrained CNN features;pretrained imagenet;spatial image context;state-of-the-art performance;supervised fine-tuning;thoraco-abdominal lymph node detection;transfer learning;unsupervised CNN pretraining","","35","","73","","","20160211","May 2016","","IEEE","IEEE Journals & Magazines"
"Fast Convolutional Neural Network Training Using Selective Data Sampling: Application to Hemorrhage Detection in Color Fundus Images","M. J. J. P. van Grinsven; B. van Ginneken; C. B. Hoyng; T. Theelen; C. I. Sánchez","Diagnostic Image Analysis Group, Department of Radiology and Nuclear Medicine, Radboud University Medical Center, Nijmegen, The Netherlands","IEEE Transactions on Medical Imaging","20160429","2016","35","5","1273","1284","Convolutional neural networks (CNNs) are deep learning network architectures that have pushed forward the state-of-the-art in a range of computer vision applications and are increasingly popular in medical image analysis. However, training of CNNs is time-consuming and challenging. In medical image analysis tasks, the majority of training examples are easy to classify and therefore contribute little to the CNN learning process. In this paper, we propose a method to improve and speed-up the CNN training for medical image analysis tasks by dynamically selecting misclassified negative samples during training. Training samples are heuristically sampled based on classification by the current status of the CNN. Weights are assigned to the training samples and informative samples are more likely to be included in the next CNN training iteration. We evaluated and compared our proposed method by training a CNN with (SeS) and without (NSeS) the selective sampling method. We focus on the detection of hemorrhages in color fundus images. A decreased training time from 170 epochs to 60 epochs with an increased performance-on par with two human experts-was achieved with areas under the receiver operating characteristics curve of 0.894 and 0.972 on two data sets. The SeS CNN statistically outperformed the NSeS CNN on an independent test set.","0278-0062;02780062","","10.1109/TMI.2016.2526689","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7401052","Convolutional neural network;deep learning;hemorrhage;selective sampling","Biomedical imaging;Databases;Hemorrhaging;Image analysis;Image color analysis;Observers;Training","biomedical optical imaging;blood;computer vision;image classification;image colour analysis;image sampling;learning (artificial intelligence);medical image processing;neural nets;sensitivity analysis","CNN learning process;CNN training iteration;color fundus images;computer vision applications;deep learning network architectures;dynamically selecting misclassified negative samples;fast convolutional neural network training;hemorrhage detection;independent test set;medical image analysis tasks;receiver operating characteristics curve;selective data sampling;selective sampling method","","7","","48","","","20160208","May 2016","","IEEE","IEEE Journals & Magazines"
"Convolutional Neural Networks for Medical Image Analysis: Full Training or Fine Tuning?","N. Tajbakhsh; J. Y. Shin; S. R. Gurudu; R. T. Hurst; C. B. Kendall; M. B. Gotway; J. Liang","Department of Biomedical Informatics, Arizona State University, Scottsdale, AZ, USA","IEEE Transactions on Medical Imaging","20160429","2016","35","5","1299","1312","Training a deep convolutional neural network (CNN) from scratch is difficult because it requires a large amount of labeled training data and a great deal of expertise to ensure proper convergence. A promising alternative is to fine-tune a CNN that has been pre-trained using, for instance, a large set of labeled natural images. However, the substantial differences between natural and medical images may advise against such knowledge transfer. In this paper, we seek to answer the following central question in the context of medical image analysis: Can the use of pre-trained deep CNNs with sufficient fine-tuning eliminate the need for training a deep CNN from scratch? To address this question, we considered four distinct medical imaging applications in three specialties (radiology, cardiology, and gastroenterology) involving classification, detection, and segmentation from three different imaging modalities, and investigated how the performance of deep CNNs trained from scratch compared with the pre-trained CNNs fine-tuned in a layer-wise manner. Our experiments consistently demonstrated that 1) the use of a pre-trained CNN with adequate fine-tuning outperformed or, in the worst case, performed as well as a CNN trained from scratch; 2) fine-tuned CNNs were more robust to the size of training sets than CNNs trained from scratch; 3) neither shallow tuning nor deep tuning was the optimal choice for a particular application; and 4) our layer-wise fine-tuning scheme could offer a practical way to reach the best performance for the application at hand based on the amount of available data.","0278-0062;02780062","","10.1109/TMI.2016.2535302","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7426826","Carotid intima-media thickness;computer-aided detection;convolutional neural networks;deep learning;fine-tuning;medical image analysis;polyp detection;pulmonary embolism detection;video quality assessment","Biomedical imaging;Computed tomography;Feature extraction;Image analysis;Image segmentation;Training;Tuning","biomedical optical imaging;endoscopes;image classification;image segmentation;medical image processing;neural nets","cardiology;classification;deep convolutional neural network;distinct medical imaging applications;gastroenterology;imaging modalities;labeled training data;layer-wise fine-tuning scheme;medical image analysis;radiology;segmentation","","34","","76","","","20160307","May 2016","","IEEE","IEEE Journals & Magazines"
"Lung Pattern Classification for Interstitial Lung Diseases Using a Deep Convolutional Neural Network","M. Anthimopoulos; S. Christodoulidis; L. Ebner; A. Christe; S. Mougiakakou","ARTORG Center for Biomedical Engineering Research, University of Bern, Switzerland","IEEE Transactions on Medical Imaging","20160429","2016","35","5","1207","1216","Automated tissue characterization is one of the most crucial components of a computer aided diagnosis (CAD) system for interstitial lung diseases (ILDs). Although much research has been conducted in this field, the problem remains challenging. Deep learning techniques have recently achieved impressive results in a variety of computer vision problems, raising expectations that they might be applied in other domains, such as medical image analysis. In this paper, we propose and evaluate a convolutional neural network (CNN), designed for the classification of ILD patterns. The proposed network consists of 5 convolutional layers with 2 × 2 kernels and LeakyReLU activations, followed by average pooling with size equal to the size of the final feature maps and three dense layers. The last dense layer has 7 outputs, equivalent to the classes considered: healthy, ground glass opacity (GGO), micronodules, consolidation, reticulation, honeycombing and a combination of GGO/reticulation. To train and evaluate the CNN, we used a dataset of 14696 image patches, derived by 120 CT scans from different scanners and hospitals. To the best of our knowledge, this is the first deep CNN designed for the specific problem. A comparative analysis proved the effectiveness of the proposed CNN against previous methods in a challenging dataset. The classification performance ( ~ 85.5%) demonstrated the potential of CNNs in analyzing lung patterns. Future work includes, extending the CNN to three-dimensional data provided by CT volume scans and integrating the proposed method into a CAD system that aims to provide differential diagnosis for ILDs as a supportive tool for radiologists.","0278-0062;02780062","","10.1109/TMI.2016.2535865","Bern University hospital Inselspital; Swiss National Science Foundation SNSF; ","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7422082","Convolutional neural networks;interstitial lung diseases;texture classification","Computed tomography;Convolution;Design automation;Diseases;Feature extraction;Lungs;Neural networks","biological tissues;computerised tomography;convolution;diseases;feature extraction;image classification;learning (artificial intelligence);lung;medical image processing;neural nets","CT volume scans;ILD pattern classification;automated tissue characterization;computer aided diagnosis system;computer vision problems;consolidation;deep convolutional neural network;deep learning techniques;feature maps;ground glass opacity;honeycombing;interstitial lung diseases;lung pattern classification;medical image analysis;micronodules;reticulation","","17","","42","","","20160229","May 2016","","IEEE","IEEE Journals & Magazines"
"Multi-Instance Deep Learning: Discover Discriminative Local Anatomies for Bodypart Recognition","Z. Yan; Y. Zhan; Z. Peng; S. Liao; Y. Shinagawa; S. Zhang; D. N. Metaxas; X. S. Zhou","Department of Computer Science, Rutgers University, Piscataway, NJ, USA","IEEE Transactions on Medical Imaging","20160429","2016","35","5","1332","1343","In general image recognition problems, discriminative information often lies in local image patches. For example, most human identity information exists in the image patches containing human faces. The same situation stays in medical images as well. “Bodypart identity” of a transversal slice-which bodypart the slice comes from-is often indicated by local image information, e.g., a cardiac slice and an aorta arch slice are only differentiated by the mediastinum region. In this work, we design a multi-stage deep learning framework for image classification and apply it on bodypart recognition. Specifically, the proposed framework aims at: 1) discover the local regions that are discriminative and non-informative to the image classification problem, and 2) learn a image-level classifier based on these local regions. We achieve these two tasks by the two stages of learning scheme, respectively. In the pre-train stage, a convolutional neural network (CNN) is learned in a multi-instance learning fashion to extract the most discriminative and and non-informative local patches from the training slices. In the boosting stage, the pre-learned CNN is further boosted by these local patches for image classification. The CNN learned by exploiting the discriminative local appearances becomes more accurate than those learned from global image context. The key hallmark of our method is that it automatically discovers the discriminative and non-informative local patches through multi-instance deep learning. Thus, no manual annotation is required. Our method is validated on a synthetic dataset and a large scale CT dataset. It achieves better performances than state-of-the-art approaches, including the standard deep CNN.","0278-0062;02780062","","10.1109/TMI.2016.2524985","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7398101","CNN;discriminative local information discovery;multi-instance;multi-stage","Algorithm design and analysis;DICOM;Image analysis;Image recognition;Machine learning;Three-dimensional displays","cardiology;computerised tomography;face recognition;image classification;learning (artificial intelligence);medical image processing","aorta arch slice;body-part recognition;cardiac slice;convolutional neural network;discriminative information;discriminative local anatomies;discriminative local appearances;global image context;human faces;human identity information;image classification problem;image recognition problems;image-level classifier;large scale CT dataset;local image information;local image patches;mediastinum region;multiinstance deep learning;multiinstance learning fashion;multistage deep learning framework;prelearned CNN;pretrain stage;synthetic dataset;transversal slice","","10","","51","","","20160203","May 2016","","IEEE","IEEE Journals & Magazines"
"Automatic Detection of Cerebral Microbleeds From MR Images via 3D Convolutional Neural Networks","Q. Dou; H. Chen; L. Yu; L. Zhao; J. Qin; D. Wang; V. C. Mok; L. Shi; P. A. Heng","Department of Computer Science and Engineering, The Chinese University of Hong Kong, HK, China","IEEE Transactions on Medical Imaging","20160429","2016","35","5","1182","1195","Cerebral microbleeds (CMBs) are small haemorrhages nearby blood vessels. They have been recognized as important diagnostic biomarkers for many cerebrovascular diseases and cognitive dysfunctions. In current clinical routine, CMBs are manually labelled by radiologists but this procedure is laborious, time-consuming, and error prone. In this paper, we propose a novel automatic method to detect CMBs from magnetic resonance (MR) images by exploiting the 3D convolutional neural network (CNN). Compared with previous methods that employed either low-level hand-crafted descriptors or 2D CNNs, our method can take full advantage of spatial contextual information in MR volumes to extract more representative high-level features for CMBs, and hence achieve a much better detection accuracy. To further improve the detection performance while reducing the computational cost, we propose a cascaded framework under 3D CNNs for the task of CMB detection. We first exploit a 3D fully convolutional network (FCN) strategy to retrieve the candidates with high probabilities of being CMBs, and then apply a well-trained 3D CNN discrimination model to distinguish CMBs from hard mimics. Compared with traditional sliding window strategy, the proposed 3D FCN strategy can remove massive redundant computations and dramatically speed up the detection process. We constructed a large dataset with 320 volumetric MR scans and performed extensive experiments to validate the proposed method, which achieved a high sensitivity of 93.16% with an average number of 2.74 false positives per subject, outperforming previous methods using low-level descriptors or 2D CNNs by a significant margin. The proposed method, in principle, can be adapted to other biomarker detection tasks from volumetric medical data.","0278-0062;02780062","","10.1109/TMI.2016.2528129","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7403984","3D convolutional neural networks;biomarker detection;cerebral microbleeds;deep learning;susceptibility-weighted imaging","Biomarkers;Feature extraction;Kernel;MIMICs;Medical diagnostic imaging;Three-dimensional displays","biomedical MRI;blood;blood vessels;brain;cognition;diseases;feature extraction;haemodynamics;medical image processing;neurophysiology;probability","3D FCN strategy;3D convolutional neural networks;3D fully convolutional network strategy;CMB detection;MR volume extraction;MRI;automatic cerebral microbleed detection;blood vessels;cerebrovascular diseases;cognitive dysfunctions;current clinical routine;diagnostic biomarkers;haemorrhages;low-level hand-crafted descriptors;magnetic resonance images;massive redundant computations;probabilities;radiologists;representative high-level features;spatial contextual information;traditional sliding window strategy;well-trained 3D CNN discrimination","","15","","52","","","20160211","May 2016","","IEEE","IEEE Journals & Magazines"
"Convolutional Neural Networks for Branch Retinal Vein Occlusion recognition?","R. Zhao; Z. Chen; Z. Chi","Department of Electronic and Information Engineering, The Hong Kong Polytechnic University, Kowloon, Hong Kong","2015 IEEE International Conference on Information and Automation","20151001","2015","","","1633","1636","Branch Retinal Vein Occlusion (BRVO) is one of the most common retinal diseases that could impair people's vision seriously if it is not timely diagnosed and treated. It would save a lot of time and money for both medical institutions and patients if BRVO could be well recognized automatically. In this paper, we propose to exploit Convolutional Neural Networks (CNN) for BRVO recognition. We propose patch-based method and image-based voting method to implement the recognition. As it could learn abstract and useful features, CNN can achieve a high recognition accuracy. The accuracy of CNN is over 97%. Experimental results demonstrate the efficiency of our proposed CNN based methods for BRVO recognition.","","Electronic:978-1-4673-9104-7; POD:978-1-4673-9105-4; USB:978-1-4673-9103-0","10.1109/ICInfA.2015.7279547","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7279547","Branch Retinal Vein Occlusion;Convolutional Neural Networks;Feature Extraction","Accuracy;Feature extraction;Image recognition;Neural networks;Retina;Training;Veins","diseases;medical image processing;neural nets;retinal recognition","BRVO recognition;CNN;branch retinal vein occlusion recognition;convolutional neural networks;image-based voting method;patch-based method;retinal diseases","","","","11","","","","8-10 Aug. 2015","","IEEE","IEEE Conference Publications"
"Deep convolutional activation features for large scale Brain Tumor histopathology image classification and segmentation","Y. Xu; Z. Jia; Y. Ai; F. Zhang; M. Lai; E. I. C. Chang","Key Laboratory of Biomechanics and Mechanobiology of Ministry of Education, Beihang University, China","2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","20150806","2015","","","947","951","We propose a simple, efficient and effective method using deep convolutional activation features (CNNs) to achieve stat- of-the-art classification and segmentation for the MICCAI 2014 Brain Tumor Digital Pathology Challenge. Common traits of such medical image challenges are characterized by large image dimensions (up to the gigabyte size of an image), a limited amount of training data, and significant clinical feature representations. To tackle these challenges, we transfer the features extracted from CNNs trained with a very large general image database to the medical image challenge. In this paper, we used CNN activations trained by ImageNet to extract features (4096 neurons, 13.3% active). In addition, feature selection, feature pooling, and data augmentation are used in our work. Our system obtained 97.5% accuracy on classification and 84% accuracy on segmentation, demonstrating a significant performance gain over other participating teams.","1520-6149;15206149","Electronic:978-1-4673-6997-8; POD:978-1-4673-6998-5; USB:978-1-4673-6996-1","10.1109/ICASSP.2015.7178109","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7178109","classification;deep convolutional activation features;deep learning;feature learning;segmentation","Biomedical imaging;Feature extraction;Image segmentation;Support vector machines;Training;Training data;Tumors","brain;feature extraction;image classification;image segmentation;medical image processing;tumours","CNN activations;ImageNet;MICCAI 2014 Brain Tumor Digital Pathology Challenge;brain tumor histopathology;deep convolutional activation features;features extraction;image classification;image dimensions;image segmentation","","3","","23","","","","19-24 April 2015","","IEEE","IEEE Conference Publications"
"Chest pathology detection using deep learning with non-medical training","Y. Bar; I. Diamant; L. Wolf; S. Lieberman; E. Konen; H. Greenspan","The Blavatnik School of Computer Science, Tel-Aviv University, Tel Aviv 69978, Israel","2015 IEEE 12th International Symposium on Biomedical Imaging (ISBI)","20150723","2015","","","294","297","In this work, we examine the strength of deep learning approaches for pathology detection in chest radiographs. Convolutional neural networks (CNN) deep architecture classification approaches have gained popularity due to their ability to learn mid and high level image representations. We explore the ability of CNN learned from a non-medical dataset to identify different types of pathologies in chest x-rays. We tested our algorithm on a 433 image dataset. The best performance was achieved using CNN and GIST features. We obtained an area under curve (AUC) of 0.87-0.94 for the different pathologies. The results demonstrate the feasibility of detecting pathology in chest x-rays using deep learning approaches based on non-medical learning. This is a first-of-its-kind experiment that shows that Deep learning with ImageNet, a large scale non-medical image database may be a good substitute to domain specific representations, which are yet to be available, for general medical image recognition tasks.","1945-7928;19457928","Electronic:978-1-4799-2374-8; POD:978-1-4673-9330-0","10.1109/ISBI.2015.7163871","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7163871","CNN;Chest Radiography;Computer-Aided Diagnosis Disease Categorization;Deep Learning;Deep Networks","Biomedical imaging;Diagnostic radiography;Feature extraction;Machine learning;Pathology;Visualization;X-rays","convolution;diagnostic radiography;diseases;feature extraction;image classification;image representation;learning (artificial intelligence);medical image processing;neural nets","AUC;CNN algorithm;CNN deep architecture classification;CNN learning;GIST feature;ImageNet;area under curve;chest X-ray image dataset;chest pathology detection;chest radiograph;convolutional neural network;deep learning;domain specific representation;general medical image recognition task;high level image representation learning;large scale nonmedical image database;mid level image representation learning;nonmedical learning;nonmedical training;pathology identification;pathology type","","10","","15","","","","16-19 April 2015","","IEEE","IEEE Conference Publications"
"Off-the-shelf convolutional neural network features for pulmonary nodule detection in computed tomography scans","B. van Ginneken; A. A. A. Setio; C. Jacobs; F. Ciompi","Diagnostic Image Analysis Group, Radboud University Medical Center, Nijmegen, The Netherlands","2015 IEEE 12th International Symposium on Biomedical Imaging (ISBI)","20150723","2015","","","286","289","Convolutional neural networks (CNNs) have emerged as the most powerful technique for a range of different tasks in computer vision. Recent work suggested that CNN features are generic and can be used for classification tasks outside the exact domain for which the networks were trained. In this work we use the features from one such network, OverFeat, trained for object detection in natural images, for nodule detection in computed tomography scans. We use 865 scans from the publicly available LIDC data set, read by four thoracic radiologists. Nodule candidates are generated by a state-of-the-art nodule detection system. We extract 2D sagittal, coronal and axial patches for each nodule candidate and extract 4096 features from the penultimate layer of OverFeat and classify these with linear support vector machines. We show for various configurations that the off-the-shelf CNN features perform surprisingly well, but not as good as the dedicated detection system. When both approaches are combined, significantly better results are obtained than either approach alone. We conclude that CNN features have great potential to be used for detection tasks in volumetric medical data.","1945-7928;19457928","Electronic:978-1-4799-2374-8; POD:978-1-4673-9330-0","10.1109/ISBI.2015.7163869","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7163869","Nodule detection;computed tomography;convolutional neural networks","Biomedical imaging;Cancer;Computed tomography;Design automation;Feature extraction;Lesions;Lungs","computerised tomography;feature extraction;image classification;medical image processing;neural nets;support vector machines","2D sagittal;CNN features;LIDC data set;OverFeat features;axial patches;computed tomography scans;coronal patches;feature extraction;image classification;linear support vector machines;object detection;off-the-shelf convolutional neural network features;pulmonary nodule detection;thoracic radiologists;volumetric medical data","","12","","11","","","","16-19 April 2015","","IEEE","IEEE Conference Publications"
"Automated anatomical landmark detection ondistal femur surface using convolutional neural network","D. Yang; S. Zhang; Z. Yan; C. Tan; K. Li; D. Metaxas","CBIM, Rutgers University, Piscataway, NJ, US","2015 IEEE 12th International Symposium on Biomedical Imaging (ISBI)","20150723","2015","","","17","21","Accurate localization of the anatomical landmarks on distal femur bone in the 3D medical images is very important for knee surgery planning and biomechanics analysis. However, the landmark identification process is often conducted manually or by using the inserted auxiliaries, which is time-consuming and lacks of accuracy. In this paper, an automatic localization method is proposed to determine positions of initial geometric landmarks on femur surface in the 3D MR images. Based on the results from the convolutional neural network (CNN) classifiers and shape statistics, we use the narrow-band graph cut optimization to achieve the 3D segmentation of femur surface. Finally, the anatomical landmarks are located on the femur according to the geometric cues of surface mesh. Experiments demonstrate that the proposed method is effective, efficient, and reliable to segment femur and locate the anatomical landmarks.","1945-7928;19457928","Electronic:978-1-4799-2374-8; POD:978-1-4673-9330-0","10.1109/ISBI.2015.7163806","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7163806","Deep learning;anatomical landmark detection;convolutional neural network;graph cut;mesh curvature","Biomedical imaging;Bones;Image segmentation;Neural networks;Shape;Three-dimensional displays;Training","biomechanics;biomedical MRI;bone;graph theory;image classification;medical image processing;neural nets;optimisation;surgery","3D MR images;3D medical images;3D segmentation;CNN classifiers;automated anatomical landmark detection;automatic localization method;biomechanics analysis;convolutional neural network;distal femur bone;distal femur surface;knee surgery planning;landmark identification process;magnetic resonance images;narrow-band graph cut optimization;shape statistics;surface mesh","","0","","20","","","","16-19 April 2015","","IEEE","IEEE Conference Publications"
"Medical image classification with convolutional neural network","Q. Li; W. Cai; X. Wang; Y. Zhou; D. D. Feng; M. Chen","Biomedical and Multimedia Information Technology (BMIT) Research Group, School of IT, University of Sydney, Australia","2014 13th International Conference on Control Automation Robotics & Vision (ICARCV)","20150323","2014","","","844","848","Image patch classification is an important task in many different medical imaging applications. In this work, we have designed a customized Convolutional Neural Networks (CNN) with shallow convolution layer to classify lung image patches with interstitial lung disease (ILD). While many feature descriptors have been proposed over the past years, they can be quite complicated and domain-specific. Our customized CNN framework can, on the other hand, automatically and efficiently learn the intrinsic image features from lung image patches that are most suitable for the classification purpose. The same architecture can be generalized to perform other medical image or texture classification tasks.","","Electronic:978-1-4799-5199-4; POD:978-1-4799-5200-7; USB:978-1-4799-5198-7","10.1109/ICARCV.2014.7064414","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7064414","","Biological neural networks;Biomedical imaging;Feature extraction;Kernel;Lungs;Neurons;Training","diseases;feature extraction;image classification;lung;medical image processing;neural nets","CNN;ILD;convolutional neural network;feature descriptors;interstitial lung disease;intrinsic image features;lung image patches classification;medical image classification;medical imaging applications;shallow convolution layer;texture classification","","11","","26","","","","10-12 Dec. 2014","","IEEE","IEEE Conference Publications"
"Cellular neural networks assisted automatic detection of elements in microscopic medical images. A preliminary study","C. Botoca","Communications Department, Electronics and Telecommunications Faculty, University Politehnica Timisoara Timisoara, Romania","2014 11th International Symposium on Electronics and Telecommunications (ISETC)","20150115","2014","","","1","4","This paper presents a new algorithm for object recognition in medical microscopic images, assisted by a cellular neural network (CNN). The CNN flowchart and its component parts are described based on successions of interconnections templates. The experiments results are shown and they appear to be promising. Our results sustain the usability of CNN as a real time processing tool for assisting the medical act.","","CD-ROM:978-1-4799-7265-4; Electronic:978-1-4799-7267-8; POD:978-1-4799-7268-5","10.1109/ISETC.2014.7010801","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7010801","cellular neural networks;cloning template;medical images processing","Cellular neural networks;Computers;Crystals;Medical diagnostic imaging;Microscopy;Noise reduction","biomedical optical imaging;cellular neural nets;flowcharting;medical image processing;object detection;optical microscopy;real-time systems","CNN component part;CNN flowchart;cellular neural network assisted automatic detection;interconnection template succession;microscopic medical image element detection;object recognition algorithm;real time processing tool","","0","","12","","","","14-15 Nov. 2014","","IEEE","IEEE Conference Publications"
"cellular neural network based medical image segmentation using artificial bee colony algorithm","M. Duraisamy; F. M. M. Jane","Department of Computer Applications, Dr NGP Institute of Technology, Coimbatore - 641 048","2014 International Conference on Green Computing Communication and Electrical Engineering (ICGCCEE)","20141016","2014","","","1","6","Magnetic Resonance Imaging (MRI) has become an efficient instrument for clinical diagnoses and research in recent years. It has become a very useful medical modality for the detection of various diseases through segmentation methods. In this paper, we have presented an effective CNN based segmentation method with lung and brain MRI images. This approach hits the target with the aid of the following major steps, which includes, 1) Preprocessing of the brain and lung images, 2) Segmentation using cellular neural network. Initially, the MRI image is pre-processed to make it fit for segmentation. Here, in the pre-processing step, image de-noising is done using the linear smoothing filters, such as Gaussian Filter. Then, the pre-processed image is segmented according to our proposed technique, CNN-based image segmentation. Finally, the different MRI images (brain and lung) are given to the proposed approach to evaluate the performance of the proposed approach in segmentation process. The Comparative analysis is carried out Fuzzy C-means (FCM) and K-means classification. From the comparative analysis, the accuracy of proposed segmentation approach produces better results (83.7% for lung and 93% for brain images) than that of existing Fuzzy C-means (FCM) and K-means classification.","","Electronic:978-1-4799-4982-3; POD:978-1-4799-4981-6","10.1109/ICGCCEE.2014.6922413","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6922413","Brain and Lung MRI image;Cellular neural network;Gaussian filter;employed bee;onlooker bee;scout bee;template design","Algorithm design and analysis;Biomedical imaging;Cellular neural networks;Image segmentation;Lungs;Magnetic resonance imaging","ant colony optimisation;biomedical MRI;brain;cellular neural nets;diseases;fuzzy set theory;image classification;image denoising;image segmentation;lung;medical image processing;smoothing methods","CNN based segmentation method;FCM classification;Gaussian filter;K-means classification;artificial bee colony algorithm;brain MRI images;brain image preprocessing;cellular neural network based medical image segmentation;clinical diagnoses;diseases;fuzzy c-means classification;image denoising;linear smoothing filters;lung MRI images;lung image preprocessing;magnetic resonance imaging;medical modality","","1","","37","","","","6-8 March 2014","","IEEE","IEEE Conference Publications"
"Sperm Morphology Analysis with CNN based algorithms","O. L. Şavkay; E. Cesur; M. E. Yalçın; V. Tavşanoğlu","Dept. of Electron. & Commun. Eng., Istanbul Tech. Univ., Istanbul, Turkey","2014 14th International Workshop on Cellular Nanoscale Networks and their Applications (CNNA)","20140901","2014","","","1","2","In this paper Morphological Analysis part of our proposed computer-aided sperm analysis system (CASA) is simulated and the results beside the algorithm steps are presented. The morphology analysis is simply dealing with shape of the sperms and extracting the shape characteristics in medical parameters. The characteristics are obtained by image processing algorithms which utilizes Cellular Nanoscale Network (CNN) based and spatial image processing blocks. The following calculation of medical parameters are obtained from the outputs of image processing blocks. The algorithm is so designed to adapt the final SoC architecture such as Xilinx Zynq7000 device.","2165-0144;21650144","Electronic:978-1-4799-6007-1; POD:978-1-4799-6008-8","10.1109/CNNA.2014.6888647","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6888647","","Algorithm design and analysis;Biomedical imaging;Computer architecture;Head;Image processing;Morphology;Shape","cellular biophysics;computer aided analysis;medical image processing;system-on-chip","CASA;CNN based algorithms;Cellular Nanoscale Network;SoC architecture;algorithm steps;computer-aided sperm analysis system;image processing algorithms;medical parameters;shape characteristics;spatial image processing blocks;sperm morphology analysis;sperm shape","","0","","10","","","","29-31 July 2014","","IEEE","IEEE Conference Publications"
"Implementation of an improved cellular neural network algorithm for brain tumor detection","A. A. Abdullah; B. S. Chize; Y. Nishio","School of Mechatronic Engineering, Universiti Malaysia Perlis (UniMAP), Ulu Pauh, 02600 Arau, Malaysia","2012 International Conference on Biomedical Engineering (ICoBE)","20120405","2012","","","611","615","Image processing plays an important role in medical diagnosis. In this paper, a brain tumor detection method based on cellular neural networks (CNNs) is proposed. Brain tumor is an abnormal growth of cells inside the skull. To examine the location of tumor in the brain, Magnetic Resonance Imaging (MRI) is used. Radiologists will evaluate the grey scale MRI images. This procedure is really time and energy consuming. To overcome this problem, an automated detection method for brain tumor using CNN is developed. By using the template in the CNN simulator, output of the desired image can be performed. Therefore, many templates were combined in order to obtain an accurate result that will help radiologists detecting the tumor in brain images easily.","","Electronic:978-1-4577-1991-2; POD:978-1-4577-1990-5","10.1109/ICoBE.2012.6178990","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6178990","Brain tumor;MRI images;cellular neural network;image processing;templates","Algorithm design and analysis;Brain;Cellular neural networks;Image segmentation;Magnetic resonance imaging;Signal processing algorithms;Tumors","biomedical MRI;brain;cellular biophysics;cellular neural nets;medical image processing;tumours","automated detection method;brain tumor detection;cells;cellular neural network algorithm;grey scale MRI images;image processing;magnetic resonance imaging;medical diagnosis;skull","","2","","6","","","","27-28 Feb. 2012","","IEEE","IEEE Conference Publications"
"Preliminary study of pneumonia symptoms detection method using Cellular Neural Network","A. A. Abdullah; Norafifah Md Posdzi; Y. Nishio","School of Mechatronic Engineering, Universiti Malaysia Perlis, Kampus Ulu Pauh, 02600 Arau, Malaysia","International Conference on Electrical, Control and Computer Engineering 2011 (InECCE)","20110714","2011","","","497","500","Medical diagnosis is one of the most important procedure in which image processing are usefully applied. In this paper, a pneumonia symptoms detection method based on cellular neural networks (CNNs) is proposed. The CNN design is characterized by a virtual template expansion obtained through a multistep operation. It is based on linear space invariant 3 × 3 templates. The proposed design is capable of performing pneumonia symptoms detection within a short time. The main idea in Cellular Neural Network is that connection is allowed between adjacent units only. There are few rules in Cellular Neural Network that has to be implemented when designing the templates, such as state equation, output equation, boundary equation, and also the initial value. These templates are combined to create the most ideal algorithm to detect the pneumonia symptoms in an image. Candy software is used as a CNN simulator to detect the pneumonia symptoms area. It was tested on the 23 grayscale pneumonia symptoms CT image obtained from the diagnostic imaging department. The simulation results show good performance based on the difference grayscale color and segmentation between the normal area and lung region area.","","Electronic:978-1-61284-230-1; POD:978-1-61284-229-5","10.1109/INECCE.2011.5953933","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5953933","CT Image;Cellular Neural Network;Image processing;Pneumonia symptoms","Cellular neural networks;Computed tomography;Diseases;Image color analysis;Lungs;Noise;Pixel","cellular neural nets;computerised tomography;diagnostic radiography;diseases;lung;medical image processing;pneumodynamics","CNN simulator;CT image;cellular neural network;diagnostic imaging;grayscale color;image processing;lung region area;medical diagnosis;pneumonia symptoms detection;segmentation;virtual template expansion","","0","","7","","","","21-22 June 2011","","IEEE","IEEE Conference Publications"
"Wireless trans-corneal stimulus for the optical nerve based on adaptive modeling using continuous neural networks","M. Alfaro; L. Niño de Rivera; I. Chairez","National Polytechnic Institute -SEPI-ESIME Culhuacan, M&#x00E9;xico D.F., M&#x00E9;xico","2010 7th International Conference on Electrical Engineering Computing Science and Automatic Control","20101025","2010","","","236","241","Retinal prosthesis design has become a hot field of researching around the world. Restoring partial vision to the blind patients that suffer from degenerative disease has become an important medical and scientific task. However, there are some doubts on how to propose the stimulation signals. The same question arises when the stimulation may be done by trans-corneal or transdermic pathways. One method that could be used is to apply a no-parametric algorithm to obtain a nonlinear model representing the relationship between the optical nerve response signal and the stimulus inputs. Then, it can be applied an inverse model methodology to identify the unknown inputs required to obtain the desired optical nerve response. In this study, we proposed an adaptive modeling based in continuous neural networks (CNN) to obtain an artificial model of the relationship between the optical nerve response and the selective stimulation. This model tries to determine the adequate stimulation signals that will be applied on the trans-corneal or transepidermic part of the eye. Indeed, the input signal effectiveness will be measured as the degree of accuracy obtaining the desired response in the optical nerve. A set of CNN working as a parallel identifier provides the adaptive model of the aforementioned relation. An artificial optical nerve response was developed as well as the electrical stimulator for the trans-corneal area. These both designs were applied into the CNN identifier to test the methodology suggested in this paper. The numerical results demonstrate the accuracy achieved by the modeling algorithm.","","Electronic:978-1-4244-7314-4; POD:978-1-4244-7312-0","10.1109/ICEEE.2010.5608568","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5608568","Electrical Stimulation;Optical Nerve;Trans-corneal Prosthesis and Adaptive Neural Networks","Adaptation model;Adaptive optics;Artificial neural networks;Biomedical optical imaging;Electrodes;Nonlinear optics;Stimulated emission","eye;neural nets;neurophysiology;prosthetics;vision","adaptive modeling;blind patient;continuous neural network;optical nerve;partial vision;retinal prosthesis design;transcorneal pathway;transdermic pathway;wireless transcorneal stimulus","","0","","15","","","","8-10 Sept. 2010","","IEEE","IEEE Conference Publications"
"Cellular neural network based algorithms in the early detection of hand osteoarthritis","S. Banerjee; G. Schaefer; I. K. Vlachos","School of Information Technology, West Bengal University of Technology, Kolkata, India","2009 IEEE International Conference on Fuzzy Systems","20091002","2009","","","1369","1373","Cellular neural network (CNN) algorithms have been successfully used in a plethora of image processing applications including the medical imaging domain. Analogic CNN algorithms use CNN templates combined with logic operations to perform operations such as blurring and thresholding for image processing. In this paper we apply CNN based techniques incorporating image enhancement, region segmentation and line detection for detecting the manifestations of osteoarthritis, a metabolic disease afflicting the elderly population caused by wear and tear of cartilage surrounding weight bearing bone joints like the human hand. The two main indicators of osteoarthritis that we examine are the cystic regions, and osteophytes or bony spurs in the vicinity of the joints, produced by the rubbing together of bones due to joint space narrowing.","1098-7584;10987584","POD:978-1-4244-3596-8","10.1109/FUZZY.2009.5276883","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5276883","","Biomedical imaging;Bone diseases;Cellular neural networks;Image enhancement;Image processing;Image segmentation;Joints;Logic;Osteoarthritis;Senior citizens","cellular neural nets;image enhancement;image segmentation","cellular neural network;hand osteoarthritis;image enhancement;image processing;image segmentation;logic operations;metabolic disease;osteoarthritis","","1","","13","","","","20-24 Aug. 2009","","IEEE","IEEE Conference Publications"
"PDE-based medical images denoising using Cellular Neural Networks","A. Gacsadi; C. Grava; O. Straciuc; I. Gavrilut","University of Oradea, Romania","2009 International Symposium on Signals, Circuits and Systems","20090818","2009","","","1","4","This paper presents the medical image denoising by using cellular neural networks (CNN), based on the variational model of Chan and Esedoglu. There are also comparatively analyzed the proposed method and other CNN methods that uses variational computation, our proposed method offering the best efficiency in terms of image denoising and edge preservation.","","POD:978-1-4244-3785-6","10.1109/ISSCS.2009.5206128","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5206128","","Additive noise;Biomedical imaging;Cellular neural networks;Gaussian noise;Image denoising;Image segmentation;Integral equations;Medical diagnostic imaging;Partial differential equations;Visualization","cellular neural nets;image denoising;medical image processing;partial differential equations;variational techniques","PDE-based medical image denoising;cellular neural networks;edge preservation;variational computation;variational model","","0","","16","","","","9-10 July 2009","","IEEE","IEEE Conference Publications"
"A New Way to Process B-Scan Images","G. Li; H. Song; H. Zhang; J. Wang; H. Hong; Y. Liu","Sch. of Math. & Phys., North China Electr. Power Univ., Beijing","2008 2nd International Conference on Bioinformatics and Biomedical Engineering","20080603","2008","","","2545","2548","Image processing is an important phase in order to improve the accuracy both for diagnosis procedure and for surgical operation. Medical diagnosis is one of the most important areas in which image processing procedures are usefully applied. In this paper, we use the Cellular Neural Networks to research diagnostic images. We present a robustness design theorem for the optimal edge detector cellular neural network (OEDGE CNN). As applications, the CNN can detect successfully the embossment of B-scan image. Our findings show that CNN may provide a useful tool for medical image processing. To this point, a novel approach to image processing has been developed in the work.","2151-7614;21517614","CD-ROM:978-1-4244-1748-3; POD:978-1-4244-1747-6","10.1109/ICBBE.2008.970","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4535850","","Artificial neural networks;Biological neural networks;Biomedical engineering;Cellular neural networks;Color;Detectors;Image edge detection;Image processing;Liver diseases;Robustness","biomedical ultrasonics;cellular neural nets;edge detection;medical image processing","B-scan images;cellular neural networks;medical diagnosis procedure;medical image processing;optimal edge detector;surgical operation","","0","","14","","","","16-18 May 2008","","IEEE","IEEE Conference Publications"
"A CNN Implementation of the Horn & Schunck Motion Estimation Method","A. Gacsadi; C. Grava; V. Tiponut; P. Szolgay","Electronics Department, University of Oradea, Str. Universit&#191;&#191;ii 1, 410087, Oradea, Romania, Tel: +40-259-408735, Fax: +40-259-432789, E-mail: agacsadi@uoradea.ro","2006 10th International Workshop on Cellular Neural Networks and Their Applications","20070410","2006","","","1","5","In this paper the parallel implementation of the Horn and Schunck motion estimation method in image sequences is presented, by using cellular neural networks (CNN). One of the drawbacks of the classical motion estimation algorithms is the computational time. The goal of the CNN implementation of the Horn & Schunck method is to increase the efficiency of the well-known classical implementation of this method, which is one of the most used algorithms among the motion estimation techniques. The aim is to obtain a smaller computation time and to include such an algorithm in motion compensation algorithms implemented using CNN, in order to obtain homogeneous algorithms for real-time applications in artificial vision or medical imaging","2165-0144;21650144","CD-ROM:1-4244-0640-4; POD:1-4244-0639-0","10.1109/CNNA.2006.341615","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4145855","cellular neural networks;image processing;motion estimation;optical flow;real-time applications","Biomedical imaging;Biomedical optical imaging;Brightness;Cellular neural networks;Electronic mail;Equations;Image motion analysis;Image processing;Image sequences;Motion estimation","cellular neural nets;image sequences;motion compensation;motion estimation","Horn motion estimation;Schunck motion estimation;artificial vision;cellular neural networks;image processing;image sequences;medical imaging;motion compensation;optical flow;parallel implementation","","0","","16","","","","28-30 Aug. 2006","","IEEE","IEEE Conference Publications"
"Detecting Structural Alterations in the Brain using a Cellular Neural Network based Classification of Magnetic Resonance Images","F. Dohler; A. Chernihovskyi; F. Mormann; C. E. Elger; K. Lehnertz","Department of Epileptology, University of Bonn, Sigmund-Freud Str. 25, 53105 Bonn, Germany; Helmholtz-Institute for Radiation and Nuclear Physics, University of Bonn, Sigmund-Freud Str. 25, 53105 Bonn, Germany","2006 10th International Workshop on Cellular Neural Networks and Their Applications","20070410","2006","","","1","4","The ability to quantify structural attributes using cellular neural networks (CNN) has been shown for a wide range of objects. We here introduce an application that allows the detection of structural alterations in the human brain. Using a CNN-based classification approach we show that a defined class of abnormalities - the so called hippocampal sclerosis - can be detected in T1-weighted magnetic resonance images. Our findings indicate that CNN may prove valuable for a computer-aided diagnosis and classification of images generated by medical imaging systems","2165-0144;21650144","CD-ROM:1-4244-0640-4; POD:1-4244-0639-0","10.1109/CNNA.2006.341648","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4145888","classification;epilepsy;image analysis;magnetic resonance imaging","Automated highways;Biomedical imaging;Cellular neural networks;Epilepsy;Image generation;Magnetic resonance;Magnetic resonance imaging;Signal processing;Ultrasonic imaging;X-ray imaging","brain;cellular neural nets;diseases;image classification;magnetic resonance imaging;medical image processing;patient diagnosis","cellular neural networks;computer-aided diagnosis;epilepsy;hippocampal sclerosis;human brain;image analysis;image classification;magnetic resonance images;medical imaging systems;structural alteration detection","","1","","23","","","","28-30 Aug. 2006","","IEEE","IEEE Conference Publications"
"Medical image enhancement by using cellular neural networks","A. Gacsadi; C. Grava; A. Grava","Univ. of Oradea","Computers in Cardiology, 2005","20060206","2005","","","821","824","The paper presents a medical image enhancement method taking the noise reduction and the contrast enhancement into consideration, as well as the possibility of implementation on an existing cellular neural network universal chip (CNN-UC), in a single step, by using only linear templates of 3times3 dimensions. Due to complete parallel processing, computing-time reduction is achieved","0276-6574;02766574","POD:0-7803-9337-6","10.1109/CIC.2005.1588231","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1588231","","Biomedical imaging;Cellular networks;Cellular neural networks;Computer architecture;Computer networks;Concurrent computing;Image enhancement;Image processing;Parallel processing;Partial differential equations","cellular neural nets;image enhancement;medical image processing;parallel processing","cellular neural network universal chip;gray-scale templates;medical image contrast enhancement;noise reduction;parallel processing","","6","","17","","","","25-28 Sept. 2005","","IEEE","IEEE Conference Publications"
"An 0.5-μm CMOS analog random access memory chip for TeraOPS speed multimedia video processing","R. Carmona-Galan; A. Rodriguez-Vazquez; S. Espejo-Meana; R. Dominguez-Castro; T. Roska; T. Kozek; L. O. Chua","Inst. de Microelectron., Seville Univ., Spain","IEEE Transactions on Multimedia","20020806","1999","1","2","121","135","Data compressing, data coding, and communications in object-oriented multimedia applications like telepresence, computer-aided medical diagnosis, or telesurgery require an enormous computing power-in the order of trillions of operations per second (TeraOPS). Compared with conventional digital technology, cellular neural/nonlinear network (CNN)-based computing is capable of realizing these TeraOPS-range image processing tasks in a cost-effective implementation. To exploit the computing power of the CNN Universal Machine (CNN-UM), the CNN chipset architecture has been developed-a mixed-signal hardware platform for CNN-based image processing. One of the nonstandard components of the chipset is the cache memory of the analog array processor, the analog random access memory (ARAM). This paper reports on an ARAM chip that has been designed and fabricated in a 0.5-μm CMOS technology. This chip consists of a fully addressable array of 32×256 analog memory registers and has a packing density of 637 analog-memory-cells/mm<sup>2</sup>. Random and nondestructive access of the memory contents is available. Bottom-plate sampling techniques have been employed to eliminate harmonic distortion introduced by signal-dependent feedthrough. Signal coupling and interaction have been minimized by proper layout measures, including the use of protection rings and separate power supplies for the analog and the digital circuitry. This prototype features an equivalent resolution of up to 7 bits-measured by comparing the reconstructed waveform with the original input signal. Measured access times for writing/reading to/from the memory registers are of 200 ns. I/O rates via the l6-line-wide I/O bus exceed 10 Msamples/s. Storage time at room temperature is in the 80 to 100 ms range, without accuracy loss","1520-9210;15209210","","10.1109/6046.766734","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=766734","","Application software;CMOS technology;Cellular neural networks;Computer applications;Image coding;Image processing;Multimedia communication;Multimedia computing;Random access memory;Registers","CMOS memory circuits;cellular arrays;cellular neural nets;multimedia systems;random-access storage;video coding","0.5-μm CMOS analog random access memory chip;CNN Universal Machine;TeraOPS speed multimedia video processing;analog random access memory;cache memory;cellular neural/nonlinear network-based computing;computer-aided medical diagnosis;data coding;data compressing;mixed-signal hardware platform;object-oriented multimedia;telepresence;telesurgery","","9","","32","","","","Jun 1999","","IEEE","IEEE Journals & Magazines"
"Reduction of false positives in lung nodule detection using a two-level neural classification","Jyh-Shyan Lin; S. C. B. Lo; A. Hasegawa; M. T. Freedman; S. K. Mun","Radiol. Dept., Georgetown Univ. Med. Center, Washington, DC, USA","IEEE Transactions on Medical Imaging","20020806","1996","15","2","206","217","The authors have developed a neural-digital computer-aided diagnosis system, based on a parameterized two-level convolution neural network (CNN) architecture and on a special multilabel output encoding procedure. The developed architecture was trained, tested, and evaluated specifically on the problem of diagnosis of lung cancer nodules found on digitized chest radiographs. The system performs automatic “suspect” localization, feature extraction, and diagnosis of a particular pattern-class aimed at a high degree of “true-positive fraction” detection and low “false-positive fraction” detection. In this paper, the authors aim at the presentation of the two-level neural classification method in reducing false-positives in their system. They employed receiver operating characteristics (ROC) method with the area under the ROC curve (A<sub>z</sub>) as the performance index to evaluate all the simulation results. The two-level CNN showed superior performance (A<sub>z</sub>=0.93) to the single-level CNN (A<sub>z</sub>=0.85). The proposed two-level CNN architecture is proven to be promising and to be extensible, problem-independent, and therefore, applicable to other medical or difficult diagnostic tasks in two-dimensional (2-D) image environments","0278-0062;02780062","","10.1109/42.491422","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=491422","","Cancer;Cellular neural networks;Computer aided diagnosis;Computer architecture;Convolution;Diagnostic radiography;Encoding;Lungs;Neural networks;Testing","diagnostic radiography;lung;medical image processing","digitized chest radiographs;false positives reduction;lung cancer diagnosis;lung nodule detection;medical diagnostic imaging;multilabel output encoding procedure;neural-digital computer-aided diagnosis system;parameterized two-level convolution neural network;performance index;receiver operating characteristics method;two-dimensional image environments;two-level neural classification","","41","8","46","","","","Apr 1996","","IEEE","IEEE Journals & Magazines"
"Color image processing in a cellular neural-network environment","Chi-Chien Lee; J. P. de Gyvez","Dept. of Electr. Eng., Texas A&M Univ., College Station, TX, USA","IEEE Transactions on Neural Networks","20020806","1996","7","5","1086","1098","When low-level hardware simulations of cellular neural networks (CNNs) are very costly for exploring new applications, the use of a behavioral simulator becomes indispensable. This paper presents a software prototype capable of performing image processing applications using CNNs. The software is based on a CNN multilayer structure in which each primary color is assigned to a unique layer. This allows an added flexibility as different processing applications can be performed in parallel. To be able to handle a full range of color tones, two novel color mapping schemes were derived. In the proposed schemes the color information is obtained from the cell's state rather than from its output. This modification is necessary because for many templates CNN has only binary stable outputs from which only either a fully saturated or a black color can be obtained. Additionally, a postprocessor capable of performing pixelwise logical operations among color layers was developed to enhance the results obtained from CNN. Examples in the areas of medical image processing, image restoration, and weather forecasting are provided to demonstrate the robustness of the software and the vast potential of CNN","1045-9227;10459227","","10.1109/72.536306","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=536306","","Application software;Biomedical image processing;Cellular neural networks;Color;Image processing;Image restoration;Multi-layer neural network;Neural network hardware;Software performance;Software prototyping","cellular neural nets;image processing;multilayer perceptrons","behavioral simulator;cellular neural networks;color image processing;image restoration;low-level hardware simulations;medical image processing;multilayer structure;pixelwise logical operations;postprocessor;software prototype;weather forecasting","","22","","25","","","","Sep 1996","","IEEE","IEEE Journals & Magazines"
"Intervertebral disc detection in X-ray images using faster R-CNN","R. Sa; W. Owens; R. Wiegand; M. Studin; D. Capoferri; K. Barooha; A. Greaux; R. Rattray; A. Hutton; J. Cintineo; V. Chaudhary","State University of New York (SUNY) at Buffalo, United States of America","2017 39th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)","20170914","2017","","","564","567","Automatic identification of specific osseous landmarks on the spinal radiograph can be used to automate calculations for correcting ligament instability and injury, which affect 75% of patients injured in motor vehicle accidents. In this work, we propose to use deep learning based object detection method as the first step towards identifying landmark points in lateral lumbar X-ray images. The significant breakthrough of deep learning technology has made it a prevailing choice for perception based applications, however, the lack of large annotated training dataset has brought challenges to utilizing the technology in medical image processing field. In this work, we propose to fine tune a deep network, Faster-RCNN, a state-of-the-art deep detection network in natural image domain, using small annotated clinical datasets. In the experiment we show that, by using only 81 lateral lumbar X-Ray training images, one can achieve much better performance compared to traditional sliding window detection method on hand crafted features. Furthermore, we fine-tuned the network using 974 training images and tested on 108 images, which achieved average precision of 0.905 with average computation time of 3 second per image, which greatly outperformed traditional methods in terms of accuracy and efficiency.","","Electronic:978-1-5090-2809-2; POD:978-1-5090-2810-8","10.1109/EMBC.2017.8036887","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8036887","X-Ray;deep learning;detection;intervertebral disc","","","","","","","","","","","11-15 July 2017","","IEEE","IEEE Conference Publications"
"Assessment of support vector machines and convolutional neural networks to detect snoring using Emfit mattress","J. M. Perez-Macias; S. Adavanne; J. Viik; A. Värri; S. L. Himanen; M. Tenhunen","Faculty Faculty of Biomedical Sciences and Engineering, University of Technology, Tampere, 33720 Finland","2017 39th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)","20170914","2017","","","2883","2886","Snoring (SN) is an essential feature of sleep breathing disorders, such as obstructive sleep apnea (OSA). In this study, we evaluate epoch-based snoring detection methods using an unobtrusive electromechanical film transducer (Emfit) mattress sensor using polysomnography recordings as a reference. Two different approaches were investigated: a support vector machine (SVM) classifier fed with a subset of spectral features and convolutional neural network (CNN) fed with spectrograms. Representative 10-min normal breathing (NB) and SN periods were selected for analysis in 30 subjects and divided into thirty-second epochs. In the evaluation, average results over 10 fold Monte Carlo cross-validation with 80% training and 20% test split were reported. Highest performance was achieved using CNN, with 92% sensitivity, 96% specificity, 94% accuracy, and 0.983 area under the receiver operating characteristics curve (AROC). Results showed a 6% average increase of performance of the CNN over SVM and greater robustness, and similar performance to ambient microphones.","","Electronic:978-1-5090-2809-2; POD:978-1-5090-2810-8","10.1109/EMBC.2017.8037459","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8037459","","","","","","","","","","","","11-15 July 2017","","IEEE","IEEE Conference Publications"
"Surgical-tools detection based on Convolutional Neural Network in laparoscopic robot-assisted surgery","B. Choi; K. Jo; S. Choi; J. Choi","Biomedical Engineering Research Center, Asan Institute for Life Sciences, Asan Medical Center, Seoul, South Korea","2017 39th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)","20170914","2017","","","1756","1759","Laparoscopic surgery, a type of minimally invasive surgery, is used in a variety of clinical surgeries because it has a faster recovery rate and causes less pain. However, in general, the robotic system used in laparoscopic surgery can cause damage to the surgical instruments, organs, or tissues during surgery due to a narrow field of view and operating space, and insufficient tactile feedback. This study proposes real-time models for the detection of surgical instruments during laparoscopic surgery by using a CNN(Convolutional Neural Network). A dataset included information of the 7 surgical tools is used for learning CNN. To track surgical instruments in real time, unified architecture of YOLO apply to the models. So as to evaluate performance of the suggested models, degree of recall and precision is calculated and compared. Finally, we achieve 72.26% mean average precision over our dataset.","","Electronic:978-1-5090-2809-2; POD:978-1-5090-2810-8","10.1109/EMBC.2017.8037183","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8037183","","","","","","","","","","","","11-15 July 2017","","IEEE","IEEE Conference Publications"
"Cerebral Micro-Bleed Detection Based on the Convolution Neural Network With Rank Based Average Pooling","S. Wang; Y. Jiang; X. Hou; H. Cheng; S. Du","School of Electronic Engineering, Nanjing University, Nanjing, China","IEEE Access","20170906","2017","5","","16576","16583","Cerebral micro-bleed (CMB) is small perivascular hemosiderin deposits from leakage through cerebral small vessels. They can result from cerebra-vascular disease, dementia, or simply from normal aging. It can be visualized via the susceptibility weighted imaging (SWI). Based on the SWI, we propose to use different structures of the CNN with rank-based average pooling to detect the CMB, and compare this method used in this paper to the current state-of-the-art methods. We can find that the CNN with five layers obtains the best performance, with a sensitivity of 96.94%, a specificity of 97.18%, and an accuracy of 97.18%.","","","10.1109/ACCESS.2017.2736558","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8013653","Convolutional neural network;cerebral micro-bleed;network structure;rank based average pooling","Convolution;Diseases;Electronic mail;Magnetic resonance imaging;Manuals;Visualization","","","","","","","","","20170821","2017","","IEEE","IEEE Journals & Magazines"
"Detection of dynamical properties of flow in an eye vessels by video sequences analysis","A. Nedzved; O. Nedzved; A. Glinsky; G. Karapetian; I. Gurevich; V. Yashina","Belorussian State University, Minsk, Belarus","2017 International Conference on Information and Digital Technologies (IDT)","20170904","2017","","","275","280","In this paper the method of dynamical properties of flow in some eye vessels is described. It is based on algorithm of segmentation on base CNN, morphological processing and optical flow. It allows to define new properties of changing blood flow in vessels that is depends from structure of vessels net.","","Electronic:978-1-5090-5689-7; POD:978-1-5090-4689-8; USB:978-1-5090-5688-0","10.1109/DT.2017.8024308","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8024308","CNN;dynamical properties;morphological properties;optical flow;vessel segmentation","Algorithm design and analysis;Biomedical imaging;Computer vision;Heuristic algorithms;Image motion analysis;Image segmentation;Video sequences","","","","","","","","","","5-7 July 2017","","IEEE","IEEE Conference Publications"
"Nursing-care text classification using word vector representation and convolutional neural networks","M. Nii; Y. Tsuchida; Y. Kato; A. Uchinuno; R. Sakashita","Graduate School of Engineering, University of Hyogo, Himeji, Hyogo, Japan","2017 Joint 17th World Congress of International Fuzzy Systems Association and 9th International Conference on Soft Computing and Intelligent Systems (IFSA-SCIS)","20170831","2017","","","1","5","In this paper, we propose a convolutional neural network (CNN) based classification method for nursing-care classification. CNNs have obtained strong performance in computer vision speech recognition areas. Recently, CNNs have been also applied sentence classification. We have studied nursing-care text classification [6]-[18]. In our former works, we proposed several types of feature definitions and examined some classification models. In this paper, each text is represented as a concatenated word vector. Then, every text is classified using CNN-based classification methods. We examined some classification models at the classification layer in CNNs. From our experimental results, the proposed CNN-based method obtained better performance than our former works.","","Electronic:978-1-5090-4917-2; POD:978-1-5090-4918-9","10.1109/IFSA-SCIS.2017.8023240","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8023240","Nursing-care text classification;convolutional neural networks;word vector representation","Computational modeling;Feature extraction;Medical services;Predictive models;Tools;Training","","","","","","","","","","27-30 June 2017","","IEEE","IEEE Conference Publications"
"Deep Learning for Categorization of Lung Cancer CT Images","A. M. Rossetto; W. Zhou","Dept. of Comput. Sci., Univ. of Massachusetts Lowell, Lowell, MA, USA","2017 IEEE/ACM International Conference on Connected Health: Applications, Systems and Engineering Technologies (CHASE)","20170817","2017","","","272","273","Lung cancer is a serious health problem. In the United States alone, approximately 225,000 people each year are diagnosed with lung cancer. Early detection is a crucial part of giving patients the best chance of recovery. Deep learning gives us an opportunity to increase the accuracy of the automated initial diagnosis. Here we present an ensemble of Convolution Neural Networks(CNN) using multiple preprocessing methods to increase the accuracy of the automated labeling of the scans. We have done this by implementing ensembles of CNNs along with a voting system to get the consensus of the two networks. The initial results of our best method show both a consistently high accuracy (97.5%) and a low percentage of false positives (<;10%).","","Electronic:978-1-5090-4722-2; POD:978-1-5090-4723-9; USB:978-1-5090-4721-5","10.1109/CHASE.2017.98","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8010653","","Cancer;Convolution;Lungs;Machine learning;Pipelines;Testing;Training","computerised tomography;learning (artificial intelligence);medical image processing;neural nets","CNN;automated initial diagnosis;automated labeling;categorization;convolution neural networks;deep learning;false positives;health problem;lung cancer CT images;multiple preprocessing methods","","","","","","","","17-19 July 2017","","IEEE","IEEE Conference Publications"
"Learning to Read Chest X-Ray Images from 16000+ Examples Using CNN","Y. Dong; Y. Pan; J. Zhang; W. Xu","Inst. for Interdiscipl. Inf. Sci., Tsinghua Univ., Beijing, China","2017 IEEE/ACM International Conference on Connected Health: Applications, Systems and Engineering Technologies (CHASE)","20170817","2017","","","51","57","Chest radiography (chest X-ray) is a low-cost yet effective and widely used medical imaging procedures. The lacking of qualified radiologist seriously limits the applicability of the technique. We explore the possibility of designing a computer-aided diagnosis for chest X-rays using deep convolutional neural networks. Using a real-world dataset of 16,000 chest X-rays with natural language diagnosis reports, we can train a multi-class classification model from images and preform accurate diagnosis, without any prior domain knowledge.","","Electronic:978-1-5090-4722-2; POD:978-1-5090-4723-9; USB:978-1-5090-4721-5","10.1109/CHASE.2017.59","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8010614","","Biomedical imaging;Convolution;Diseases;Feature extraction;Lungs;Neural networks;X-ray imaging","computerised tomography;diagnostic radiography;image classification;medical image processing;neural nets","CNN;chest X-ray image;chest X-rays;chest radiography;computer-aided diagnosis;deep convolutional neural networks;medical imaging procedures;multiclass image classification;natural language diagnosis reports","","","","","","","","17-19 July 2017","","IEEE","IEEE Conference Publications"
"Deep learning for tumour classification in homogeneous breast tissue in medical microwave imaging","B. Gerazov; R. C. Conceicao","Faculty of Electrical Engineering and Information Technologies, Ss Cyril and Methodius University in Skopje, Skopje, Macedonia","IEEE EUROCON 2017 -17th International Conference on Smart Technologies","20170817","2017","","","564","569","Deep learning has become the state-of-the-art in the area of biomedical imaging, leading to a large boost in performance that approaches human levels. Medical microwave imaging is an emerging technology that has great potential especially in the area of breast cancer diagnosis. Moreover, the obtained backscatter signals have also been shown to be a good basis for differentiating malignant and benign tumour type. We further analyse these results by applying deep learning methods to a dataset of Finite Difference Time Domain (FDTD) numerical simulations of tumour models embedded in homogeneous breast adipose tissue. Specifically we use Deep and Convolutional Neural Networks and obtain an accuracy of 93.44% which outperforms conventional machine learning previously used on the analysed dataset.","","Electronic:978-1-5090-3843-5; POD:978-1-5090-3844-2; USB:978-1-5090-3842-8","10.1109/EUROCON.2017.8011175","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8011175","CNN;DNN;breast tumour classification;deep learning;feature embedding;medical microwave imaging","Biomedical imaging;Finite difference methods;Machine learning;Microwave theory and techniques;Numerical models;Time-domain analysis;Tumors","cancer;convolution;finite difference time-domain analysis;image classification;learning (artificial intelligence);medical image processing;microwave imaging;neural nets;tumours","FDTD numerical simulations;backscatter signals;breast cancer diagnosis;convolutional neural networks;deep learning;deep neural networks;finite difference time domain;homogeneous breast tissue;medical microwave imaging;tumour classification","","","","","","","","6-8 July 2017","","IEEE","IEEE Conference Publications"
"Real-time EEG-based person authentication system using face rapid serial visual presentation","Q. Wu; Y. Zeng; Z. Lin; X. Wang; B. Yan","China National Digital Switching System Engineering and Technological R&D Center, No.7, Jianxue Street, Wenhua Road, Zhengzhou, 450000, China","2017 8th International IEEE/EMBS Conference on Neural Engineering (NER)","20170814","2017","","","564","567","As a new biometric, the Electroencephalogram (EEG) signal has the advantages of invisibility, non-clonability, and non-coercion compare to traditional biometrics. However, the real-time and stability are the difficulties that the current EEG-based person authentication systems face. In this paper, we design a real-time and stable person authentication system using EEG signals, which are elicited by self- and non-self-face rapid serial visual presentation (RSVP). Convolutional neural network (CNN) is applied to dig the specific feature of different individuals. The mean accuracy of 85.03% and 91.27% is achieved with the login time of 3 seconds and 6 seconds respectively, which illustrates the precision and real-time of the system.","","Electronic:978-1-5090-4603-4; POD:978-1-5090-4604-1","10.1109/NER.2017.8008414","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8008414","","Authentication;Convolution;Electroencephalography;Face;Real-time systems;Training;Visualization","biometrics (access control);convolution;electroencephalography;medical signal processing;neural nets","biometric;convolutional neural network;electroencephalogram;face rapid serial visual presentation;invisibility;non-clonability;non-coercion;real-time EEG-based person authentication system;time 3 s;time 6 s","","","","","","","","25-28 May 2017","","IEEE","IEEE Conference Publications"
"A medical image fusion method based on convolutional neural networks","Y. Liu; X. Chen; J. Cheng; H. Peng","Department of Biomedical Engineering, Hefei University of Technology, Hefei 230009, China","2017 20th International Conference on Information Fusion (Fusion)","20170814","2017","","","1","7","Medical image fusion technique plays an an increasingly critical role in many clinical applications by deriving the complementary information from medical images with different modalities. In this paper, a medical image fusion method based on convolutional neural networks (CNNs) is proposed. In our method, a siamese convolutional network is adopted to generate a weight map which integrates the pixel activity information from two source images. The fusion process is conducted in a multi-scale manner via image pyramids to be more consistent with human visual perception. In addition, a local similarity based strategy is applied to adaptively adjust the fusion mode for the decomposed coefficients. Experimental results demonstrate that the proposed method can achieve promising results in terms of both visual quality and objective assessment.","","Electronic:978-0-9964-5270-0; POD:978-1-5090-4582-2","10.23919/ICIF.2017.8009769","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8009769","","Image fusion;Laplace equations;Medical diagnostic imaging;Training;Transforms","image fusion;medical image processing;neural nets;visual perception","CNN;clinical applications;convolutional neural networks;human visual perception;image pyramids;medical image fusion;pixel activity information;siamese convolutional network;visual quality","","","","","","","","10-13 July 2017","","IEEE","IEEE Conference Publications"
"Dynamic stopping in P300 speller with convolutional neural network","Z. Chen; X. Zhang","College of Automation Science and Engineering, South China University of Technology, Guangzhou 510640, China","2017 8th International IEEE/EMBS Conference on Neural Engineering (NER)","20170814","2017","","","383","386","In P300 speller brain-computer interface (BCI), the stimulus sequence is presented to subject for several rounds to achieve reliable P300 detection. Traditionally, the number of rounds is fixed and relatively large (e.g., 15 in the Wadsworth Dataset of BCI Competition 2005), which results in low information transfer rate. In order to improve the speed of character recognition without affecting the spelling accuracy, we propose to use convolutional neural network (CNN) into the dynamic stopping. Compared with the traditional static stopping criterion (SSC), our method can effectively improve the information transfer rate of the system.","","Electronic:978-1-5090-4603-4; POD:978-1-5090-4604-1","10.1109/NER.2017.8008370","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8008370","","Character recognition;Convolution;Electroencephalography;Indexes;Signal to noise ratio;Testing;Training","brain;brain-computer interfaces;medical computing;neural nets","P300 detection;P300 speller brain-computer interface;SSC;convolutional neural network;dynamic stopping;information transfer rate;static stopping criterion;stimulus sequence","","","","","","","","25-28 May 2017","","IEEE","IEEE Conference Publications"
"EEG-based biometric identification with deep learning","Z. Mao; W. X. Yao; Y. Huang","Department of Electrical and Computer Engineering, University of Texas at San Antonio, USA","2017 8th International IEEE/EMBS Conference on Neural Engineering (NER)","20170814","2017","","","609","612","Despite the recent increasing interest in biometric identification using electroencephalogram (EEG) signals, the state of the art still lacks a simple and robust model that is useful in real applications. This work proposes a new approach based on convolutional neural network CNN. The proposed CNN works directly on raw EEG data, thus alleviating the need for engineering features. We investigate the performance of the CNN on datasets of 100 subjects collected from one driving fatigue experiment. Our results show that the CNN model is fast highly efficient in training (<;0.5h on >100K training epochs) and highly robust, achieving 97% accuracy in identifying ~14K testing epochs from 100 subjects with non-time-locked natural driving fatigue data and much higher than from randomly sampled epochs (90%). Overall, this work demonstrates the potential of deep learning solutions for real-life EEG-based biometric identification.","","Electronic:978-1-5090-4603-4; POD:978-1-5090-4604-1","10.1109/NER.2017.8008425","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8008425","biometric identification;brain-computer interface;convolutional neural networks;deconvolutional networks;deep learning","Brain modeling;Convolution;Electroencephalography;Fatigue;Feature extraction;Machine learning;Training","electroencephalography;feature extraction;medical signal processing;neural nets;neurophysiology;signal sampling","CNN;EEG-based biometric identification;convolutional neural network;datasets;deep learning solutions;driving fatigue experiment;electroencephalogram signals;engineering features;non-time-locked natural driving fatigue data;randomly sampled epochs;raw EEG data","","","","","","","","25-28 May 2017","","IEEE","IEEE Conference Publications"
"Smartphone-based food category and nutrition quantity recognition in food image with deep learning algorithm","C. L. Chin; C. C. Huang; B. J. Lin; G. R. Wu; T. C. Weng; H. F. Chen","Department of Medical Informatics, Chung Shan Medical University, Taichung, Taiwan","2016 International Conference on Fuzzy Theory and Its Applications (iFuzzy)","20170810","2016","","","1","1","According to the similar nutritional properties, foods could be classified in six groups (Vegetables, Fruits, Dairy, Oils, Grains and Protein foods) and nourish human body respectively. However, people could not understand the nutrients of foods which they obtained generally. Hence, this paper proposes a system based on deep learning for training. Users take pictures on diets by their smartphones and the system will recognize both what kinds of group and how much of nutrients they will take in. With our system, users could recognize the nutrients in their diet and they can administer their health effectively. During training, we not only confirm the architecture of CNN, but also find out that the color feature of foods in the images has significant effect on the identification result about up to seventy percent of the resolution ratio.","","Electronic:978-1-5090-4111-4; POD:978-1-5090-4112-1; USB:978-1-5090-4110-7","10.1109/iFUZZY.2016.8004962","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8004962","","Biomedical imaging;Image color analysis;Image recognition;Machine learning;Network architecture;Smart phones;Training","food products;image recognition;learning (artificial intelligence);neural nets;smart phones","CNN;deep learning algorithm;food color feature;food image;food image recognition;nutritional properties;smartphone-based food category recognition;smartphone-based nutrition quantity recognition","","","","","","","","9-11 Nov. 2016","","IEEE","IEEE Conference Publications"
"Super-resolution of Magnetic Resonance Images using deep Convolutional Neural Networks","K. Srinivasan; A. Ankur; A. Sharma","Department of Computer Science & Information Engineering, National Ilan University, China","2017 IEEE International Conference on Consumer Electronics - Taiwan (ICCE-TW)","20170727","2017","","","41","42","This research focuses on developing a Super-resolution magnetic resonance (MR) Image restoration method using Convolutional Neural Networks (CNN). The main aim is to train an end to end mapping that takes low-resolution image as input and returns a high-resolution output. Low overhead and a state of the art reconstruction makes the model perform efficiently.","","Electronic:978-1-5090-4017-9; POD:978-1-5090-4018-6","10.1109/ICCE-China.2017.7990985","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7990985","","Conferences;Image reconstruction;Image resolution;Image restoration;Interpolation;Magnetic resonance;Neural networks","biomedical MRI;feedforward neural nets;image resolution;image restoration;medical image processing","CNN;MR;deep convolutional neural networks;end-to-end mapping;high-resolution output;image restoration method;low-resolution image;magnetic resonance images;super-resolution","","","","","","","","12-14 June 2017","","IEEE","IEEE Conference Publications"
"Automatic 1D convolutional neural network-based detection of artifacts in MEG acquired without electrooculography or electrocardiography","P. Garg; E. Davenport; G. Murugesan; B. Wagner; C. Whitlow; J. Maldjian; A. Montillo","UT Southwestern Medical Center, Dallas, Texas, USA","2017 International Workshop on Pattern Recognition in Neuroimaging (PRNI)","20170720","2017","","","1","4","Magnetoencephalography (MEG) is a functional neuroimaging tool that records the magnetic fields induced by electrical neuronal activity; however, signal from non-neuronal sources can corrupt the data. Eye-Blinks (EB) and Cardiac Activity (CA) are two of the most common types of non-neuronal artifacts. They can be measured by affixing eye proximal electrodes, as in electrooculography (EOG) and chest electrodes, as in electrocardiography (EKG), however this complicates imaging setup, decreases patient comfort, and often induces further artifacts from facial twitching and postural muscle movement. We propose an EOG- and EKG-free approach to identify eye-blink, cardiac, or neuronal signals for automated artifact suppression. Our contributions are two-fold. First, we combine a data driven, multivariate decomposition approach based on Independent Component Analysis (ICA) and a highly accurate classifier constructed as a deep 1-D Convolutional Neural Network. Second, we visualize the features learned to reveal what features the model uses and to bolster user confidence in our model's training and potential for generalization. We train and test three variants of our method on resting state MEG data from 49 subjects. Our cardiac model achieves a 96% sensitivity and 99% specificity on the set-aside test-set. Our eye-blink model achieves a sensitivity of 85% and specificity of 97%. This work facilitates automated MEG processing for both, clinical and research use, and can obviate the need for EOG or EKG electrodes.","","Electronic:978-1-5386-3159-1; POD:978-1-5386-3160-7","10.1109/PRNI.2017.7981506","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7981506","CNN;EKG;EOG;MEG;artifact;deep learning","Brain modeling;Convolution;Electrocardiography;Electrodes;Electrooculography;Neuroscience;Sensitivity","cardiology;eye;gait analysis;independent component analysis;magnetoencephalography;medical signal detection;medical signal processing;neural nets","ICA;MEG acquisition;MEG processing;affixing eye proximal electrodes;automatic 1D convolutional neural network-based detection;cardiac activity;cardiac model;chest electrodes;electrical neuronal activity;eye-blink model;eye-blinks activity;facial twitching;feature learning;functional neuroimaging tool;independent component analysis;magnetic fields;magnetoencephalography;multivariate decomposition approach;nonneuronal artifacts;nonneuronal sources;postural muscle movement","","","","","","","","21-23 June 2017","","IEEE","IEEE Conference Publications"
"Tongue shape classification integrating image preprocessing and Convolution Neural Network","C. M. Huo; H. Zheng; H. Y. Su; Z. L. Sun; Y. J. Cai; Y. F. Xu","Key Lab of Intelligent Information Technology, Beijing Institute of Technology, Beijing, China","2017 2nd Asia-Pacific Conference on Intelligent Robot Systems (ACIRS)","20170720","2017","","","42","46","Tongue diagnosis is one of the most important parts in “inspection diagnosis” of Traditional Chinese Medicine (TCM). Observing tongue shape can help to understand the changes in human body and thereby to estimate the illness. This paper presents a method of recognizing tongue shapes based on Convolution Neural Network. The proposed method enhances the features of tongue images with preprocessing to ensure the data suitable for tongue shape binary classification. In view of the special texture and outline of tongue, the whole tongue images of dot-sting tongue and fissured tongue is transformed by Gabor filter, and the tooth-marked are processed by boundary detection approach. CNN is adopted because it has achieved remarkable results in computer vision and pattern recognition, and the model training through neural network coincides with the Chinese medicine dialectics through experience. Based on commonly used Alex-net, network is optimized with batch normalization to improve efficiency. The experimental results indicate that the preprocessing methods increase the accuracy and decreases the time of training process of tongue shape classification, which proves that the method is effective for the recognition of different tongue shapes.","","DVD:978-1-5090-6791-6; Electronic:978-1-5090-6793-0; POD:978-1-5090-6794-7; Paper:978-1-5090-6792-3","10.1109/ACIRS.2017.7986062","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7986062","Gabor filtering;convolution neural network;deep learning;tongue shape classification","Biological neural networks;Convolution;Feature extraction;Gabor filters;Shape;Tongue;Training","Gabor filters;computer vision;image classification;image texture;medical computing;neural nets;patient diagnosis;shape recognition","Alex-net;Chinese medicine dialectics;Gabor filter;TCM;computer vision;convolution neural network;dot-sting tongue;image preprocessing;image texture;inspection diagnosis;pattern recognition;tongue diagnosis;tongue images;tongue shape binary classification;traditional Chinese medicine","","","","","","","","16-18 June 2017","","IEEE","IEEE Conference Publications"
"Segmentation of Fetal Left Ventricle in Echocardiographic Sequences Based on Dynamic Convolutional Neural Networks","L. Yu; Y. Guo; Y. Wang; J. Yu; P. Chen","Department of Electronic EngineeringFudan University","IEEE Transactions on Biomedical Engineering","20170714","2017","64","8","1886","1895","Segmentation of fetal left ventricle (LV) in echocardiographic sequences is important for further quantitative analysis of fetal cardiac function. However, image gross inhomogeneities and fetal random movements make the segmentation a challenging problem. In this paper, a dynamic convolutional neural networks (CNN) based on multiscale information and fine-tuning is proposed for fetal LV segmentation. The CNN is pretrained by amount of labeled training data. In the segmentation, the first frame of each echocardiographic sequence is delineated manually. The dynamic CNN is fine-tuned by deep tuning with the first frame and shallow tuning with the rest of frames, respectively, to adapt to the individual fetus. Additionally, to separate the connection region between LV and left atrium (LA), a matching approach, which consists of block matching and line matching, is used for mitral valve (MV) base points tracking. Advantages of our proposed method are compared with an active contour model (ACM), a dynamical appearance model (DAM), and a fixed multiscale CNN method. Experimental results in 51 echocardiographic sequences show that the segmentation results agree well with the ground truth, especially in the cases with leakage, blurry boundaries, and subject-to-subject variations. The CNN architecture can be simple, and the dynamic fine-tuning is efficient.","0018-9294;00189294","","10.1109/TBME.2016.2628401","Clinical Technology Innovation Project of Hospital Development Center of Shanghai ShenKang; National Basic Research Program of China; 10.13039/501100001809 - National Natural Science Foundation of China; ","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7744576","Dynamic convolutional neural networks (CNN);echocardiographic sequences;fine-tuning;mitral valve (MV) base points","Biomedical imaging;Convolution;Image segmentation;Kernel;Training data;Tuning;Valves","blood vessels;echocardiography;image matching;image segmentation;image sequences;medical image processing;neural nets;obstetrics","ACM;CNN architecture;DAM;active contour model;block matching;blurry boundaries;connection region;deep tuning;dynamic CNN;dynamic convolutional neural networks;dynamic fine-tuning;dynamical appearance model;echocardiographic sequence;fetal LV segmentation;fetal cardiac function;fetal random movements;fixed multiscale CNN method;ground truth;image gross inhomogeneities;individual fetus;labeled training data;left atrium;line matching;matching approach;mitral valve base points;multiscale information;shallow tuning;subject-to-subject variations","","","","","","","20161115","Aug. 2017","","IEEE","IEEE Journals & Magazines"
"Computer aided diagnosis in digital pathology application: Review and perspective approach in lung cancer classification","A. K. AlZubaidi; F. B. Sideseq; A. Faeq; M. Basil","Biomedical Engineering Department, AlMustaqbal University College, Babil, Iraq","2017 Annual Conference on New Trends in Information & Communications Technology Applications (NTICT)","20170713","2017","","","219","224","This electronic document is a “live” template and already defines the components of your paper [title, text, heads, etc.] in its style sheet This paper provide a broad review for most important algorithms used in the CAD application for lung tissue diagnostics and highlighted the performance of each distinctive algorithm. Moreover, ROC characteristics have been made for each selected algorithms (support vector machine (SVM), Fuzzy C-mean (FCM), Conventional Neural network (CNN) and CAD-FCM). The features for each algorithm discussed and related performance in clinical aided diagnosis (CAD) discussed and explained. Moreover, comparison of different research groups has been made to spotlight each criterion for different algorithms and approach used in CAD platforms in lung cancer. Finally, limitation and constrains for these algorithms has been discussed in order to optimize performance for each of these algorithms.","","Electronic:978-1-5386-2962-8; POD:978-1-5386-2963-5","10.1109/NTICT.2017.7976109","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7976109","Digital pathology;artificial intelligence (AI);classification algorithms;computer aided diagnosis;histopathology;machine learning (ML);tumor staging and grading","Cancer;Classification algorithms;Feature extraction;Imaging;Lungs;Pathology;Support vector machines","CAD;biological tissues;cancer;fuzzy set theory;image classification;lung;medical image processing;neural nets;optimisation;support vector machines","CAD application;CAD-FCM;CNN;FCM algorithms;ROC characteristics;SVM;clinical aided diagnosis;computer aided diagnosis;conventional neural network;digital pathology application;electronic document;fuzzy C-mean algorithms;lung cancer classification;lung tissue diagnostics;performance optimization;support vector machine","","","","","","","","7-9 March 2017","","IEEE","IEEE Conference Publications"
"Deep Convolutional Neural Network for Inverse Problems in Imaging","K. H. Jin; M. T. McCann; E. Froustey; M. Unser","Biomedical Imaging Group, &#x00C9;cole Polytechnique F&#x00E9;d&#x00E9;rale de Lausanne, Lausanne, Switzerland","IEEE Transactions on Image Processing","20170711","2017","26","9","4509","4522","In this paper, we propose a novel deep convolutional neural network (CNN)-based algorithm for solving ill-posed inverse problems. Regularized iterative algorithms have emerged as the standard approach to ill-posed inverse problems in the past few decades. These methods produce excellent results, but can be challenging to deploy in practice due to factors including the high computational cost of the forward and adjoint operators and the difficulty of hyperparameter selection. The starting point of this paper is the observation that unrolled iterative methods have the form of a CNN (filtering followed by pointwise nonlinearity) when the normal operator (H*H, where H* is the adjoint of the forward imaging operator, H) of the forward model is a convolution. Based on this observation, we propose using direct inversion followed by a CNN to solve normal-convolutional inverse problems. The direct inversion encapsulates the physical model of the system, but leads to artifacts when the problem is ill posed; the CNN combines multiresolution decomposition and residual learning in order to learn to remove these artifacts while preserving image structure. We demonstrate the performance of the proposed network in sparse-view reconstruction (down to 50 views) on parallel beam X-ray computed tomography in synthetic phantoms as well as in real experimental sinograms. The proposed network outperforms total variation-regularized iterative reconstruction for the more realistic phantoms and requires less than a second to reconstruct a 512 × 512 image on the GPU.","1057-7149;10577149","","10.1109/TIP.2017.2713099","10.13039/100000070 - National Institute of Biomedical Imaging and Bioengineering; 10.13039/100010661 - European Union¿¿¿s Horizon 2020 Framework Programme for Research and Innovation (call 2015); 10.13039/501100000781 - European Research Council (H2020-ERC Project GlobalBioIm); 10.13039/501100006391 - Center for Biomedical Imaging of the Geneva-Lausanne Universities and EPFL; ","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7949028","Image restoration;biomedical imaging;biomedical signal processing;computed tomography;image reconstruction;magnetic resonance imaging;reconstruction algorithms;tomography","Computed tomography;Convolution;Image reconstruction;Inverse problems;Iterative methods;Neural networks","computerised tomography;feedforward neural nets;image resolution;iterative methods;learning (artificial intelligence);medical image processing","CNN;GPU;adjoint operators;deep convolutional neural network;direct inversion;forward model;forward operators;hyperparameter selection;ill-posed inverse problems;image structure;multiresolution decomposition;normal-convolutional inverse problems;parallel beam X-ray computed tomography;regularized iterative algorithms;residual learning;synthetic phantoms;total variation-regularized iterative reconstruction","","","","","","","20170615","Sept. 2017","","IEEE","IEEE Journals & Magazines"
"Semantic segmentation of microscopic images of H&E stained prostatic tissue using CNN","J. Isaksson; I. Arvidsson; K. Åaström; A. Heyden","Lund University, Centre for Mathematical Sciences, Lund, Sweden","2017 International Joint Conference on Neural Networks (IJCNN)","20170703","2017","","","1252","1256","There is a need for an automatic Gleason scoring system that can be used for prostate cancer diagnosis. Today the diagnoses are determined by pathologists manually, which is both a complex and a time-consuming task. To reduce the pathologists' workload, but also to reduce variations between different pathologists, an automatic classification system would be of great use. Some previous works have aimed for this, but still more work needs to be done. It is probable that such a tool would benefit from having access to individually segmented, pathologically relevant objects from the images. Therefore, we have developed an algorithm for semantic segmentation of the microscopic images of H&E stained prostate tissue into Background, Stroma, Epithelial Cytoplasm and Nuclei. This algorithm is based on deep learning, or more specifically a convolutional neural network. The network design is inspired by architectures that previously have been proved successful in different applications. It consists of a contracting and an expanding part, which are symmetrical. We have reached an accuracy of 80 %, as measured by the mean of the intersection over union, for segmentation into four classes. Previous works have only investigated nuclei segmentation, and our network performed similar but for the more challenging task of four class segmentation.","","Electronic:978-1-5090-6182-2; POD:978-1-5090-6183-9","10.1109/IJCNN.2017.7965996","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7965996","","Cancer;Gold;Image segmentation;Microscopy;Neural networks;Semantics;Standards","biological tissues;cancer;image classification;image segmentation;medical image processing;neural nets;patient diagnosis","CNN;H&E stained prostatic tissue;automatic Gleason scoring system;automatic classification system;epithelial cytoplasm;microscopic image semantic segmentation;prostate cancer diagnosis","","","","","","","","14-19 May 2017","","IEEE","IEEE Conference Publications"
"Deeply-supervised CNN for prostate segmentation","Q. Zhu; B. Du; B. Turkbey; P. L. Choyke; P. Yan","School of Computer, Wuhan University, WuHan, China, 430079","2017 International Joint Conference on Neural Networks (IJCNN)","20170703","2017","","","178","184","Prostate segmentation from Magnetic Resonance (MR) images plays an important role in image guided intervention. However, the lack of clear boundary specifically at the apex and base, and huge variation of shape and texture between the images from different patients make the task very challenging. To overcome these problems, in this paper, we propose a deeply supervised convolutional neural network (CNN) utilizing the convolutional information to accurately segment the prostate from MR images. The proposed model can effectively detect the prostate region with additional deeply supervised layers compared with other approaches. Since some information will be abandoned after convolution, it is necessary to pass the features extracted from early stages to later stages. The experimental results show that significant segmentation accuracy improvement has been achieved by our proposed method compared to other reported approaches.","","Electronic:978-1-5090-6182-2; POD:978-1-5090-6183-9","10.1109/IJCNN.2017.7965852","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7965852","","Convolution;Feature extraction;Image segmentation;Machine learning;Medical diagnostic imaging;Training","biomedical MRI;feature extraction;feedforward neural nets;image segmentation;medical image processing","MR images;convolutional information;deeply supervised convolutional neural network;deeply supervised layers;deeply-supervised CNN;feature extraction;image guided intervention;magnetic resonance images;prostate region detection;prostate segmentation","","","","","","","","14-19 May 2017","","IEEE","IEEE Conference Publications"
"Similarities and differences between stimulus tuning in the inferotemporal visual cortex and convolutional networks","B. P. Tripp","Department of Systems Design Engineering & Centre for Theoretical Neuroscience, Waterloo, Ontario, Canada","2017 International Joint Conference on Neural Networks (IJCNN)","20170703","2017","","","3551","3560","Deep convolutional neural networks (CNNs) trained for object classification have a number of striking similarities with the primate ventral visual stream. In particular, activity in early, intermediate, and late layers is closely related to activity in V1, V4, and the inferotemporal cortex (IT). This study further compares activity in late layers of object-classification CNNs to activity patterns reported in the IT electrophysiology literature. There are a number of close similarities, including the distributions of population response sparseness across stimuli, and the distribution of size tuning bandwidth. Statisics of scale invariance, responses to clutter and occlusion, and orientation tuning are less similar. Statistics of object selectivity are quite different. These results agree with recent studies that highlight strong parallels between object-categorization CNNs and the ventral stream, and also highlight differences that could perhaps be reduced in future CNNs.","","Electronic:978-1-5090-6182-2; POD:978-1-5090-6183-9","10.1109/IJCNN.2017.7966303","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7966303","","Bandwidth;Correlation;Neurons;Sociology;Tuning;Visualization","bioelectric phenomena;image classification;learning (artificial intelligence);medical image processing;object detection;scaling phenomena;statistics","CNN training;IT electrophysiology literature;activity patterns;clutter responses;deep convolutional neural networks;inferotemporal visual cortex;object classification;object selectivity statistics;object-categorization CNNs;object-classification CNNs;occlusion responses;orientation tuning;primate ventral visual stream;scale invariance statistics;size tuning bandwidth;stimulus tuning;ventral stream","","","","","","","","14-19 May 2017","","IEEE","IEEE Conference Publications"
"Pill Recognition Using Minimal Labeled Data","Y. Wang; J. Ribera; C. Liu; S. Yarlagadda; F. Zhu","","2017 IEEE Third International Conference on Multimedia Big Data (BigMM)","20170703","2017","","","346","353","Inappropriate medication use such as wrong drug or wrong dose intake can be harmful to patients. In this work we present a method to automatically identify a pill from a single image using Convolutional Neural Network (CNN). We first localize the pill in the image by detecting the region with the highest concentration of edges. To overcome the challenge of minimal labeled training data and domain shift from the training images taken under the controlled lab environment to the consumer images taken under natural living conditions, several data augmentation techniques are applied on the Region of Interest to generate synthetic pill images for training the CNN. We adopted GoogLeNet Inception Network as our main classifier. Three GoogLeNet models with different specialties on color, shape and feature are trained on the augmented dataset. We evaluate our proposed method with a publicly available dataset provided by National Institute of Health that contains 1000 different pill classes.","","Electronic:978-1-5090-6549-3; POD:978-1-5090-6550-9","10.1109/BigMM.2017.61","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7966771","convolutional neural network;image analysis;pill recognition","Drugs;Image color analysis;Image edge detection;Shape;Training;Visualization","drugs;edge detection;feedforward neural nets;image classification;image colour analysis;learning (artificial intelligence);medical computing","CNN;GoogLeNet Inception Network;GoogLeNet models;National Institute of Health;augmented dataset;classifier;consumer images;controlled lab environment;convolutional neural network;data augmentation;domain shift;drug dose;edge concentration;medication;minimal labeled training data;natural living conditions;pill recognition;region detection;region of interest;synthetic pill images;training images","","","","","","","","19-21 April 2017","","IEEE","IEEE Conference Publications"
"Multi-Task Convolutional Neural Network for Patient Detection and Skin Segmentation in Continuous Non-Contact Vital Sign Monitoring","S. Chaichulee; M. Villarroel; J. Jorge; C. Arteta; G. Green; K. McCormick; A. Zisserman; L. Tarassenko","Dept. of Eng. Sci., Univ. of Oxford, Oxford, UK","2017 12th IEEE International Conference on Automatic Face & Gesture Recognition (FG 2017)","20170629","2017","","","266","272","Patient detection and skin segmentation are important steps in non-contact vital sign monitoring as skin regions contain pulsatile information required for the estimation of vital signs such as heart rate, respiratory rate and peripheral oxygen saturation (SpO2). Previous methods based on face detection or colour-based image segmentation are less reliable in a hospital setting. In this paper, we develop a multi-task convolutional neural network (CNN) for detecting the presence of a patient and segmenting the patient's skin regions. The multi-task model has a shared core network with two branches: a segmentation branch which was implemented using a fully convolutional network, and a classification branch which was implemented using global average pooling. The whole network was trained using images from a clinical study conducted in the neonatal intensive care unit (NICU) of the John Radcliffe hospital, Oxford, UK. Our model can produce accurate results and is robust to changes in different skin tones, pose variations, lighting variations, and routine interaction of clinical staff.","","Electronic:978-1-5090-4023-0; POD:978-1-5090-4024-7","10.1109/FG.2017.41","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7961751","","Cameras;Hospitals;Image color analysis;Image segmentation;Monitoring;Pediatrics;Skin","face recognition;hospitals;image classification;image colour analysis;image segmentation;medical image processing;neural nets;patient monitoring;skin","CNN;John Radcliffe hospital;NICU;Oxford;UK;colour-based image segmentation;continuous noncontact vital sign monitoring;face detection;multitask convolutional neural network;neonatal intensive care unit;patient detection;patient skin region segmentation;pulsatile information","","","","","","","","May 30 2017-June 3 2017","","IEEE","IEEE Conference Publications"
"A deep learning based approach for classification of CerbB2 tumor cells in breast cancer","G. A. Tataroğlu; A. Genç; K. A. Kabakçı; A. Çapar; B. U. Töreyin; H. K. Ekenel; İ. Türkmen; A. Çakır","Bili&#x015F;im Enstit&#x00FC;s&#x00FC;, &#x0130;stanbul Teknik &#x00DC;niversitesi","2017 25th Signal Processing and Communications Applications Conference (SIU)","20170629","2017","","","1","4","This study proposes a unique approach to classify CerbB2 tumor cell scores in breast cancer based on deep learning models. Another contribution of the study is the creation of a dataset from original breast cancer tissues. On the purpose of training, validating and testing with deep learning models cell fragments were generated from sample tissue images. CerbB2 tumor scores were generated for the cell fragments were classified with high performance by the aid of convolutional neural networks (CNN).","","Electronic:978-1-5090-6494-6; POD:978-1-5090-6495-3","10.1109/SIU.2017.7960587","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7960587","CerbB2 marker;Convolutional Neural Networks (CNN);classification;score;tumor","Breast cancer;Fasteners;Fish;Machine learning;Neural networks;Proteins;Tumors","cancer;learning (artificial intelligence);medical image processing;neural nets;tumours","CNN;CerbB2 tumor cells;breast cancer;breast cancer tissues;cell fragments;convolutional neural networks;deep learning;deep learning models;sample tissue images","","","","","","","","15-18 May 2017","","IEEE","IEEE Conference Publications"
"Segmentation of precursor lesions in cervical cancer using convolutional neural networks","A. Albayrak; A. Ünlü; N. Çalık; G. Bilgin; İ. Türkmen; A. Çakır; A. Çapar; B. U. Töreyin; L. D. Ata","Bilgisayar M&#x00FC;hendisli&#x011F;i B&#x00F6;l&#x00FC;m&#x00FC;, Y&#x0131;ld&#x0131;z Teknik &#x00DC;niversitesi","2017 25th Signal Processing and Communications Applications Conference (SIU)","20170629","2017","","","1","4","Cervical carcinoma is one of the frequently seen cancers in the world and in our country, develops from precursor lesions. These precursor lesions are analyzed by pathologists so that the diagnosis of the disease can be made. In this study, a system that performs automatic detection of pre-cancerous lesions was performed using the convolutional neural networks (CNNs). In the training phase, lesion recognition performance of the proposed system has reached 92%. Thereafter, whole image was segmented by using 60 × 60 pixel tiles during the training phase. After all, the precursor lesions were segmented with 81.71% Dice coefficient.","","Electronic:978-1-5090-6494-6; POD:978-1-5090-6495-3","10.1109/SIU.2017.7960459","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7960459","Cervical cancer;convolutional neural networks;histopathological images;precursor lesions;segmentation","Biomedical imaging;Cancer;Dogs;Image segmentation;Lesions;Neural networks;Training","cancer;feedforward neural nets;gynaecology;image recognition;image segmentation;medical image processing","CNN;Dice coefficient;cervical cancer;cervical carcinoma;convolutional neural networks;disease diagnosis;lesion recognition performance;precancerous lesions;precursor lesions segmentation","","","","","","","","15-18 May 2017","","IEEE","IEEE Conference Publications"
"Cerebral vessel classification with convolutional neural networks","Y. H. Şahin; G. Ünal","Bilgisayar M&#x00FC;hendisli&#x011F;i B&#x00F6;l&#x00FC;m&#x00FC;, &#x0130;stanbul Teknik &#x00DC;niversitesi, &#x0130;stanbul, T&#x00FC;rkiye","2017 25th Signal Processing and Communications Applications Conference (SIU)","20170629","2017","","","1","4","Analysing brain magnetic resonance angiography (MRA) images is important for detecting arteriovenous malformations and aneurysms. To detect these diseases, extracting the vessel structure in the image can be seen as a first step. In this paper, it was aimed to classify the cubic image parts obtained from brain MRA images according to whether they belong to vein structure or not. For this purpose, a 9 layers deep convolutional neural network (CNN) architecture is designed. With the model trained using this architecture, 85% accuracy was obtained in the classification performed on the test data.","","Electronic:978-1-5090-6494-6; POD:978-1-5090-6495-3","10.1109/SIU.2017.7960697","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7960697","cerebral vessel classification;convolutional neural networks;deep learning;magnetic resonance angiography (MRA)","Biological neural networks;Biomedical imaging;Brain modeling;Dogs;Image segmentation;Magnetic resonance;Nanoelectromechanical systems","biomedical MRI;diseases;feature extraction;feedforward neural nets;image classification;medical image processing;object detection","CNN architecture;aneurysm detection;arteriovenous malformation detection;brain MRA images;brain magnetic resonance angiography image analysis;cerebral vessel classification;cubic image part classification;deep convolutional neural network architecture;disease detection;vein structure;vessel structure extraction","","","","","","","","15-18 May 2017","","IEEE","IEEE Conference Publications"
"Auto-context Convolutional Neural Network (Auto-Net) for Brain Extraction in Magnetic Resonance Imaging","S. S. M. Salehi; D. Erdogmus; A. Gholipour","Electrical and Computer Engineering Department, Northeastern University, Boston, MA, 02115 and Radiology Department, Boston Children&#x2019;s Hospital and Harvard Medical School, Boston MA 02115.","IEEE Transactions on Medical Imaging","","2017","PP","99","1","1","Brain extraction or whole brain segmentation is an important first step in many of the neuroimage analysis pipelines. The accuracy and robustness of brain extraction, therefore, is crucial for the accuracy of the entire brain analysis process. State-of-the-art brain extraction techniques rely heavily on the accuracy of alignment or registration between brain atlases and query brain anatomy, and/or make assumptions about the image geometry; therefore have limited success when these assumptions do not hold or image registration fails. With the aim of designing an accurate, learning-based, geometry-independent and registration-free brain extraction tool in this study, we present a technique based on an auto-context convolutional neural network (CNN), in which intrinsic local and global image features are learned through 2D patches of different window sizes. We consider two different architectures: 1) a voxelwise approach based on three parallel 2D convolutional pathways for three different directions (axial, coronal, and sagittal) that implicitly learn 3D image information without the need for computationally expensive 3D convolutions, and 2) a fully convolutional network based on the U-net architecture. Posterior probability maps generated by the networks are used iteratively as context information along with the original image patches to learn the local shape and connectedness of the brain to extract it from non-brain tissue. The brain extraction results we have obtained from our CNNs are superior to the recently reported results in the literature on two publicly available benchmark datasets, namely LPBA40 and OASIS, in which we obtained Dice overlap coefficients of 97.73% and 97.62%, respectively. Significant improvement was achieved via our auto-context algorithm. Furthermore, we evaluated the performance of our algorithm in the challenging problem of extracting arbitrarily-oriented fetal brains in reconstructed fe- al brain magnetic resonance imaging (MRI) datasets. In this application our voxelwise auto-context CNN performed much better than the other methods (Dice coefficient: 95.97%), where the other methods performed poorly due to the non-standard orientation and geometry of the fetal brain in MRI. Through training, our method can provide accurate brain extraction in challenging applications. This in-turn may reduce the problems associated with image registration in segmentation tasks.","0278-0062;02780062","","10.1109/TMI.2017.2721362","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7961201","Auto-Context;Brain extraction;CNN;Convolutional neural network;MRI;U-net;Whole brain segmentation","Computer architecture;Context;Feature extraction;Image segmentation;Magnetic resonance imaging;Three-dimensional displays;Two dimensional displays","","","","","","","","","20170628","","","IEEE","IEEE Early Access Articles"
"Deep Learning Segmentation of Optical Microscopy Images Improves 3-D Neuron Reconstruction","R. Li; T. Zeng; H. Peng; S. Ji","School of Electrical Engineering and Computer Science, Washington State University, Pullman, WA, USA","IEEE Transactions on Medical Imaging","20170628","2017","36","7","1533","1541","Digital reconstruction, or tracing, of 3-D neuron structure from microscopy images is a critical step toward reversing engineering the wiring and anatomy of a brain. Despite a number of prior attempts, this task remains very challenging, especially when images are contaminated by noises or have discontinued segments of neurite patterns. An approach for addressing such problems is to identify the locations of neuronal voxels using image segmentation methods, prior to applying tracing or reconstruction techniques. This preprocessing step is expected to remove noises in the data, thereby leading to improved reconstruction results. In this paper, we proposed to use 3-D convolutional neural networks (CNNs) for segmenting the neuronal microscopy images. Specifically, we designed a novel CNN architecture, that takes volumetric images as the inputs and their voxel-wise segmentation maps as the outputs. The developed architecture allows us to train and predict using large microscopy images in an end-to-end manner. We evaluated the performance of our model on a variety of challenging 3-D microscopy images from different organisms. Results showed that the proposed methods improved the tracing performance significantly when combined with different reconstruction algorithms.","0278-0062;02780062","","10.1109/TMI.2017.2679713","10.13039/100000001 - National Science Foundation; 10.13039/100007588 - Washington State University; 10.13039/100009980 - Old Dominion University; ","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7874113","BigNeuron;Deep learning;image denoising;image segmentation;neuron reconstruction","Convolution;Image reconstruction;Image segmentation;Microscopy;Morphology;Neurons;Three-dimensional displays","biomedical optical imaging;brain;image denoising;image reconstruction;image segmentation;learning (artificial intelligence);medical image processing;neural nets;neurophysiology;optical microscopy","3-D convolutional neural networks;3-D microscopy images;3-D neuron reconstruction;3-D neuron structure;CNN architecture;brain anatomy;brain wiring;deep learning segmentation;digital reconstruction;digital tracing;discontinued segments;image segmentation methods;neurite patterns;neuronal microscopy images;neuronal voxels;noise removal;optical microscopy images;organisms;preprocessing step;reconstruction algorithms;reversing engineering;tracing performance;volumetric images;voxel-wise segmentation maps","","","","","","","20170308","July 2017","","IEEE","IEEE Journals & Magazines"
"Classification of thyroid nodules in ultrasound images using deep model based transfer learning and hybrid features","T. Liu; S. Xie; J. Yu; L. Niu; W. Sun","Dept. of Electronic Engineering, Tsinghua University, Beijing 100084, China","2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","20170619","2017","","","919","923","Ultrasonography is a valuable diagnosis method for thyroid nodules. Automatically discriminating benign and malignant nodules in the ultrasound images can provide aided diagnosis suggestions, or increase the diagnosis accuracy when lack of experts. The core problem in this issue is how to capture appropriate features for this specific task. Here, we propose a feature extraction method for ultrasound images based on the convolution neural networks (CNNs), try to introduce more meaningful semantic features to the classification. Firstly, a CNN model trained with a massive natural dataset is transferred to the ultrasound image domain, to generate semantic deep features and handle the small sample problem. Then, we combine those deep features with conventional features such as Histogram of Oriented Gradient (HOG) and Local Binary Patterns (LBP) together, to form a hybrid feature space. Finally, a positive-sample-first majority voting and a feature-selected based strategy are employed for the hybrid classification. Experimental results on 1037 images show that the accuracy of our proposed method is 0.931, which outperformed other relative methods by over 10%.","","Electronic:978-1-5090-4117-6; POD:978-1-5090-4118-3; USB:978-1-5090-4116-9","10.1109/ICASSP.2017.7952290","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7952290","classification;deep learning;feature fusion;transfer learning;ultrasound image","Biomedical imaging;Cancer;Feature extraction;Indexes;Machine learning;Semantics;Ultrasonic imaging","biomedical ultrasonics;feature extraction;feedforward neural nets;image classification;learning (artificial intelligence);medical image processing;ultrasonic imaging","CNN model trained;HOG;LBP;benign nodules;convolution neural networks;deep model based transfer learning;feature extraction method;feature-selected based strategy;histogram of oriented gradient;hybrid feature space;local binary patterns;malignant nodules;positive-sample-first majority voting;semantic deep features;thyroid nodule classification;thyroid nodules;ultrasonography;ultrasound images","","","","","","","","5-9 March 2017","","IEEE","IEEE Conference Publications"
"Automatic 3D ultrasound segmentation of the first trimester placenta using deep learning","P. Looney; G. N. Stevenson; K. H. Nicolaides; W. Plasencia; M. Molloholli; S. Natsis; S. L. Collins","Nuffield Department of Obstetrics and Gynaecology, University of Oxford, UK","2017 IEEE 14th International Symposium on Biomedical Imaging (ISBI 2017)","20170619","2017","","","279","282","Placental volume measured with 3D ultrasound in the first trimester has been shown to be correlated to adverse pregnancy outcomes. This could potentially be used as a screening test to predict the “at risk” pregnancy. However, manual segmentation whilst previously shown to be accurate and repeatable is very time consuming and semi-automated methods still require operator input. To generate a screening tool, fully automated placental segmentation is required. In this work, a deep convolutional neural network (cNN), DeepMedic, was trained using the output of the semi-automated Random Walker method as ground truth. 300 3D ultrasound scans of first trimester placentas were used to train, validate and test the cNN. Compared against the semi-automated segmentation, resultant median (1<sup>st</sup> Quartile, 3<sup>rd</sup> Quartile) Dice Similarity Coefficient was 0.73 (0.66, 0.76). The median (1<sup>st</sup> Quartile, 3<sup>rd</sup> Quartile) Hausdorff distance was 27 mm (18 mm, 36 mm). We present the first attempt at using a deep cNN for segmentation of 3D ultrasound of the placenta. This work shows that feasible results compared to ground truth were obtained that could form the basis of a fully automatic segmentation method.","","Electronic:978-1-5090-1172-8; POD:978-1-5090-1173-5","10.1109/ISBI.2017.7950519","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7950519","3D;automatic segmentation;deep learning;neural network;placenta;random walker;ultrasound","Biological neural networks;Image segmentation;Magnetic resonance imaging;Pregnancy;Three-dimensional displays;Ultrasonic imaging","biomedical ultrasonics;image segmentation;learning (artificial intelligence);medical image processing;neural nets;obstetrics","DeepMedic;automatic 3D ultrasound segmentation;deep convolutional neural network;deep learning;first trimester placenta","","","","","","","","18-21 April 2017","","IEEE","IEEE Conference Publications"
"Classifying histopathology whole-slides using fusion of decisions from deep convolutional network on a collection of random multi-views at multi-magnification","K. Das; S. P. K. Karri; A. Guha Roy; J. Chatterjee; D. Sheet","Department of Electrical Engineering, IIT Kharagpur, India","2017 IEEE 14th International Symposium on Biomedical Imaging (ISBI 2017)","20170619","2017","","","1024","1027","Histopathology forms the gold standard for confirmed diagnosis of a suspicious hyperplasia being benign or malignant and for its sub-typing. While techniques like whole-slide imaging have enabled computer assisted analysis for exhaustive reporting of the tissue section, it has also given rise to the big-data deluge and the time complexity associated with processing GBs of image data acquired over multiple magnifications. Since preliminary screening of a slide into benign or malignant carried out on the fly during the digitization process can reduce a Pathologist's work load, to devote more time for detailed analysis, slide screening has to be performed on the fly with high sensitivity. We propose a deep convolutional neural network (CNN) based solution, where we analyse images from random number of regions of the tissue section at multiple magnifications without any necessity of view correspondence across magnifications. Further a majority voting based approach is used for slide level diagnosis, i.e., the class posteriori estimate of each views at a particular magnification is obtained from the magnification specific CNN, and subsequently posteriori estimate across random multi-views at multi-magnification are voting filtered to provide a slide level diagnosis. We have experimentally evaluated performance using a patient level 5-folded cross-validation with 58 malignant and 24 benign cases of breast tumors to obtain average accuracy of 94.67 ± 14.60%, sensitivity of 96.00 ± 8.94%, specificity of 92.00 ± 17.85% and F-score of 96.24 ± 5.29% while processing each view in ≈ 10 ms.","","Electronic:978-1-5090-1172-8; POD:978-1-5090-1173-5","10.1109/ISBI.2017.7950690","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7950690","Convolutional neural network;histopathology image analysis;multi-scale analysis;multi-view analysis;whole slide imaging","Breast;Cancer;Image analysis;Neural networks;Sensitivity;Standards;Support vector machines","cancer;convolution;image classification;medical image processing;neural nets;tumours","big-data deluge;breast tumors;computer assisted analysis;deep convolutional neural network based solution;histopathology whole-slide classification;suspicious hyperplasia diagnosis;tissue section","","","","","","","","18-21 April 2017","","IEEE","IEEE Conference Publications"
"Deep residual learning for compressed sensing MRI","D. Lee; J. Yoo; J. C. Ye","Bio Imaging and Signal Processing Lab., Dep. of Bio and Brain Engineering, KAIST, South Korea","2017 IEEE 14th International Symposium on Biomedical Imaging (ISBI 2017)","20170619","2017","","","15","18","Compressed sensing (CS) enables significant reduction of MR acquisition time with performance guarantee. However, computational complexity of CS is usually expensive. To address this, here we propose a novel deep residual learning algorithm to reconstruct MR images from sparsely sampled k-space data. In particular, based on the observation that coherent aliasing artifacts from downsampled data has topologically simpler structure than the original image data, we formulate a CS problem as a residual regression problem and propose a deep convolutional neural network (CNN) to learn the aliasing artifacts. Experimental results using single channel and multi channel MR data demonstrate that the proposed deep residual learning outperforms the existing CS and parallel imaging algorithms. Moreover, the computational time is faster in several orders of magnitude.","","Electronic:978-1-5090-1172-8; POD:978-1-5090-1173-5","10.1109/ISBI.2017.7950457","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7950457","CNN;Compressed sensing MRI;deep learning;residual learning","Complexity theory;Image reconstruction;Machine learning;Magnetic resonance imaging;Manifolds;Topology","biomedical MRI;compressed sensing;data acquisition;image reconstruction;learning (artificial intelligence);medical image processing;neural nets;regression analysis","MR acquisition time;MR image reconstruction;compressed sensing MRI;deep convolutional neural network;deep residual learning algorithm;residual regression problem;sparsely sampled k-space data","","","","","","","","18-21 April 2017","","IEEE","IEEE Conference Publications"
"Feature selection and thyroid nodule classification using transfer learning","T. Liu; S. Xie; Y. Zhang; J. Yu; L. Niu; W. Sun","Dept. of Electronic Engineering, Tsinghua University, Beijing 100084, China","2017 IEEE 14th International Symposium on Biomedical Imaging (ISBI 2017)","20170619","2017","","","1096","1099","Ultrasonography is a valuable diagnosis method for thyroid nodules. Automatically discriminating benign and malignant nodules in the ultrasound images can provide aided diagnosis suggestions, or increase the diagnosis accuracy when lack of experts. The core problem in this issue is how to capture appropriate features for this specific task. Here, we propose a feature extraction method for ultrasound images based on the convolution neural networks (CNNs), try to introduce more meaningful and specific features to the classification. A CNN model trained with ImageNet data is transferred to the ultrasound image domain, to generate semantic deep features under small sample condition. Then, we combine those deep features with conventional features such as Histogram of Oriented Gradient (HOG) and Scale Invariant Feature Transform (SIFT) together to form a hybrid feature space. Furthermore, to make the general deep features more pertinent to our problem, a feature subset selection process is employed for the hybrid nodule classification, followed by a detailed discussion on the influence of feature number and feature composition method. Experimental results on 1037 images show that the accuracy of our proposed method is 0.929, which outperforms other relative methods by over 10%.","","Electronic:978-1-5090-1172-8; POD:978-1-5090-1173-5","10.1109/ISBI.2017.7950707","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7950707","feature subset selection;thyroid nodules classification;transfer learning;ultrasound image","Biomedical imaging;Cancer;Convolution;Feature extraction;Indexes;Training;Ultrasonic imaging","biomedical ultrasonics;feature extraction;feature selection;image classification;learning (artificial intelligence);medical image processing;neural nets;programming language semantics","ImageNet data;benign nodules;convolution neural networks;diagnosis accuracy;feature extraction method;feature selection;histogram-of-oriented-gradient;malignant nodules;scale-invariant-feature-transform;semantic deep features;thyroid nodule classification;transfer learning;ultrasonography;ultrasound images","","","","","","","","18-21 April 2017","","IEEE","IEEE Conference Publications"
"Hybrid dermoscopy image classification framework based on deep convolutional neural network and Fisher vector","Z. Yu; D. Ni; S. Chen; J. Qin; S. Li; T. Wang; B. Lei","School of Biomedical Engineering, Shenzhen University, National-Regional Key Technology Engineering Laboratory for Medical Ultrasound, Guangdong Key Laboratory for Biomedical Measurements and Ultrasound Imaging, China","2017 IEEE 14th International Symposium on Biomedical Imaging (ISBI 2017)","20170619","2017","","","301","304","Dermoscopy image is usually used in early diagnosis of malignant melanoma. The diagnosis accuracy by visual inspection is highly relied on the dermatologist's clinical experience. Due to the inaccuracy, subjectivity, and poor reproducibility of human judgement, an automatic recognition algorithm of dermoscopy image is highly desired. In this work, we present a hybrid classification framework for dermoscopy image assessment by combining deep convolutional neural network (CNN), Fisher vector (FV) and support vector machine (SVM). Specifically, the deep representations of subimages at various locations of a rescaled dermoscopy image are first extracted via a natural image dataset pre-trained on CNN. Then we adopt an orderless visual statistics based FV encoding methods to aggregate these features to build more invariant representations. Finally, the FV encoded representations are classified for diagnosis using a linear SVM. Compared with traditional low-level visual features based recognition approaches, our scheme is simpler and requires no complex preprocessing. Furthermore, the orderless representations are less sensitive to geometric deformation. We evaluate our proposed method on the ISBI 2016 Skin lesion challenge dataset and promising results are obtained. Also, we achieve consistent improvement in accuracy even without fine-tuning the CNN.","","Electronic:978-1-5090-1172-8; POD:978-1-5090-1173-5","10.1109/ISBI.2017.7950524","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7950524","Classification;Deep convolutional neural network;Dermoscopy image;Fisher vector","Feature extraction;Image coding;Lesions;Malignant tumors;Skin;Support vector machines;Visualization","image classification;medical image processing;neural nets;optical microscopy;skin;support vector machines","Fisher vector;deep convolutional neural network;dermoscopy image assessment;hybrid classification framework;skin lesion;support vector machine","","","","","","","","18-21 April 2017","","IEEE","IEEE Conference Publications"
"Automated vesicle fusion detection using Convolutional Neural Networks","H. Li; Z. Yin; Y. Xu","Department of Computer Science, Missouri University of Science and Technology, Rolla, 65401, USA","2017 IEEE 14th International Symposium on Biomedical Imaging (ISBI 2017)","20170619","2017","","","183","187","Quantitative analysis of vesicle-plasma membrane fusion events in the fluorescence microscopy, has been proven to be important in the vesicle exocytosis study. In this paper, we present a framework to automatically detect fusion events. First, an iterative searching algorithm is developed to extract image patch sequences containing potential events. Then, we propose an event image to integrate the critical image patches of a candidate event into a single-image joint representation as the input to Convolutional Neural Networks (CNNs). According to the duration of candidate events, we design three CNN architectures to automatically learn features for the fusion event classification. Compared on 9 challenging datasets, our proposed method showed very competitive performance and outperformed two state-of-the-arts.","","Electronic:978-1-5090-1172-8; POD:978-1-5090-1173-5","10.1109/ISBI.2017.7950497","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7950497","Vesicle exocytosis;convolutional neural networks;fusion event identification","Biomembranes;Computer architecture;Correlation;Image sequences;Microprocessors;Neural networks;Shape","biomedical optical imaging;biomembranes;cellular biophysics;fluorescence;image fusion;image sequences;iterative methods;medical image processing;neural nets;optical microscopes","CNN architecture;automated vesicle fusion detection;convolutional neural networks;fluorescence microscopy;fusion event classification;image patch sequences;image patches;iterative searching algorithm;single-image joint representation;vesicle exocytosis study;vesicle-plasma membrane fusion event","","","","","","","","18-21 April 2017","","IEEE","IEEE Conference Publications"
"A novel hybrid approach for severity assessment of Diabetic Retinopathy in colour fundus images","P. Roy; R. Tennakoon; K. Cao; S. Sedai; D. Mahapatra; S. Maetschke; R. Garnavi","IBM Research - Australia, Melbourne, VIC, Australia","2017 IEEE 14th International Symposium on Biomedical Imaging (ISBI 2017)","20170619","2017","","","1078","1082","Diabetic Retinopathy (DR) is one of the leading causes of blindness worldwide. Detecting DR and grading its severity is essential for disease treatment. Convolutional neural networks (CNNs) have achieved state-of-the-art performance in many different visual classification tasks. In this paper, we propose to combine CNNs with dictionary based approaches, which incorporates pathology specific image representation into the learning framework, for improved DR severity classification. Specifically, we construct discriminative and generative pathology histograms and combine them with feature representations extracted from fully connected CNN layers. Our experimental results indicate that the proposed method shows improvement in quadratic kappa score (κ<sup>2</sup> = 0.86) compared to the state-of-the-art CNN based method (κ<sup>2</sup> = 0.81).","","Electronic:978-1-5090-1172-8; POD:978-1-5090-1173-5","10.1109/ISBI.2017.7950703","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7950703","Convolution Neural Network;Fisher Vector;Mixture of Gaussians;Principle Component Analysis;Random Forest","Dictionaries;Feature extraction;Histograms;Pathology;Radio frequency;Retina;Training","diseases;eye;feature extraction;image classification;image representation;medical image processing;neural nets","CNN;DR severity classification;blindness;colour fundus images;convolutional neural networks;diabetic retinopathy;dictionary based approaches;disease treatment;feature extraction;generative pathology histogram;quadratic kappa score;specific image representation;visual classification","","","","","","","","18-21 April 2017","","IEEE","IEEE Conference Publications"
"Lung nodule segmentation using deep learned prior based graph cut","S. Mukherjee; X. Huang; R. R. Bhagalia","GE Global Research, Bangalore, India","2017 IEEE 14th International Symposium on Biomedical Imaging (ISBI 2017)","20170619","2017","","","1205","1208","We propose an automated framework for lung nodule segmentation from pulmonary CT scan using graph cut with a deep learned prior. The segmentation problem is formulated as a hybrid cost function minimization task, which combines a domain specific data term with a deep learned probability map. The proposed segmentation framework embodies the robustness of deep learning in object localization, while retaining the hallmark of traditional segmentation models in addressing the morphological intricacies of elaborate objects. The proposed solution offers more than 20% performance improvement over a contemporary data driven model, and also outperforms traditional graph cuts especially in situations where model initialization is slightly inaccurate.","","Electronic:978-1-5090-1172-8; POD:978-1-5090-1173-5","10.1109/ISBI.2017.7950733","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7950733","CNN;CT;graph cuts;segmentation","Cost function;Image segmentation;Lungs;Neural networks;Robustness;Solids;Two dimensional displays","computerised tomography;image segmentation;learning (artificial intelligence);lung;medical image processing;physiological models;probability","contemporary data driven model;deep learned prior based graph cut;deep learned probability map;lung nodule segmentation;pulmonary CT scan","","","","","","","","18-21 April 2017","","IEEE","IEEE Conference Publications"
"Realistic human action recognition: When CNNS meet LDS","L. Zhang; Y. Feng; X. Xiang; X. Zhen","College of Information and Communication Engineering, Harbin Engineering University, China","2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","20170619","2017","","","1622","1626","In this paper, we proposed new framework for human action representation, which leverages the strengths of convolutional neural networks (CNNs) and the linear dynamical system (LDS) to represent both spatial and temporal structures of actions in videos. We make two principal contributions: first, we incorporate image-trained CNNs to detect action clip concepts, which takes advantage of different levels of information by combining the two layers in CNNs trained from images; Second, we further propose adopting a linear dynamical system (LDS) to model the relationships between these clip concepts, which captures temporal structures of actions. We have applied the proposed method on two challenging realistic benchmark datasets, and our method achieves high performance up to 86.16% on the YouTube and 82.76% UCF50 datasets, which largely outperforms most of the state-of-the-art algorithms with more sophisticated techniques.","","Electronic:978-1-5090-4117-6; POD:978-1-5090-4118-3; USB:978-1-5090-4116-9","10.1109/ICASSP.2017.7952431","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7952431","Concept confidence;Deep learning;Image-trained CNNs;Linear dynamical system","Data mining;Feature extraction;Heuristic algorithms;Machine learning;Trajectory;Videos;YouTube","convolution;image recognition;image representation;learning (artificial intelligence);neural nets;principal component analysis;video signal processing","CNN;LDS;convolutional neural networks;deep learning;human action representation;linear dynamical system;realistic human action recognition","","","","","","","","5-9 March 2017","","IEEE","IEEE Conference Publications"
"Adapting fisher vectors for histopathology image classification","Y. Song; J. J. Zou; H. Chang; W. Cai","School of Information Technologies, University of Sydney, Australia","2017 IEEE 14th International Symposium on Biomedical Imaging (ISBI 2017)","20170619","2017","","","600","603","Histopathology image classification can provide automated support towards cancer diagnosis. In this paper, we present a transfer learning-based approach for histopathology image classification. We first represent the image feature by Fisher Vector (FV) encoding of local features that are extracted using the Convolutional Neural Network (CNN) model pretrained on ImageNet. Next, to better transfer the pretrained model to the histopathology image dataset, we design a new adaptation layer to further transform the FV descriptors for higher discriminative power and classification accuracy. We used the publicly available BreaKHis image dataset for classifying between benign and malignant breast tumors, and obtained improved performance over the state-of-the-art.","","Electronic:978-1-5090-1172-8; POD:978-1-5090-1173-5","10.1109/ISBI.2017.7950592","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7950592","Convolutional Neural Network;Fisher Vector;image classification;transfer learning","Adaptation models;Biological system modeling;Cancer;Feature extraction;Image coding;Support vector machines;Training","biomedical optical imaging;cancer;feature extraction;image classification;image coding;learning (artificial intelligence);medical image processing;neural nets;tumours","BreaKHis image dataset;Convolutional Neural Network model;FV descriptors;Fisher Vector encoding;ImageNet;adaptation layer;benign breast tumors;cancer diagnosis;classification accuracy;discriminative power;feature extraction;histopathology image classification;histopathology image dataset;image feature;local features;malignant breast tumors;pretrained model;transfer learning-based approach","","","","","","","","18-21 April 2017","","IEEE","IEEE Conference Publications"
"Atherosclerotic vascular calcification detection and segmentation on low dose computed tomography scans using convolutional neural networks","K. Chellamuthu; J. Liu; J. Yao; M. Bagheri; L. Lu; V. Sandfort; R. M. Summers","Imaging Biomarkers and Computer-aided Diagnosis Laboratory, Radiology and Imaging Sciences, National Institutes of Health Clinical Center, Building 10 Room 1C224 MSC 1182, Bethesda, MD 20892-1182, United States of America","2017 IEEE 14th International Symposium on Biomedical Imaging (ISBI 2017)","20170619","2017","","","388","391","We propose an automated platform for extra-coronary calcification detection on low dose CT scans. We utilize faster regional convolutional neural networks (R-CNN) to directly detect calcifications at the lesion-level without performing vessel extraction. To segment detected calcifications at the voxel-level, we employ holistically nested edge detection (HED). CT scans of 112 vasculitis patients and 3219 images with labeled calcifications were used to develop and evaluate our method. By employing a two-class faster R-CNN, the average precision (AP) increased from 49.2% to 84.4% for calcification detection. In addition, sensitivity of 85.0% at 1 false positive per image was observed. The Dice Similarity Coefficient (DSC) for calcification segmentation using HED (0.83±0.08) was significantly better (p≪0.01) than the traditional threshold-based method (0.59±0.26).","","Electronic:978-1-5090-1172-8; POD:978-1-5090-1173-5","10.1109/ISBI.2017.7950544","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7950544","CNNs;Calcification;HED;plaque;region proposal","Atherosclerosis;Computed tomography;Computer vision;Image edge detection;Image segmentation;Proposals","blood vessels;computerised tomography;diseases;feature extraction;image segmentation;medical image processing;neural nets","Dice similarity coefficient;atherosclerotic vascular calcification detection;average precision;convolutional neural networks;extracoronary calcification detection;holistically nested edge detection;low dose CT scans;low dose computed tomography scans;segmentation method;threshold-based method;vasculitis patients;vessel extraction;voxel-level","","","","","","","","18-21 April 2017","","IEEE","IEEE Conference Publications"
"M-net: A Convolutional Neural Network for deep brain structure segmentation","R. Mehta; J. Sivaswamy","Center for Visual Information Technology (CVIT), IIIT-Hyderabad, India","2017 IEEE 14th International Symposium on Biomedical Imaging (ISBI 2017)","20170619","2017","","","437","440","In this paper, we propose an end-to-end trainable Convolutional Neural Network (CNN) architecture called the M-net, for segmenting deep (human) brain structures from Magnetic Resonance Images (MRI). A novel scheme is used to learn to combine and represent 3D context information of a given slice in a 2D slice. Consequently, the M-net utilizes only 2D convolution though it operates on 3D data, which makes M-net memory efficient. The segmentation method is evaluated on two publicly available datasets and is compared against publicly available model based segmentation algorithms as well as other classification based algorithms such as Random Forrest and 2D CNN based approaches. Experiment results show that the M-net outperforms all these methods in terms of dice coefficient and is at least 3 times faster than other methods in segmenting a new volume which is attractive for clinical use.","","Electronic:978-1-5090-1172-8; POD:978-1-5090-1173-5","10.1109/ISBI.2017.7950555","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7950555","Convolutional Neural Networks;Deep Brain Structures;Magnetic Resonance Images;Segmentation","Brain;Convolution;Image segmentation;Magnetic resonance imaging;Three-dimensional displays;Training;Two dimensional displays","biomedical MRI;brain;convolution;image segmentation;medical image processing;neural nets","2D convolution;M-net;convolutional neural network;deep brain structure segmentation;magnetic resonance images","","","","","","","","18-21 April 2017","","IEEE","IEEE Conference Publications"
"Deep learning model based breast cancer histopathological image classification","Benzheng Wei; Zhongyi Han; Xueying He; Yilong Yin","College of Science and Technology, Shandong University of Traditional Chinese Medicine, Jinan, China","2017 IEEE 2nd International Conference on Cloud Computing and Big Data Analysis (ICCCBDA)","20170619","2017","","","348","353","The automatic and precision classification for breast cancer histopathological image has a great significance in clinical application. However, the existing analysis approaches are difficult to addressing the breast cancer classification problem because the feature subtle differences of inter-class histopathological image and the classification accuracy still hard to meet the clinical application. Recent advancements in data-driven sharing processing and multi-level hierarchical feature learning have made available considerable chance to dope out a solution to this problem. To address the challenging problem, we propose a novel breast cancer histopathological image classification method based on deep convolutional neural networks, named as BiCNN model, to address the two-class breast cancer classification on the pathological image. This deep learning model considers class and sub-class labels of breast cancer as prior knowledge, which can restrain the distance of features of different breast cancer pathological images. In addition, an advanced data augmented method is proposed to fit tolerance whole slide image recognition, which can full reserve image edge feature of cancerization region. The transfer learning and fine-tuning method are adopted as an optimal training strategy to improve breast cancer histopathological image classification accuracy. The experiment results show that the proposed method leads to a higher classification accuracy (up to 97%) and displays good robustness and generalization, which provides efficient tools for breast cancer clinical diagnosis.","","CD:978-1-5090-4497-9; Electronic:978-1-5090-4499-3; POD:978-1-5090-4500-6; Paper:978-1-5090-4498-6","10.1109/ICCCBDA.2017.7951937","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7951937","CNN;breast cancer;classification;deep learning;histopathological image;massive image data","Cancer;Feature extraction;Image color analysis;Image recognition;Image reconstruction;Neurons;Robustness","cancer;convolution;image classification;learning (artificial intelligence);medical image processing;neural nets","BiCNN model;advanced data augmented method;breast cancer clinical diagnosis;breast cancer histopathological image classification method;cancerization region;class labels;classification accuracy;data-driven sharing processing;deep convolutional neural networks;deep learning model;fine-tuning method;fit tolerance whole slide image recognition;image edge feature;multilevel hierarchical feature learning;optimal training strategy;subclass labels;transfer learning","","","","","","","","28-30 April 2017","","IEEE","IEEE Conference Publications"
"Convolutional neural networks for predicting molecular profiles of non-small cell lung cancer","D. Yu; M. Zhou; F. Yang; D. Dong; O. Gevaert; Z. Liu; J. Shi; J. Tian","The Key Laboratory of Molecular Imaging, Institute of Automation, Chinese Academy of Sciences, China","2017 IEEE 14th International Symposium on Biomedical Imaging (ISBI 2017)","20170619","2017","","","569","572","Quantitative imaging biomarkers identification has become a powerful tool for predictive diagnosis given increasingly available clinical imaging data. In parallel, molecular profiles have been well documented in non-small cell lung cancers (NSCLCs). However, there has been limited studies on leveraging the two major sources for improving lung cancer computer-aided diagnosis. In this paper, we investigate the problem of predicting molecular profiles with CT imaging arrays in NSCLC. In particular, we formulate a discriminative convolutional neural network to learn deep features for predicting epidermal growth factor receptor (EGFR) mutation states that are associated with cancer cell growth. We evaluated our approach on two independent datasets including a discovery set with 595 patients (Datset1) and a validation set with 89 patients (Dataset2). Extensive experimental results demonstrated that the learned CNN-based features are effective in predicting EGFR mutation states (AUC=0.828, ACC=76.16%) on Dataset1, and it further demonstrated generalized predictive performance (AUC=0.668, ACC=67.55%) on Dataset2.","","Electronic:978-1-5090-1172-8; POD:978-1-5090-1173-5","10.1109/ISBI.2017.7950585","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7950585","Computed tomography;Computed-aided diagnosis;Convolutional neural networks;Non-Small Cell Lung Carcinoma","Cancer;Computed tomography;Convolution;Feature extraction;Lungs;Neural networks","cancer;cellular biophysics;computerised tomography;feature extraction;lung;medical image processing;molecular biophysics;neural nets;proteins","CT imaging arrays;EGFR mutation state prediction;biomarker identification;cancer cell growth;clinical imaging data;discriminative convolutional neural network;epidermal growth factor receptor;learned CNN-based feature;lung cancer computer-aided diagnosis;molecular profile;nonsmall cell lung cancer;quantitative imaging","","","","","","","","18-21 April 2017","","IEEE","IEEE Conference Publications"
"Exploring texture Transfer Learning for Colonic Polyp Classification via Convolutional Neural Networks","E. Ribeiro; M. Häfner; G. Wimmer; T. Tamaki; J. J. W. Tischendorf; S. Yoshida; S. Tanaka; A. Uhl","University of Salzburg - Department of Computer Sciences, AT","2017 IEEE 14th International Symposium on Biomedical Imaging (ISBI 2017)","20170619","2017","","","1044","1048","This work addresses Transfer Learning via Convolutional Neural Networks (CNN's) for the automated classification of colonic polyps in eight HD-endoscopic image databases acquired using different modalities. For this purpose, we explore if the architecture, the training approach, the number of classes, the number of images as well as the nature of the images in the training phase can influence the results. The experiments show that when the number of classes and the nature of the images are similar to the target database, the results are improved. Also, the better results obtained by the transfer learning compared to the most used features in the literature suggest that features learned by CNN's can be highly relevant for automated classification of colonic polyps.","","Electronic:978-1-5090-1172-8; POD:978-1-5090-1173-5","10.1109/ISBI.2017.7950695","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7950695","Colonic Polyp Classification;Convolutional Neural Networks;Deep Learning;Texture Transfer Learning","Biomedical imaging;Colonic polyps;Computers;Feature extraction;Image databases;Training","biomedical optical imaging;endoscopes;image classification;learning (artificial intelligence);medical image processing;neural nets","HD-endoscopic image databases;colonic polyp classification;convolutional neural networks;deep learning;transfer learning","","","","","","","","18-21 April 2017","","IEEE","IEEE Conference Publications"
"Modeling Task fMRI Data via Deep Convolutional Autoencoder","H. Huang; X. Hu; Y. Zhao; M. Makkie; Q. Dong; S. Zhao; L. Guo; T. Liu","School of Automation, Northwestern Polytechnical University, Xi&#x2019;an, 710072, China.","IEEE Transactions on Medical Imaging","","2017","PP","99","1","1","Task-based fMRI (tfMRI) has been widely used to study functional brain networks under task performance. Modeling tfMRI data is challenging due to at least two problems: the lack of the ground truth of underlying neural activity and the highly complex intrinsic structure of tfMRI data. To better understand brain networks based on fMRI data, data-driven approaches have been proposed, for instance, Independent Component Analysis (ICA) and Sparse Dictionary Learning (SDL). However, both ICA and SDL only build shallow models, and they are under the strong assumption that original fMRI signal could be linearly decomposed into time series components with their corresponding spatial maps. As growing evidence shows that human brain function is hierarchically organized, new approaches that can infer and model the hierarchical structure of brain networks are widely called for. Recently, deep convolutional neural network (CNN) has drawn much attention, in that deep CNN has proven to be a powerful method for learning high-level and mid-level abstractions from low-level raw data. Inspired by the power of deep CNN, in this study, we developed a new neural network structure based on CNN, called Deep Convolutional Auto-Encoder (DCAE), in order to take the advantages of both data-driven approach and CNN’s hierarchical feature abstraction ability for the purpose of learning mid-level and high-level features from complex, large-scale tfMRI time series in an unsupervised manner. The DCAE has been applied and tested on the publicly available human connectome project (HCP) tfMRI datasets, and promising results are achieved.","0278-0062;02780062","","10.1109/TMI.2017.2715285","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7949140","CNN;Task fMRI;deep learning;unsupervised","Brain modeling;Convolution;Data models;Decoding;Hidden Markov models;Machine learning;Time series analysis","","","","","","","","","20170615","","","IEEE","IEEE Early Access Articles"
"Identifying Carotid Plaque Composition in MRI with Convolutional Neural Networks","Y. Dong; Y. Pan; X. Zhao; R. Li; C. Yuan; W. Xu","Inst. for Interdiscipl. Inf. Sci., Tsinghua Univ., Beijing, China","2017 IEEE International Conference on Smart Computing (SMARTCOMP)","20170615","2017","","","1","8","Carotid plaques may cause strokes. The composition of the plaque helps assessing the risk. Magnetic resonance imaging (MRI) is a powerful technology for analyzing the composition. It is both tedious and error-prone for a human radiologist to review such images. Traditional computer-aided diagnosis tools use manually crafted features that lack both generality and accuracy. We propose a novel approach using Deep convolutional neural networks (CNN) to classify these plaque tissues. In order to accommodate the multi-contrast MRI images, we modify state-of-the-art CNN models to support different number of input channels, and also adapt the models to do pixel- wise predictions. On a dataset with 1,098 human subjects, we show that we achieve significantly better accuracy than previous models. Our result also indicates interesting relations between contrast weightings and tissue types.","","Electronic:978-1-5090-6517-2; POD:978-1-5090-6518-9","10.1109/SMARTCOMP.2017.7947015","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7947015","","Adaptation models;Atherosclerosis;Biomedical imaging;Hemorrhaging;Magnetic resonance imaging;Neural networks","biomedical MRI;feedforward neural nets;medical image processing","CNN;carotid plaque composition;contrast weightings;deep convolutional neural networks;human radiologist;magnetic resonance imaging;multicontrast MRI images;plaque tissues;tissue types","","","","","","","","29-31 May 2017","","IEEE","IEEE Conference Publications"
"Poster Abstract: Maximizing Accuracy of Fall Detection and Alert Systems Based on 3D Convolutional Neural Network","S. Hwang; D. Ahn; H. Park; T. Park","Hanyang Univ., Seoul, South Korea","2017 IEEE/ACM Second International Conference on Internet-of-Things Design and Implementation (IoTDI)","20170615","2017","","","343","344","We present a deep-learning-based approach to maximize the accuracy and reliability of vision-based fall detection and alert systems. The proposed approach utilizes a 3D convolutional neural network (3D-CNN) to analyze the continuous motion data obtained from depth cameras and exploits a data augmentation method to do away with overfitting. Our preliminary evaluation results demonstrate that it achieves the classification accuracy of up to 96.9%.","","Electronic:978-1-4503-4966-6; POD:978-1-4673-9146-7","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7946918","3D convolutional neural network;IoT applications;deep learning;elderly care;fall detection","Medical services;Neural networks;Reliability;Senior citizens;Shape;Three-dimensional displays;Training","convolution;geriatrics;image classification;learning (artificial intelligence);medical computing;neural nets;stereo image processing","3D convolutional neural network;3D-CNN;activity classification;activity recognition;alert systems;data augmentation;deep learning;elderly care;fall detection","","","","","","","","18-21 April 2017","","IEEE","IEEE Conference Publications"
"Spoken Language Understanding for a Nutrition Dialogue System","M. Korpusik; J. Glass","MIT Computer Science and Artificial Intelligence Laboratory, Cambridge, MA, USA","IEEE/ACM Transactions on Audio, Speech, and Language Processing","20170605","2017","25","7","1450","1461","Food logging is recommended by dieticians for prevention and treatment of obesity, but currently available mobile applications for diet tracking are often too difficult and time-consuming for patients to use regularly. For this reason, we propose a novel approach to food journaling that uses speech and language understanding technology in order to enable efficient self-assessment of energy and nutrient consumption. This paper presents ongoing language understanding experiments conducted as part of a larger effort to create a nutrition dialogue system that automatically extracts food concepts from a user's spoken meal description. We first summarize the data collection and annotation of food descriptions performed via Amazon Mechanical Turk (AMT), for both a written corpus and spoken data from an in-domain speech recognizer. We show that the addition of word vector features improves conditional random field (CRF) performance for semantic tagging of food concepts, achieving an average F1 test score of 92.4 on written data; we also demonstrate that a convolutional neural network (CNN) with no hand-crafted features outperforms the best CRF on spoken data, achieving an F1 test score of 91.3. We illustrate two methods for associating foods with properties: segmenting meal descriptions with a CRF, and a complementary method that directly predicts associations with a feed-forward neural network. Finally, we conduct an end-to-end system evaluation through an AMT user study with worker ratings of 83% semantic tagging accuracy.","2329-9290;23299290","","10.1109/TASLP.2017.2694699","National Defense Science and Engineering Graduate Fellowship (NDSEG) Program; Quanta Computing, Inc.; 10.13039/100000002 - NIH; 10.13039/100000005 - Department of Defense (DoD); ","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7902155","Conditional random field;crowdsourcing;neural networks;semantic tagging;word vectors","Hidden Markov models;Neural networks;Semantics;Speech;Speech processing;Speech recognition;Tagging","feedforward neural nets;medical computing;mobile computing;natural language processing;patient treatment;speech recognition;statistical analysis","AMT user study;Amazon Mechanical Turk;CNN;CRF;average F1 test score;conditional random field;convolutional neural network;data collection;diet tracking;energy consumption;feed-forward neural network;food concept automatic extraction;food concept semantic tagging;food description annotation;food journaling;in-domain speech recognizer;language understanding technology;meal description segmentation;mobile applications;nutrient consumption;obesity treatment;speech understanding technology;spoken data;user spoken meal description;word vector features","","","","","","","20170417","July 2017","","IEEE","IEEE Journals & Magazines"
"Deep Convolutional Neural Networks and Learning ECG Features for Screening Paroxysmal Atrial Fibrillation Patients","B. Pourbabaee; M. J. Roshtkhari; K. Khorasani","Department of Electrical and Computer Engineering, Concordia University, Montreal, QC H3G1M8, Canada.","IEEE Transactions on Systems, Man, and Cybernetics: Systems","","2017","PP","99","1","10","In this paper, a novel computationally intelligent-based electrocardiogram (ECG) signal classification methodology using a deep learning (DL) machine is developed. The focus is on patient screening and identifying patients with paroxysmal atrial fibrillation (PAF), which represents a life threatening cardiac arrhythmia. The proposed approach operates with a large volume of raw ECG time-series data as inputs to a deep convolutional neural networks (CNN). It autonomously learns representative and key features of the PAF to be used by a classification module. The features are therefore learned directly from the large time domain ECG signals by using a CNN with one fully connected layer. The learned features can effectively replace the traditional ad hoc and time-consuming user's hand-crafted features. Our experimental results verify and validate the effectiveness and capabilities of the learned features for PAF patient screening. The main advantages of our proposed approach are to simplify the feature extraction process corresponding to different cardiac arrhythmias and to remove the need for using a human expert to define appropriate and critical features working with a large time-series data set. The extensive simulations and case studies conducted indicate that combining the learned features with other classifiers will significantly improve the performance of the patient screening system as compared to an end-to-end CNN classifier. The effectiveness and capabilities of our proposed ECG DL classification machine is demonstrated and quantitative comparisons with several conventional machine learning classifiers are also provided.","2168-2216;21682216","","10.1109/TSMC.2017.2705582","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7937819","Biomedical monitoring;deep convolution neural network;electrocardiogram (ECG);feature extraction;neural network architecture;paroxysmal atrial fibrillation (PAF)","Convolution;Electrocardiography;Feature extraction;Hidden Markov models;Medical services;Monitoring;Neural networks","","","","","","","","","20170601","","","IEEE","IEEE Early Access Articles"
"Direct Multitype Cardiac Indices Estimation via Joint Representation and Regression Learning","W. Xue; A. Islam; M. Bhaduri; S. Li","Department of Medical Imaging, Western University, London, ON N6A 3K7, Canada and also with Digital Imaging Group of London, London, ON N6A 3K7, Canada.","IEEE Transactions on Medical Imaging","","2017","PP","99","1","1","Cardiac indices estimation is of great importance during identification and diagnosis of cardiac disease in clinical routine. However, estimation of multitype cardiac indices with consistently reliable and high accuracy is still a great challenge due to the high variability of cardiac structures and complexity of temporal dynamics in cardiac MR sequences. While efforts have been devoted into cardiac volumes estimation through feature engineering followed by a independent regression model, these methods suffer from the vulnerable feature representation and incompatible regression model. In this paper, we propose a semi-automated method for multitype cardiac indices estimation. After manual labelling of two landmarks for ROI cropping, an integrated deep neural network Indices-Net is designed to jointly learn the representation and regression models. It comprises two tightly-coupled networks: a deep convolution autoencoder (DCAE) for cardiac image representation, and a multiple output convolution neural network (CNN) for indices regression. Joint learning of the two networks effectively enhances the expressiveness of image representation with respect to cardiac indices, and the compatibility between image representation and indices regression, thus leading to accurate and reliable estimations for all the cardiac indices. When applied with five-fold cross validation on MR images of 145 subjects, Indices-Net achieves consistently low estimation error for LV wall thicknesses (1.440.71mm) and areas of cavity and myocardium (204133mm2). It outperforms, with significant error reductions, segmentation method (55.1% and 17.4%) and two-phase direct volume-only methods (12.7% and 14.6%) for wall thicknesses and areas, respectively. These advantages endow the proposed method a great potential in clinical cardiac function assessment","0278-0062;02780062","","10.1109/TMI.2017.2709251","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7934404","cardiac MR;deep convolution autoencoder;direct estimation;joint learning;multitype cardiac indices","Convolution;Estimation;Feature extraction;Image representation;Image segmentation;Myocardium;Volume measurement","","","","","","","","","20170526","","","IEEE","IEEE Early Access Articles"
"Generative Adversarial Networks for Noise Reduction in Low-Dose CT","J. M. Wolterink; T. Leiner; M. A. Viergever; I. Isgum","","IEEE Transactions on Medical Imaging","","2017","PP","99","1","1","Noise is inherent to low-dose CT acquisition. We propose to train a convolutional neural network (CNN) jointly with an adversarial CNN to estimate routine-dose CT images from low-dose CT images and hence reduce noise. A generator CNN was trained to transform low-dose CT images into routine-dose CT images using voxel-wise loss minimization. An adversarial discriminator CNN was simultaneously trained to distinguish the output of the generator from routinedose CT images. The performance of this discriminator was used as an adversarial loss for the generator. Experiments were performed using CT images of an anthropomorphic phantom containing calcium inserts, as well as patient non-contrast-enhanced cardiac CT images. The phantom and patients were scanned at 20% and 100% routine clinical dose. Three training strategies were compared: the first used only voxel-wise loss, the second combined voxel-wise loss and adversarial loss, and the third used only adversarial loss. The results showed that training with only voxel-wise loss resulted in the highest peak signal-to-noise ratio with respect to reference routine-dose images. However, the CNNs trained with adversarial loss captured image statistics of routine-dose images better. Noise reduction improved quantification of low-density calcified inserts in phantom CT images and allowed coronary calcium scoring in low-dose patient CT images with high noise levels. Testing took less than 10 seconds per CT volume. CNN-based low-dose CT noise reduction in the image domain is feasible. Training with an adversarial network improves the CNN’s ability to generate images with an appearance similar to that of reference routine-dose CT images.","0278-0062;02780062","","10.1109/TMI.2017.2708987","Netherlands Organization for Health Research and Development ZonMw; ","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7934380","Low-dose cardiac CT;coronary calcium scoring;deep learning,;generative adversarial networks;noise reduction","Calcium;Computed tomography;Convolution;Generators;Noise reduction;Training;Transforms","","","","","","","","","20170526","","","IEEE","IEEE Early Access Articles"
"Single-Trial Classification of Event-Related Potentials in Rapid Serial Visual Presentation Tasks Using Supervised Spatial Filtering","H. Cecotti; M. P. Eckstein; B. Giesbrecht","Department of Psychological and Brain Sciences, Institute for Collaborative Biotechnologies, University of California, Santa Barbara, CA, USA","IEEE Transactions on Neural Networks and Learning Systems","20170520","2014","25","11","2030","2042","Accurate detection of single-trial event-related potentials (ERPs) in the electroencephalogram (EEG) is a difficult problem that requires efficient signal processing and machine learning techniques. Supervised spatial filtering methods that enhance the discriminative information in EEG data are commonly used to improve single-trial ERP detection. We propose a convolutional neural network (CNN) with a layer dedicated to spatial filtering for the detection of ERPs and with training based on the maximization of the area under the receiver operating characteristic curve (AUC). The CNN is compared with three common classifiers: 1) Bayesian linear discriminant analysis; 2) multilayer perceptron (MLP); and 3) support vector machines. Prior to classification, the data were spatially filtered with xDAWN (for the maximization of the signal-to-signal-plus-noise ratio), common spatial pattern, or not spatially filtered. The 12 analytical techniques were tested on EEG data recorded in three rapid serial visual presentation experiments that required the observer to discriminate rare target stimuli from frequent nontarget stimuli. Classification performance discriminating targets from nontargets depended on both the spatial filtering method and the classifier. In addition, the nonlinear classifier MLP outperformed the linear methods. Finally, training based AUC maximization provided better performance than training based on the minimization of the mean square error. The results support the conclusion that the choice of the systems architecture is critical and both spatial filtering and classification must be considered together.","2162-237X;2162237X","","10.1109/TNNLS.2014.2302898","Institute for Collaborative Biotechnologies through the U.S. Army Research Office; ","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6737255","Brain–computer interface (BCI);Brain-computer interface (BCI);common spatial patterns (CSP);convolution;electroencephalogram (EEG);neural networks;rapid serial visual presentation (RSVP);spatial filters;spatial filters.","Biological neural networks;Convolution;Electroencephalography;Neurons;Sensors;Training;Visualization","Bayes methods;electroencephalography;learning (artificial intelligence);medical signal detection;medical signal processing;multilayer perceptrons;signal classification;spatial filters;support vector machines;visual evoked potentials","Bayesian linear discriminant analysis;CNN;EEG data;area maximization;convolutional neural network;discriminative information;frequent nontarget stimuli;linear methods;machine learning techniques;mean square error minimization;multilayer perceptron;nonlinear classifier MLP;rapid serial visual presentation;rapid serial visual presentation tasks;receiver operating characteristic curve;signal processing;signal-to-signal-plus-noise ratio;single-trial ERP detection;single-trial classification;single-trial event-related potentials;spatial pattern;supervised spatial filtering methods;support vector machines;target stimuli;training based AUC maximization;xDAWN","0;Adolescent;Adult;Algorithms;Area Under Curve;Brain Mapping;Electroencephalography;Evoked Potentials;Female;Filtration;Humans;Male;Neural Networks (Computer);Photic Stimulation;ROC Curve;Reaction Time;Signal Processing, Computer-Assisted;Support Vector Machine;Visual Perception;Young Adult","12","","61","","","20140211","Nov. 2014","","IEEE","IEEE Journals & Magazines"
"Ultrasound Standard Plane Detection Using a Composite Neural Network Framework","H. Chen; L. Wu; Q. Dou; J. Qin; S. Li; J. Z. Cheng; D. Ni; P. A. Heng","Department of Computer Science and Engineering, Chinese University of Hong Kong, Hong Kong","IEEE Transactions on Cybernetics","20170520","2017","47","6","1576","1586","Ultrasound (US) imaging is a widely used screening tool for obstetric examination and diagnosis. Accurate acquisition of fetal standard planes with key anatomical structures is very crucial for substantial biometric measurement and diagnosis. However, the standard plane acquisition is a labor-intensive task and requires operator equipped with a thorough knowledge of fetal anatomy. Therefore, automatic approaches are highly demanded in clinical practice to alleviate the workload and boost the examination efficiency. The automatic detection of standard planes from US videos remains a challenging problem due to the high intraclass and low interclass variations of standard planes, and the relatively low image quality. Unlike previous studies which were specifically designed for individual anatomical standard planes, respectively, we present a general framework for the automatic identification of different standard planes from US videos. Distinct from conventional way that devises hand-crafted visual features for detection, our framework explores in- and between-plane feature learning with a novel composite framework of the convolutional and recurrent neural networks. To further address the issue of limited training data, a multitask learning framework is implemented to exploit common knowledge across detection tasks of distinctive standard planes for the augmentation of feature learning. Extensive experiments have been conducted on hundreds of US fetus videos to corroborate the better efficacy of the proposed framework on the difficult standard plane detection problem.","2168-2267;21682267","","10.1109/TCYB.2017.2685080","National Basic Research Program of China, 973 Program; National Natural Science Foundation of China; Research Grants Council of Hong Kong Special Administrative Region; ","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7890445","Convolutional neural network (CNN);deep learning;knowledge transfer;recurrent neural network (RNN);standard plane;ultrasound (US)","Biomedical imaging;Feature extraction;Fetus;Machine learning;Standards;Training data;Videos","","","","","","","","","20170330","June 2017","","IEEE","IEEE Journals & Magazines"
"ECG Monitoring System Integrated With IR-UWB Radar Based on CNN","W. Yin; X. Yang; L. Zhang; E. Oki","Beijing University of Posts and Telecommunications, Beijing, China","IEEE Access","20170520","2016","4","","6344","6351","In the demand for protecting the increasing aged groups from heart attacks, the improvement of the mobile electrocardiogram (ECG) monitoring systems becomes significant. The limitations of the arrhythmia classification in these systems are the lack of ability to cope with motion state and the low accuracy in new users' data. This paper proposes a system which applies the impulse radio ultra wideband radar data as additional information to assist the arrhythmia classification of ECG recordings in the slight motion state. Besides, this proposed system employs a cascade convolutional neural network to achieve an integrated analysis of ECG recordings and radar data. The experiments are implemented in the Caffe platform and the result reaches an accuracy of 88.89% in the slight motion state. It turns out that this proposed system keeps a stable accuracy of classification for normal and abnormal heartbeats in the slight motion state.","2169-3536;21693536","","10.1109/ACCESS.2016.2608777","111 Project; EU FP7IRSES Mobile Cloud Project; 10.13039/501100001809 - National Science Foundation of China; ","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7576640","Electrocardiography;neural networks;ultra wideband radar","Convolution;Electrocardiography;Feature extraction;Heart beat;Kernel;Monitoring;Radar","bioelectric potentials;electrocardiography;medical disorders;medical signal processing;neurophysiology;signal classification;ultra wideband radar","CNN;Caffe platform;ECG recordings;IR-UWB radar data;abnormal heartbeats;arrhythmia classification;cascade convolutional neural network;heart attacks;impulse radio ultra wideband radar data;mobile ECG monitoring system;mobile electrocardiogram monitoring systems","","","","","","","20160926","2016","","IEEE","IEEE Journals & Magazines"
"A Convolutional Neural Network for Automatic Characterization of Plaque Composition in Carotid Ultrasound","K. Lekadir; A. Galimzianova; À. Betriu; M. del Mar Vila; L. Igual; D. L. Rubin; E. Fernández; P. Radeva; S. Napel","Department of Radiology, Stanford University School of Medicine, Stanford, CA, USA","IEEE Journal of Biomedical and Health Informatics","20170520","2017","21","1","48","55","Characterization of carotid plaque composition, more specifically the amount of lipid core, fibrous tissue, and calcified tissue, is an important task for the identification of plaques that are prone to rupture, and thus for early risk estimation of cardiovascular and cerebrovascular events. Due to its low costs and wide availability, carotid ultrasound has the potential to become the modality of choice for plaque characterization in clinical practice. However, its significant image noise, coupled with the small size of the plaques and their complex appearance, makes it difficult for automated techniques to discriminate between the different plaque constituents. In this paper, we propose to address this challenging problem by exploiting the unique capabilities of the emerging deep learning framework. More specifically, and unlike existing works which require a priori definition of specific imaging features or thresholding values, we propose to build a convolutional neural network (CNN) that will automatically extract from the images the information that is optimal for the identification of the different plaque constituents. We used approximately 90 000 patches extracted from a database of images and corresponding expert plaque characterizations to train and to validate the proposed CNN. The results of cross-validation experiments show a correlation of about 0.90 with the clinical assessment for the estimation of lipid core, fibrous cap, and calcified tissue areas, indicating the potential of deep learning for the challenging task of automatic characterization of plaque composition in carotid ultrasound.","2168-2194;21682194","","10.1109/JBHI.2016.2631401","European Regions Development; FIS; Marie-Curie Actions Program of the European Union; 10.13039/100000002 - NIH; 10.13039/100007065 - NVIDIA; 10.13039/501100000783 - REA; 10.13039/501100003741 - ICREA; ","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7752798","Atherosclerosis;carotid artery;convolutional neural networks (CNNs);plaque composition;ultrasound","Atherosclerosis;Feature extraction;Imaging;Lipidomics;Machine learning;Neural networks;Ultrasonic imaging","biomedical ultrasonics;blood vessels;cardiovascular system;feature extraction;image segmentation;learning (artificial intelligence);medical image processing;neural nets","calcified tissue;cardiovascular events;carotid plaque composition;carotid ultrasound;cerebrovascular events;convolutional neural network;deep learning framework;fibrous cap;fibrous tissue;image noise;imaging features;lipid core;plaque constituents;thresholding values","","","","","","","20161122","Jan. 2017","","IEEE","IEEE Journals & Magazines"
"Computer diagnostic tools based on biomedical image analysis","O. Berezsky; O. Pitsun; S. Verbovyy; T. Datsko; A. Bodnar","Computer Engineering Department, Ternopil National Economic University, UKRAINE, Ternopil, 11 Lvivska str.","2017 14th International Conference The Experience of Designing and Application of CAD Systems in Microelectronics (CADSM)","20170504","2017","","","388","391","In this paper, the authors investigated the main types of mammary dysplasia. In order to classify biomedical images, the researchers developed a basic model of convolutional neural network (CNN). Input parameters of the neural network to classify cytological and histological images were thoroughly researched and selected.","","Electronic:978-1-5090-5045-1; POD:978-1-5090-5046-8","10.1109/CADSM.2017.7916157","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7916157","convolutional neural network;cytological and histological images;mammary dysplasia","Biological neural networks;Breast;Connective tissue;Diseases;Ducts;Image classification;Kernel","cellular biophysics;diseases;feedforward neural nets;image classification;medical image processing","Input parameters;biomedical image analysis;biomedical image classification;computer diagnostic tools;convolutional neural network;cytological image classification;histological image classification;mammary dysplasia","","","","","","","","21-25 Feb. 2017","","IEEE","IEEE Conference Publications"
"Convolutional neural networks for lung cancer screening in computed tomography (CT) scans","P. Rao; N. A. Pereira; R. Srinivasan","Department of Electronics and Communication Engineering, M. S. Ramaiah Institute of Technology, Bengaluru 560054, India","2016 2nd International Conference on Contemporary Computing and Informatics (IC3I)","20170504","2016","","","489","493","Diagnosis and cure of cancer has been one of the biggest challenges faced by mankind in the last few decades. Early detection of cancer would facilitate in saving millions of lives across the globe every year. This paper presents an approach which uses a Convolutional Neural Network (CNNs) to classify tumours seen in lung cancer screening computed tomography scans as malignant or benign. CNNs have special properties such as spatial invariance, and allow for multiple feature extraction. When such layers are cascaded, leading to Deep CNNs, it has been shown widely that the accuracy of prediction increases dramatically. In this work, we have designed a CNN suitable for the analysis of CT scans with tumours, using domain knowledge from both medicine and neural networks. The results show that the accuracy of classification for our network performs better than both the traidtional neural networks, and also existing CNNs built for image classification purposes.","","Electronic:978-1-5090-5256-1; POD:978-1-5090-5257-8; USB:978-1-5090-5255-4","10.1109/IC3I.2016.7918014","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7918014","","Cancer;Computed tomography;Computer architecture;Convolution;Feature extraction;Neural networks;Tumors","cancer;computerised tomography;feature extraction;feedforward neural nets;image classification;lung;medical image processing","CT scan analysis;cancer detection;cancer diagnosis;computed tomography scans;convolutional neural networks;deep CNN;feature extraction;image classification purposes;lung cancer screening;tumour classification","","","","","","","","14-17 Dec. 2016","","IEEE","IEEE Conference Publications"
"Skin disease classification versus skin lesion characterization: Achieving robust diagnosis using multi-label deep neural networks","Haofu Liao; Yuncheng Li; Jiebo Luo","Department of Computer Science, University of Rochester, New York 14627, USA","2016 23rd International Conference on Pattern Recognition (ICPR)","20170424","2016","","","355","360","In this study, we investigate what a practically useful approach is in order to achieve robust skin disease diagnosis. A direct approach is to target the ground truth diagnosis labels, while an alternative approach instead focuses on determining skin lesion characteristics that are more visually consistent and discernible. We argue that, for computer aided skin disease diagnosis, it is both more realistic and more useful that lesion type tags should be considered as the target of an automated diagnosis system such that the system can first achieve a high accuracy in describing skin lesions, and in turn facilitate disease diagnosis using lesion characteristics in conjunction with other evidences. To further meet such an objective, we employ convolutional neutral networks (CNNs) for both the disease-targeted and lesion-targeted classifications. We have collected a large-scale and diverse dataset of 75,665 skin disease images from six publicly available dermatology atlantes. Then we train and compare both disease-targeted and lesion-targeted classifiers, respectively. For disease-targeted classification, only 27.6% top-1 accuracy and 57.9% top-5 accuracy are achieved with a mean average precision (mAP) of 0.42. In contrast, for lesion-targeted classification, we can achieve a much higher mAP of 0.70.","","Electronic:978-1-5090-4847-2; POD:978-1-5090-4848-9","10.1109/ICPR.2016.7899659","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7899659","convolutional neural networks;skin disease classification;skin lesion characterization","Dermatology;Diseases;Lesions;Malignant tumors;Skin;Training;Visualization","diseases;medical image processing;neural nets;skin","CNN;automated diagnosis system;computer aided skin disease diagnosis;convolutional neutral networks;disease-targeted classification;ground truth diagnosis labels;lesion-targeted classifications;lesion-targeted classifiers;mean average precision;multilabel deep neural networks;publicly available dermatology atlantes;robust diagnosis;robust skin disease diagnosis;skin disease classification;skin lesion characteristics;skin lesion characterization","","","","","","","","4-8 Dec. 2016","","IEEE","IEEE Conference Publications"
"Severity grading of psoriatic plaques using deep CNN based multi-task learning","A. Pal; A. Chaturvedi; U. Garain; A. Chandra; R. Chatterjee","CVPR Unit, Indian Statistical Unit, Kolkata 700108, West Bengal, India","2016 23rd International Conference on Pattern Recognition (ICPR)","20170424","2016","","","1478","1483","This paper addresses the problem of automatic machine analysis based severity scoring of psoriasis skin disease. Three different disease parameters namely, erythema, scaling and induration are considered for such severity grading. Given an image containing a psoriatic plaque the task is to predict severity scores for all the three parameters. This paper presents a novel deep CNN based architecture for achieving the task. Apart from viewing this task as three different single task learning (STL) problems (i.e. three different classification problems), a new multi-task learning (MTL) is also presented where the three classification tasks are treated as interdependent and thereby the neural net is trained accordingly. A new annotated dataset consisting of seven hundred and seven (707) images has been constructed on which the performance of the severity scoring algorithms have been reported. Several competing baselines are considered to compare the performance of STL and MTL approaches. Experimental result shows that the deep CNN based architectures (both the STL and MTL) achieve promising performances, MTL producing slightly superior results to that of STL.","","Electronic:978-1-5090-4847-2; POD:978-1-5090-4848-9","10.1109/ICPR.2016.7899846","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7899846","","Computer architecture;Convolution;Diseases;Drugs;Estimation;Kernel;Skin","diseases;image classification;learning (artificial intelligence);medical image processing;neural net architecture","MTL;automatic machine analysis;deep CNN based architecture;deep CNN based multitask learning;disease parameters;erythema;image classification tasks;induration;neural net;psoriasis skin disease;psoriatic plaque severity grading;scaling;severity scoring algorithms;single task learning problem","","","","","","","","4-8 Dec. 2016","","IEEE","IEEE Conference Publications"
"Deep learning for magnification independent breast cancer histopathology image classification","N. Bayramoglu; J. Kannala; J. Heikkilä","Center for Machine Vision and Signal Analysis, University of Oulu, Finland","2016 23rd International Conference on Pattern Recognition (ICPR)","20170424","2016","","","2440","2445","Microscopic analysis of breast tissues is necessary for a definitive diagnosis of breast cancer which is the most common cancer among women. Pathology examination requires time consuming scanning through tissue images under different magnification levels to find clinical assessment clues to produce correct diagnoses. Advances in digital imaging techniques offers assessment of pathology images using computer vision and machine learning methods which could automate some of the tasks in the diagnostic pathology workflow. Such automation could be beneficial to obtain fast and precise quantification, reduce observer variability, and increase objectivity. In this work, we propose to classify breast cancer histopathology images independent of their magnifications using convolutional neural networks (CNNs). We propose two different architectures; single task CNN is used to predict malignancy and multi-task CNN is used to predict both malignancy and image magnification level simultaneously. Evaluations and comparisons with previous results are carried out on BreaKHis dataset. Experimental results show that our magnification independent CNN approach improved the performance of magnification specific model. Our results in this limited set of training data are comparable with previous state-of-the-art results obtained by hand-crafted features. However, unlike previous methods, our approach has potential to directly benefit from additional training data, and such additional data could be captured with same or different magnification levels than previous data.","","Electronic:978-1-5090-4847-2; POD:978-1-5090-4848-9","10.1109/ICPR.2016.7900002","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7900002","","Breast cancer;Databases;Microscopy;Pathology;Training;Training data","cancer;computer vision;image classification;learning (artificial intelligence);medical image processing;neural nets","BreaKHis dataset;breast tissues;computer vision;convolutional neural networks;deep learning;diagnostic pathology workflow;digital imaging techniques;image classification;machine learning;magnification independent breast cancer histopathology image classification;microscopic analysis;multitask CNN;single task CNN","","","","","","","","4-8 Dec. 2016","","IEEE","IEEE Conference Publications"
"Skin lesion segmentation in clinical images using deep learning","M. H. Jafari; N. Karimi; E. Nasr-Esfahani; S. Samavi; S. M. R. Soroushmehr; K. Ward; K. Najarian","Department of Electrical and Computer Engineering, Isfahan University of Technology, 84156-83111 Iran","2016 23rd International Conference on Pattern Recognition (ICPR)","20170424","2016","","","337","342","Melanoma is the most aggressive form of skin cancer and is on rise. There exists a research trend for computerized analysis of suspicious skin lesions for malignancy using images captured by digital cameras. Analysis of these images is usually challenging due to existence of disturbing factors such as illumination variations and light reflections from skin surface. One important stage in diagnosis of melanoma is segmentation of lesion region from normal skin. In this paper, a method for accurate extraction of lesion region is proposed that is based on deep learning approaches. The input image, after being preprocessed to reduce noisy artifacts, is applied to a deep convolutional neural network (CNN). The CNN combines local and global contextual information and outputs a label for each pixel, producing a segmentation mask that shows the lesion region. This mask will be further refined by some post processing operations. The experimental results show that our proposed method can outperform the existing state-of-the-art algorithms in terms of segmentation accuracy.","","Electronic:978-1-5090-4847-2; POD:978-1-5090-4848-9","10.1109/ICPR.2016.7899656","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7899656","Melanoma;convolutional neural network;deep learning;medical image segmentation;skin cancer","Feature extraction;Image segmentation;Lesions;Lighting;Machine learning;Malignant tumors;Skin","cancer;convolution;image segmentation;learning (artificial intelligence);medical image processing;neural nets","CNN;clinical images;computerized analysis;convolutional neural network;deep learning approaches;digital cameras;global contextual information;illumination variations;lesion region extraction;light reflections;local contextual information;melanoma;noisy artifacts reduction;normal skin;post processing operations;segmentation accuracy;segmentation mask;skin cancer;skin lesion segmentation","","","","","","","","4-8 Dec. 2016","","IEEE","IEEE Conference Publications"
"Quantifying radiographic knee osteoarthritis severity using deep convolutional neural networks","J. Antony; K. McGuinness; N. E. O'Connor; K. Moran","Insight Centre for Data Analytics, Dublin City University, Ireland","2016 23rd International Conference on Pattern Recognition (ICPR)","20170424","2016","","","1195","1200","This paper proposes a new approach to automatically quantify the severity of knee osteoarthritis (OA) from radiographs using deep convolutional neural networks (CNN). Clinically, knee OA severity is assessed using Kellgren & Lawrence (KL) grades, a five point scale. Previous work on automatically predicting KL grades from radiograph images were based on training shallow classifiers using a variety of hand engineered features. We demonstrate that classification accuracy can be significantly improved using deep convolutional neural network models pre-trained on ImageNet and fine-tuned on knee OA images. Furthermore, we argue that it is more appropriate to assess the accuracy of automatic knee OA severity predictions using a continuous distance-based evaluation metric like mean squared error than it is to use classification accuracy. This leads to the formulation of the prediction of KL grades as a regression problem and further improves accuracy. Results on a dataset of X-ray images and KL grades from the Osteoarthritis Initiative (OAI) show a sizable improvement over the current state-of-the-art.","","Electronic:978-1-5090-4847-2; POD:978-1-5090-4848-9","10.1109/ICPR.2016.7899799","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7899799","Convolutional neural network;KL grades;Knee osteoarthritis;classification;regression;wndchrm","Feature extraction;Indexes;Neural networks;Osteoarthritis;Radiography;Support vector machines;Training","X-ray imaging;image classification;medical image processing;neural nets;radiography","CNN;ImageNet;KL grades;OAI;Osteoarthritis Initiative;X-ray images;automatic knee OA severity predictions;continuous distance-based evaluation;deep convolutional neural network models;knee OA images;mean squared error;radiograph images;radiographic knee osteoarthritis severity;radiographs;regression problem","","","","","","","","4-8 Dec. 2016","","IEEE","IEEE Conference Publications"
"Optic Disc Detection Using Fine Tuned Convolutional Neural Networks","F. Calimeri; A. Marzullo; C. Stamile; G. Terracina","Dept. of Math. & Comput. Sci., Univ. of Calabria, Rende, Italy","2016 12th International Conference on Signal-Image Technology & Internet-Based Systems (SITIS)","20170424","2016","","","69","75","The detection of the Optic Disc (OD) is an significant step in retinal fundus images analysis, it allows to extract relevant information that proved to be useful for the prevention of several pathologies, such as glaucoma, hypertension, diabetes and other cardiovascular diseases, which manifest their effects in the retina. In this work we present a supervised method for automatically detecting the position of the Optic Disc in retinal fundus digital images, the goal has been achieved by means of a proper reuse of previous knowledge from a pre-trained Convolutional Neural Network (CNN), already able to detect faces in an image. Experimental analyses showed high level of accuracy in the detection of the optic disc on the DRIVE, STARE and DRIONS databases.","","Electronic:978-1-5090-5698-9; POD:978-1-5090-5699-6","10.1109/SITIS.2016.20","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7907447","Convolutional Neural Networks;Fine Tuning;Fundus Image;Optic Disc Detection;Transfer Learning","Biomedical optical imaging;Feature extraction;Neural networks;Optical computing;Optical fiber networks;Optical imaging;Retina","feature extraction;medical image processing;neural nets;object detection","CNN;DRIONS database;DRIVE database;OD;STARE database;fine tuned convolutional neural networks;information extraction;optic disc detection;pathologies prevention;retinal fundus image analysis","","","","","","","","Nov. 28 2016-Dec. 1 2016","","IEEE","IEEE Conference Publications"
"Hybrid deep learning for Reflectance Confocal Microscopy skin images","P. Kaur; K. J. Dana; G. O. Cula; M. C. Mack","Department of Electrical and Computer Engineering, Rutgers University, NJ, USA","2016 23rd International Conference on Pattern Recognition (ICPR)","20170424","2016","","","1466","1471","Reflectance Confocal Microscopy (RCM) is used for evaluation of human skin disorders and the effects of skin treatments by imaging the skin layers at different depths. Traditionally, clinical experts manually categorize the images captured into different skin layers. This time-consuming labeling task impedes the convenient analysis of skin image datasets. In recent automated image recognition tasks, deep learning with convolutional neural nets (CNN) has achieved remarkable results. However in many clinical settings, training data is often limited and insufficient for CNN training. For recognition of RCM skin images, we demonstrate that a CNN trained on a moderate size dataset leads to low accuracy. We introduce a hybrid deep learning approach which uses traditional texton-based feature vectors as input to train a deep neural network. This hybrid method uses fixed filters in the input layer instead of tuned filters, yet superior performance is achieved. Our dataset consists of 1500 images from 15 RCM stacks belonging to six different categories of skin layers. We show that our hybrid deep learning approach performs with a test accuracy of 82% compared with 51% for CNN. We also compare the results with additional proposed methods for RCM image recognition and show improved accuracy.","","Electronic:978-1-5090-4847-2; POD:978-1-5090-4848-9","10.1109/ICPR.2016.7899844","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7899844","","Epidermis;Histograms;Image recognition;Libraries;Machine learning;Neural networks","convolution;data analysis;filtering theory;image recognition;learning (artificial intelligence);medical image processing;microscopy;vectors;visual databases","CNN training;RCM;automated image recognition tasks;clinical experts;convolutional neural nets;fixed filters;human skin disorders;hybrid deep learning approach;reflectance confocal microscopy skin images;skin image datasets;skin layers;traditional texton-based feature vectors","","","","","","","","4-8 Dec. 2016","","IEEE","IEEE Conference Publications"
"HEp-2 specimen classification via deep CNNs and pattern histogram","Hongwei Li; Hao Huang; W. S. Zheng; Xiaohua Xie; J. Zhang","School of Data and Computer Science, Sun Yat-sen University, Guangzhou, China","2016 23rd International Conference on Pattern Recognition (ICPR)","20170424","2016","","","2145","2149","Automatic classification of Human Epithelial Type-2 (HEp-2) specimen patterns is an important yet challenging problem in medical image analysis. Most prior works have primarily focused on cells images classification problem which is one of the early essential steps in the system pipeline, while less attention has been paid to the classification of whole-specimen ones. In this work, a specimen pattern recognition system combining convolutional neural networks (CNNs) and pattern histogram was proposed. The pattern histograms were obtained based on the prediction of each single cell inside the specimens. Two strategies were designed to predicted the pattern of a whole specimen: 1) the most dominant cell pattern in pattern histogram was represented as the specimen pattern, 2) the pattern histograms were employed as bags of patterns and then were trained and predicted separately by a SVM classifier. Experimental results show that the proposed system is effective and achieves high classification accuracy on public benchmark datasets. We further evaluate the robustness of the proposed framework by testing trained CNNs on another different dataset, demonstrating that the system is robust to inter-lab data.","","Electronic:978-1-5090-4847-2; POD:978-1-5090-4848-9","10.1109/ICPR.2016.7899953","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7899953","","Convolution;Feature extraction;Histograms;Image segmentation;Neural networks;Support vector machines;Training","biology computing;feedforward neural nets;image classification;support vector machines","HEp-2 specimen classification;SVM classifier;cells images classification problem;convolutional neural networks;deep CNN;human epithelial type-2 specimen patterns;interlab data;medical image analysis;pattern histogram;pattern histograms;specimen pattern recognition system;system pipeline","","","","","","","","4-8 Dec. 2016","","IEEE","IEEE Conference Publications"
"Deep convolutional neural network based HEp-2 cell classification","Xi Jia; Linlin Shen; Xiande Zhou; Shiqi Yu","Computer Vision Institute, College of Computer Science and Software Engineering, Shenzhen University, China","2016 23rd International Conference on Pattern Recognition (ICPR)","20170424","2016","","","77","80","As different staining patterns of HEp-2 cells indicate different diseases, the classification of Indirect Immune Fluorescence (IIF) images on Human Epithelial-2 (HEp-2) cell is important for clinical applications. Different from traditional pattern recognition techniques, we use CNN to extract more high-level features for cell images classification. Compared to the existing CNN based HEp-2 classification methods, we proposed a network with deeper architecture. A class-balanced approach is also proposed to augment the HEp-2 cell dataset for network training. The proposed framework achieves an average class accuracy of 79.29% on ICPR 2012 HEp-2 dataset and a mean class accuracy of 98.26% on ICPR 2016 HEp-2 training set.","","Electronic:978-1-5090-4847-2; POD:978-1-5090-4848-9","10.1109/ICPR.2016.7899611","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7899611","CNN;Hep-2;class-balanced;classification","Computer architecture;Feature extraction;Immune system;Microprocessors;Pattern recognition;Testing;Training","cellular biophysics;diseases;feature extraction;image classification;medical image processing;neural net architecture","CNN;HEp-2 cell classification;IIF cell image classification;class-balanced approach;clinical applications;deep convolutional neural network;diseases;high-level feature extraction;human epithelial-2 cell;indirect immune fluorescence image classification;network training;pattern recognition techniques;staining patterns","","","","","","","","4-8 Dec. 2016","","IEEE","IEEE Conference Publications"
"A temporal deep learning approach for MR perfusion parameter estimation in stroke","K. C. Ho; F. Scalzo; K. V. Sarma; S. El-Saden; C. W. Arnold","Medical Imaging Informatics Group, Department of Radiological Sciences, University of California Los Angeles, 90024, USA","2016 23rd International Conference on Pattern Recognition (ICPR)","20170424","2016","","","1315","1320","Perfusion magnetic resonance (MR) images are often used in the assessment of acute ischemic stroke to distinguish between salvageable tissue and infarcted core. Deconvolution methods such as singular value decomposition have been used to approximate model-based perfusion parameters from these images. However, studies have shown that these existing deconvolution algorithms can introduce distortions that may negatively influence the utility of these parameter maps. There is limited previous work on utilizing machine learning algorithms to estimate perfusion parameters. In this work, we present a novel bi-input convolutional neural network (bi-CNN) to approximate four perfusion parameters without using an explicit deconvolution method. These bi-CNNs produced good approximations for all four parameters, with relative average root-mean-square errors (ARMSEs) ≤ 5% of the maximum values. We further demonstrate the utility of the estimated perfusion maps for quantifying the salvageable tissue volume in stroke, with more than 80% agreement with the ground truth. These results show that deep learning techniques are a promising tool for perfusion parameter estimation without requiring a standard deconvolution process.","","Electronic:978-1-5090-4847-2; POD:978-1-5090-4848-9","10.1109/ICPR.2016.7899819","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7899819","","Biological neural networks;Biological tissues;Convolution;Deconvolution;Estimation;Imaging;Parameter estimation","approximation theory;biological tissues;biomedical MRI;deconvolution;feedforward neural nets;haemorheology;learning (artificial intelligence);medical signal processing;parameter estimation;singular value decomposition","MR perfusion parameter estimation;acute ischemic stroke assessment;bi-CNN;bi-input convolutional neural network;infarcted core;model-based perfusion parameters;perfusion magnetic resonance images;perfusion parameter approximation;relative average root-mean-square errors;salvageable tissue volume;singular value decomposition;temporal deep learning","","","","","","","","4-8 Dec. 2016","","IEEE","IEEE Conference Publications"
"A deep learning approach to monitoring and detecting atrial fibrillation using wearable technology","S. P. Shashikumar; A. J. Shah; Q. Li; G. D. Clifford; S. Nemati","School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA 30332","2017 IEEE EMBS International Conference on Biomedical & Health Informatics (BHI)","20170413","2017","","","141","144","Atrial Fibrillation (AF) is the most common cardiac arrhythmia in clinical practice, with a prevalence of 2% in the community. Not only it is associated with reduced quality of life, but also increased risk of stroke and myocardial infarction. Unfortunately, many cases of AF are clinically silent and undiagnosed, but long-term monitoring is difficult. Nonetheless, efforts at monitoring at-risk individuals and detecting clinically silent AF may yield significant public health benefit, as individuals with new-onset, asymptomatic AF would receive preventive therapies with anticoagulants and beta-blockers, for example. Wearables have enormous potential to provide low-risk and low-cost long-term monitoring of AF, but signals from such devices suffer from significant movement related noise that resembles AF. This work presents a robust approach to AF detection in a sequence of short windows with significant movement artifact. Pulsatile photoplethysmographic (PPG) data and triaxial accelerometry from 98 subjects (45 with AF and 53 with other rhythms) were captured using a multichannel wrist-worn device. A single channel electrocardiogram (ECG) was recorded (for rhythm verification only) simultaneously. A novel deep neural network approach to classify AF from wrist-worn PPG signals was developed on this data. A continuous wavelet transform was applied to the PPG data and a convolutional neural network (CNN) was trained on the derived spectrograms to detect AF. Combining the output of the CNN with features calculated based on beat-to-beat variability and signal quality provided a significant accuracy boost. Leave-one-out cross validation resulted in a pooled AUC of 0.95 (Accuracy=91.8%). The proposed approach resulted in a novel robust and accurate algorithm for detection of AF from PPG data, which is scalable and likely to improve in accuracy as the dataset size continues to expand.","","Electronic:978-1-5090-4179-4; POD:978-1-5090-4180-0","10.1109/BHI.2017.7897225","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7897225","","Biomedical monitoring;Detection algorithms;Electrocardiography;Feature extraction;Heart beat;Wavelet transforms","accelerometers;diseases;electrocardiography;medical signal processing;neural nets;photoplethysmography;wavelet transforms","ECG;PPG data;atrial fibrillation detection;atrial fibrillation monitoring;cardiac arrhythmia;continuous wavelet transform;convolutional neural network;deep learning approach;deep neural network;electrocardiogram;multichannel wrist-worn device;myocardial infarction;pulsatile photoplethysmographic data;signal quality;triaxial accelerometry;wearable technology;wrist-worn PPG signal","","","","","","","","16-19 Feb. 2017","","IEEE","IEEE Conference Publications"
"Low quality dermal image classification using transfer learning","M. S. Elmahdy; S. S. Abdeldayem; I. A. Yassine","Systems and Biomedical Department, Faculty of Engineering, Cairo University. Giza, Egypt","2017 IEEE EMBS International Conference on Biomedical & Health Informatics (BHI)","20170413","2017","","","373","376","In this study, we investigate three class skin lesion classification problem of a low quality and small size dataset using transfer learning using AlexNet deep Convolutional Neural Network (CNN). Our approach involves modifying the pre-trained AlexNet model; through replacing the decision layer to be compatible with our three class problem. In addition, we propose adding two dropout layers to overcome the over fitting problem. The fine tuning process of the complete network, based on stochastic gradient descent, is performed using skin lesion dataset. Furthermore, we investigated augmenting the original dataset through three flipping directions and sixteen rotation angles processes using a new methodology. The proposed algorithm has been compared with a hand crafted features, based on Local Binary Pattern (LBP) representation followed by Support Vector Machine (SVM) classifier. Increasing the dataset size has dramatically boosted the performance of classifiers achieving accuracy of 98.67% for the modified AlexNet compared to 96.8% using the LBP based system.","","Electronic:978-1-5090-4179-4; POD:978-1-5090-4180-0","10.1109/BHI.2017.7897283","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7897283","","Diseases;Feature extraction;Lesions;Neural networks;Skin;Support vector machines;Tuning","biomedical optical imaging;convolutional codes;image classification;medical image processing;neural nets;skin;support vector machines","AlexNet deep convolutional neural network;CNN;LBP;SVM;class skin lesion classification;local binary pattern representation;low quality dermal image classification;stochastic gradient descent;support vector machine classifier;transfer learning","","","","","","","","16-19 Feb. 2017","","IEEE","IEEE Conference Publications"
"Augmenting data when training a CNN for retinal vessel segmentation: How to warp?","A. Oliveira; S. Pereira; C. A. Silva","CMEMS-UMinho Research Unit, University of Minho, Guimar&#x00E3;es, Portugal","2017 IEEE 5th Portuguese Meeting on Bioengineering (ENBENG)","20170330","2017","","","1","4","The retinal vascular condition is a trustworthy biomarker of several ophthalmologic and cardiovascular diseases, so automatic vessel segmentation is a crucial step to diagnose and monitor these problems. Deep Learning models have recently revolutionized the state-of-the-art in several fields, since they can learn features with multiple levels of abstraction from the data itself. However, these methods can easily fall into overfitting, since a huge number of parameters must be learned. Having bigger datasets may act as regularization and lead to better models. Yet, acquiring and manually annotating images, especially in the medical field, can be a long and costly procedure. Hence, when using regular datasets, people heavily need to apply artificial data augmentation. In this work, we use a fully convolutional neural network capable of reaching the state-of-the-art. Also, we investigate the benefits of augmenting data with new samples created by warping retinal fundus images with nonlinear transformations. Our results hint that may be possible to halve the amount of data, while maintaining the same performance.","","Electronic:978-1-5090-4801-4; POD:978-1-5090-4802-1","10.1109/ENBENG.2017.7889443","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7889443","Convolutional neural network;Data augmentation;Retinal blood vessel segmentation","Data mining;Image segmentation;Neural networks;Retinal vessels;Training;Two dimensional displays","biomedical optical imaging;blood vessels;cardiovascular system;diseases;eye;image segmentation;learning (artificial intelligence);medical image processing;neural nets;vision defects","CNN;artificial data augmentation;automatic vessel segmentation;biomarker;cardiovascular diseases;deep Learning models;fully convolutional neural network;medical field;nonlinear transformations;ophthalmologic diseases;regular datasets;retinal fundus images;retinal vascular condition;retinal vessel segmentation","","","","","","","","16-18 Feb. 2017","","IEEE","IEEE Conference Publications"
"A Digital Pathology application for whole-slide histopathology image analysis based on genetic algorithm and Convolutional Networks","M. Puerto; T. Vargas; A. Cruz-Roa","GITECX Research Group, University of Los Llanos, Colombia","2016 IEEE Latin American Conference on Computational Intelligence (LA-CCI)","20170327","2016","","","1","7","The last decade Digital Pathology is coming as a relevant and promising area for cancer research and clinical practice thanks to two main trends, 1) the availability of whole slide scanners for complete pathology slide digitalization, and 2) the development of several computational method for histopathology image analysis. However, there are very few works addressed to analyze the whole-slide digitized images (WSI) because their large resolution (e.g. 80,000 × 80,000 pixels at 40× magnification) resulting in huge computational cost for automatic analysis. This paper presents an application design of a meta-heuristic optimization method based on a genetic algorithm (GA) for exploration and exploitation of regions of interest for diagnosis in a WSI in combination with a Convolutional Neural Network (CNN) trained in previous works [10], [11]. The preliminary results show that presented solution scales in computing time given the initial number of samples (initial population). The developed application in Java including the GA method for WSI analysis could be used for diagnosis support by pathologists thanks of its usability and visual interpretability through a probability map of the invasive tumor regions in the WSI.","","Electronic:978-1-5090-5105-2; POD:978-1-5090-5106-9; USB:978-1-5090-5104-5","10.1109/LA-CCI.2016.7885738","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7885738","Adaptive Sampling;Convolutional Neural Network;Digital pathology;Genetic Algorithm;Whole-Slide Imaging","Biological cells;Cancer;Genetic algorithms;Pathology;Sociology;Statistics;Tumors","cancer;genetic algorithms;learning (artificial intelligence);medical image processing;neural nets;tumours","CNN training;Java;WSI analysis;cancer research;clinical practice;complete pathology slide digitalization;convolutional neural network;diagnosis;digital pathology application;genetic algorithm;invasive tumor region;metaheuristic optimization method;probability map;visual interpretability;whole slide scanner;whole-slide digitized image;whole-slide histopathology image analysis","","","","","","","","2-4 Nov. 2016","","IEEE","IEEE Conference Publications"
"Multimodal learning using convolution neural network and Sparse Autoencoder","Tien Duong Vu; Hyung-Jeong Yang; V. Q. Nguyen; A-Ran Oh; Mi-Sun Kim","Department of Electronics and Computer Engineering, Chonnam National University, Gwangju, South Korea","2017 IEEE International Conference on Big Data and Smart Computing (BigComp)","20170320","2017","","","309","312","In the last decade, pattern recognition methods using neuroimaging data for the diagnosis of Alzheimer's disease (AD) have been the subject of extensive research. Deep learning has recently been a great interest in AD classification. Previous works had done almost on single modality dataset, such as Magnetic Resonance Imaging (MRI) or Positron Emission Tomography (PET), shown high performances. However, identifying the distinctions between Alzheimer's brain data and healthy brain data in older adults (age > 75) is challenging due to highly similar brain patterns and image intensities. The corporation of multimodalities can solve this issue since it discovers and uses the further complementary of hidden biomarkers from other modalities instead of only one, which itself cannot provide. We therefore propose a deep learning method on fusion multimodalities. In details, our approach includes Sparse Autoencoder (SAE) and convolution neural network (CNN) train and test on combined PET-MRI data to diagnose the disease status of a patient. We focus on advantages of multimodalities to help providing complementary information than only one, lead to improve classification accuracy. We conducted experiments in a dataset of 1272 scans from ADNI study, the proposed method can achieve a classification accuracy of 90% between AD patients and healthy controls, demonstrate the improvement than using only one modality.","","Electronic:978-1-5090-3015-6; POD:978-1-5090-3016-3; USB:978-1-5090-3014-9","10.1109/BIGCOMP.2017.7881683","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7881683","Alzheimer's disease;MRI;PET;autoencoder;convolutional neural network;deep learning","Biological neural networks;Convolution;Feature extraction;Magnetic resonance imaging;Positron emission tomography;Support vector machines;Three-dimensional displays","biomedical MRI;brain;convolution;diseases;image classification;image coding;image fusion;learning (artificial intelligence);medical image processing;neural nets;positron emission tomography","Alzheimer disease diagnosis;convolution neural network;deep learning method;image fusion multimodalities;magnetic resonance imaging;multimodal learning method;neuroimaging data;pattern recognition methods;positron emission tomography;sparse autoencoder","","","","","","","","13-16 Feb. 2017","","IEEE","IEEE Conference Publications"
"Ischemic stroke identification based on EEG and EOG using ID convolutional neural network and batch normalization","E. P. Giri; M. I. Fanany; A. M. Arymurthy; S. K. Wijaya","Computer Sciences Department, Faculty of Mathematics and Natural Sciences, Bogor Agricultural University, Bogor 16680, West Java, Indonesia","2016 International Conference on Advanced Computer Science and Information Systems (ICACSIS)","20170309","2016","","","484","491","In 2015, stroke was the number one cause of death in Indonesia. The majority type of stroke is ischemic. The standard tool for diagnosing stroke is CT-Scan. For developing countries like Indonesia, the availability of CT-Scan is very limited and still relatively expensive. Because of the availability, another device that potential to diagnose stroke in Indonesia is EEG. Ischemic stroke occurs because of obstruction that can make the cerebral blood flow (CBF) on a person with stroke has become lower than CBF on a normal person (control) so that the EEG signal have a deceleration. On this study, we perform the ability of ID Convolutional Neural Network (1DCNN) to construct classification model that can distinguish the EEG and EOG stroke data from EEG and EOG control data. To accelerate training process our model we use Batch Normalization. Involving 62 person data object and from leave one out the scenario with five times repetition of measurement we obtain the average of accuracy 0.86 (F-Score 0.861) only at 200 epoch. This result is better than all over shallow and popular classifiers as the comparator (the best result of accuracy 0.69 and F-Score 0.72). The feature used in our study were only 24 handcrafted feature with simple feature extraction process.","","Electronic:978-1-5090-4629-4; POD:978-1-5090-4630-0; USB:978-1-5090-4628-7","10.1109/ICACSIS.2016.7872780","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7872780","EEG;ID CNN;deep learning;ischemic;stroke","Brain modeling;Computed tomography;Convolution;Electroencephalography;Electrooculography;Feature extraction;Hospitals","blood;convolution;electro-oculography;electroencephalography;feature extraction;medical signal processing;neural nets;patient diagnosis","1D convolutional neural network;1DCNN;CBF;CT-Scan;EEG;EOG;batch normalization;cerebral blood flow;electroencephalography;electrooculography;feature extraction;ischemic stroke identification;stroke diagnosis","","","","","","","","15-16 Oct. 2016","","IEEE","IEEE Conference Publications"
"Simultaneous reconstruction and restoration of sparsely sampled optical coherence tomography image through learning separable filters for deep architectures","S. P. K. Karri; N. Garai; D. Nawn; S. Ghosh; D. Chakraborty; J. Chatterjee","IIT Kharagpur, Kharagpur, India 721302","2016 IEEE Students&#8217; Technology Symposium (TechSym)","20170309","2016","","","52","55","Spectral domain optical coherence tomography (SD-OCT) is widely employed across ophthalmology practices for visual investigation of live tissues. The involuntary movements of subjects frequently infuse motion artifacts to SD-OCT images. Sub-sampling of signals is introduced in imaging protocol to avoid such artifacts which causes fall in spatial resolution and peak signal to noise ratio (PSNR). Sparse coding (SC) is opted for restoration and rectification of complete signals from sparse samples through constructing complete and sparse space dictionaries independently. Convolutional neural networks (CNN) can be casted as SC for jointly learning dictionaries resulting less number of CNN filters (equivalence of SC dictionaries) to be trained. The proposed approach extends the separable filters to CNN through architectural constrain. This results in a parallel architecture and reduced number of parameters without compromising on performance. The approach scaled down trainable parameters by 46% with a trade-off of 0.108 PSNR during training and 0.107 PSNR during testing in comparison to conventional CNN.","","Electronic:978-1-5090-5163-2; POD:978-1-5090-5164-9","10.1109/TechSym.2016.7872654","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7872654","convolutional neural network;denoising;image restoration;optical coherence tomography;separable filters;sparse coding","Convolution;Dictionaries;High definition video;Image restoration;Optical coherence tomography;Testing;Training","biological tissues;image restoration;medical image processing;neural nets;optical tomography","SD-OCT images;convolutional neural networks;deep architectures;learning separable filters;live tissues;ophthalmology;simultaneous image reconstruction;simultaneous image restoration;sparse coding;sparsely sampled optical coherence tomography image;spatial resolution;spectral domain optical coherence tomography","","","","","","","","Sept. 30 2016-Oct. 2 2016","","IEEE","IEEE Conference Publications"
"HEp-2 Cell Image Classification With Deep Convolutional Neural Networks","Z. Gao; L. Wang; L. Zhou; J. Zhang","School of Computing and Information Technology, University of Wollongong, Wollongong, NSW, Australia","IEEE Journal of Biomedical and Health Informatics","20170303","2017","21","2","416","428","Efficient Human Epithelial-2 cell image classification can facilitate the diagnosis of many autoimmune diseases. This paper proposes an automatic framework for this classification task, by utilizing the deep convolutional neural networks (CNNs) which have recently attracted intensive attention in visual recognition. In addition to describing the proposed classification framework, this paper elaborates several interesting observations and findings obtained by our investigation. They include the important factors that impact network design and training, the role of rotation-based data augmentation for cell images, the effectiveness of cell image masks for classification, and the adaptability of the CNN-based classification system across different datasets. Extensive experimental study is conducted to verify the above findings and compares the proposed framework with the well-established image classification models in the literature. The results on benchmark datasets demonstrate that 1) the proposed framework can effectively outperform existing models by properly applying data augmentation, 2) our CNN-based framework has excellent adaptability across different datasets, which is highly desirable for cell image classification under varying laboratory settings. Our system is ranked high in the cell image classification competition hosted by ICPR 2014.","2168-2194;21682194","","10.1109/JBHI.2016.2526603","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7400923","Deep convolutional neural networks;indirect immunofluorescence (IIF);staining patterns classification","Brain models;Computer architecture;Feature extraction;Informatics;Microprocessors;Visualization","biomedical optical imaging;cancer;cellular biophysics;fluorescence;image classification;medical image processing;neural nets","CNN-based classification system;HEp-2 cell image classification;ICPR 2014;autoimmune disease diagnosis;benchmark datasets;cell image classification competition;cell image masks;data augmentation;deep convolutional neural networks;human epithelial-2 cell image classification task;impact network design;impact network training;rotation-based data augmentation;visual recognition","","","","","","","20160208","March 2017","","IEEE","IEEE Journals & Magazines"
"Subject-specific detection of ventricular tachycardia using convolutional neural networks","B. S. Chandra; C. S. Sastry; S. Jana","Indian Institute of Technology, Hyderabad, Telangana, India","2016 Computing in Cardiology Conference (CinC)","20170302","2016","","","53","56","Onset of ventricular tachycardia (VT) is clinically significant, including as a trigger to defibrillator implants. In this paper, we propose a reliable technique to detect such onset using convolutional neural networks (CNNs). The proposed CNN adds convolution and pooling layers below the input layer and above the hidden and output layers of usual neural network (NN). Such layers would learn suitable linear features from training data, while eliminating the need to extract the traditionally used adhoc features. Employing such subject-specific features, we reported the performance of the proposed classifier using Creighton University ventricular tachyarrhythmia database (CUVT). In particular, we achieved mean (± standard deviation) performance of 95.6 (± 00.6) using subject-specific evaluation scheme over 100 random independent iterations.","","Electronic:978-1-5090-0895-7; POD:978-1-5090-0896-4","10.23919/CIC.2016.7868677","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7868677","","Convolution;Databases;Electrocardiography;Feature extraction;Neural networks;Standards;Training","electrocardiography;medical disorders;medical signal processing;neural nets;pattern classification;prosthetics","CUVT;Creighton University ventricular tachyarrhythmia database;classifier;convolutional neural network;defibrillator implant;ventricular tachycardia detection","","","","","","","","11-14 Sept. 2016","","IEEE","IEEE Conference Publications"
"Classification of heart sound recordings using convolution neural network","H. Ryu; J. Park; H. Shin","Industrial and Systems Engineering, Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea","2016 Computing in Cardiology Conference (CinC)","20170302","2016","","","1153","1156","Aims: This study proposes a cardiac diagnostic model using convolution neural network (CNN). This model can predict whether a heart sound recording is normal or not by classifying phonocardiograms (PCGs) from both clinical and non-clinical environments - in accordance with the “2016 Physionet/CinCChallenge”. Methods: Heart sound recordings in the training data set are filtered by using Windowed-sinc Hamming filter algorithm to remove signals regarded as noise. The filtered recordings are then scaled and segmented. Using the filtered and segmented recordings, CNN is trained to extract features and construct a classification function. The CNN is trained by back propagation algorithm with stochastic gradient descent and mini-batch learning. To classify one sound recording, the signal should be filtered and segmented. Each segment of the signal is then classified by the trained CNN model. The model assigns each segment signal a relative probability between normal and abnormal labels. By accumulating these relative probability values for all the segmented signals, one can reliably and robustly determine whether the target signal is normal or abnormal. Results: The proposed model achieved an overall score of 79.5 with a sensitivity of 70.8 and a specificity of 88.2.","","Electronic:978-1-5090-0895-7; POD:978-1-5090-0896-4","10.23919/CIC.2016.7868952","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7868952","","Classification algorithms;Convolution;Feature extraction;Filtering;Filtering algorithms;Heart;Hidden Markov models","bioacoustics;biomedical ultrasonics;cardiology;feature extraction;filters;medical signal processing;neural nets;signal classification;signal denoising","Windowed-sinc Hamming filter algorithm;back propagation algorithm;cardiac diagnostic model;convolution neural network;feature extraction;heart sound recording classification;phonocardiogram classification;signal classification;signal removal;signal segmentation","","","","","","","","11-14 Sept. 2016","","IEEE","IEEE Conference Publications"
"Heart sound classification using deep structured features","M. Tschannen; T. Kramer; G. Marti; M. Heinzmann; T. Wiatowski","Dept. IT & EE, ETH Zurich, Switzerland","2016 Computing in Cardiology Conference (CinC)","20170302","2016","","","565","568","We present a novel machine learning-based method for heart sound classification which we submitted to the PhysioNet/CinC Challenge 2016. Our method relies on a robust feature representation - generated by a wavelet-based deep convolutional neural network (CNN) - of each cardiac cycle in the test recording, and support vector machine classification. In addition to the CNN-based features, our method incorporates physiological and spectral features to summarize the characteristics of the entire test recording. The proposed method obtained a score, sensitivity, and specificity of 0.812, 0.848, and 0.776, respectively, on the hidden challenge testing set.","","Electronic:978-1-5090-0895-7; POD:978-1-5090-0896-4","10.23919/CIC.2016.7868805","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7868805","","Convolution;Feature extraction;Heart;Robustness;Sensitivity;Support vector machines;Wavelet transforms","bioacoustics;biomedical ultrasonics;cardiology;learning (artificial intelligence);medical signal processing;neural nets;signal classification;support vector machines","cardiac cycle;deep structured feature;feature representation;heart sound classification;machine learning method;support vector machine classification;wavelet-based deep convolutional neural network","","","","","","","","11-14 Sept. 2016","","IEEE","IEEE Conference Publications"
"Ensemble of feature-based and deep learning-based classifiers for detection of abnormal heart sounds","C. Potes; S. Parvaneh; A. Rahman; B. Conroy","Philips Research North America, Acute Care Solutions, Cambridge, MA, USA","2016 Computing in Cardiology Conference (CinC)","20170302","2016","","","621","624","The goal of the 2016 PhysioNet/CinC Challenge is the development of an algorithm to classify normal/abnormal heart sounds. A total of 124 time-frequency features were extracted from the phonocardiogram (PCG) and input to a variant of the AdaBoost classifier. A second classifier using convolutional neural network (CNN) was trained using PCGs cardiac cycles decomposed into four frequency bands. The final decision rule to classify normal/abnormal heart sounds was based on an ensemble of classifiers combining the outputs of AdaBoost and the CNN. The algorithm was trained on a training dataset (normal= 2575, abnormal= 665) and evaluated on a blind test dataset. Our classifier ensemble approach obtained the highest score of the competition with a sensitivity, specificity, and overall score of 0.9424, 0.7781, and 0.8602, respectively.","","Electronic:978-1-5090-0895-7; POD:978-1-5090-0896-4","10.23919/CIC.2016.7868819","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7868819","","Databases;Heart beat;Mel frequency cepstral coefficient;Phonocardiography;Sensitivity;Training","feature extraction;learning (artificial intelligence);medical signal processing;neural nets;pattern classification;phonocardiography;signal classification;time-frequency analysis","AdaBoost classifier;PCG cardiac cycle;abnormal heart sound detection;convolutional neural network;deep learning-based classifier;feature extraction;feature-based classifier;normal-abnormal heart sound classification;phonocardiogram;time-frequency analysis","","","","","","","","11-14 Sept. 2016","","IEEE","IEEE Conference Publications"
"Adaptive Estimation of Active Contour Parameters Using Convolutional Neural Networks and Texture Analysis","A. Hoogi; A. Subramaniam; R. Veerapaneni; D. L. Rubin","Departments of Biomedical Data Science, Radiology, and Medicine (Biomedical Informatics Research), Stanford University, Stanford, CA, USA","IEEE Transactions on Medical Imaging","20170301","2017","36","3","781","791","In this paper, we propose a generalization of the level set segmentation approach by supplying a novel method for adaptive estimation of active contour parameters. The presented segmentation method is fully automatic once the lesion has been detected. First, the location of the level set contour relative to the lesion is estimated using a convolutional neural network (CNN). The CNN has two convolutional layers for feature extraction, which lead into dense layers for classification. Second, the output CNN probabilities are then used to adaptively calculate the parameters of the active contour functional during the segmentation process. Finally, the adaptive window size surrounding each contour point is re-estimated by an iterative process that considers lesion size and spatial texture. We demonstrate the capabilities of our method on a dataset of 164 MRI and 112 CT images of liver lesions that includes low contrast and heterogeneous lesions as well as noisy images. To illustrate the strength of our method, we evaluated it against state of the art CNN-based and active contour techniques. For all cases, our method, as assessed by Dice similarity coefficients, performed significantly better than currently available methods. An average Dice improvement of 0.27 was found across the entire dataset over all comparisons. We also analyzed two challenging subsets of lesions and obtained a significant Dice improvement of 0.24 with our method (p <;0.001, Wilcoxon).","0278-0062;02780062","","10.1109/TMI.2016.2628084","10.13039/100000054 - National Cancer Institute, National Institutes of Health; ","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7742396","Active contours;adaptive parameters;convolutional neural network;image segmentation","Active contours;Adaptation models;Adaptive estimation;Image segmentation;Lesions;Level set;Neural networks","biomedical MRI;computerised tomography;feature extraction;image classification;image segmentation;image texture;iterative methods;liver;medical image processing;neural nets;probability","CNN-based techniques;CT images;Dice similarity coefficients;MRI images;active contour functional;active contour parameters;active contour techniques;adaptive estimation;adaptive window size;average Dice improvement;contour point;convolutional neural networks;feature extraction;heterogeneous lesions;image classification;iterative process;lesion size;level set contour location;level set segmentation;liver lesions;low contrast lesions;noisy images;output CNN probability;segmentation method;spatial texture;texture analysis","","","","","","","20161111","March 2017","","IEEE","IEEE Journals & Magazines"
"Prognostic Analysis of Polypoidal Choroidal Vasculopathy Using an Image-Based Approach","Y. M. Chen; W. Y. Lin; C. L. Tsai","Dept. of Comput. Sci. & Inf. Eng., Nat. Chung Cheng Univ., Chiayi, Taiwan","2016 International Computer Symposium (ICS)","20170220","2016","","","406","409","In this paper, we firstly propose to perform prognostic analysis of polypoidal choroidal vasculopathy (PCV) using indocyanine green angiography (ICGA) sequence. Our goal is to develop a computer-aided diagnostic system which can predict the likely treatment outcome of patients with PCV based on their before-treatment ICGA sequences. In order to create a prognostic model for PCV, we utilize both the before-treatment and the aftertreatment ICGA sequences collected in the EVEREST study. By comparing the before-treatment and the after-treatment PCV region in ICGA sequences, we can generate positive and negative samples for training our prognostic model. Here, we design an 8-layer convolution neural network (CNN) and use it to serve as the prognostic model. We have conducted experiments using 17 patients cases. In particular, we perform leave-one-out cross validation so that each patient can be utilized as testing case once. Our proposed method achieves promising results on the EVEREST dataset.","","Electronic:978-1-5090-3438-3; POD:978-1-5090-3439-0","10.1109/ICS.2016.0088","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7858510","indocyanine green angiography;polypoidal choroidal vasculopathy;prognostic analysis","Computers;Sensitivity","biomedical MRI;medical image processing;neural nets","CNN;ICGA sequences;PCV;after-treatment PCV region;before-treatment PCV region;computer-aided diagnostic system;convolution neural network;image-based approach;indocyanine green angiography sequence;leave-one-out cross validation;polypoidal choroidal vasculopathy;prognostic analysis","","","","","","","","15-17 Dec. 2016","","IEEE","IEEE Conference Publications"
"Brain tumor image segmentation based on convolution neural network","R. Lang; L. Zhao; K. Jia","Beijing Laboratory of Advanced Information Networks & College of Information and Communication, Beijing University of Technology, China","2016 9th International Congress on Image and Signal Processing, BioMedical Engineering and Informatics (CISP-BMEI)","20170216","2016","","","1402","1406","Automatic segmentation and early diagnosis of brain tumor is a challenging problem in computer vision and it can provide possibility for pre-operative planning, and solve the problem such as low accurateness and time-consuming in traditional manual segmentation. Under the mentioned problems above, this paper put forward a new method: Based on traditional convolutional neural networks (CNNs), a new architecture model is proposed for automatic brain tumor segmentation, which combines multi-modality images. The newly designed CNNs model automatically learns useful features from multi-modality images to combine multi-modality information. Experiment results show that the proposed model is more accurate than traditional methods and can provide reliable information for clinic treatments.","","Electronic:978-1-5090-3710-0; POD:978-1-5090-3711-7; USB:978-1-5090-3709-4","10.1109/CISP-BMEI.2016.7852936","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7852936","CNNs;brain tumor segmentation;multi-modality tumor image","Cancer;Computer architecture;Convolution;Feature extraction;Image segmentation;Tumors;Two dimensional displays","brain;computer vision;feature extraction;feedforward neural nets;image segmentation;medical image processing;tumours","CNN;automatic brain tumor image segmentation;brain tumor early diagnosis;clinic treatments;computer vision;convolution neural network;multimodality images;multimodality information;preoperative planning","","","","","","","","15-17 Oct. 2016","","IEEE","IEEE Conference Publications"
"Mitosis detection using convolutional neural network based features","A. Albayrak; G. Bilgin","Department of Computer Engineering, Signal and Image Processing Lab. (SIMPLAB), Yildiz Technical University, 34220 Istanbul, Turkey","2016 IEEE 17th International Symposium on Computational Intelligence and Informatics (CINTI)","20170209","2016","","","000335","000340","Breast cancer is the second leading cause of cancer death in women according to World Health Organization (WHO). Development of computer aided diagnostic (CAD) systems has great importance as a secondary reader systems for a correct diagnosis and treatment process. In this paper, a deep learning based feature extraction method by convolutional neural network (CNN) is proposed for automated mitosis detection for cancer diagnosis and grading by histopathological images. The proposed framework is tested on the MITOS data set provided for a contest on mitosis detection in breast cancer histological images released for research purposes in International Conference on Pattern Recognition (ICPR'2014). By using provided histopathological images, cellular structures are initially found by combined clustering based segmentation and blob analysis after preprocessing step. Then, obtained cellular image patches are cropped automatically from the histopathological images for feature extraction stage. CNN, which is a prominent deep learning method on image processing tasks, is utilized for extracting discriminative features. Due to the high dimensional output of the CNN, combination of PCA and LDA dimension reduction methods are performed respectively for regularization and dimension reduction process. Afterwards, a robust kernel based classifier, support vector machine (SVM), is used for final classification of mitotic and non-mitotic cells. The test results on MITOS data set prove that the proposed framework achieved promising results for mitosis detection on histopathological images.","","Electronic:978-1-5090-3909-8; POD:978-1-5090-3910-4; USB:978-1-5090-3908-1","10.1109/CINTI.2016.7846429","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7846429","","Breast cancer;Clustering algorithms;Feature extraction;Image segmentation;Kernel;Neural networks","cancer;feature extraction;image segmentation;medical image processing;neural nets;pattern clustering;principal component analysis;support vector machines","CAD systems;CNN;International Conference on Pattern Recognition;LDA dimension reduction methods;MITOS data set;PCA;SVM;WHO;World Health Organization;automated mitosis detection;blob analysis;breast cancer histological images;cancer death;cancer diagnosis;cellular image patches;cellular structures;clustering based segmentation;computer aided diagnostic systems;convolutional neural network;deep learning based feature extraction;deep learning method;dimension reduction process;histopathological images;image processing tasks;nonmitotic cells;regularization;robust kernel based classifier;secondary reader systems;support vector machine","","","","","","","","17-19 Nov. 2016","","IEEE","IEEE Conference Publications"
"Automatic segmentation of the left atrium from MR images via semantic information","Chunhua Deng; Xiaolong Zhang","College of Computer Science and Technology Wuhan University of Science and Technology, 430065, China","2016 IEEE International Conference on Systems, Man, and Cybernetics (SMC)","20170209","2016","","","003312","003316","Magnetic resonance imaging (MRI) can aid in assessing post-ablation scar formation. Automatic segmentation of left atrium (LA) offers great benefits for an accurate statistical assessment of LA region. However, how to robustly segment LA is still remaining as a challenging task for its high anatomical variability. In this paper, a robust segmentation method that exploits semantic information from different parts is proposed. The semantic correlation is exploited by the K Nearest Neighbor (KNN) search from corpus images with Convolutional Neural Network (CNN) features, which can be regarded as our main contribution. We propose a graph model to fuse semantic cues and eliminate accidental factors. Meanwhile, to optimize segmentation results, a super pixel voting method is also proposed. Experiments on public datasets of MRI image demonstrate the validity and accuracy of our semantic segmentation.","","Electronic:978-1-5090-1897-0; POD:978-1-5090-1898-7; USB:978-1-5090-1819-2","10.1109/SMC.2016.7844745","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7844745","Convolutional Neural Network (CNN);K Nearest Neighbor (KNN);Magnetic resonance images;Semantic segmentation;left atrium","Conferences;Cybernetics;Heart;Image segmentation;Magnetic resonance imaging;Semantics;Three-dimensional displays","biomedical MRI;graph theory;image segmentation;medical image processing;neural nets;search problems;statistical analysis","CNN;K nearest neighbor search;KNN search;MRI;automatic segmentation;convolutional neural network;corpus images;graph model;high anatomical variability;left atrium;magnetic resonance imaging;semantic information;statistical assessment;super pixel voting method","","","","","","","","9-12 Oct. 2016","","IEEE","IEEE Conference Publications"
"DemNet: A Convolutional Neural Network for the detection of Alzheimer's Disease and Mild Cognitive Impairment","C. D. Billones; O. J. L. D. Demetria; D. E. D. Hostallero; P. C. Naval","Computer Vision & Machine Intelligence Group, Department of Computer Science, College of Engineering, University of the Philippines-Diliman, Philippines","2016 IEEE Region 10 Conference (TENCON)","20170209","2016","","","3724","3727","The early diagnosis of Alzheimer's Disease (AD) and its prodromal form, Mild Cognitive Impairment (MCI), has been the subject of extensive research in recent years. Some recent studies have shown promising results in the diagnosis of AD and MCI using structural Magnetic Resonance Imaging (MRI) scans. In this paper, we propose the use of a Convolutional Neural Network (CNN) in the detection of AD and MCI. In particular, we modified the 16-layered VGGNet for the 3-way classification of AD, MCI and Healthy Controls (HC) on the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset achieving an overall accuracy of 91.85% and outperforming several classifiers from other studies.","","Electronic:978-1-5090-2597-8; POD:978-1-5090-2598-5; USB:978-1-5090-2596-1","10.1109/TENCON.2016.7848755","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7848755","","Alzheimer's disease;Biological neural networks;Feature extraction;Kernel;Magnetic resonance imaging;Neurons","biomedical MRI;convolution;data analysis;medical image processing;neural nets","16-layered VGGNet;3-way classification;AD;ADNI dataset;Alzheimer disease neuroimaging initiative dataset;CNN;DemNet;HC;MCI;MRI scans;convolutional neural network;healthy controls;magnetic resonance imaging scans;mild cognitive impairment detection;prodromal form;structural magnetic resonance imaging","","","","","","","","22-25 Nov. 2016","","IEEE","IEEE Conference Publications"
"Simple and effective pre-processing for automated melanoma discrimination based on cytological findings","T. Yoshida; M. E. Celebi; G. Schaefer; H. Iyatomi","Department of Applied Informatics, Graduate School of Science and Engineering, Hosei University, Japan","2016 IEEE International Conference on Big Data (Big Data)","20170206","2016","","","3439","3442","In this paper, we propose a simple and effective preprocessing method for melanoma classification by considering cytological properties of melanomas, in particular the alignment of the major axis of the tumor in the same direction. We evaluate our method with a set of 1,760 dermoscopic images (329 of melanomas and 1,431 of nevi) and a simple convolutional neural network (CNN) classifier with five-fold cross validation. The proposed tumor alignment method improves the classification performance by 5.8% in terms of the area under the ROC curve (AUC). In addition, it proves to be 2.1% better in term of AUC when compared with the same configured CNN trained using images that are nine times larger. Our results also show that considering the intrinsic features of the classification target is important even when the classifier has a capability to obtain effective features automatically through its learning process.","","Electronic:978-1-4673-9005-7; POD:978-1-4673-9006-4","10.1109/BigData.2016.7841005","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7841005","","Cancer;Feature extraction;Lesions;Malignant tumors;Skin;Training","cellular biophysics;feature extraction;feedforward neural nets;image classification;medical image processing;tumours","AUC;CNN classifier;ROC curve;automated melanoma discrimination;convolutional neural network classifier;cytological findings;melanoma classification;preprocessing method;tumor major axis alignment","","","","","","","","5-8 Dec. 2016","","IEEE","IEEE Conference Publications"
"Stereotypical Motor Movement Detection in Dynamic Feature Space","N. M. Rad; S. M. Kia; C. Zarbo; G. Jurman; P. Venuti; C. Furlanello","Fondazione Bruno Kessler, Trento, Italy","2016 IEEE 16th International Conference on Data Mining Workshops (ICDMW)","20170202","2016","","","487","494","Stereotypical Motor Movements (SMMs) are abnormal postural or motor behaviors that interfere with learning and social interaction in Autism Spectrum Disorder patients. An automatic SMM detection system, employing inertial sensing technology, provides a useful tool for real-time alert on the onset of these atypical behaviors, therefore facilitating personalized intervention therapies. To tackle critical issues with inter-subject variability, in this study, we propose to combine long short-term memory (LSTM) with convolutional neural network (CNN) to model the temporal patterns in the sequence of multi-axes IMU signals. Our results, on one simulated and two experimental datasets, show that transferring the raw feature space to a dynamic feature space via the proposed architecture enhances the performance of automatic SMM detection system especially for skewed training data. These findings facilitate the application of SMM detection system in real-time scenarios.","","Electronic:978-1-5090-5910-2; POD:978-1-5090-5911-9","10.1109/ICDMW.2016.0076","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7836707","Feature Learning;Human Activity Recognition;Long Short-term Memory;Stereotypical Motor Movement;Wearable Sensors","Accelerometers;Activity recognition;Computer architecture;Detectors;Feature extraction;Real-time systems","feedforward neural nets;learning (artificial intelligence);medical computing;medical disorders","CNN;LSTM;abnormal motor behavior;abnormal postural behavior;atypical behaviors;autism spectrum disorder patients;automatic SMM detection system;convolutional neural network;dynamic feature space;inertial sensing technology;intersubject variability;learning;long-short-term memory;multiaxis IMU signal sequence;personalized intervention therapies;raw feature space;real-time alert;skewed training data;social interaction;stereotypical motor movement detection;temporal patterns","","","","","","","","12-15 Dec. 2016","","IEEE","IEEE Conference Publications"
"DeepCut: Object Segmentation From Bounding Box Annotations Using Convolutional Neural Networks","M. Rajchl; M. C. H. Lee; O. Oktay; K. Kamnitsas; J. Passerat-Palmbach; W. Bai; M. Damodaram; M. A. Rutherford; J. V. Hajnal; B. Kainz; D. Rueckert","Department of Computing, Imperial College London, SW7 2AZ, London, U.K","IEEE Transactions on Medical Imaging","20170201","2017","36","2","674","683","In this paper, we propose DeepCut, a method to obtain pixelwise object segmentations given an image dataset labelled weak annotations, in our case bounding boxes. It extends the approach of the well-known GrabCut[1] method to include machine learning by training a neural network classifier from bounding box annotations. We formulate the problem as an energy minimisation problem over a densely-connected conditional random field and iteratively update the training targets to obtain pixelwise object segmentations. Additionally, we propose variants of the DeepCut method and compare those to a naïve approach to CNN training under weak supervision. We test its applicability to solve brain and lung segmentation problems on a challenging fetal magnetic resonance dataset and obtain encouraging results in terms of accuracy.","0278-0062;02780062","","10.1109/TMI.2016.2621185","Developing Human Connectome Project; iFIND project; 10.13039/501100000266 - Wellcome Trust and EPSRC IEH; 10.13039/501100000272 - National Institute for Health Research (NIHR) Biomedical Research Centre based at Guy¿s and St Thomas¿ NHS Foundation Trust and King¿s College London; 10.13039/501100000781 - ERC; 10.13039/501100000781 - Synergy Grant by the European Research Council (ERC); 10.13039/501100004963 - European Union¿s Seventh Framework Programme; ","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7739993","Bounding box;DeepCut;convolutional neural networks;image segmentation;machine learning;weak annotations","Biological neural networks;Computational modeling;Image segmentation;Imaging;Object segmentation;Optimization;Training","biomedical MRI;brain;image segmentation;learning (artificial intelligence);lung;medical image processing;neural nets","DeepCut;GrabCut;bounding box annotations;brain segmentation;convolutional neural networks;densely connected conditional random field;fetal magnetic resonance dataset;lung segmentation;machine learning;pixelwise object segmentation","","","","","","","20161109","Feb. 2017","","IEEE","IEEE Journals & Magazines"
"Memristor circuits and systems for future computing and bio-inspired information processing","S. N. Truong; K. Van Pham; W. Yang; K. S. Min","School of Electrical Engineering, Kookmin University, Seoul, Korea","2016 IEEE Biomedical Circuits and Systems Conference (BioCAS)","20170126","2016","","","456","459","Memristors can be used in mimicking synaptic plasticity of biological neuronal systems. In addition, memristor crossbars can be realized in 3-dimensional architecture like human brain. This possibility of 3-dimensional integration is crucial in implementing the full-scale electronic neuron-synapse system in future. One more thing to note here is that memristor-based neuromorphic systems can be more energy-efficient than the conventional Von Neumann ones in some applications such as bio-inspired pattern processing. This is because they are more suitable to brain-like parallel processing. Based on these advantages of memristor-based neuromorphic systems, this paper reviews the memristor logics, where the computation and memory can be merged together. Then, we introduce neuromorphic memristor crossbars which can mimic the brain's pattern recognition of speech and image. The simulation results of neuromorphic crossbars strongly highlight the future possibility of memristor circuits in brain-mimicking pattern processing. In Cellular Nanoscale Network (CNN), memristors can be used in analog multiplication that is essential to perform CNN pixel calculation with low power consumption and high-area density.","","Electronic:978-1-5090-2959-4; POD:978-1-5090-2960-0","10.1109/BioCAS.2016.7833830","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7833830","bio-inspired pattern processing;cellular nanoscale network;future computing;memristor logic;memristors;neuromorphic memristor crossbar","Computer architecture;Energy efficiency;Memristors;Neuromorphics;Speech;Speech recognition;Training","biomedical electronics;brain;medical image processing;memristor circuits;neurophysiology;parallel processing;pattern recognition","CNN pixel calculation;Von Neumann;bioinspired information processing;bioinspired pattern processing;biological neuronal system;brain pattern recognition;brain-like parallel processing;cellular nanoscale network;electronic neuron-synapse system;human brain;memory;memristor circuit;memristor logics;memristor-based neuromorphic system;neuromorphic memristor crossbar;power consumption;speech;synaptic plasticity","","","","","","","","17-19 Oct. 2016","","IEEE","IEEE Conference Publications"
"Convolutional Neural Network for Retinal Blood Vessel Segmentation","Z. Yao; Z. Zhang; L. Q. Xu","Beijing Adv. innovation center for future internet Technol., Beijing Univ. of Technol., Beijing, China","2016 9th International Symposium on Computational Intelligence and Design (ISCID)","20170126","2016","1","","406","409","This paper proposes a CNN (Convolutional neural network) based blood vessel segmentation algorithm. Each pixel with its neighbors of the fundus image is checked by the CNN. The preliminary segmentation results of fundus images were refined by a two stages binarization and a morphological operation successively. The algorithm was tested on DRIVE dataset. While the specificity is 0.9603, sensitivity is 0.7731, which is very close to that of manual annotation. The sensitivity is 2% better than the ones found in current studies. The CNN based algorithm improves the segmentation of blood vessels performance significantly.","","Electronic:978-1-5090-3558-8; POD:978-1-5090-3559-5","10.1109/ISCID.2016.1100","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7830374","CNN;Two Stages Binarization;fundus image;vessel segmentation","Computational intelligence;Decision support systems;Handheld computers;Image segmentation;Sensitivity","blood vessels;image segmentation;medical image processing;neural nets","CNN;DRIVE dataset;blood vessel performance segmentation improvement;convolutional neural network;fundus image;morphological operation;retinal blood vessel segmentation algorithm","","","","","","","","10-11 Dec. 2016","","IEEE","IEEE Conference Publications"
"Cancer Cells Detection in Phase-Contrast Microscopy Images Based on Faster R-CNN","J. Zhang; H. Hu; S. Chen; Y. Huang; Q. Guan","Coll. of Comput. Sci. & Technol., Zhejiang Univ. of Technol., Hangzhou, China","2016 9th International Symposium on Computational Intelligence and Design (ISCID)","20170126","2016","1","","363","367","In biology and medicine research, detection and identification of cancer cells plays an essential role to further analysis of cell properties and developing new drugs experiments. However, owing to the adhesion among cells and great changes in morphology, it is a very challenging task to detect and locate the cells accurately, especially for the cells adhesion area. In this work, a deep detector for cells based on the framework of Faster R-CNN is proposed, and based on this, a Circle Scanning Algorithm (CSA) is presented for the redetection of adhesion cells. And then a series of experiments are achieved. The results show that the proposed deep detector can detect and identify all separate individual cells in an image, and that the hybrid method by combining Faster R-CNN with the proposed CSA can effectively detect and identify the adhesion cells under the conditions of the limited samples of adhesion cells.","","Electronic:978-1-5090-3558-8; POD:978-1-5090-3559-5","10.1109/ISCID.2016.1090","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7830364","CSA;Cell detector;Faster R-CNN;RPN","Adhesives;Cancer;Cells (biology);Detectors;Morphology;Proposals;Training","cancer;cellular biophysics;feedforward neural nets;image classification;medical image processing","CSA;Faster-R-CNN;adhesion cell redetection;cancer cell detection;cancer cell identification;circle scanning algorithm;deep detector;hybrid method;phase-contrast microscopy images","","","","","","","","10-11 Dec. 2016","","IEEE","IEEE Conference Publications"
"Orientation estimation and grasp type detection of household objects for upper limb prostheses with dynamic vision sensor","S. Tang; R. Ghosh; N. V. Thakor; S. L. Kukreja","Singapore Institute for Neurotechnology (SiNAPSE), National University of Singapore, Singapore","2016 IEEE Biomedical Circuits and Systems Conference (BioCAS)","20170126","2016","","","99","102","Although the past decade has seen important advances in prosthetic technologies, grasping household objects with an artificial hand still requires significant skill and effort for an amputee to regulating hand behaviour. A solution to this problem is to automate the process by using vision sensors that determine the object's orientation and optimal grasp procedure. In this paper, we use a neuromorphic dynamic vision sensor (DVS) to assist amputees with object grasping. Event-driven sensors such as the DVS have gained popularity in recent years as an alternative to conventional frame-based sensors due to their low-power consumption and low-latency. Here, we use event data from a DVS to find a grasp-appropriate orientation for the object and subsequently its optimal grasp type. Our estimation technique exploits general assumptions such as object symmetry and grasps preference to be along the smallest major dimension of an object. The grasp type is determined through a combination of multiple convolutional neural network (CNN) classifiers. We evaluated our grasp estimation methodology on a set of 20 household objects. The results of this study show that 96.25% of the estimated orientations were within ±10° of the actual orientations. In addition, our grasp detection method yielded a 99.47% accuracy on unseen object classes.","","Electronic:978-1-5090-2959-4; POD:978-1-5090-2960-0","10.1109/BioCAS.2016.7833734","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7833734","","Detection algorithms;Estimation;Grasping;Mirrors;Principal component analysis;Prosthetic hand;Voltage control","image sensors;medical control systems;neural nets;pattern classification;prosthetics","CNN classifier;artificial hand;convolutional neural network;hand behaviour;household object grasp type detection;household object orientation estimation;neuromorphic dynamic vision sensor;object symmetry;prosthetic technology;upper limb prostheses","","","","","","","","17-19 Oct. 2016","","IEEE","IEEE Conference Publications"
"CNN transfer learning for the automated diagnosis of celiac disease","G. Wimmer; A. Vécsei; A. Uhl","University of Salzburg, Department of Computer Sciences, Salzburg, Austria","2016 Sixth International Conference on Image Processing Theory, Tools and Applications (IPTA)","20170119","2016","","","1","6","In this work, four well known convolutional neural networks (CNNs) that were pretrained on the ImageNet database are applied for the computer assisted diagnosis of celiac disease based on endoscopic images of the duodenum. The images are classified using three different transfer learning strategies and a experimental setup specifically adapted for the classification of endoscopic imagery. The CNNs are either used as fixed feature extractors without any fine-tuning to our endoscopic celiac disease image database or they are fine-tuned by training either all layers of the CNN or by fine-tuning only the fully connected layers. Classification is performed by the CNN SoftMax classifier as well as linear support vector machines. The CNN results are compared with the results of four state-of-the-art image representations. We will show that fine-tuning all the layers of the nets achieves the best results and outperforms the comparison approaches.","","Electronic:978-1-4673-8910-5; POD:978-1-4673-8911-2","10.1109/IPTA.2016.7821020","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7821020","Automated diagnois;Celiac Disease;Convolutional neural networks;Endoscopy;Transfer learning","Databases;Diseases;Endoscopes;Feature extraction;Image representation;Support vector machines;Training","biomedical optical imaging;diseases;endoscopes;feature extraction;image classification;image representation;learning (artificial intelligence);medical image processing;neural nets;support vector machines","CNN SoftMax classifier;CNN transfer learning;ImageNet database;automated celiac disease diagnosis;computer assisted diagnosis;convolutional neural networks;duodenum;endoscopic celiac disease image database;endoscopic imagery;fine-tuning;fixed feature extractors;fully connected layers;image classification;image representation;linear support vector machines","","","","","","","","12-15 Dec. 2016","","IEEE","IEEE Conference Publications"
"Automated human physical function measurement using constrained high dispersal network with SVM-linear","Dan Meng; G. Cao; Xinyu Song; W. Chen; Wenming Cao","School of Computer Scinence and Software Engineering, East China Normal University, Shanghai, China 200062","2016 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)","20170119","2016","","","1520","1526","Physical measurement have been becoming increasingly helpful in monitoring the humans health status. Manual measurement of physical status is time consuming and may result in misdiagnosing, so an automatic method for identification the status of physical is urgently needed. This paper presents a novel feature extraction method based on using constrained high dispersal network for depth images and coped with Support Vector Machines (SVM) to measure human physical function. The proposed method can catch the most representative features of depth images belonging to different actions and statuses. We analyze the representation efficiency of hand-crafted features (HOG features, and LBP features), deep learning features (CNN features, and PCANet features) and our proposed deep learning features separately in order to validate the efficiency and accuracy of our proposed method. The results show superior performance of 85.19% on 3840 samples (three actions, each with four different statuses, and every status contains sixteen sequences) when the proposed deep features combined with SVM.","","Electronic:978-1-5090-1611-2; POD:978-1-5090-1612-9","10.1109/BIBM.2016.7822747","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7822747","PCA lter;Physical function measurement;SVM;deep learning;high dispersal;local normalization;multi-scale feature","Artificial neural networks;Biomedical imaging;Histograms;Manuals;Principal component analysis;Support vector machines;Training","feature extraction;image representation;learning (artificial intelligence);medical image processing;patient monitoring;support vector machines","CNN features;HOG features;LBP features;PCANet features;SVM-linear;automated human physical function measurement;constrained high dispersal network;deep learning features;depth images;feature extraction;hand-crafted features;human physical function;humans health status monitoring;representation efficiency;support vector machine","","","","","","","","15-18 Dec. 2016","","IEEE","IEEE Conference Publications"
"Emotion recognition from multi-channel EEG data through Convolutional Recurrent Neural Network","Xiang Li; Dawei Song; Peng Zhang; Guangliang Yu; Yuexian Hou; Bin Hu","Tianjin Key Laboratory of Cognitive Computing and Application, Tianjin University, China","2016 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)","20170119","2016","","","352","359","Automatic emotion recognition based on multi-channel neurophysiological signals, as a challenging pattern recognition task, is becoming an important computer-aided method for emotional disorder diagnoses in neurology and psychiatry. Traditional approaches require designing and extracting a range of features from single or multiple channel signals based on extensive domain knowledge. This may be an obstacle for non-domain experts. Moreover, traditional feature fusion method can not fully utilize correlation information between different channels. In this paper, we propose a preprocessing method that encapsulates the multi-channel neurophysiological signals into grid-like frames through wavelet and scalogram transform. We further design a hybrid deep learning model that combines the `Convolutional Neural Network (CNN)' and `Recurrent Neural Network (RNN)', for extracting task-related features, mining inter-channel correlation and incorporating contextual information from those frames. Experiments are carried out, in a trial-level emotion recognition task, on the DEAP benchmarking dataset. Our results demonstrate the effectiveness of the proposed methods, with respect to the emotional dimensions of Valence and Arousal.","","Electronic:978-1-5090-1611-2; POD:978-1-5090-1612-9","10.1109/BIBM.2016.7822545","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7822545","CNN;EEG;LSTM;emotion recognition;physiological signal","Continuous wavelet transforms;Correlation;Electroencephalography;Emotion recognition;Feature extraction","data mining;electroencephalography;emotion recognition;feature extraction;medical disorders;medical signal processing;neurophysiology;wavelet transforms","CNN;DEAP benchmarking dataset;RNN;automatic emotion recognition;computer-aided method;contextual information;convolutional neural network;convolutional recurrent neural network;emotional dimensions;emotional disorder diagnoses;extensive domain knowledge;grid-like frames;hybrid deep learning model;interchannel correlation mining;multichannel EEG data;multichannel neurophysiological signals;multiple channel signals;neurology;nondomain experts;pattern recognition task;psychiatry;recurrent neural network;scalogram transform;single channel signals;task-related feature extraction;trial-level emotion recognition task;valence-and-arousal;wavelet transform","","","","","","","","15-18 Dec. 2016","","IEEE","IEEE Conference Publications"
"ML-CNN: A novel deep learning based disease named entity recognition architecture","Zhehuan Zhao; Zhihao Yang; Ling Luo; Yin Zhang; Lei Wang; Hongfei Lin; Jian Wang","College of Computer Science and Technology, Dalian University of Technology, China, 116023","2016 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)","20170119","2016","","","794","794","In this paper, we present a deep learning based disease named entity recognition architecture. First, the word-level embedding, character-level embedding and lexicon feature embedding are concatenated as input. Then multiple convolutional layers are stacked over the input to extract useful features automatically. Finally, multiple label strategy, which is firstly introduced, is applied to the output layer to capture the correlation information between neighboring labels. Experimental results on both NCBI and CDR corpora show that ML-CNN can achieve the state-of-the-art performance.","","Electronic:978-1-5090-1611-2; POD:978-1-5090-1612-9","10.1109/BIBM.2016.7822625","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7822625","convolutional neural network;deep learning;disease;multiple label strategy;named entity recognition","Computational linguistics;Computer architecture;Context;Correlation;Diseases;Feature extraction;Machine learning","diseases;feature extraction;learning (artificial intelligence);medical computing;neural nets","CDR corpora;ML-CNN;NCBI corpora;character-level embedding;deep learning method;disease named entity recognition architecture;feature extraction;lexicon feature embedding;multiple label convolutional neural network;word-level embedding","","","","","","","","15-18 Dec. 2016","","IEEE","IEEE Conference Publications"
"CNN-based image analysis for malaria diagnosis","Z. Liang; A. Powell; I. Ersoy; M. Poostchi; K. Silamut; K. Palaniappan; P. Guo; M. A. Hossain; A. Sameer; R. J. Maude; J. X. Huang; S. Jaeger; G. Thoma","School of Information Technology, York University, Toronto, ON, M3J1P3, Canada","2016 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)","20170119","2016","","","493","496","Malaria is a major global health threat. The standard way of diagnosing malaria is by visually examining blood smears for parasite-infected red blood cells under the microscope by qualified technicians. This method is inefficient and the diagnosis depends on the experience and the knowledge of the person doing the examination. Automatic image recognition technologies based on machine learning have been applied to malaria blood smears for diagnosis before. However, the practical performance has not been sufficient so far. This study proposes a new and robust machine learning model based on a convolutional neural network (CNN) to automatically classify single cells in thin blood smears on standard microscope slides as either infected or uninfected. In a ten-fold cross-validation based on 27,578 single cell images, the average accuracy of our new 16-layer CNN model is 97.37%. A transfer learning model only achieves 91.99% on the same images. The CNN model shows superiority over the transfer learning model in all performance indicators such as sensitivity (96.99% vs 89.00%), specificity (97.75% vs 94.98%), precision (97.73% vs 95.12%), F1 score (97.36% vs 90.24%), and Matthews correlation coefficient (94.75% vs 85.25%).","","Electronic:978-1-5090-1611-2; POD:978-1-5090-1612-9","10.1109/BIBM.2016.7822567","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7822567","computer-aided diagnosis;convolutional neural network;deep learning;machine learning;malaria","Blood;Data models;Diseases;Machine learning;Mathematical model;Microscopy;Training","blood;cellular biophysics;diseases;image recognition;learning (artificial intelligence);medical image processing;neural nets","CNN-based image analysis;Matthews correlation coefficient;automatic image recognition technology;convolutional neural network;machine learning model;malaria diagnosis;parasite-infected red blood cell;single cell classification;single cell images","","","","","","","","15-18 Dec. 2016","","IEEE","IEEE Conference Publications"
"Cardiac left ventricular volumes prediction method based on atlas location and deep learning","G. Luo; S. Dong; K. Wang; H. Zhang","School of Computer Science and Technology, Harbin Institute of Technology, China","2016 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)","20170119","2016","","","1604","1610","In this paper, we proposed a novel left ventricular volumes prediction method. This method is a cascade architecture which is based on multi-scale LV atlas location and deep convolutional neural networks (CNN). Firstly, we adopted LV atlas mapping method to achieve accurate location of LV region in cardiac magnetic resonance (CMR) images. And then, the CNN were used to train an end-to-end LV volumes prediction model to achieve the direct prediction. What's more, the large number of CMR images data (1140 subjects, more than 1026000 images) make the proposed deep CNN have relatively better feature representation and robust prediction ability. The experiment results on the large-scale CMR datasets prove that the proposed method has higher accuracy than the state-of-the-art prediction methods in terms of the end-diastole volumes (EDV), the end-systole volumes (ESV), and the ejection fraction (EF). Besides, we make the proposed method open accessible to public for wide application in other biomedical image processing fields.","","Electronic:978-1-5090-1611-2; POD:978-1-5090-1612-9","10.1109/BIBM.2016.7822759","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7822759","CMR images;LV atlas;deep convolutional neural networks;volumes prediction","Fitting;Image segmentation;Kernel;Manuals","biomedical MRI;cardiology;convolution;feature extraction;image representation;learning (artificial intelligence);medical image processing;neural nets","biomedical image processing fields;cardiac left ventricular volume prediction method;cardiac magnetic resonance images;deep convolutional neural networks;deep learning;end-diastole volumes;end-systole volumes;feature representation;multiscale LV atlas mapping method","","","","","","","","15-18 Dec. 2016","","IEEE","IEEE Conference Publications"
"Oriented tooth localization for periapical dental X-ray images via convolutional neural network","H. Eun; C. Kim","School of Electrical Engineering, Korea Advanced Institute of Science and Technology (KAIST)","2016 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA)","20170119","2016","","","1","7","In studies using dental X-ray images, tooth localization is essential to produce accurate results. In this paper, we propose a tooth localization method that tightly localize diverse teeth in periapical dental X-ray images. Oriented tooth proposals are generated by using teeth separation lines (TSLs) and a tooth top line, which are reliable and tight to teeth. To classify each tooth proposal into either a tooth or a non-tooth, we utilize a convolutional neural network (CNN). Our CNN model is trained with three classes, i.e., one negative and two positives, for better classification. In addition, we propose scale based non-maximum suppression by integrating scale confidence with non-maximum suppression to efficiently eliminate multiple tooth localizations.","","Electronic:978-9-8814-7682-1; POD:978-1-5090-2401-8","10.1109/APSIPA.2016.7820720","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7820720","","Dentistry;Image segmentation;Neural networks;Proposals;Teeth;Training;X-ray imaging","dentistry;medical image processing;neural nets","CNN model;convolutional neural network;oriented tooth localization;periapical dental X-ray images;teeth separation lines;tooth localization method","","","","","","","","13-16 Dec. 2016","","IEEE","IEEE Conference Publications"
"A Novel Deep Model for Biopsy Image Grading","G. Zhang; Z. H. Liang; H. D. Lai; Y. Y. Lin; D. Lin; Z. P. Li","Sch. of Autom., Guangdong Univ. of Technol., Guangzhou, China","2016 International Conference on Information System and Artificial Intelligence (ISAI)","20170116","2016","","","323","326","We propose in this paper a deep learning model based on convolutional neural network (CNN) for biopsy image grading. The model outputs a vector of scores indicating presence or severity of the target histopathological characteristics. Within the model, we first design a 7-layer CNN for feature representation and high level concept extraction. Each biopsy image is expressed as a feature vector through our CNN processor. We then place a sigmoid function into the output layer so as to generate a score for each target characteristic. The proposed model is evaluated on a benchmark dataset and a real biopsy image dataset to show its effectiveness.","","Electronic:978-1-5090-1585-6; POD:978-1-5090-1586-3","10.1109/ISAI.2016.0075","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7816728","biopsy image grading;convolutional neural network;deep learning;histopathological image analysis;sigmoid function","Biological system modeling;Biopsy;Computational modeling;Feature extraction;Machine learning;Solid modeling;Training","feature extraction;learning (artificial intelligence);medical image processing;neural nets","CNN;biopsy image grading;convolutional neural network;deep learning model;feature representation;high level concept extraction;histopathological characteristics;sigmoid function","","","","","","","","24-26 June 2016","","IEEE","IEEE Conference Publications"
"Deep Learning-Aided Parkinson's Disease Diagnosis from Handwritten Dynamics","C. R. Pereira; S. A. T. Weber; C. Hook; G. H. Rosa; J. P. Papa","Dept. of Comput., Fed. Univ. of Sao Carlos, Sao Carlos, Brazil","2016 29th SIBGRAPI Conference on Graphics, Patterns and Images (SIBGRAPI)","20170116","2016","","","340","346","Parkinson's Disease (PD) automatic identification in early stages is one of the most challenging medicine-related tasks to date, since a patient may have a similar behaviour to that of a healthy individual at the very early stage of the disease. In this work, we cope with PD automatic identification by means of a Convolutional Neural Network (CNN), which aims at learning features from a signal extracted during the individual's exam by means of a smart pen composed of a series of sensors that can extract information from handwritten dynamics. We have shown CNNs are able to learn relevant information, thus outperforming results obtained from raw data. Also, this work aimed at building a public dataset to be used by researchers worldwide in order to foster PD-related research.","","Electronic:978-1-5090-3568-7; POD:978-1-5090-3569-4","10.1109/SIBGRAPI.2016.054","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7813053","Convolutional Neural Networks;Parkinson's Disease","Convolution;Feature extraction;Neural networks;Parkinson's disease;Sensors;Spirals","convolution;diseases;feature extraction;handwriting recognition;learning (artificial intelligence);medical diagnostic computing;neural nets","Parkinson's disease automatic identification;convolutional neural network;deep learning-aided Parkinson's disease diagnosis;feature extraction;handwritten dynamics;smart pen","","","","","","","","4-7 Oct. 2016","","IEEE","IEEE Conference Publications"
"Recognition of persisting emotional valence from EEG using convolutional neural networks","M. Yanagimoto; C. Sugimoto","Graduate School of Engineering, Yokohama National University, Yokohama, Japan","2016 IEEE 9th International Workshop on Computational Intelligence and Applications (IWCIA)","20170105","2016","","","27","32","Recently there has been considerable interest in EEG-based emotion recognition (EEG-ER), which is one of the utilization of BCI. However, it is not easy to realize the EEG-ER system which can recognize emotions with high accuracy because of the tendency for important information in EEG signals to be concealed by noises. Deep learning is the golden tool to grasp the features concealed in EEG data and enable highly accurate EEG-ER because deep neural networks (DNNs) may have higher recognition capability than humans'. The publicly available dataset named DEAP, which is for emotion analysis using EEG, was used in the experiment. The CNN and a conventional model used for comparison are evaluated by the tests according to 11-fold cross validation scheme. EEG raw data obtained from 16 electrodes without general preprocesses were used as input data. The models classify and recognize EEG signals according to the emotional states ""positive"" or ""negative"" which were caused by watching music videos. The results show that the more training data are, the much higher the accuracies of CNNs are (by over 20%). It also suggests that the increased training data need not to belong to the same person's EEG data as the test data so as to get the CNN recognizing emotions accurately. The results indicate that there are not only the considerable amount of the interpersonal difference but also commonality of EEG properties.","","Electronic:978-1-5090-2775-0; POD:978-1-5090-2776-7","10.1109/IWCIA.2016.7805744","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7805744","BCI;Convolutional neural networks;Deep learning;EEG;Emotion recognition;Interpersonal difference/commonality","Brain modeling;Convolution;Data models;Electroencephalography;Emotion recognition;Feature extraction;Videos","brain-computer interfaces;convolution;electroencephalography;emotion recognition;learning (artificial intelligence);medical signal processing;neural nets;signal classification","BCI;DEAP dataset;EEG signal classification;EEG-ER system;EEG-based emotion recognition;convolutional neural networks;deep learning;deep neural networks;emotion analysis;persisting emotional valence recognition","","","","","","","","5-5 Nov. 2016","","IEEE","IEEE Conference Publications"
"Deep convolutional encoder-decoder for myelin and axon segmentation","R. Mesbah; B. McCane; S. Mills","Department of Computer Science, University of Otago, New Zealand","2016 International Conference on Image and Vision Computing New Zealand (IVCNZ)","20170105","2016","","","1","6","We propose a fully automatic method for segmenting myelin and axon from microscopy images of excised mouse spinal cord based on Convolutional Neural Networks (CNNs) and Deep Convolutional Encoder-Decoder. We compare a two-class CNN, multi-class CNN, and multi-class deep convolutional encoder-decoder with traditional methods. The CNN method gives a pixel-wise accuracy of 79.7% whereas an Active Contour method gives 59.4%. The encoder-decoder shows better performance with 82.3% and noticeably shorter classification time than CNN methods.","","Electronic:978-1-5090-2748-4; POD:978-1-5090-2749-1; USB:978-1-5090-2747-7","10.1109/IVCNZ.2016.7804455","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7804455","","Axons;Computer architecture;Convolution;Decoding;Image segmentation;Microscopy;Training","feedforward neural nets;image classification;image segmentation;medical image processing","active contour method;axon segmentation;classification time;convolutional neural networks;excised mouse spinal cord;medical image processing;microscopy images;multiclass CNN;multiclass deep convolutional encoder-decoder;myelin segmentation;pixel-wise accuracy;two-class CNN","","","","","","","","21-22 Nov. 2016","","IEEE","IEEE Conference Publications"
"Diagnosis of Parkinson's disease from continuous speech using deep convolutional networks without manual selection of features","A. Frid; A. Kantor; D. Svechin; L. M. Manevitz","Department of Computer Science and Neurocomputation Lab., University of Haifa, Haifa, Israel","2016 IEEE International Conference on the Science of Electrical Engineering (ICSEE)","20170105","2016","","","1","4","Parkinson's Disease (PD) is a relatively common neurodegenerative disabling disease. It affects central nervous system with profound effect on the motor system. The most common symptoms include slowness, rigidity and tremor during motion. It has been suggested that the vocal cords are among the first one to be affected and thus the speech is affected at very early stage of the disease and continues to deteriorate as the disease progress. In this work, we focus on automating the process of diagnosis from continuous native speech by removing the necessity of a trained personal from the diagnosis process. This is done by using an adaptation of Convolutional Neural Network (CNN) architecture for one-dimensional signal processing (i.e. raw speech signal) on a relatively small training set. This is a continuation to previous works where we showed (i) that this task can be achieved by using manually-extracted features of the speech (such as formants and their ratios) and (ii) by using an automatic process of auditory features extraction, where the features were selected by signal processing specialist.","","Electronic:978-1-5090-2152-9; POD:978-1-5090-2153-6","10.1109/ICSEE.2016.7806118","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7806118","Convolutional Neural Networks (CNN);Machine Learning;Parkinson's Disease;Speech Analysis","Biological neural networks;Convolution;Diseases;Feature extraction;Neurons;Speech;Training","auditory evoked potentials;convolution;diseases;feature extraction;learning (artificial intelligence);medical signal processing;neural nets;neurophysiology;speech processing","Parkinson disease diagnosis;auditory feature extraction;central nervous system;continuous native speech;convolutional neural network architecture;deep convolutional networks;manually-extracted features;motor system;neurodegenerative disabling disease;one-dimensional signal processing;vocal cords","","","","","","","","16-18 Nov. 2016","","IEEE","IEEE Conference Publications"
"Mental Disease Feature Extraction with MRI by 3D Convolutional Neural Network with Multi-channel Input","L. Cao; Z. Liu; X. He; Y. Cao; K. Li","Sch. of Inf. Sci. & Eng., Shandong Univ., Jinan, China","2016 IEEE International Conference on Smart Cloud (SmartCloud)","20161226","2016","","","224","227","Magnetic resonance imaging (MRI) plays an important role in early diagnosis, which can accurately capture the disease variations of the anatomical brain structure. We propose a novel method for improving feature extraction performance from magnetic resonance images (MRI). This study presents a combination of multi-channel input and 3D convolutional neural network architecture which can reduce the feature dimensionality. Multi-channel input scheme is devised to apply prior knowledge on MRI original inputs in order to overcame possibly uncertainty and unsteadiness on the final features. While, the 3D-CNN model can simultaneously extract features from spatial and temporal dimensions for purpose of capturing the variations of constructive information.","","Electronic:978-1-5090-5263-9; POD:978-1-5090-5264-6","10.1109/SmartCloud.2016.38","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7796178","3D convolutional neural network;MRI;Multi-channel input;feature extraction","Convolution;Feature extraction;Kernel;Magnetic resonance imaging;Three-dimensional displays;Wavelet transforms","biomedical MRI;brain;convolution;diseases;feature extraction;medical image processing;neural nets;patient diagnosis;stereo image processing","3D convolutional neural network;MRI;anatomical brain structure;diagnosis;magnetic resonance imaging;mental disease feature extraction;multichannel input","","","","","","","","18-20 Nov. 2016","","IEEE","IEEE Conference Publications"
"Image Registration for Placenta Reconstruction","F. Gaisser; P. P. Jonker; T. Chiba","Dept. of Biomech. Eng., Delft Univ. of Technol., Delft, Netherlands","2016 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)","20161219","2016","","","473","480","In this paper we introduce a method to handle the challenges posed by image registration for placenta reconstruction from fetoscopic video as used in the treatment of Twinto-Twin Transfusion Syndrome (TTTS). Panorama reconstruction of the placenta greatly supports the surgeon in obtaining a complete view of the placenta to localize vascular anastomoses. The found shunts can subsequently be blocked by coagulation in the correct order. By using similarity learning in training a Convolutional Neural Network we created a novel feature extraction method, allowing robust matching of keypoints for image registration and therefore taking the most critical step in placenta reconstruction from fetoscopic video. The fetoscopic video we used for our experiments was acquired from a training simulator for TTTS surgery. We compared our method with state-of-the-art methods. The matching performance of our method is up to three times better while the mean projection error is reduced with 64% for the registered images. Our image registration method provides the ground work for a complete panorama reconstruction of the placenta.","","Electronic:978-1-5090-1437-8; POD:978-1-5090-1438-5","10.1109/CVPRW.2016.66","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7789556","","Feature extraction;Image reconstruction;Image registration;Robustness;Surgery;Training;Transforms","feature extraction;image matching;image reconstruction;image registration;medical image processing;neural nets;obstetrics;video signal processing","CNN;TTTS surgery;convolutional neural network;feature extraction method;fetoscopic video;image registration;keypoint matching;mean projection error;placenta panorama reconstruction;similarity learning;twin-to-twin transfusion syndrome;vascular anastomoses","","","","","","","","June 26 2016-July 1 2016","","IEEE","IEEE Conference Publications"
"Neuron Segmentation Based on CNN with Semi-Supervised Regularization","K. Xu; H. Su; J. Zhu; J. S. Guan; B. Zhang","Dept. of Comput. Sci. & Technol., Tsinghua Univ., Beijing, China","2016 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)","20161219","2016","","","1324","1332","Neuron segmentation in two-photon microscopy images is a critical step to investigate neural network activities in vivo. However, it still remains as a challenging problem due to the image qualities, which largely results from the non-linear imaging mechanism and 3D imaging diffusion. To address these issues, we proposed a novel framework by incorporating the convolutional neural network (CNN) with a semi-supervised regularization term, which reduces the human efforts in labeling without sacrificing the performance. Specifically, we generate a putative label for each unlabeled sample regularized with a graph-smooth term, which are used as if they were true labels. A CNN model is therefore trained in a supervised fashion with labeled and unlabeled data simultaneously, which is used to detect neuron regions in 2D images. Afterwards, neuron segmentation in a 3D volume is conducted by associating the corresponding neuron regions in each image. Experiments on real-world datasets demonstrate that our approach outperforms neuron segmentation based on the graph-based semisupervised learning, the supervised CNN and variants of the semi-supervised CNN.","","Electronic:978-1-5090-1437-8; POD:978-1-5090-1438-5","10.1109/CVPRW.2016.167","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7789657","","Biological neural networks;Image segmentation;Microscopy;Neurons;Three-dimensional displays;Two dimensional displays","feedforward neural nets;graph theory;image segmentation;learning (artificial intelligence);medical image processing;neurophysiology;two-photon spectroscopy","3D imaging diffusion;3D volume;convolutional neural network;graph-based semisupervised learning;graph-smooth term;image qualities;neural network activities;neuron region detection;neuron segmentation;nonlinear imaging mechanism;semisupervised regularization;supervised CNN model;two-photon microscopy images","","","","","","","","June 26 2016-July 1 2016","","IEEE","IEEE Conference Publications"
"Deepmotion: a deep convolutional neural network on inertial body sensors for gait assessment in multiple sclerosis*","Gong; Goldman; Lach","Department of Electrical and Computer Engineering, UVA Center for Wireless Health, University of Virginia, Charlottesville, VA, USA","2016 IEEE Wireless Health (WH)","20161215","2016","","","1","8","Walking impairment resulted by various chronic diseases, disorders and injuries have been investigated using recent emerging wearable technology, for instance, gait assessment using inertial body sensors in 6-minute walk (6MW) for persons with Multiple Sclerosis (PwMS) to identify spatiotemporal features useful to assess MS progression. However, most studies to date have investigated the features extracted from movements of the lower limbs and do not provide a holistic gait assessment. A recent pilot study demonstrated that the holistic gait assessment such as evaluating the associations among lower and upper limbs provided better discrimination between healthy controls and PwMS. This paper is motivated by this and further aim to answer the following question: can we identify the temporal gait patterns in terms of the holistic gait assessment? Traditionally this suffers from the statistical property of the causality inference method adopted by previous study. We proposed a deep convolutional neural network (CNN) to learn the temporal and spectral associations among the time-series motion data captured by the inertial body sensors. A simulated model was developed to train the CNN, and then the trained CNN was adopted to assess the gait performance from a pilot dataset with 41 subjects (28 PwMS and 13 healthy controls). Experimental results are reported to illustrate the performance of the proposed approach.","","Electronic:978-1-5090-3090-3; POD:978-1-5090-3091-0","10.1109/WH.2016.7764572","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7764572","","Data processing;Legged locomotion;Machine learning;Physiology;Pulse width modulation;Sensor phenomena and characterization","body sensor networks;diseases;gait analysis;inertial systems;injuries;medical disorders;neural nets","Deepmotion;chronic diseases;deep convolutional neural network;disorders;gait assessment;inertial body sensors;injuries;multiple sclerosis;spatiotemporal features;walking impairment;wearable technology","","","","","","","","25-27 Oct. 2016","","IEEE","IEEE Conference Publications"
"Patch-Based Convolutional Neural Network for Whole Slide Tissue Image Classification","L. Hou; D. Samaras; T. M. Kurc; Y. Gao; J. E. Davis; J. H. Saltz","","2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)","20161212","2016","","","2424","2433","Convolutional Neural Networks (CNN) are state-of-theart models for many image classification tasks. However, to recognize cancer subtypes automatically, training a CNN on gigapixel resolution Whole Slide Tissue Images (WSI) is currently computationally impossible. The differentiation of cancer subtypes is based on cellular-level visual features observed on image patch scale. Therefore, we argue that in this situation, training a patch-level classifier on image patches will perform better than or similar to an image-level classifier. The challenge becomes how to intelligently combine patch-level classification results and model the fact that not all patches will be discriminative. We propose to train a decision fusion model to aggregate patch-level predictions given by patch-level CNNs, which to the best of our knowledge has not been shown before. Furthermore, we formulate a novel Expectation-Maximization (EM) based method that automatically locates discriminative patches robustly by utilizing the spatial relationships of patches. We apply our method to the classification of glioma and non-small-cell lung carcinoma cases into subtypes. The classification accuracy of our method is similar to the inter-observer agreement between pathologists. Although it is impossible to train CNNs on WSIs, we experimentally demonstrate using a comparable non-cancer dataset of smaller images that a patch-based CNN can outperform an image-based CNN.","","Electronic:978-1-4673-8851-1; POD:978-1-4673-8852-8","10.1109/CVPR.2016.266","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7780635","","Cancer;Image resolution;Neural networks;Predictive models;Robustness;Training;Visualization","cancer;image classification;learning (artificial intelligence);medical image processing;neural nets;optimisation","CNN training;EM based method;WSI;cancer subtype differentiation;cellular-level visual features;decision fusion model training;discriminative patch automatic location;expectation-maximization based method;glioma classification;image patch scale;nonsmall-cell lung carcinoma;patch spatial relationships;patch-based CNN;patch-based convolutional neural network;patch-level CNN;patch-level classifier;patch-level prediction aggregation;whole slide tissue image classification","","","","","","","","27-30 June 2016","","IEEE","IEEE Conference Publications"
"Cellular neural network processing of CEUS examination. A pilot study","C. Botoca; M. Botoca","Communications Department, Politehnica University of Timi&#x015F;oara, Romania","2016 12th IEEE International Symposium on Electronics and Telecommunications (ISETC)","20161212","2016","","","309","312","A new method for a differential diagnosis of focal liver lesions (FLL), using cellular neural networks (CNN), intended to develop a computer assisted diagnosis (CAD) procedure, is presented. Two types of lesions with a known typical behavior were selected for the CNN image processing. The database consisted of 20 cases of video recordings of contrast enhancement ultrasound (CEUS) examination. The images processed by the CNN algorithm were selected by ultrasound experts. The images resulted from the CNN processing were accurate and characteristic enough to make possible an instant differential diagnosis between hemangioma and hepatocellular carcinoma.","","Electronic:978-1-5090-3748-3; POD:978-1-5090-3749-0","10.1109/ISETC.2016.7781119","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7781119","cellular neural networks;computer assisted diagnosis hemangioma;contrast enhancement ultrasound;hepatocellular carcinoma;image processing","Biomedical imaging;Cellular neural networks;Computers;Image processing;Lesions;Portals;Ultrasonic imaging","biomedical ultrasonics;image enhancement;medical image processing;neural nets","CAD;CEUS examination;CNN image processing;FLL;cellular neural network processing;computer assisted diagnosis;contrast enhancement ultrasound examination;focal liver lesions;hemangioma carcinoma;hepatocellular carcinoma;video recordings","","","","","","","","27-28 Oct. 2016","","IEEE","IEEE Conference Publications"
"Learning to Read Chest X-Rays: Recurrent Neural Cascade Model for Automated Image Annotation","H. C. Shin; K. Roberts; L. Lu; D. Demner-Fushman; J. Yao; R. M. Summers","Imaging Biomarkers & Comput. Aided Diagnosis Lab., Nat. Inst. of Health, Bethesda, MD, USA","2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)","20161212","2016","","","2497","2506","Despite the recent advances in automatically describing image contents, their applications have been mostly limited to image caption datasets containing natural images (e.g., Flickr 30k, MSCOCO). In this paper, we present a deep learning model to efficiently detect a disease from an image and annotate its contexts (e.g., location, severity and the affected organs). We employ a publicly available radiology dataset of chest x-rays and their reports, and use its image annotations to mine disease names to train convolutional neural networks (CNNs). In doing so, we adopt various regularization techniques to circumvent the large normalvs-diseased cases bias. Recurrent neural networks (RNNs) are then trained to describe the contexts of a detected disease, based on the deep CNN features. Moreover, we introduce a novel approach to use the weights of the already trained pair of CNN/RNN on the domain-specific image/text dataset, to infer the joint image/text contexts for composite image labeling. Significantly improved image annotation results are demonstrated using the recurrent neural cascade model by taking the joint image/text contexts into account.","","Electronic:978-1-4673-8851-1; POD:978-1-4673-8852-8","10.1109/CVPR.2016.274","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7780643","","Biomedical imaging;Context;Diseases;Radiology;Recurrent neural networks;Training;X-rays","X-rays;convolution;diagnostic radiography;diseases;image annotation;medical image processing;radiology;recurrent neural nets","CNNs;automated image annotation;chest X-rays;convolutional neural networks;deep learning model;image caption datasets;natural images;normalvs-diseased cases bias;radiology dataset;recurrent neural cascade model","","","","","","","","27-30 June 2016","","IEEE","IEEE Conference Publications"
"Automating Carotid Intima-Media Thickness Video Interpretation with Convolutional Neural Networks","J. Y. Shin; N. Tajbakhsh; R. T. Hurst; C. B. Kendall; J. Liang","Dept. of Biomed. Inf., Arizona State Univ., Scottsdale, AZ, USA","2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)","20161212","2016","","","2526","2535","Cardiovascular disease (CVD) is the leading cause of mortality yet largely preventable, but the key to prevention is to identify at-risk individuals before adverse events. For predicting individual CVD risk, carotid intima-media thickness (CIMT), a noninvasive ultrasound method, has proven to be valuable, offering several advantages over CT coronary artery calcium score. However, each CIMT examination includes several ultrasound videos, and interpreting each of these CIMT videos involves three operations: (1) select three end-diastolic ultrasound frames (EUF) in the video, (2) localize a region of interest (ROI) in each selected frame, and (3) trace the lumen-intima interface and the media-adventitia interface in each ROI to measure CIMT. These operations are tedious, laborious, and time consuming, a serious limitation that hinders the widespread utilization of CIMT in clinical practice. To overcome this limitation, this paper presents a new system to automate CIMT video interpretation. Our extensive experiments demonstrate that the suggested system performs reliably. The reliable performance is attributable to our unified framework based on convolutional neural networks (CNNs) coupled with our informative image representation and effective post-processing of the CNN outputs, which are uniquely designed for each of the above three operations.","","Electronic:978-1-4673-8851-1; POD:978-1-4673-8852-8","10.1109/CVPR.2016.277","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7780646","","Carotid arteries;Electrocardiography;Image restoration;Neural networks;Reliability;Training;Ultrasonic imaging","biomedical ultrasonics;cardiovascular system;diseases;image representation;medical image processing;neural nets;video signal processing","CIMT examination;CIMT video interpretation;CNN outputs;CVD risk;ROI;at-risk individuals;cardiovascular disease;carotid intima-media thickness video interpretation automation;clinical practice;convolutional neural networks;end-diastolic ultrasound frames;informative image representation;lumen-intima interface;media-adventitia interface;noninvasive ultrasound method;ultrasound videos","","","","","","","","27-30 June 2016","","IEEE","IEEE Conference Publications"
"Automatic histopathology image analysis with CNNs","L. Hou; K. Singh; D. Samaras; T. M. Kurc; Y. Gao; R. J. Seidman; J. H. Saltz","Dept of Computer Science, Stony Brook University","2016 New York Scientific Data Summit (NYSDS)","20161121","2016","","","1","6","We define Pathomics as the process of high throughput generation, interrogation, and mining of quantitative features from high-resolution histopathology tissue images. Analysis and mining of large volumes of imaging features has great potential to enhance our understanding of tumors. The basic Pathomics workflow consists of several steps: segmentation of tissue images to delineate the boundaries of nuclei, cells, and other structures; computation of size, shape, intensity, and texture features for each segmented object; classification of images and patients based on imaging features; and correlation of classification results with genomic signatures and clinical outcome. Executing a Pathomics workflow on a dataset of thousands of very high resolution (gigapixels) and heterogeneous histopathology images is a computationally challenging problem. In this paper, we use Convolutional Neural Networks (CNN) for automatic recognition of nuclear morphological attributes in histopathology images of glioma, the most common malignant brain tumor. We constructed a comprehensive multi-label dataset of glioma nuclei and applied two CNN based methods on this dataset. Both methods perform well recognizing some but not all morphological attributes and are complementary with each other.","","Electronic:978-1-4673-9051-4; POD:978-1-4673-9052-1","10.1109/NYSDS.2016.7747812","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7747812","Convolutional Neural Network;Nucleus Classification;Pathomics","Feature extraction;Image recognition;Image reconstruction;Image segmentation;Neurons;Support vector machines;Training","biological tissues;brain;cellular biophysics;data mining;genomics;image classification;image resolution;image segmentation;image texture;medical image processing;neural nets;tumours","CNN;Pathomics workflow;automatic histopathology image analysis;automatic nuclear morphological attribute recognition;cell boundary delineation;convolutional neural networks;genomic signatures;glioma nuclei;heterogeneous histopathology images;high-resolution histopathology tissue images;image classification;imaging feature analysis;imaging feature mining;malignant brain tumor;nuclei boundary delineation;texture features;tissue image segmentation","","","","","","","","14-17 Aug. 2016","","IEEE","IEEE Conference Publications"
"Customizing CNNs for blood vessel segmentation from fundus images","S. K. Vengalil; N. Sinha; S. S. S. Kruthiventi; R. V. Babu","International Institute of Information Technology, Bangalore, India","2016 International Conference on Signal Processing and Communications (SPCOM)","20161117","2016","","","1","4","For automatic screening of eye diseases, it is very important to segment regions corresponding to the different eye-parts from the fundal images. A challenging task, in this context, is to segment the network of blood vessels. The blood vessel network runs all along the fundal image, varying in density and fineness of structure. Besides, changes in illumination, color and pathology also add to the difficulties in blood vessel segmentation. In this paper, we propose segmentation of blood vessels from fundal images in the deep learning framework, without any pre-processing. A deep convolutional network, consisting of 8 convolutional layers and 3 pooling layers in between, is used to achieve the segmentation. In this work, a Convolutional Neural Network currently in use for semantic image segmentation is customized for blood vessel segmentation by replacing the output layer with a convolutional layer of kernel size 1 × 1 which generates the final segmented image. The output of CNN is a gray scale image and is binarized by thresholding. The proposed method is applied on 2 publicly available databases DRIVE and HRF (capturing diversity in image resolution), consisting of healthy and diseased fundal images boosted by mirror versions of the originals. The method results in an accuracy of 93.94% and yields 0.894 as area under the ROC curve on the test data comprising of randomly selected 23 images from HRF dataset. The promising results illustrate generalizability of the proposed approach.","","Electronic:978-1-5090-1746-1; POD:978-1-5090-1747-8","10.1109/SPCOM.2016.7746702","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7746702","","Biomedical imaging;Blood vessels;Image resolution;Image segmentation;Pathology;Testing;Training","blood vessels;convolution;diseases;image colour analysis;image resolution;image segmentation;learning (artificial intelligence);medical image processing;neural nets","CNN;DRIVE database;HRF databases;ROC curve;automatic screening;blood vessel network;blood vessel segmentation;convolutional neural network;deep learning framework;eye diseases;fundal images;fundus images;gray scale image;image resolution;semantic image segmentation","","","","","","","","12-15 June 2016","","IEEE","IEEE Conference Publications"
"Deep convolutional neural networks for classification of mild cognitive impaired and Alzheimer's disease patients from scalp EEG recordings","F. C. Morabito; M. Campolo; C. Ieracitano; J. M. Ebadi; L. Bonanno; A. Bramanti; S. Desalvo; N. Mammone; P. Bramanti","DICEAM Department, Mediterranean University of Reggio Calabria, Via Graziella Feo di Vito, 89060 Reggio Calabria, Italy","2016 IEEE 2nd International Forum on Research and Technologies for Society and Industry Leveraging a better tomorrow (RTSI)","20161114","2016","","","1","6","In spite of the worldwide financial and research efforts made, the pathophysiological mechanism at the basis of Alzheimer's disease (AD) is still poorly understood. Previous studies using electroencephalography (EEG) have focused on the slowing of oscillatory brain rhythms, coupled with complexity reduction of the corresponding time-series and their enhanced compressibility. These analyses have been typically carried out on single channels. However, limited investigations have focused on the possibility yielded by computational intelligence methodologies and novel machine learning approaches applied to multichannel schemes. The study at screening level on EEG recordings of subjects at risk could be useful to highlight the emergence of underlying AD progression (or at least support any further clinical investigation). In this work, the representational power of Deep Learning on Convolutional Neural Networks (CNN) is exploited to generate suitable sets of features that are then able to classify EEG patterns of AD from a prodromal version of dementia (Mild Cognitive Impairment, MCI) and from age-matched Healthy Controls (HC). The processing system here used enforces a series of convolutional-subsampling layers in order to derive a multivariate assembly of latent, novel patterns, finally used to categorize sets of EEG from different classes of subjects. The final processor here proposed is able to reach an averaged 80% of correct classification with good performance on both sensitivity and specificity by using a Multilayered Feedforward Perceptron (MLP) of the standard type as a final block of the procedure.","","Electronic:978-1-5090-1131-5; POD:978-1-5090-1132-2","10.1109/RTSI.2016.7740576","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7740576","Alzheimer's disease;Convolutional Neural Networks;Deep Learning;Mild Cognitive Impairment;Scalp EEG","Databases;Diseases;Electroencephalography;Feature extraction;Scalp;Standards;Time-frequency analysis","diseases;electroencephalography;learning (artificial intelligence);medical signal processing;neural nets","AD progression;Alzheimer's disease patients;EEG classification;computational intelligence methodologies;convolutional-subsampling layers;deep convolutional neural networks;electroencephalography;healthy controls;machine learning approaches;mild cognitive impairment;multilayered feedforward perceptron;oscillatory brain rhythms;pathophysiological mechanism;scalp EEG recordings","","","","","","","","7-9 Sept. 2016","","IEEE","IEEE Conference Publications"
"Improving convolutional neural network using accelerated proximal gradient method for epilepsy diagnosis","D. Li; G. Wang; T. Song; Q. Jin","Department of Automation, Beijing University of Chemical Technology, Beijing, China","2016 UKACC 11th International Conference on Control (CONTROL)","20161110","2016","","","1","6","The task of epilepsy diagnosing in medicine by classification of electroencephao-graph (EEG) signals is considered. Since an EEG signal has a large number of dimensions as an input sample vector, many previous classification methods have been proposed as hybrid frameworks, which are structurally complex and computationally expensive. In this paper, convolutional neural network (CNN) is used to realize feature extraction and classification simultaneously. The scheme of CNN is adopted to overcome the curse of dimensionality. Meanwhile, the accelerated proximal gradient method is used to increase the training ratio. Experimental results show that the proposed method achieves ideal accuracy of epilepsy diagnosis and converges faster than CNNs based on traditional gradient back propagation.","","Electronic:978-1-4673-9891-6; POD:978-1-4673-9892-3","10.1109/CONTROL.2016.7737620","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7737620","classification;convolutional neural network;epilepsy;feature extraction;proximal gradient","Acceleration;Biological neural networks;Classification algorithms;Convolution;Electroencephalography;Epilepsy;Feature extraction","electroencephalography;feature extraction;gradient methods;medical signal processing;neural nets;patient diagnosis;signal classification","CNN;EEG signal classification;accelerated proximal gradient method;convolutional neural network;curse of dimensionality;electroencephalograph signal;epilepsy diagnosis;feature extraction;input sample vector;training ratio","","","","","","","","Aug. 31 2016-Sept. 2 2016","","IEEE","IEEE Conference Publications"
"An Automated ECG Beat Classification System Using Convolutional Neural Networks","M. Zubair; J. Kim; C. Yoon","Inf. & Commun. Network Dept., Korea Univ. of Sci. & Technol., Daejeon, South Korea","2016 6th International Conference on IT Convergence and Security (ICITCS)","20161110","2016","","","1","5","Classification of Electrocardiogram (ECG) plays an important role in clinical diagnosis of cardiac diseases. In this paper, we introduce an ECG beat classification system using convolutional neural networks (CNNs). The proposed model integrates two main parts, feature extraction and classification, of ECG pattern recognition system. This model automatically learns a suitable feature representation from raw ECG data and thus negates the need of hand-crafted features. By using a small and patient-specific training data, the proposed classification system efficiently classified ECG beats into five different classes recommended by Association for Advancement of Medical Instrumentation (AAMI). ECG signal from 44 recordings of the MIT-BIH database are used to evaluate the classification performance and the results demonstrate that the proposed approach achieves a significant classification accuracy and superior computational efficiency than most of the state-of-the-art methods for ECG signal classification.","","Electronic:978-1-5090-3765-0; POD:978-1-5090-3766-7","10.1109/ICITCS.2016.7740310","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7740310","","Classification algorithms;Convolution;Databases;Electrocardiography;Feature extraction;Heart rate variability;Neural networks","convolution;diseases;electrocardiography;feature extraction;medical signal processing;neural nets;patient diagnosis;signal classification","CNN;ECG beat classification system;cardiac disease;clinical diagnosis;convolutional neural network;electrocardiogram signal;feature classification;feature extraction","","","","","","","","26-26 Sept. 2016","","IEEE","IEEE Conference Publications"
"Lung nodule detection in CT images using deep convolutional neural networks","R. Golan; C. Jacob; J. Denzinger","Dept. of Computer Science, University of Calgary, Alberta, Canada T2N 1N4","2016 International Joint Conference on Neural Networks (IJCNN)","20161103","2016","","","243","250","Early detection of lung nodules in thoracic Computed Tomography (CT) scans is of great importance for the successful diagnosis and treatment of lung cancer. Due to improvements in screening technologies, and an increased demand for their use, radiologists are required to analyze an ever increasing amount of image data, which can affect the quality of their diagnoses. Computer-Aided Detection (CADe) systems are designed to assist radiologists in this endeavor. Here, we present a CADe system for the detection of lung nodules in thoracic CT images. Our system is based on (1) the publicly available Lung Image Database Consortium (LIDC) and Image Database Resource Initiative (IDRI) database, which contains 1018 thoracic CT scans with nodules of different shape and size, and (2) a deep Convolutional Neural Network (CNN), which is trained, using the back-propagation algorithm, to extract valuable volumetric features from the input data and detect lung nodules in sub-volumes of CT images. Considering only those test nodules that have been annotated by four radiologists, our CADe system achieves a sensitivity (true positive rate) of 78.9% with 20 false positives (FPs) per scan, or a sensitivity of 71.2% with 10 FPs per scan. This is achieved without using any segmentation or additional FP reduction procedures, both of which are commonly used in other CADe systems. Furthermore, our CADe system is validated on a larger number of lung nodules compared to other studies, which increases the variation in their appearance, and therefore, makes their detection by a CADe system more challenging.","","","10.1109/IJCNN.2016.7727205","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7727205","","Biological neural networks;Biomedical imaging;Cancer;Computed tomography;Image databases;Lungs","backpropagation;cancer;computerised tomography;feature extraction;medical image processing;neural nets;object detection;patient diagnosis;patient treatment","CADe systems;CNN;IDRI database;LIDC database;backpropagation algorithm;computer-aided detection system;deep convolutional neural network;deep convolutional neural networks;image data;image database resource initiative database;lung cancer diagnosis;lung cancer treatment;lung image database consortium database;lung nodule detection;screening technology;thoracic CT images;thoracic computed tomography scans;valuable volumetric feature extraction","","","","","","","","24-29 July 2016","","IEEE","IEEE Conference Publications"
"Breast cancer histopathological image classification using Convolutional Neural Networks","F. A. Spanhol; L. S. Oliveira; C. Petitjean; L. Heutte","Federal University of Technology - Parana, Toledo, Brazil","2016 International Joint Conference on Neural Networks (IJCNN)","20161103","2016","","","2560","2567","The performance of most conventional classification systems relies on appropriate data representation and much of the efforts are dedicated to feature engineering, a difficult and time-consuming process that uses prior expert domain knowledge of the data to create useful features. On the other hand, deep learning can extract and organize the discriminative information from the data, not requiring the design of feature extractors by a domain expert. Convolutional Neural Networks (CNNs) are a particular type of deep, feedforward network that have gained attention from research community and industry, achieving empirical successes in tasks such as speech recognition, signal processing, object recognition, natural language processing and transfer learning. In this paper, we conduct some preliminary experiments using the deep learning approach to classify breast cancer histopathological images from BreaKHis, a publicly dataset available at http://web.inf.ufpr.br/vri/breast-cancer-database. We propose a method based on the extraction of image patches for training the CNN and the combination of these patches for final classification. This method aims to allow using the high-resolution histopathological images from BreaKHis as input to existing CNN, avoiding adaptations of the model that can lead to a more complex and computationally costly architecture. The CNN performance is better when compared to previously reported results obtained by other machine learning models trained with hand-crafted textural descriptors. Finally, we also investigate the combination of different CNNs using simple fusion rules, achieving some improvement in recognition rates.","","","10.1109/IJCNN.2016.7727519","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7727519","","Neural networks","cancer;image classification;medical image processing;neural nets","BreaKHis;CNN performance;breast cancer histopathological image classification;breast cancer histopathological images;convolutional neural networks;data representation;deep learning;discriminative information;domain expert;feature extractors;feedforward network;fusion rules;hand-crafted textural descriptors;high-resolution histopathological images;image patches;machine learning models;natural language processing;object recognition;recognition rates;research community;signal processing;speech recognition;time-consuming process;transfer learning","","1","","","","","","24-29 July 2016","","IEEE","IEEE Conference Publications"
"Classification of mammogram images by using CNN classifier","K. Sharma; B. Preet","Dept. of Electronics and Communication, Chandigarh University, Gharuan, Mohali, India","2016 International Conference on Advances in Computing, Communications and Informatics (ICACCI)","20161103","2016","","","2743","2749","Classification of the breast tissues into the benign and malignant classes is a difficult assignment. The experimental results are takes 40 input images from DDSM dataset. We extract the GLCM, GLDM and Geometrical features from the mammogram images. In this paper we apply Convolution Neural Network as a classifier on the mammogram images to enhance the accuracy rate of CAD. Performance of the different classifiers is measured on receiver operating characteristic. In training stage, overall classification accuracy of 73%, with 71.5% sensitivity and 73.5% specificity for dense tissue is achieved by our proposed method along with it, accuracy of 79.23%, 73.25% sensitivity and 74.5% specificity is achieved for fatty tissue. Convolution neural network classifier is used to boost the classification performance. This classifier performs better than previous classifiers in that it shows more accuracy than the other classifiers, the misclassification rate of normal mammograms as abnormal. This approach performs good on overlapping problem. This method is different from all other approaches, which are used to identify normal mammograms by detecting cancers. Overlapped tissues are also detected by this using this classifier.","","","10.1109/ICACCI.2016.7732477","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7732477","Computer-aided diagnosis (CADx);Convolution neural network (CNN);Logistic regression (LR);mammography;microcalcifications","Cancer;Digital filters;Image edge detection;Image segmentation;Mammography;Training;Wiener filters","CAD;biological tissues;geometry;image classification;mammography;medical image processing;neural nets","CAD;CNN classifier;DDSM dataset;GLCM;GLDM;breast tissues;convolution neural network;dense tissue;geometrical features;mammogram image classification","","","","","","","","21-24 Sept. 2016","","IEEE","IEEE Conference Publications"
"Using Convolutional Neural Network for edge detection in musculoskeletal ultrasound images","S. I. Jabbar; C. R. Day; N. Heinz; E. K. Chadwick","Biomedical Engineering, Institute for Science and Technology in Medicine, Keele University, UK","2016 International Joint Conference on Neural Networks (IJCNN)","20161103","2016","","","4619","4626","Fast and accurate segmentation of musculoskeletal ultrasound images is an on-going challenge. Two principal factors make this task difficult: firstly, the presence of speckle noise arising from the interference that accompanies all coherent imaging approaches; secondly, the sometimes subtle interaction between musculoskeletal components that leads to non-uniformity of the image intensity. Our work presents an investigation of the potential of Convolutional Neural Networks (CNNs) to address both of these problems. CNNs are an effective tool that has previously been used in image processing of several biomedical imaging modalities. However, there is little published material addressing the processing of musculoskeletal ultrasound images. In our work we explore the effectiveness of CNNs when trained to act as a pre-segmentation pixel classifier that determines whether a pixel is an edge or non-edge pixel. Our CNNs are trained using two different ground truth interpretations. The first one uses an automatic Canny edge detector to provide the ground truth image; the second ground truth was obtained using the same image marked-up by an expert anatomist. In this initial study the CNNs have been trained using half of the prepared data from one image, using the other half for testing; validation was also carried out using three unseen ultrasound images. CNN performance was assessed using Mathew's Correlation Coefficient, Sensitivity, Specificity and Accuracy. The results show that CNN performance when using expert ground truth image is better than using Canny ground truth image. Our technique is promising and has the potential to speed-up the image processing pipeline using appropriately trained CNNs.","","","10.1109/IJCNN.2016.7727805","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7727805","Convolutional Neural Networks;Musculoskeletal model;Segmentation;Ultrasound image","Biological system modeling;Biomedical imaging;Image edge detection;Image segmentation;Kernel;Musculoskeletal system;Ultrasonic variables measurement","biomedical ultrasonics;bone;edge detection;image classification;image resolution;image segmentation;learning (artificial intelligence);medical image processing;muscle;neural nets;ultrasonic imaging","CNN performance;Mathew's correlation coefficient;automatic Canny edge detector;biomedical imaging modalities;convolutional neural network;edge pixel;expert ground truth image;ground truth images;ground truth interpretations;image intensity;image processing;image processing pipeline;musculoskeletal components;musculoskeletal ultrasound image segmentation;nonedge pixel;presegmentation pixel classifier;speckle noise","","","","","","","","24-29 July 2016","","IEEE","IEEE Conference Publications"
"Feature leaning with deep Convolutional Neural Networks for screening patients with paroxysmal atrial fibrillation","B. Pourbabaee; M. J. Roshtkhari; K. Khorasani","Department of Electrical and Computer Engineering, Concordia University, Montreal, Canada","2016 International Joint Conference on Neural Networks (IJCNN)","20161103","2016","","","5057","5064","In this paper, a novel electrocardiogram (ECG) signal classification and patient screening method is developed. The focus is on identifying patients with paroxysmal atrial fibrillation (PAF) which is a life threatening cardiac arrhythmia. The proposed approach uses the raw ECG signal as the input and automatically learns the representative features for PAF to be used by a classification mechanism. The features are learned directly from the time domain ECG signals by using a Convolutional Neural Network (CNN) with one fully connected layer. The learned features can replace the hand-crafted features and our experimental results indicate the effectiveness of the learned features in patient screening. The experimental results indicate that combining the learned features with other classifiers will improve the performance of the patient screening system as compared to an End-to-End convolutional neural network classifier. The major characteristics of the proposed approach are to simplify the process of feature extraction for different cardiac arrhythmias and to remove the need for using a human expert to specify the appropriate features. The effectiveness of the proposed ECG classification method is demonstrated through performing extensive simulation studies.","","","10.1109/IJCNN.2016.7727866","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7727866","","Biological neural networks;Convolution;Electrocardiography;Feature extraction;Hidden Markov models;Learning systems","convolution;diseases;electrocardiography;feature extraction;learning (artificial intelligence);medical signal processing;neural nets;signal classification;signal representation;time-domain analysis","CNN;ECG signal classification;PAF;deep convolutional neural networks;electrocardiogram;feature extraction;feature leaning;life threatening cardiac arrhythmia;paroxysmal atrial fibrillation;patients screening;representative features;time domain ECG signals","","","","","","","","24-29 July 2016","","IEEE","IEEE Conference Publications"
"Class-wise deep dictionaries for EEG classification","P. Khurana; A. Majumdar; R. Ward","IIIT Delhi, New Delhi, India","2016 International Joint Conference on Neural Networks (IJCNN)","20161103","2016","","","3556","3563","In this work we propose a classification framework called class-wise deep dictionary learning (CWDDL). For each class, multiple levels of dictionaries are learnt using features from the previous level as inputs (for first level the input is the raw training sample). It is assumed that the cascaded dictionaries form a basis for expressing test samples for that class. Based on this assumption sparse representation based classification is employed. Benchmarking experiments have been carried out on some deep learning datasets (MNIST and its variations, CIFAR and SVHN); our proposed method has been compared with Deep Belief Network (DBN), Stacked Autoencoder, Convolutional Neural Net (CNN) and Label Consistent KSVD (dictionary learning). We find that our proposed method yields better results than these techniques and requires much smaller run-times. The technique is applied for Brain Computer Interface (BCI) classification problems using EEG signals. For this problem our method performs significantly better than Convolutional Deep Belief Network(CDBN).","","","10.1109/IJCNN.2016.7727656","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7727656","EEG;deep learning;dictionary learning","Benchmark testing;Dictionaries;Machine learning;Minimization;Neural networks;Sparse matrices;Training","belief networks;brain-computer interfaces;electroencephalography;feedforward neural nets;learning (artificial intelligence);medical signal processing;signal classification;signal representation","CDBN;CIFAR;CNN;CWDDL;EEG classification;EEG signals;MNIST;SVHN;brain computer interface classification problems;cascaded dictionaries;class-wise deep dictionary learning;convolutional deep belief network;convolutional neural net;deep learning datasets;label consistent KSVD;sparse representation based classification;stacked autoencoder","","","","","","","","24-29 July 2016","","IEEE","IEEE Conference Publications"
"Vessel extraction in X-ray angiograms using deep learning","E. Nasr-Esfahani; S. Samavi; N. Karimi; S. M. R. Soroushmehr; K. Ward; M. H. Jafari; B. Felfeliyan; B. Nallamothu; K. Najarian","Department of Electrical and Computer Engineering, Isfahan University of Technology, Isfahan 84156-83111, Iran","2016 38th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)","20161018","2016","","","643","646","Coronary artery disease (CAD) is the most common type of heart disease which is the leading cause of death all over the world. X-ray angiography is currently the gold standard imaging technique for CAD diagnosis. These images usually suffer from low quality and presence of noise. Therefore, vessel enhancement and vessel segmentation play important roles in CAD diagnosis. In this paper a deep learning approach using convolutional neural networks (CNN) is proposed for detecting vessel regions in angiography images. Initially, an input angiogram is preprocessed to enhance its contrast. Afterward, the image is evaluated using patches of pixels and the network determines the vessel and background regions. A set of 1,040,000 patches is used in order to train the deep CNN. Experimental results on angiography images of a dataset show that our proposed method has a superior performance in extraction of vessel regions.","1557-170X;1557170X","Electronic:978-1-4577-0220-4; POD:978-1-4577-0219-8","10.1109/EMBC.2016.7590784","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7590784","Angiography;convolutional neural networks;deep learning;vessel segmentation","Angiography;Arteries;Feature extraction;Filter banks;Image segmentation;Training;Transforms","blood vessels;diagnostic radiography;diseases;image segmentation;learning (artificial intelligence);medical image processing;neural nets;noise","CAD diagnosis;X-ray angiography;convolutional neural networks;coronary artery disease;death;deep learning;heart disease;noise;vessel enhancement;vessel extraction;vessel segmentation","","1","","","","","","16-20 Aug. 2016","","IEEE","IEEE Conference Publications"
"Thorax disease diagnosis using deep convolutional neural network","J. Chen; X. Qi; O. Tervonen; O. Silvén; G. Zhao; M. Pietikäinen","University of Oulu, Finland","2016 38th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)","20161018","2016","","","2287","2290","Computer aided diagnosis (CAD) is an important issue, which can significantly improve the efficiency of doctors. In this paper, we propose a deep convolutional neural network (CNN) based method for thorax disease diagnosis. We firstly align the images by matching the interest points between the images, and then enlarge the dataset by using Gaussian scale space theory. After that we use the enlarged dataset to train a deep CNN model and apply the obtained model for the diagnosis of new test data. Our experimental results show our method achieves very promising results.","1557-170X;1557170X","Electronic:978-1-4577-0220-4; POD:978-1-4577-0219-8","10.1109/EMBC.2016.7591186","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7591186","","Diseases;Filtering theory;Machine learning;Radiography;Solid modeling;Thorax;Training","Gaussian processes;diagnostic radiography;diseases;image matching;medical image processing;neural nets;radiology","CAD;Gaussian scale space theory;computer aided diagnosis;deep CNN model;deep convolutional neural network;image alignment;image matching;radiograph;radiology;thorax disease diagnosis","","","","","","","","16-20 Aug. 2016","","IEEE","IEEE Conference Publications"
"Encoding physiological signals as images for affective state recognition using convolutional neural networks","G. Yu; X. Li; D. Song; X. Zhao; P. Zhang; Y. Hou; B. Hu","Tianjin Key Laboratory of Cognitive Computing and Application, Tianjin University, China","2016 38th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)","20161018","2016","","","812","815","Affective state recognition based on multiple modalities of physiological signals has been a hot research topic. Traditional methods require designing hand-crafted features based on domain knowledge, which is time-consuming and has not achieved a satisfactory performance. On the other hand, conducting classification on raw signals directly can also cause some problems, such as the interference of noise and the curse of dimensionality. To address these problems, we propose a novel approach that encodes different modalities of data as images and use convolutional neural networks (CNN) to perform the affective state recognition task. We validate our aproach on the DECAF dataset in comparison with two state-of-the-art methods, i.e., the Support Vector Machines (SVM) and Random Forest (RF). Experimental results show that our aproach outperforms the baselines by 5% to 9%.","1557-170X;1557170X","Electronic:978-1-4577-0220-4; POD:978-1-4577-0219-8","10.1109/EMBC.2016.7590825","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7590825","","Convolution;Electrooculography;Feature extraction;Physiology;Support vector machines;Time series analysis;Time-frequency analysis","electro-oculography;magnetoencephalography;medical signal processing;neural nets;random processes;support vector machines","CNN;DECAF dataset;SVM;affective state recognition;convolutional neural networks;dimensionality curse;domain knowledge;hand-crafted features;noise interference;physiological signal encoding;random forest;raw signals;support vector machines","","","","","","","","16-20 Aug. 2016","","IEEE","IEEE Conference Publications"
"Melanoma detection by analysis of clinical images using convolutional neural network","E. Nasr-Esfahani; S. Samavi; N. Karimi; S. M. R. Soroushmehr; M. H. Jafari; K. Ward; K. Najarian","Department of Electrical and Computer Engineering, Isfahan University of Technology, Isfahan 84156-83111, Iran","2016 38th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)","20161018","2016","","","1373","1376","Melanoma, most threatening type of skin cancer, is on the rise. In this paper an implementation of a deep-learning system on a computer server, equipped with graphic processing unit (GPU), is proposed for detection of melanoma lesions. Clinical (non-dermoscopic) images are used in the proposed system, which could assist a dermatologist in early diagnosis of this type of skin cancer. In the proposed system, input clinical images, which could contain illumination and noise effects, are preprocessed in order to reduce such artifacts. Afterward, the enhanced images are fed to a pre-trained convolutional neural network (CNN) which is a member of deep learning models. The CNN classifier, which is trained by large number of training samples, distinguishes between melanoma and benign cases. Experimental results show that the proposed method is superior in terms of diagnostic accuracy in comparison with the state-of-the-art methods.","1557-170X;1557170X","Electronic:978-1-4577-0220-4; POD:978-1-4577-0219-8","10.1109/EMBC.2016.7590963","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7590963","","Computers;Feature extraction;Lesions;Lighting;Machine learning;Malignant tumors;Training","biomedical optical imaging;cancer;graphics processing units;image classification;image denoising;learning (artificial intelligence);medical image processing;neural nets;skin","CNN classifier;artifact reduction;clinical image analysis;convolutional neural network;deep-learning system;diagnostic accuracy;early skin cancer diagnosis;graphic processing unit;illumination effect;input clinical image;melanoma detection;noise effect;nondermoscopic image","","","","","","","","16-20 Aug. 2016","","IEEE","IEEE Conference Publications"
"Automatic Lumbar Vertebrae Detection Based on Feature Fusion Deep Learning for Partial Occluded C-arm X-ray Images","Y. Li; W. Liang; Y. Zhang; H. An; J. Tan","Key Laboratory of Networked Control Systems, Shenyang Institute of Automation, Chinese Academy of Sciences, Shenyang, 110016, China","2016 38th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)","20161018","2016","","","647","650","Automatic and accurate lumbar vertebrae detection is an essential step of image-guided minimally invasive spine surgery (IG-MISS). However, traditional methods still require human intervention due to the similarity of vertebrae, abnormal pathological conditions and uncertain imaging angle. In this paper, we present a novel convolutional neural network (CNN) model to automatically detect lumbar vertebrae for C-arm X-ray images. Training data is augmented by DRR and automatic segmentation of ROI is able to reduce the computational complexity. Furthermore, a feature fusion deep learning (FFDL) model is introduced to combine two types of features of lumbar vertebrae X-ray images, which uses sobel kernel and Gabor kernel to obtain the contour and texture of lumbar vertebrae, respectively. Comprehensive qualitative and quantitative experiments demonstrate that our proposed model performs more accurate in abnormal cases with pathologies and surgical implants in multi-angle views.","1557-170X;1557170X","Electronic:978-1-4577-0220-4; POD:978-1-4577-0219-8","10.1109/EMBC.2016.7590785","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7590785","","Computational modeling;Feature extraction;Kernel;Machine learning;Pathology;Surgery;X-ray imaging","computational complexity;computerised tomography;image fusion;image segmentation;image texture;learning (artificial intelligence);medical image processing;neural nets;prosthetics;surgery","CNN;DRR;FFDL;Gabor kernel;IG-MISS;ROI;abnormal pathological condition;automatic lumbar vertebrae detection;automatic segmentation;computational complexity;convolutional neural network model;feature fusion deep learning model;image-guided minimally invasive spine surgery;imaging angle;lumbar vertebrae X-ray images;lumbar vertebrae contour;lumbar vertebrae texture;partial occluded C-arm X-ray images;sobel kernel;surgical implants;training data","","1","","","","","","16-20 Aug. 2016","","IEEE","IEEE Conference Publications"
"Predicting seizures from local field potentials recorded via intracortical microelectrode arrays","M. Aghagolzadeh; L. R. Hochberg; S. S. Cash; W. Truccolo","Department of Neuroscience, Brown University, and the Center for Neurorestoration and Neurotechnology, U.S. Department of Veterans Affairs, Providence, RI 02912","2016 38th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)","20161018","2016","","","6353","6356","The need for new therapeutic interventions to treat pharmacologically resistant focal epileptic seizures has led recently to the development of closed-loop systems for seizure control. Once a seizure is predicted/detected by the system, electrical stimulation is delivered to prevent seizure initiation or spread. So far, seizure prediction/detection has been limited to tracking non-invasive electroencephalogram (EEG) or intracranial EEG (iEEG) signals. Here, we examine seizure prediction based on local field potentials (LFPs) from a small neocortical patch recorded via a 10×10 microelectrode array implanted in a patient with focal seizures. We formulate the seizure (ictal) prediction problem in terms of discriminating between interictal and preictal neural activity. Using deep Convolutional Neural Networks (CNNs), we show that periods of preictal activity can be successfully discriminated (80% detection; no false positives) from periods of interictal activity several (2-18) minutes prior to seizure onset. CNN input features consisted of the spectral power of LFP channels (1-second time windows) computed in 50 frequency bands (0-100 Hz; 2 Hz steps). Our preliminary results show that intracortical LFPs may be a promising neural signal for seizure prediction in focal epilepsy.","1557-170X;1557170X","Electronic:978-1-4577-0220-4; POD:978-1-4577-0219-8","10.1109/EMBC.2016.7592181","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7592181","","Convolution;Electroencephalography;Epilepsy;Hospitals;Microelectrodes;Neuroscience;Training","bioelectric potentials;biomedical electrodes;brain;medical signal detection;medical signal processing;microelectrodes;neural nets;neurophysiology","CNN;closed-loop systems;convolutional neural networks;electrical stimulation;focal epilepsy;frequency 0 Hz to 100 Hz;interictal neural activity;intracortical microelectrode arrays;local field potentials;microelectrode array;neocortical patch;pharmacologically resistant focal epileptic seizures;preictal neural activity;seizure control;seizure detection;seizure prediction;therapeutic interventions;time 2 min to 8 min","","","","","","","","16-20 Aug. 2016","","IEEE","IEEE Conference Publications"
"A deep learning based approach to classification of CT brain images","X. W. Gao; R. Hui","Department of Computer Science, Middlesex University, London NW4 4BT, UK","2016 SAI Computing Conference (SAI)","20160901","2016","","","28","31","This study explores the applicability of the state of the art of deep learning convolutional neural network (CNN) to the classification of CT brain images, aiming at bring images into clinical applications. Towards this end, three categories are clustered, which contains subjects' data with either Alzheimer's disease (AD) or lesion (e.g. tumour) or normal ageing. Specifically, due to the characteristics of CT brain images with larger thickness along depth (z) direction (~5mm), both 2D and 3D CNN are employed in this research. The fusion is therefore conducted based on both 2D CT images along axial direction and 3D segmented blocks with the accuracy rates are 88.8%, 76.7% and 95% for classes of AD, lesion and normal respectively, leading to an average of 86.8%.","","Electronic:978-1-4673-8460-5; POD:978-1-4673-8461-2","10.1109/SAI.2016.7555958","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7555958","3D CNN;CT brain images;Classification;convolutional neural network","Alzheimer's disease;Brain;Computed tomography;Kernel;Lesions;Three-dimensional displays;Two dimensional displays","computerised tomography;diseases;image classification;learning (artificial intelligence);medical image processing;neural nets","2D CNN;2D CT images;3D CNN;3D segmented blocks;AD;Alzheimer's disease;CT brain image classification;axial direction;clinical applications;deep learning based approach;deep learning convolutional neural network;lesion;normal ageing","","","","","","","","13-15 July 2016","","IEEE","IEEE Conference Publications"
"A deep symmetry convnet for stroke lesion segmentation","Y. Wang; A. K. Katsaggelos; X. Wang; T. B. Parrish","Northwestern University, Department of EECS, Evanston, IL, USA","2016 IEEE International Conference on Image Processing (ICIP)","20160819","2016","","","111","115","Stroke is one of the leading causes of death and disability. Clinically, to establish stroke patient prognosis, an accurate delineation of brain lesion is essential, which is time consuming and prone to subjective errors. In this paper, we propose a novel method call Deep Lesion Symmetry ConvNet to automatically segment chronic stroke lesions using MRI. An 8-layer 3D convolutional neural network is constructed to handle the MRI voxels. An additional CNN stream using the corresponding symmetric MRI voxels is combined, leading to a significant improvement in system performance. The high average dice coefficient achieved on our dataset based on data collected from three research labs demonstrates the effectiveness of our method.","","Electronic:978-1-4673-9961-6; POD:978-1-4673-9962-3","10.1109/ICIP.2016.7532329","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7532329","Brain Quasi-symmetry;Deep Learning;Image Segmentation;MRI;Stroke","Biological neural networks;Brain modeling;Image segmentation;Lesions;Magnetic resonance imaging;Pipelines;Three-dimensional displays","biomedical MRI;brain;image segmentation;medical image processing;neural nets;patient treatment","3D convolutional neural network;MRI voxels;brain lesion;death;deep symmetry ConvNet;disability;stroke lesion segmentation;stroke patient prognosis","","","","13","","","","25-28 Sept. 2016","","IEEE","IEEE Conference Publications"
"Alzheimer's disease diagnostics by adaptation of 3D convolutional network","E. Hosseini-Asl; R. Keynton; A. El-Baz","Electrical and Computer Engineering Department, University of Louisville, Louisville, KY, USA","2016 IEEE International Conference on Image Processing (ICIP)","20160819","2016","","","126","130","Early diagnosis, playing an important role in preventing progress and treating the Alzheimer's disease (AD), is based on classification of features extracted from brain images. The features have to accurately capture main AD-related variations of anatomical brain structures, such as, e.g., ventricles size, hippocampus shape, cortical thickness, and brain volume. This paper proposed to predict the AD with a deep 3D convolutional neural network (3D-CNN), which can learn generic features capturing AD biomarkers and adapt to different domain datasets. The 3D-CNN is built upon a 3D convolutional autoencoder, which is pre-trained to capture anatomical shape variations in structural brain MRI scans. Fully connected upper layers of the 3D-CNN are then fine-tuned for each task-specific AD classification. Experiments on the CADDementia MRI dataset with no skull-stripping preprocessing have shown our 3D-CNN outperforms several conventional classifiers by accuracy. Abilities of the 3D-CNN to generalize the features learnt and adapt to other domains have been validated on the ADNI dataset.","","Electronic:978-1-4673-9961-6; POD:978-1-4673-9962-3","10.1109/ICIP.2016.7532332","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7532332","3D convolutional neural network;Alzheimer's disease;autoencoder;brain MRI;deep learning","Convolution;Feature extraction;Hippocampus;Magnetic resonance imaging;Positron emission tomography;Three-dimensional displays;Training","biomedical MRI;brain;diseases;feature extraction;generalisation (artificial intelligence);image classification;learning (artificial intelligence);medical image processing;neural nets;neurophysiology","3D convolutional autoencoder;3D-CNN;AD biomarkers;ADNI dataset;Alzheimer's disease diagnostics;Alzheimer's disease progress prevention;Alzheimer's disease treatment;CADDementia MRI dataset;anatomical brain structures;anatomical shape variation;brain image;brain volume;cortical thickness;deep 3D convolutional neural network;early diagnosis;feature classification;feature extraction;feature generalization;generic feature learning;hippocampus shape;structural brain MRI scan;ventricles size","","","","38","","","","25-28 Sept. 2016","","IEEE","IEEE Conference Publications"
"Label inference encoded with local and global patch priors","S. Bao; A. C. S. Chung","Lo Kwee-Seong Medical Image Analysis Laboratory, Department of Computer Science and Engineering, The Hong Kong University of Science and Technology, Hong Kong","2016 IEEE International Conference on Image Processing (ICIP)","20160819","2016","","","3374","3378","In this paper, a novel label inference method encoded with local and global patch priors is introduced for the segmentation of subcortical structures in brain MR images. Due to the serious overlap of intensity profiles among different tissues in brain MR images, the conventional patch prior estimated with similarity measurement can be adversely impacted and become misleading during the final label inference procedure. As such, to obtain a more discriminative patch representation, we propose to capture local patch prior using sparse learning. Besides the local and low-level patch prior, the high-level structural properties of each subcortical structure are also taken into consideration and global patch prior is extracted with Convolutional Neural Networks. Experiments have been carried out on two publicly available datasets and results indicate that the proposed method can obtain the best performance as compared with other state-of-the-art methods.","","Electronic:978-1-4673-9961-6; POD:978-1-4673-9962-3","10.1109/ICIP.2016.7532985","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7532985","CNN;Segmentation;brain MR image;sparse learning","Biomedical imaging;Feature extraction;Hippocampus;Image edge detection;Image segmentation;Labeling;Lattices","biomedical MRI;feature extraction;image coding;image segmentation;inference mechanisms;learning (artificial intelligence);medical image processing;neural net architecture","brain MR image tissues;convolutional neural networks;global patch priors;high-level structural properties;intensity profile overlap;label inference encoding;publicly available datasets;sparse learning;sparse local low-level patch prior;subcortical structure segmentation","","","","17","","","","25-28 Sept. 2016","","IEEE","IEEE Conference Publications"
"Improving Tuberculosis Diagnostics Using Deep Learning and Mobile Health Technologies among Resource-Poor and Marginalized Communities","Y. Cao; C. Liu; B. Liu; M. J. Brunette; N. Zhang; T. Sun; P. Zhang; J. Peinado; E. S. Garavito; L. L. Garcia; W. H. Curioso","Dept. of Comput. Sci., Univ. of Massachusetts-Lowell, Lowell, MA, USA","2016 IEEE First International Conference on Connected Health: Applications, Systems and Engineering Technologies (CHASE)","20160818","2016","","","274","281","Tuberculosis (TB) is a chronic infectious disease worldwide and remains a major cause of death globally. Of the estimated 9 million people who developed TB in 2013, over 80% were in South-East Asia, Western Pacific, and African. The majority of the infected populations was from resource-poor and marginalized communities with weak healthcare infrastructure. Reducing TB diagnosis delay is critical in mitigating disease transmission and minimizing the reproductive rate of the tuberculosis epidemic. The combination of machine learning and mobile computing techniques offers a unique opportunity to accelerate the TB diagnosis among these communities. The ultimate goal of our research is to reduce patient wait times for being diagnosed with this infectious disease by developing new machine learning and mobile health techniques to the TB diagnosis problem. In this paper, we first introduce major technique barriers and proposed system architecture. Then we report two major progresses we recently made. The first activity aims to develop large-scale, real-world and well-annotated X-ray image database dedicated for automated TB screening. The second research activity focus on developing effective and efficient computational models (in particularly, deep convolutional neural networks (CNN)-based models) to classify the image into different category of TB manifestations. Experimental results have demonstrated the effectiveness of our approach. Our future work includes: (1) to further improve the performance of the algorithms, and (2) to deploy our system in the city of Carabayllo in Perú, a densely occupied urban community and high-burden TB.","","Electronic:978-1-5090-0943-5; POD:978-1-5090-0944-2","10.1109/CHASE.2016.18","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7545842","Perú;deep convolutional neural networks;deep learning;diagnosis;mHealth;mobile computing;tuberculosis","Diagnostic radiography;Image databases;Mobile communication;Mobile computing;Mobile handsets;X-ray imaging","diagnostic radiography;diseases;epidemics;image classification;learning (artificial intelligence);medical image processing;mobile computing;neural nets;patient diagnosis;visual databases","African;CNN-based models;Deep Learning;Mobile Health Technologies;South-East Asia;TB diagnosis delay;Tuberculosis Diagnostics;Western Pacific;X-ray image database;automated TB screening;chronic infectious disease;deep convolutional neural network-based models;disease transmission;healthcare;image classification;machine learning;mobile computing;tuberculosis epidemic","","","","","","","","27-29 June 2016","","IEEE","IEEE Conference Publications"
"Human Pulse Recognition Based on Convolutional Neural Networks","S. R. Zhang; Q. F. Sun","Coll. of Commun. & Inf. Eng., Xi'an Univ. of Sci. & Technol., Xi'an, China","2016 International Symposium on Computer, Consumer and Control (IS3C)","20160818","2016","","","366","369","Human pulse recognition is an important part of the objective study of Traditional Chinese Medicine (TCM). In the current human pulse recognition methods, there are many feature extraction algorithms but many are complex and redundancy exists in the features selections. This paper focused on the typical convolutional neural network (CNN), and designed a 9-layer CNN which can be used to human wrist pulse signal classification. Feature extraction process is not necessary in the proposed method so the computing and the complexity are reduced. Experimental results show that the recognition rate can be 93.49%, which further verified the feasibility of our method.","","Electronic:978-1-5090-3071-2; POD:978-1-5090-3072-9","10.1109/IS3C.2016.101","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7545211","Back propagation;convolutional neural network;traditional Chinese medicine;wrist pulse signal","Convolution;Cost function;Feature extraction;Kernel;Neural networks;Training;Wrist","computational complexity;medical signal processing;medicine;neural nets;signal classification","9-layer CNN;TCM;computational complexity reduction;convolutional neural networks;human pulse recognition methods;human wrist pulse signal classification;traditional Chinese medicine","","","","","","","","4-6 July 2016","","IEEE","IEEE Conference Publications"
"Application of deep learning for recognizing infant cries","C. Y. Chang; J. J. Li","National Yunlin University of Science & Technology, Taiwan","2016 IEEE International Conference on Consumer Electronics-Taiwan (ICCE-TW)","20160728","2016","","","1","2","Crying is a way which infants express their needs to their parents. In general, parents often feel worried and anxious when infant crying. For realizing the reason of baby crying, this paper presents an automatic infant crying recognition method. Crying is convert to spectrogram. A convolutional neural networks (CNN) based deep learning is then adopted to train and classify the crying into three categories including hungry, pain, and sleepy. Experimental results shows that the proposed method achieves high classification accuracy.","","Electronic:978-1-5090-2073-7; POD:978-1-5090-2074-4","10.1109/ICCE-TW.2016.7520947","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7520947","","Biological neural networks;Convolution;Machine learning;Neurons;Pain;Spectrogram;Speech recognition","audio signal processing;convolution;learning (artificial intelligence);medical signal processing;neural nets;paediatrics","CNN based deep learning;automatic infant crying recognition method;convolutional neural networks;spectrogram","","","","","","","","27-29 May 2016","","IEEE","IEEE Conference Publications"
"Prediction of visual attention with Deep CNN for studies of neurodegenerative diseases","S. Chaabouni; F. Tison; J. Benois-Pineau; C. Ben Amar","LaBRI UMR 5800, University of Bordeaux, Cours de la Libration, 33405 Talence Cedex, France","2016 14th International Workshop on Content-Based Multimedia Indexing (CBMI)","20160630","2016","","","1","6","As a part of the automatic study of visual attention of affected populations with neurodegenerative diseases and to predict whether new gaze records a complaint of these diseases, we should design an automatic model that predicts salient areas in video. Past research showed, that people suffering form dementia are not reactive with regard to degradations on still images. In this paper we study the reaction of healthy normal control subjects on degraded area in videos. Furthermore, in the goal to build an automatic prediction model for salient areas in intentionally degraded videos, we design a deep learning architecture and measure its performances when predicting salient regions on completely unseen data. The obtained results are interesting regarding the reaction of normal control subjects against a degraded area in video.","","Electronic:978-1-4673-8695-1; POD:978-1-4673-8696-8","10.1109/CBMI.2016.7500243","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7500243","","Degradation;Diseases;Measurement;Predictive models;Sociology;Statistics;Visualization","diseases;medical image processing;video signal processing","automatic prediction model;deep CNN;deep learning architecture;dementia;gaze records;neurodegenerative diseases;visual attention prediction","","","","21","","","","15-17 June 2016","","IEEE","IEEE Conference Publications"
"New Signal Processing Methods for the Development of Seizure Warning Devices in Epilepsy","V. Senger; R. Tetzlaff","Chair of Fundamentals of Electrical Engineering, Faculty of Electrical and Computer Engineering, Technische Universit&#228;t Dresden, Dresden, Germany","IEEE Transactions on Circuits and Systems I: Regular Papers","20160628","2016","63","5","609","616","The seizure prediction problem has been addressed by many researchers from very different fields for more than three decades. The vision of an implantable seizure prediction device may become reality soon: the first clinical study of such a device has been realized very recently and other realizations are not far behind. Cellular Nonlinear Networks (CNN) were firstly introduced by Chua and Yang in 1988 and later extended to an inherently parallel processing framework called the CNN Universal Machine (CNN-UM). This framework combines high computational power with low power consumption and miniaturized design-making it a very promising basis for the realization of a seizure warning device. In this contribution, we compare the seizure prediction performance of an eigenvalue based PCA-preprocessing followed by a nonlinear CNN signal prediction to the performance of a linear signal prediction approach followed by a level-crossing behavior analysis as well as to the performance of a combination of the two methods.","1549-8328;15498328","","10.1109/TCSI.2016.2553278","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7464898","Cellular Nonlinear Networks;epilepsy;level-crossing analysis;multivariate signal processing;seizure prediction;statistical analysis","Eigenvalues and eigenfunctions;Electroencephalography;Epilepsy;Performance evaluation;Principal component analysis;Signal processing;Signal processing algorithms","diseases;medical signal processing;principal component analysis","CNN universal machine;PCA-preprocessing;cellular nonlinear networks;epilepsy;implantable seizure prediction device;level-crossing behavior analysis;nonlinear CNN signal prediction;seizure prediction problem;seizure warning devices;signal processing methods","","","","20","","","20160504","May 2016","","IEEE","IEEE Journals & Magazines"
"Feature extraction for histopathological images using Convolutional Neural Network","N. Hatipoglu; G. Bilgin","Bilgisayar Teknolojileri B&#246;l&#252;m&#252;, Trakya &#220;niversitesi, 22030 Edirne, Turkiye","2016 24th Signal Processing and Communication Application Conference (SIU)","20160623","2016","","","645","648","In this study, it is intended to increase the classification accuracy results of histopathalogical images by evaluating spatial relations. As a first step, Convolutional Neural Network (CNN) based features are extracted in the original RGB color space of digital histopathalogical images. Training data sets are formed by selecting equal number of different cellular and extra-cellular structures in spatial domain from the images. Classification models of each training data set are obtained by utilizing CNN (as a supervised classifier), Support Vector Machine (SVM) and Random Forest (RF) methods. Visual classification maps and output tables which are obtained from supervised training methods are presented for comparison purpose in the experimental results section.","","Electronic:978-1-5090-1679-2; POD:978-1-5090-1680-8; USB:978-1-5090-1678-5","10.1109/SIU.2016.7495823","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7495823","Histopathologic images;classification;convolutional neural network;feature extraction;spatial relations","Biomedical imaging;Feature extraction;Image analysis;Image color analysis;Neural networks;Support vector machines;Training data","cellular biophysics;feature extraction;feedforward neural nets;image classification;image colour analysis;learning (artificial intelligence);medical image processing;support vector machines","CNN;RGB color space;SVM;cellular structures;classification models;convolutional neural network;digital histopathalogical images;extra-cellular structures;feature extraction;output tables;random forest methods;supervised classifier;supervised training methods;support vector machine;training data sets;visual classification maps","","","","","","","","16-19 May 2016","","IEEE","IEEE Conference Publications"
"Efficient convolutional neural networks for pixelwise classification on heterogeneous hardware systems","F. Tschopp; J. N. P. Martel; S. C. Turaga; M. Cook; J. Funke","Department of Computer Science, ETH Zurich","2016 IEEE 13th International Symposium on Biomedical Imaging (ISBI)","20160616","2016","","","1225","1228","With recent advances in high-throughput Electron Microscopy (EM) imaging it is now possible to image an entire nervous system of organisms like Drosophila melanogaster. One of the bottlenecks to reconstruct a connectome from these large volumes (≈ 100 TiB) is the pixel-wise prediction of membranes. The time it would typically take to process such a volume using a convolutional neural network (CNN) with a sliding window approach is in the order of years on a current GPU. With sliding windows, however, a lot of redundant computations are carried out. In this paper, we present an extension to the Caffe library to increase throughput by predicting many pixels at once. On a sliding window network successfully used for membrane classification, we show that our method achieves a speedup of up to 57×, maintaining identical prediction results.","","Electronic:978-1-4799-2349-6; POD:978-1-4799-2351-9","10.1109/ISBI.2016.7493487","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7493487","convolutional neural networks;electron microscopy;loss functions;pixel wise classification","Biological neural networks;Graphics processing units;Hardware;Kernel;Libraries;Throughput;Training","biology computing;biomembranes;electron microscopy;graphics processing units;image classification;image reconstruction;neural nets;neurophysiology","Caffe library;Drosophila melanogaster;connectome reconstruction;convolutional neural network;efficient convolutional neural networks;heterogeneous hardware systems;high-throughput electron microscopy imaging;membrane classification;nervous system;pixel-wise prediction;pixelwise classification;sliding window approach","","","","10","","","","13-16 April 2016","","IEEE","IEEE Conference Publications"
"Automatic segmentation of the left ventricle in cardiac CT angiography using convolutional neural networks","M. Zreik; T. Leiner; B. D. de Vos; R. W. van Hamersvelt; M. A. Viergever; I. Išgum","Image Sciences Institute, University Medical Center Utrecht, The Netherlands","2016 IEEE 13th International Symposium on Biomedical Imaging (ISBI)","20160616","2016","","","40","43","Accurate delineation of the left ventricle (LV) is an important step in evaluation of cardiac function. In this paper, we present an automatic method for segmentation of the LV in cardiac CT angiography (CCTA) scans. Segmentation is performed in two stages. First, a bounding box around the LV is detected using a combination of three convolutional neural networks (CNNs). Subsequently, to obtain the segmentation of the LV, voxel classification is performed within the defined bounding box using a CNN. The study included CCTA scans of sixty patients, fifty scans were used to train the CNNs for the LV localization, five scans were used to train LV segmentation and the remaining five scans were used for testing the method. Automatic segmentation resulted in the average Dice coefficient of 0.85 and mean absolute surface distance of 1.1 mm. The results demonstrate that automatic segmentation of the LV in CCTA scans using voxel classification with convolutional neural networks is feasible.","","Electronic:978-1-4799-2349-6; POD:978-1-4799-2351-9","10.1109/ISBI.2016.7493206","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7493206","Cardiac CT Angiography;Classification;Convolutional Neural Network;Deep learning;Left ventricle segmentation","Biomedical imaging;Computed tomography;Heart;Image segmentation;Manuals;Neural networks;Observers","","","","","","16","","","","13-16 April 2016","","IEEE","IEEE Conference Publications"
"Non-uniform patch sampling with deep convolutional neural networks for white matter hyperintensity segmentation","M. Ghafoorian; N. Karssemeijer; T. Heskes; I. W. M. van Uder; F. E. de Leeuw; E. Marchiori; B. van Ginneken; B. Platel","Diagnostic Image Analysis Group, Radboud University Medical Center, Nijmegen, the Netherlands","2016 IEEE 13th International Symposium on Biomedical Imaging (ISBI)","20160616","2016","","","1414","1417","Convolutional neural networks (CNN) have been widely used for visual recognition tasks including semantic segmentation of images. While the existing methods consider uniformly sampled single-or multi-scale patches from the neighborhood of each voxel, this approach might be sub-optimal as it captures and processes unnecessary details far away from the center of the patch. We instead propose to train CNNs with non-uniformly sampled patches that allow a wider extent for the sampled patches. This results in more captured contextual information, which is in particular of interest for biomedical image analysis, where the anatomical location of imaging features are often crucial. We evaluate and compare this strategy for white matter hyperintensity segmentation on a test set of 46 MRI scans. We show that the proposed method not only outperforms identical CNNs with uniform patches of the same size (0.780 Dice coefficient compared to 0.736), but also gets very close to the performance of an independent human expert (0.796 Dice coefficient).","","Electronic:978-1-4799-2349-6; POD:978-1-4799-2351-9","10.1109/ISBI.2016.7493532","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7493532","convolutional neural network;deep learning;non-uniform patch;white matter hyperintensity","Biological neural networks;Biomedical imaging;Convolution;Image segmentation;Sampling methods;Training;Visualization","biomedical MRI;brain;feature extraction;image sampling;image segmentation;medical image processing;neural nets;neurophysiology","Dice coefficient;MRI scans;anatomical location;biomedical image analysis;captured contextual information;deep convolutional neural networks;identical CNNs;imaging features;independent human expert;nonuniform patch sampling;sampled multiscale patches;sampled single-scale patches;semantic image segmentation;visual recognition tasks;white matter hyperintensity segmentation","","1","","9","","","","13-16 April 2016","","IEEE","IEEE Conference Publications"
"Structure-based assessment of cancerous mitochondria using deep networks","M. Mishra; S. Schmitt; L. Wang; M. K. Strasser; C. Marr; N. Navab; H. Zischka; T. Peng","Computer Aided Medical Procedures (CAMP), Technische Universitaet Muenchen, Germany","2016 IEEE 13th International Symposium on Biomedical Imaging (ISBI)","20160616","2016","","","545","548","Mitochondrial functions are essential for cell survival. Pathologic situations, e.g. cancer, can impair mitochondrial function which is frequently reflected by an altered morphology. So far, feature description of mitochondrial structure in cancer remains largely qualitative. In this study, we propose a learning-based approach to quantitatively assess the structure of mitochondria isolated from liver tumor cell lines using convolutional neural network (CNN). Besides achieving a high classification accuracy on isolated mitochondria from healthy tissue and different tumor cell lines which the CNN model was trained on, CNN is also able to classify unseen tumor cell lines, which suggests its superior capability to capture the intrinsic structural transition from healthy to tumor mitochondria.","","Electronic:978-1-4799-2349-6; POD:978-1-4799-2351-9","10.1109/ISBI.2016.7493327","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7493327","Mitochondria;convolutional neural network;deep learning;electron microscopy","Indexes;Liver;Standards;Support vector machines;Training;Tumors","cancer;cellular biophysics;learning (artificial intelligence);liver;medical image processing;microorganisms;neurophysiology;tumours","CNN model;altered morphology;cancer;cancerous mitochondria;cell survival;convolutional neural network;deep networks;healthy tumor mitochondria;high classification accuracy;learning-based approach;liver tumor cell lines;mitochondria isolated structure;mitochondrial functions;mitochondrial structure;pathologic situations;structural transition;structure-based assessment;tumor cell lines","","","","10","","","","13-16 April 2016","","IEEE","IEEE Conference Publications"
"Gland segmentation in colon histology images using hand-crafted features and convolutional neural networks","W. Li; S. Manivannan; S. Akbar; J. Zhang; E. Trucco; S. J. McKenna","CVIP, School of Science and Engineering, University of Dundee, Dundee, UK","2016 IEEE 13th International Symposium on Biomedical Imaging (ISBI)","20160616","2016","","","1405","1408","We investigate glandular structure segmentation in colon histology images as a window-based classification problem. We compare and combine methods based on fine-tuned convolutional neural networks (CNN) and hand-crafted features with support vector machines (HC-SVM). On 85 images of H&E-stained tissue, we find that fine-tuned CNN outperforms HC-SVM in gland segmentation measured by pixel-wise Jaccard and Dice indices. For HC-SVM we further observe that training a second-level window classifier on the posterior probabilities - as an output refinement - can substantially improve the segmentation performance. The final performance of HC-SVM with refinement is comparable to that of CNN. Furthermore, we show that by combining and refining the posterior probability outputs of CNN and HC-SVM together, a further performance boost is obtained.","","Electronic:978-1-4799-2349-6; POD:978-1-4799-2351-9","10.1109/ISBI.2016.7493530","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7493530","Convolutional neural network;Gland segmentation;Histology image analysis","Dictionaries;Feature extraction;Glands;Image segmentation;Neural networks;Support vector machines;Training","biological organs;biological tissues;feature extraction;image classification;image segmentation;medical image processing;neural nets;probability;support vector machines","H&E-stained tissue;colon histology images;fine-tuned convolutional neural networks;glandular structure segmentation;hand-crafted features;pixel-wise Dice indices;pixel-wise Jaccard indices;posterior probabilities;second-level window classifier;support vector machines;window-based classification problem","","3","","17","","","","13-16 April 2016","","IEEE","IEEE Conference Publications"
"X-ray image classification using domain transferred convolutional neural networks and local sparse spatial pyramid","E. Ahn; A. Kumar; J. Kim; C. Li; D. Feng; M. Fulham","School of Information Technologies, University of Sydney, Australia","2016 IEEE 13th International Symposium on Biomedical Imaging (ISBI)","20160616","2016","","","855","858","The classification of medical images is a critical step for imaging-based clinical decision support systems. Existing classification methods for X-ray images, however, generally represent the image using only local texture or generic image features (e.g. color or shape) derived from predefined feature spaces. This limits the ability to quantify the image characteristics using general data-derived features learned from image datasets. In this study we present a new algorithm to improve the performance of X-ray image classification, where we propose a late-fusion of domain transferred convolutional neural networks (DT-CNNs) with sparse spatial pyramid (SSP) features derived from a local image dictionary. Our method is robust as it exploits the rich generic information provided by the DT-CNNs and uses the specific local features and characteristics inherent in the X-ray images. Our method was evaluated on a public dataset of X-ray images and was compared to several state-of-the-art approaches. Experimental results show that our method was the most accurate for classification.","","Electronic:978-1-4799-2349-6; POD:978-1-4799-2351-9","10.1109/ISBI.2016.7493400","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7493400","X-ray;classification;convolutional neural network;sparse coding;transfer learning","Biomedical imaging;Dictionaries;Encoding;Feature extraction;Image classification;Support vector machines;X-ray imaging","decision support systems;diagnostic radiography;image classification;image fusion;image representation;medical image processing;neurophysiology","DT-CNN;X-ray image classification;data-derived features;domain transferred convolutional neural networks;feature spaces;generic image features;generic information;image datasets;image representation;imaging-based clinical decision support systems;local image dictionary;local sparse spatial pyramid;local texture;medical image classification;public dataset;sparse spatial pyramid features","","1","","18","","","","13-16 April 2016","","IEEE","IEEE Conference Publications"
"Sub-cortical brain structure segmentation using F-CNN'S","M. Shakeri; S. Tsogkas; E. Ferrante; S. Lippe; S. Kadoury; N. Paragios; I. Kokkinos","Polytechnique Montreal","2016 IEEE 13th International Symposium on Biomedical Imaging (ISBI)","20160616","2016","","","269","272","In this paper we propose a deep learning approach for segmenting sub-cortical structures of the human brain in Magnetic Resonance (MR) image data. We draw inspiration from a state-of-the-art Fully-Convolutional Neural Network (F-CNN) architecture for semantic segmentation of objects in natural images, and adapt it to our task. Unlike previous CNN-based methods that operate on image patches, our model is applied on a full blown 2D image, without any alignment or registration steps at testing time. We further improve segmentation results by interpreting the CNN output as potentials of a Markov Random Field (MRF), whose topology corresponds to a volumetric grid. Alpha-expansion is used to perform approximate inference imposing spatial volumetric homogeneity to the CNN priors. We compare the performance of the proposed pipeline with a similar system using Random Forest-based priors, as well as state-of-art segmentation algorithms, and show promising results on two different brain MRI datasets.","","Electronic:978-1-4799-2349-6; POD:978-1-4799-2351-9","10.1109/ISBI.2016.7493261","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7493261","Convolutional neural networks;Magnetic Resonance Imaging;Markov Random Fields;semantic segmentation;sub-cortical structures","Brain;Image segmentation;Magnetic resonance imaging;Markov random fields;Semantics;Three-dimensional displays;Training","Markov processes;biomedical MRI;brain;image segmentation;medical image processing;neural nets","F-CNN architecture;Markov random field;brain MRI dataset;deep learning approach;fully-convolutional neural network;human brain;image patch;image registration;image segmentation;magnetic resonance image data;random forest-based prior;semantic segmentation;subcortical brain structure segmentation","","","","12","","","","13-16 April 2016","","IEEE","IEEE Conference Publications"
"Handcrafted features with convolutional neural networks for detection of tumor cells in histology images","M. N. Kashif; S. E. A. Raza; K. Sirinukunwattana; M. Arif; N. Rajpoot","Department of Electrical Engineering, Pakistan Institute of Engineering and Applied Sciences, Islamabad, Pakistan","2016 IEEE 13th International Symposium on Biomedical Imaging (ISBI)","20160616","2016","","","1029","1032","Detection of tumor nuclei in cancer histology images requires sophisticated techniques due to the irregular shape, size and chromatin texture of the tumor nuclei. Some very recently proposed methods employ deep convolutional neural networks (CNNs) to detect cells in H&E stained images. However, all such methods use some form of raw pixel intensities as input and rely on the CNN to learn the deep features. In this work, we extend a recently proposed spatially constrained CNN (SC-CNN) by proposing features that capture texture characteristics and show that although CNN produces good results on automatically learned features, it can perform better if the input consists of a combination of handcrafted features and the raw data. The handcrafted features are computed through the scattering transform which gives non-linear invariant texture features. The combination of handcrafted features with raw data produces sharp proximity maps and better detection results than the results of raw intensities with a similar kind of CNN architecture.","","Electronic:978-1-4799-2349-6; POD:978-1-4799-2351-9","10.1109/ISBI.2016.7493441","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7493441","Convolutional Neural Network;Digital Pathology;Scattering Transform;Tumor Nuclei Detection","Feature extraction;Image color analysis;Neural networks;Scattering;Standards;Transforms;Tumors","cellular biophysics;feature extraction;medical image processing;neural nets;tumours","cancer histology images;handcrafted features;nonlinear invariant texture features;scattering transform;spatially constrained convolutional neural networks;tumor cell detection","","","","13","","","","13-16 April 2016","","IEEE","IEEE Conference Publications"
"An automatic breast cancer grading method in histopathological images based on pixel-, object-, and semantic-level features","J. Cao; Z. Qin; J. Jing; J. Chen; T. Wan","Intelligent Computing & Machine Learning Lab, School of ASEE, Beihang University, China","2016 IEEE 13th International Symposium on Biomedical Imaging (ISBI)","20160616","2016","","","1151","1154","We present an automatic breast cancer grading method in histopathological images based on the computer extracted pixel-, object-, and semantic-level features derived from convolutional neural networks (CNN). The multiple level features allow not only characterization of nuclear polymorphism, but also extraction of structural and interpretable information within the images. In this study, a hybrid level set based segmentation method was used to segment nuclei from the images. A quantile normalization approach was utilized to improve image color consistency. The semantic level features are extracted by a CNN approach, which describe the proportions of nuclei belonging to the different grades, in conjunction with pixel-level (texture) and object-level (structure) features, to form an integrated set of attributes. A support vector machine classifier was trained to discriminate the breast cancer between low, intermediate, and high grades. The results demonstrated that our method achieved accuracy of 0.90 (low vs. high), and 0.74 (low vs. intermediate), and 0.76 (intermediate vs. high), suggesting that the present method could play a fundamental role in developing a computer-aided breast cancer grading system.","","Electronic:978-1-4799-2349-6; POD:978-1-4799-2351-9","10.1109/ISBI.2016.7493470","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7493470","breast cancer grading;convolutional neural networks;histopathology;multi-level features","Breast cancer;Feature extraction;Image color analysis;Image segmentation;Neurons;Support vector machines","","","","1","","9","","","","13-16 April 2016","","IEEE","IEEE Conference Publications"
"Real-time 2D/3D registration via CNN regression","S. Miao; Z. J. Wang; Y. Zheng; R. Liao","Electrical and Computer Engineering, University of British Columbia, Canada","2016 IEEE 13th International Symposium on Biomedical Imaging (ISBI)","20160616","2016","","","1430","1434","In this paper, we present a Convolutional Neural Network (CNN) regression approach for real-time 2-D/3-D registration. Different from optimization-based methods, which iteratively optimize the transformation parameters over a scalar-valued metric function representing the quality of the registration, the proposed method exploits the information embedded in the appearances of the Digitally Reconstructed Radiograph and X-ray images, and employs CNN regressors to directly estimate the transformation parameters. The CNN regressors are trained for local zones and applied in a hierarchical manner to break down the complex regression task into simpler sub-tasks that can be learned separately. Our experiment results demonstrate the advantage of the proposed method in computational efficiency with negligible degradation of registration accuracy compared to intensity-based methods.","","Electronic:978-1-4799-2349-6; POD:978-1-4799-2351-9","10.1109/ISBI.2016.7493536","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7493536","2-D/3-D Registration;Convolutional Neural Network;Deep Learning;Image Guided Intervention","Biomedical imaging;Feature extraction;Neural networks;Real-time systems;Solid modeling;Training;X-ray imaging","","","","","","18","","","","13-16 April 2016","","IEEE","IEEE Conference Publications"
"Colitis detection on computed tomography using regional convolutional neural networks","J. Liu; D. Wang; Z. Wei; L. Lu; L. Kim; E. Turkbey; R. M. Summers","Imaging Biomarkers and Computer-aided Diagnosis Laboratory, Radiology and Imaging Sciences, National Institutes of Health Clinical Center, Building 10 Room 1C224 MSC 1182, Bethesda, MD 20892-1182","2016 IEEE 13th International Symposium on Biomedical Imaging (ISBI)","20160616","2016","","","863","866","Colitis is inflammation of the colon that is frequently associated with infection and immune compromise. The wall of a colon afflicted with colitis is much thicker than normal. Colitis can be debilitating or life threatening, and early detection is essential to initiate proper treatment. In this work, we apply high-capacity convolutional neural net-works (CNNs) to bottom-up region proposals to detect potential colitis on CT scans. Our method first generates around 3000 category-independent region proposals for each slice of the input CT scan using selective search. Then, a fixed-length feature vector is extracted from each region proposal using a CNN. Finally, each region proposal is classified and assigned a confidence score with a linear SVM. We applied the detection method to 448 images from 56 CT scans of patients with colitis for evaluation. The detection system achieved 85% sensitivity at 1 false positive per image.","","Electronic:978-1-4799-2349-6; POD:978-1-4799-2351-9","10.1109/ISBI.2016.7493402","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7493402","CNNs;Colitis;Region proposal;SVM","Biological neural networks;Colon;Computed tomography;Feature extraction;Image segmentation;Proposals;Support vector machines","computerised tomography;diseases;feature extraction;image classification;medical image processing;support vector machines","CT scans;bottom-up region;category-independent region;classification;colitis detection;colon inflammation;computed tomography;detection method;early detection;fixed-length feature vector;high-capacity convolutional neural networks;immune compromise;infection;life threatening;linear SVM;potential colitis;regional convolutional neural networks","","","","20","","","","13-16 April 2016","","IEEE","IEEE Conference Publications"
"Epileptiform spike detection via convolutional neural networks","A. R. Johansen; J. Jin; T. Maszczyk; J. Dauwels; S. S. Cash; M. B. Westover","Technical University of Denmark, DTU Compute, Lyngby, Denmark","2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","20160519","2016","","","754","758","The EEG of epileptic patients often contains sharp waveforms called ""spikes"", occurring between seizures. Detecting such spikes is crucial for diagnosing epilepsy. In this paper, we develop a convolutional neural network (CNN) for detecting spikes in EEG of epileptic patients in an automated fashion. The CNN has a convolutional architecture with filters of various sizes applied to the input layer, leaky ReLUs as activation functions, and a sigmoid output layer. Balanced mini-batches were applied to handle the imbalance in the data set. Leave-one-patient-out cross-validation was carried out to test the CNN and benchmark models on EEG data of five epilepsy patients. We achieved 0.947 AUC for the CNN, while the best performing benchmark model, Support Vector Machines with Gaussian kernel, achieved an AUC of 0.912.","","Electronic:978-1-4799-9988-0; POD:978-1-4799-9989-7; USB:978-1-4799-9987-3","10.1109/ICASSP.2016.7471776","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7471776","Convolutional neural network;Deep learning;EEG;Epilepsy;Spike detection","Benchmark testing;Biological neural networks;Brain models;Computational modeling;Electroencephalography;Epilepsy","electroencephalography;medical signal processing;neural nets","CNN;EEG;convolutional neural networks;electroencephalography;epileptic patients;epileptiform spike detection;leave-one-patient-out cross-validation;support vector machines","","","","29","","","","20-25 March 2016","","IEEE","IEEE Conference Publications"
"AggNet: Deep Learning From Crowds for Mitosis Detection in Breast Cancer Histology Images","S. Albarqouni; C. Baur; F. Achilles; V. Belagiannis; S. Demirci; N. Navab","Chair for Computer Aided Medical Procedure (CAMP), Technische Universit&#x00E4;t M&#x00FC;nchen (TUM), Munich, Germany","IEEE Transactions on Medical Imaging","20160502","2016","35","5","1313","1321","The lack of publicly available ground-truth data has been identified as the major challenge for transferring recent developments in deep learning to the biomedical imaging domain. Though crowdsourcing has enabled annotation of large scale databases for real world images, its application for biomedical purposes requires a deeper understanding and hence, more precise definition of the actual annotation task. The fact that expert tasks are being outsourced to non-expert users may lead to noisy annotations introducing disagreement between users. Despite being a valuable resource for learning annotation models from crowdsourcing, conventional machine-learning methods may have difficulties dealing with noisy annotations during training. In this manuscript, we present a new concept for learning from crowds that handle data aggregation directly as part of the learning process of the convolutional neural network (CNN) via additional crowdsourcing layer (AggNet). Besides, we present an experimental study on learning from crowds designed to answer the following questions. 1) Can deep CNN be trained with data collected from crowdsourcing? 2) How to adapt the CNN to train on multiple types of annotation datasets (ground truth and crowd-based)? 3) How does the choice of annotation and aggregation affect the accuracy? Our experimental setup involved Annot8, a self-implemented web-platform based on Crowdflower API realizing image annotation tasks for a publicly available biomedical image database. Our results give valuable insights into the functionality of deep CNN learning from crowd annotations and prove the necessity of data aggregation integration.","0278-0062;02780062","","10.1109/TMI.2016.2528120","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7405343","Aggregation;crowdsourcing;deep learning;gamification;online learning","Biomedical imaging;Computational modeling;Crowdsourcing;Data models;Machine learning;Noise measurement;Robustness","biological organs;cancer;data aggregation;image classification;image denoising;learning (artificial intelligence);medical image processing","biomedical image database;breast cancer histology imaging;conventional machine-learning methods;convolutional neural network;crowd annotation datasets;crowd flower API;crowd sourcing layer;data aggregation;deep CNN learning;ground-truth data;image annotation tasks;learning annotation models;learning process;mitosis detection;noisy annotations;self-implemented web-platform","","12","","38","","","20160211","May 2016","","IEEE","IEEE Journals & Magazines"
"Brain Tumor Segmentation Using Convolutional Neural Networks in MRI Images","S. Pereira; A. Pinto; V. Alves; C. A. Silva","CMEMS-UMinho Research Unit, University of Minho, Guimar&#x00E3;es, Portugal","IEEE Transactions on Medical Imaging","20160429","2016","35","5","1240","1251","Among brain tumors, gliomas are the most common and aggressive, leading to a very short life expectancy in their highest grade. Thus, treatment planning is a key stage to improve the quality of life of oncological patients. Magnetic resonance imaging (MRI) is a widely used imaging technique to assess these tumors, but the large amount of data produced by MRI prevents manual segmentation in a reasonable time, limiting the use of precise quantitative measurements in the clinical practice. So, automatic and reliable segmentation methods are required; however, the large spatial and structural variability among brain tumors make automatic segmentation a challenging problem. In this paper, we propose an automatic segmentation method based on Convolutional Neural Networks (CNN), exploring small 3 ×3 kernels. The use of small kernels allows designing a deeper architecture, besides having a positive effect against overfitting, given the fewer number of weights in the network. We also investigated the use of intensity normalization as a pre-processing step, which though not common in CNN-based segmentation methods, proved together with data augmentation to be very effective for brain tumor segmentation in MRI images. Our proposal was validated in the Brain Tumor Segmentation Challenge 2013 database (BRATS 2013), obtaining simultaneously the first position for the complete, core, and enhancing regions in Dice Similarity Coefficient metric (0.88, 0.83, 0.77) for the Challenge data set. Also, it obtained the overall first position by the online evaluation platform. We also participated in the on-site BRATS 2015 Challenge using the same model, obtaining the second place, with Dice Similarity Coefficient metric of 0.78, 0.65, and 0.75 for the complete, core, and enhancing regions, respectively.","0278-0062;02780062","","10.1109/TMI.2016.2538465","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7426413","Brain tumor;brain tumor segmentation;convolutional neural networks;deep learning;glioma;magnetic resonance imaging","Brain modeling;Context;Image segmentation;Kernel;Magnetic resonance imaging;Training;Tumors","biomedical MRI;brain;cancer;image segmentation;medical image processing;neurophysiology;tumours","CNN-based segmentation methods;Dice similarity coefficient metrics;MRI images;automatic segmentation;automatic segmentation methods;brain tumor segmentation;clinical practice;convolutional neural networks;data augmentation;gliomas;imaging technique;intensity normalization;kernels;magnetic resonance imaging;manual segmentation;on-site BRATS 2015 Challenge;oncological patients;online evaluation platform;precise quantitative measurements;preprocessing step;quality-of-life;reliable segmentation methods;spatial variability;structural variability","","15","","52","","","20160304","May 2016","","IEEE","IEEE Journals & Magazines"
"Locality Sensitive Deep Learning for Detection and Classification of Nuclei in Routine Colon Cancer Histology Images","K. Sirinukunwattana; S. E. A. Raza; Y. W. Tsang; D. R. J. Snead; I. A. Cree; N. M. Rajpoot","Department of Computer Science, University of Warwick, Coventry, UK","IEEE Transactions on Medical Imaging","20160429","2016","35","5","1196","1206","Detection and classification of cell nuclei in histopathology images of cancerous tissue stained with the standard hematoxylin and eosin stain is a challenging task due to cellular heterogeneity. Deep learning approaches have been shown to produce encouraging results on histopathology images in various studies. In this paper, we propose a Spatially Constrained Convolutional Neural Network (SC-CNN) to perform nucleus detection. SC-CNN regresses the likelihood of a pixel being the center of a nucleus, where high probability values are spatially constrained to locate in the vicinity of the centers of nuclei. For classification of nuclei, we propose a novel Neighboring Ensemble Predictor (NEP) coupled with CNN to more accurately predict the class label of detected cell nuclei. The proposed approaches for detection and classification do not require segmentation of nuclei. We have evaluated them on a large dataset of colorectal adenocarcinoma images, consisting of more than 20,000 annotated nuclei belonging to four different classes. Our results show that the joint detection and classification of the proposed SC-CNN and NEP produces the highest average F1 score as compared to other recently published approaches. Prospectively, the proposed methods could offer benefit to pathology practice in terms of quantitative analysis of tissue constituents in whole-slide images, and potentially lead to a better understanding of cancer.","0278-0062;02780062","","10.1109/TMI.2016.2525803","10.13039/100008982 - Qatar National Research Fund; ","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7399414","Convolutional neural network;deep learning;histology image analysis;nucleus detection","Cancer;Computer architecture;Feature extraction;Machine learning;Microprocessors;Shape;Tumors","biological organs;biomedical optical imaging;cancer;cellular biophysics;image classification;learning (artificial intelligence);medical image processing;probability;tumours","NEP;SC-CNN;cancerous tissue;cell nuclei classification;cell nuclei detection;cellular heterogeneity;colorectal adenocarcinoma images;dataset;eosin stain;high-probability values;highest average F1 score;histopathology images;joint detection;locality sensitive deep learning;neighboring ensemble predictor;quantitative analysis;routine colon cancer histology images;spatially constrained convolutional neural network;standard hematoxylin;tissue constituents;whole-slide images","","16","","38","","","20160204","May 2016","","IEEE","IEEE Journals & Magazines"
"A CNN Regression Approach for Real-Time 2D/3D Registration","S. Miao; Z. J. Wang; R. Liao","Department of Electrical and Computer Engineering, University of British Columbia, Vancouver","IEEE Transactions on Medical Imaging","20160429","2016","35","5","1352","1363","In this paper, we present a Convolutional Neural Network (CNN) regression approach to address the two major limitations of existing intensity-based 2-D/3-D registration technology: 1) slow computation and 2) small capture range. Different from optimization-based methods, which iteratively optimize the transformation parameters over a scalar-valued metric function representing the quality of the registration, the proposed method exploits the information embedded in the appearances of the digitally reconstructed radiograph and X-ray images, and employs CNN regressors to directly estimate the transformation parameters. An automatic feature extraction step is introduced to calculate 3-D pose-indexed features that are sensitive to the variables to be regressed while robust to other factors. The CNN regressors are then trained for local zones and applied in a hierarchical manner to break down the complex regression task into multiple simpler sub-tasks that can be learned separately. Weight sharing is furthermore employed in the CNN regression model to reduce the memory footprint. The proposed approach has been quantitatively evaluated on 3 potential clinical applications, demonstrating its significant advantage in providing highly accurate real-time 2-D/3-D registration with a significantly enlarged capture range when compared to intensity-based methods.","0278-0062;02780062","","10.1109/TMI.2016.2521800","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7393571","2-D/3-D registration;convolutional neural network;deep learning;image guided intervention","Attenuation;Biomedical imaging;Computed tomography;Feature extraction;Real-time systems;X-ray imaging","diagnostic radiography;feature extraction;image reconstruction;image registration;iterative methods;medical image processing;neural nets;optimisation;regression analysis","3D pose-indexed features;CNN regression approach;CNN regressors;X-ray images;automatic feature extraction step;complex regression task;convolutional neural network regression approach;digitally reconstructed radiograph;formation parameters;intensity-based 2D-3D registration technology;intensity-based methods;iterative optimization;memory footprint;multiple simpler subtasks;optimization-based methods;real-time 2D-3D registration;scalar-valued metric function;transformation parameters","","4","","31","","","20160126","May 2016","","IEEE","IEEE Journals & Magazines"
"Using Deep Learning for Energy Expenditure Estimation with wearable sensors","J. Zhu; A. Pande; P. Mohapatra; J. J. Han","Department of Computer Science, University of California at Davis, 95616, United States","2015 17th International Conference on E-health Networking, Application & Services (HealthCom)","20160419","2015","","","501","506","Energy Expenditure (EE) Estimation is an important step in tracking personal activity and preventing chronic diseases such as obesity, diabetes and cardiovascular diseases. Accurate and online EE estimation using small wearable sensors is a difficult task, primarily because most existing schemes work offline or using heuristics. In this work, we focus on accurate EE estimation for tracking ambulatory activities (walking, standing, climbing upstairs or downstairs) of individuals wearing mobile sensors. We use Convolution Neural Networks (CNNs) to automatically detect important features from data collected from triaxial accelerometer and heart rate sensors. Using CNNs, we find a significant improvement in EE estimation compared to other state-of-the-art models. We compare our results against state-of-the-art Activity-Specific Linear Regression as well as Artificial Neural Networks (ANN) based models. Using a universal CNN model, we obtain an overall low Root Mean Square Error (RMSE) of 1.12 which is 30% and 35% lower than existing models. The results were calibrated against a COSMED K4b2 indirect calorimeter readings.","","Electronic:978-1-4673-8325-7; POD:978-1-4673-8326-4","10.1109/HealthCom.2015.7454554","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7454554","","Accelerometers;Estimation;Feature extraction;Heart rate;Machine learning;Neural networks;Sensors","accelerometers;biomedical equipment;calibration;cardiology;feature extraction;learning (artificial intelligence);medical computing;neural nets;sensors","COSMED K4b2 indirect calorimeter readings;ambulatory activity tracking;calibration;chronic diseases;convolution neural networks;deep learning;energy expenditure estimation;feature detection;heart rate sensors;mobile sensors;personal activity tracking;root mean square error;standing;triaxial accelerometer;walking;wearable sensors","","","","22","","","","14-17 Oct. 2015","","IEEE","IEEE Conference Publications"
"Deep Learning for Imbalanced Multimedia Data Classification","Y. Yan; M. Chen; M. L. Shyu; S. C. Chen","Dept. of Electr. & Comput. Eng., Univ. of Miami, Coral Gables, FL, USA","2015 IEEE International Symposium on Multimedia (ISM)","20160328","2015","","","483","488","Classification of imbalanced data is an important research problem as lots of real-world data sets have skewed class distributions in which the majority of data instances (examples) belong to one class and far fewer instances belong to others. While in many applications, the minority instances actually represent the concept of interest (e.g., fraud in banking operations, abnormal cell in medical data, etc.), a classifier induced from an imbalanced data set is more likely to be biased towards the majority class and show very poor classification accuracy on the minority class. Despite extensive research efforts, imbalanced data classification remains one of the most challenging problems in data mining and machine learning, especially for multimedia data. To tackle this challenge, in this paper, we propose an extended deep learning approach to achieve promising performance in classifying skewed multimedia data sets. Specifically, we investigate the integration of bootstrapping methods and a state-of-the-art deep learning approach, Convolutional Neural Networks (CNNs), with extensive empirical studies. Considering the fact that deep learning approaches such as CNNs are usually computationally expensive, we propose to feed low-level features to CNNs and prove its feasibility in achieving promising performance while saving a lot of training time. The experimental results show the effectiveness of our framework in classifying severely imbalanced data in the TRECVID data set.","","Electronic:978-1-5090-0379-2; POD:978-1-5090-0380-8; USB:978-1-5090-0378-5","10.1109/ISM.2015.126","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7442383","classification;convolutional neural network (CNN);deep learning;imbalanced data;semantic indexing","Classification algorithms;Convolution;Data models;Machine learning;Multimedia communication;Neural networks;Training","convolution;data analysis;learning (artificial intelligence);multimedia computing;neural nets","CNN;TRECVID data set;banking operations;convolutional neural networks;data instances;deep learning approaches;imbalanced multimedia data classification;low-level features;real-world data sets","","4","","41","","","","14-16 Dec. 2015","","IEEE","IEEE Conference Publications"
"ABM and CNN application in ventral stream of visual system","B. Yousefi; P. Yousefi","Department of Electrical and robotic engineering, Shahrood University Technology, Shahrood, Iran","2015 IEEE Student Symposium in Biomedical Engineering & Sciences (ISSBES)","20160321","2015","","","87","92","This paper addresses an investigation regarding the suitability of two different techniques, Active Basis Model (ABM) and Gabor based Convolutional Neural Network (CNN or G-ConvNets) in the mechanism for recognition of biological movement (mammalian visual system model). This method inspired by ventral streams which provide the form information. Both of these approaches contain information of the shape of human object obtained by the Gabor features. The comparison of these methods concludes advantages and drawbacks of both methods that shown CNN have advantage of recognition of the action (for CNN only walking, running and waving) however ABM basically used for object recognition task (not particularly for action recognition).","","CD-ROM:978-1-4673-7815-4; Electronic:978-1-4673-7816-1; POD:978-1-4673-7817-8","10.1109/ISSBES.2015.7435920","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7435920","Gabor Convolutional Neural Network;Ventral stream;active basis model;biologically inspired model;human actionrecognition","Biological system modeling;Convolution;Gabor filters;Neurons;Shape;Training","Gabor filters;biomechanics;convolution;image recognition;medical image processing;neural nets","ABM application;CNN application;G-ConvNets;Gabor based convolutional neural network;Gabor features;active basis model;biological movement recognition;human object;mammalian visual system model;object recognition task;ventral stream","","","","25","","","","4-4 Nov. 2015","","IEEE","IEEE Conference Publications"
"A hybrid convolutional neural networks with extreme learning machine for WCE image classification","J. s. Yu; J. Chen; Z. Q. Xiang; Y. X. Zou","ADSPLAB, School of ECE, Peking University, Shenzhen 518055, China","2015 IEEE International Conference on Robotics and Biomimetics (ROBIO)","20160225","2015","","","1822","1827","Wireless Capsule Endoscopy (WCE) is considered as a promising technology for non-invasive gastrointestinal disease examination. This paper studies the classification problem of the digestive organs for wireless capsule endoscopy (WCE) images aiming at saving the review time of doctors. Our previous study has proved the Convolutional Neural Networks (CNN)-based WCE classification system is able to achieve 95% classification accuracy in average, but it is difficult to further improve the classification accuracy owing to the variations of individuals and the complex digestive tract circumstance. Research shows that there are two possible approaches to improve classification accuracy: to extract more discriminative image features and to employ a more powerful classifier. In this paper, we propose to design a WCE classification system by a hybrid CNN with Extreme Learning Machine (ELM). In our approach, we construct the CNN as a data-driven feature extractor and the cascaded ELM as a strong classifier instead of the conventional used full-connection classifier in deep CNN classification system. Moreover, to improve the convergence and classification capability of ELM under supervision manner, a new initialization is employed. Our developed WCE image classification system is named as HCNN-NELM. With about 1 million real WCE images (25 examinations), intensive experiments are conducted to evaluate its performance. Results illustrate its superior performance compared to traditional classification methods and conventional CNN-based method, where about 97.25% classification accuracy can be achieved in average.","","Electronic:978-1-4673-9675-2; USB:978-1-4673-9674-5","10.1109/ROBIO.2015.7419037","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7419037","","Endoscopes;Esophagus;Feature extraction;Image classification;Iron;Testing;Training","diseases;endoscopes;feature extraction;image classification;learning (artificial intelligence);medical image processing;neural nets","CNN-based WCE classification system;HCNN-NELM;WCE image classification system;cascaded ELM;complex digestive tract;data-driven feature extractor;deep CNN classification system;digestive organs;discriminative image features extraction;extreme learning machine;full-connection classifier;hybrid CNN;hybrid convolutional neural networks;noninvasive gastrointestinal disease examination;wireless capsule endoscopy","","1","","14","","","","6-9 Dec. 2015","","IEEE","IEEE Conference Publications"
"Deep Feature Learning with Discrimination Mechanism for Brain Tumor Segmentation and Diagnosis","L. Zhao; K. Jia","Multimedia Inf. Process. Group, Beijing Univ. of Technol., Beijing, China","2015 International Conference on Intelligent Information Hiding and Multimedia Signal Processing (IIH-MSP)","20160225","2015","","","306","309","Brain tumor segmentation is one of the main challenging problems in computer vision and its early diagnosis is critical to clinics. Segmentation needs to be accurate, efficient and robust to avoid influences caused by various large and complex biases added to images. This paper proposes a multiple convolutional neural network (CNNs) framework with discrimination mechanism which is effective to achieve these goals. First of all, this paper proposes to construct different triplanar 2D CNNs architecture for 3D voxel classification, greatly reducing segmentation time. Experiment is conducted on images provided by Multimodal Brain Tumor Image Segmentation Benchmark (BRATS) organized by MICCAI 2013 for both training and testing. As T1, T1-enhanced, T2 and FLAIR MRI images are utilized, multimodal features are combined. As a result, accuracy, sensitivity and specificity are comparable in comparison with manual gold standard images and better than state-of-the-art segmentation methods.","","CD-ROM:978-1-5090-0187-3; Electronic:978-1-5090-0188-0; POD:978-1-5090-0189-7","10.1109/IIH-MSP.2015.41","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7415818","CNNs;brain tumor segmentation;voting strategy","Cancer;Computer architecture;Feature extraction;Image segmentation;Magnetic resonance imaging;Three-dimensional displays;Tumors","biomedical MRI;brain;computational geometry;computer vision;feedforward neural nets;image classification;image segmentation;learning (artificial intelligence);medical image processing;tumours","3D voxel classification;BRATS;FLAIR MRI image utilization;MICCAI 2013;T1 image utilization;T1-enhanced image utilization;T2 image utilization;brain tumor diagnosis;brain tumor segmentation;computer vision;deep feature learning;discrimination mechanism;multimodal brain tumor image segmentation benchmark;multiple convolutional neural network framework;segmentation time reduction;triplanar 2D CNN architecture","","","","14","","","","23-25 Sept. 2015","","IEEE","IEEE Conference Publications"
"Real-Time Patient-Specific ECG Classification by 1-D Convolutional Neural Networks","S. Kiranyaz; T. Ince; M. Gabbouj","Electrical Engineering Department, College of Engineering, Doha, Qatar","IEEE Transactions on Biomedical Engineering","20160218","2016","63","3","664","675","Goal: This paper presents a fast and accurate patient-specific electrocardiogram (ECG) classification and monitoring system. Methods: An adaptive implementation of 1-D convolutional neural networks (CNNs) is inherently used to fuse the two major blocks of the ECG classification into a single learning body: feature extraction and classification. Therefore, for each patient, an individual and simple CNN will be trained by using relatively small common and patient-specific training data, and thus, such patient-specific feature extraction ability can further improve the classification performance. Since this also negates the necessity to extract hand-crafted manual features, once a dedicated CNN is trained for a particular patient, it can solely be used to classify possibly long ECG data stream in a fast and accurate manner or alternatively, such a solution can conveniently be used for real-time ECG monitoring and early alert system on a light-weight wearable device. Results: The results over the MIT-BIH arrhythmia benchmark database demonstrate that the proposed solution achieves a superior classification performance than most of the state-of-the-art methods for the detection of ventricular ectopic beats and supraventricular ectopic beats. Conclusion: Besides the speed and computational efficiency achieved, once a dedicated CNN is trained for an individual patient, it can solely be used to classify his/her long ECG records such as Holter registers in a fast and accurate manner. Significance: Due to its simple and parameter invariant nature, the proposed system is highly generic, and, thus, applicable to any ECG dataset.","0018-9294;00189294","","10.1109/TBME.2015.2468589","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7202837","Convolutional Neural Networks;Convolutional neural networks (CNNs);Patient-specific ECG classification;patient-specific ECG classification;real-time heart monitoring","Databases;Electrocardiography;Feature extraction;Kernel;Monitoring;Neurons;Training","diseases;electrocardiography;feature extraction;medical signal processing;patient monitoring;signal classification","1D convolutional neural networks;ECG data stream;ECG records;Holter registers;MIT-BIH arrhythmia benchmark database;classification performance;light-weight wearable device;patient-specific electrocardiogram classification system;patient-specific electrocardiogram monitoring system;patient-specific feature extraction;patient-specific training data;real-time ECG monitoring;real-time patient-specific ECG classification system;supraventricular ectopic beats","","12","","27","","","20150814","March 2016","","IEEE","IEEE Journals & Magazines"
"Patient prognosis from vital sign time series: Combining convolutional neural networks with a dynamical systems approach","L. w. Lehman; M. Ghassemi; J. Snoek; S. Nemati","Massachusetts Institute of Technology, Cambridge, USA","2015 Computing in Cardiology Conference (CinC)","20160218","2015","","","1069","1072","In this work, we propose a stacked switching vector-autoregressive (SVAR)-CNN architecture to model the changing dynamics in physiological time series for patient prognosis. The SVAR-layer extracts dynamical features (or modes) from the time-series, which are then fed into the CNN-layer to extract higher-level features representative of transition patterns among the dynamical modes. We evaluate our approach using 8-hours of minute-by-minute mean arterial blood pressure (BP) from over 450 patients in the MIMIC-II database. We modeled the time-series using a third-order SVAR process with 20 modes, resulting in first-level dynamical features of size 20×480 per patient. A fully connected CNN is then used to learn hierarchical features from these inputs, and to predict hospital mortality. The combined CNN/SVAR approach using BP time-series achieved a median and interquartile-range AUC of 0.74 [0.69, 0.75], significantly outperforming CNN-alone (0.54 [0.46, 0.59]), and SVAR-alone with logistic regression (0.69 [0.65, 0.72]). Our results indicate that including an SVAR layer improves the ability of CNNs to classify nonlinear and nonstationary time-series.","2325-8861;23258861","Electronic:978-1-5090-0684-7; POD:978-1-5090-0660-1","10.1109/CIC.2015.7411099","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7411099","","Physiology;Prognostics and health management;Switches","autoregressive processes;blood pressure measurement;feature extraction;medical signal processing;neural nets;signal classification;time series","MIMIC-II database;SVAR;convolutional neural networks;dynamical feature extraction;dynamical modes;dynamical systems approach;logistic regression;mean arterial blood pressure;nonlinear time series classification;nonstationary time series classification;patient prognosis;physiological time series;stacked switching vector-autoregressive-CNN architecture;transition patterns;vital sign time series","","1","","10","","","","6-9 Sept. 2015","","IEEE","IEEE Conference Publications"
"A supervised method using convolutional neural networks for retinal vessel delineation","Q. Li; L. Xie; Q. Zhang; S. Qi; P. Liang; H. Zhang; T. Wang","National-Regional Key Technology Engineering Laboratory for Medical Ultrasound, Guangdong Key Laboratory for Biomedical Measurements and Ultrasound Imaging, Department of Biomedical Engineering, School of Medicine, Shenzhen University, Shenzhen 518060","2015 8th International Congress on Image and Signal Processing (CISP)","20160218","2015","","","418","422","Retinal vessel delineation is a hot research topic owing to its importance in a lot of clinic application. Several methods have been proposed in the past decades. Here we will present a new supervised method for retinal vessel segmentation. The method is designed to explore the complex relationship between retinal images and their corresponding vessel label maps. Specifically, in order to build a model describing the direct transformation from retinal image to vessel map, we introduce a deep convolutional neural network (abbreviation as CNN), which has strong enough induction ability. For the purpose of constructing the whole vessel probability map, we also design a synthesis method. Our method shows better performance on DRIVE dataset than state-of-the-art of reported approaches in the light of sensitivity (abbreviation as Se), specificity (abbreviation as Sp) and accuracy (abbreviation as Acc). Our proposed method has great potential to be applied in existing computer-assisted diagnostic system of ophthalmologic diseases. Meanwhile, the method may offer a novel, general computing framework for segmentation in other fields.","","Electronic:978-1-4673-9098-9; POD:978-1-4673-9099-6; USB:978-1-4673-9097-2","10.1109/CISP.2015.7407916","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7407916","CNN;deep learning;retinal image;vessel delineation","Feature extraction;Image segmentation;Measurement;Neural networks;Retinal vessels;Training","blood vessels;eye;feedforward neural nets;image segmentation;medical image processing;patient diagnosis;probability","DRIVE dataset;clinic application;computer-assisted diagnostic system;convolutional neural networks;deep convolutional neural network;general computing framework;ophthalmologic diseases;retinal images;retinal vessel delineation;retinal vessel segmentation;supervised method;synthesis method;vessel label maps;vessel probability map","","","","9","","","","14-16 Oct. 2015","","IEEE","IEEE Conference Publications"
"Im2Calories: Towards an Automated Mobile Vision Food Diary","A. Myers; N. Johnston; V. Rathod; A. Korattikara; A. Gorban; N. Silberman; S. Guadarrama; G. Papandreou; J. Huang; K. Murphy","","2015 IEEE International Conference on Computer Vision (ICCV)","20160218","2015","","","1233","1241","We present a system which can recognize the contents of your meal from a single image, and then predict its nutritional contents, such as calories. The simplest version assumes that the user is eating at a restaurant for which we know the menu. In this case, we can collect images offline to train a multi-label classifier. At run time, we apply the classifier (running on your phone) to predict which foods are present in your meal, and we lookup the corresponding nutritional facts. We apply this method to a new dataset of images from 23 different restaurants, using a CNN-based classifier, significantly outperforming previous work. The more challenging setting works outside of restaurants. In this case, we need to estimate the size of the foods, as well as their labels. This requires solving segmentation and depth / volume estimation from a single image. We present CNN-based approaches to these problems, with promising preliminary results.","","Electronic:978-1-4673-8391-2; POD:978-1-4673-8392-9","10.1109/ICCV.2015.146","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7410503","","Cameras;Image recognition;Image segmentation;Machine learning;Mobile communication;Visualization","computer vision;image classification;image segmentation;medical computing;mobile computing;neural nets;personal computing;prediction theory","CNN-based classifier;Im2Calories;automated mobile vision food diary;content recognition;depth estimation;food prediction;food size estimation;multilabel classifier;nutritional content prediction;nutritional facts;restaurant;volume estimation","","13","","39","","","","7-13 Dec. 2015","","IEEE","IEEE Conference Publications"
"Lesion detection of endoscopy images based on convolutional neural network features","R. Zhu; R. Zhang; D. Xue","Department of Electronic Engineering and Information Science, University of Science and Technology of China","2015 8th International Congress on Image and Signal Processing (CISP)","20160218","2015","","","372","376","Since gastroscopy is able to observe the interior of gastrointestinal tract directly, it has been widely used for gastrointestinal examination. But it is hard for clinicians to accurately detect gastrointestinal disease due to its great dependence on doctors experiences. Therefore, a computer-aided lesion detection system can offer great help for clinicians. In this paper, we propose a new scheme for endoscopy image lesion detection. A trainable feature extractor based on convolutional neural network (CNN) is utilized to get more generic features for endoscopy images. And features are fed to support vector machine (SVM) to enhance the generalization ability. Experiments show that the proposed scheme outperforms the previous conventional methods based on color and texture features.","","Electronic:978-1-4673-9098-9; POD:978-1-4673-9099-6; USB:978-1-4673-9097-2","10.1109/CISP.2015.7407907","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7407907","","Endoscopes;Feature extraction;Gastrointestinal tract;Histograms;Image color analysis;Lesions;Support vector machines","cancer;endoscopes;feature extraction;image colour analysis;image texture;medical image processing;neural nets;support vector machines","CNN;SVM;color features;computer-aided lesion detection system;convolutional neural network features;detect gastrointestinal disease;endoscopy image lesion detection;gastrointestinal examination;gastrointestinal tract directly;support vector machine;texture features;trainable feature extractor","","4","","26","","","","14-16 Oct. 2015","","IEEE","IEEE Conference Publications"
"An Automatic Learning-Based Framework for Robust Nucleus Segmentation","F. Xing; Y. Xie; L. Yang","Department of Electrical and Computer Engineering, University of Florida, Gainesville","IEEE Transactions on Medical Imaging","20160202","2016","35","2","550","566","Computer-aided image analysis of histopathology specimens could potentially provide support for early detection and improved characterization of diseases such as brain tumor, pancreatic neuroendocrine tumor (NET), and breast cancer. Automated nucleus segmentation is a prerequisite for various quantitative analyses including automatic morphological feature computation. However, it remains to be a challenging problem due to the complex nature of histopathology images. In this paper, we propose a learning-based framework for robust and automatic nucleus segmentation with shape preservation. Given a nucleus image, it begins with a deep convolutional neural network (CNN) model to generate a probability map, on which an iterative region merging approach is performed for shape initializations. Next, a novel segmentation algorithm is exploited to separate individual nuclei combining a robust selection-based sparse shape model and a local repulsive deformable model. One of the significant benefits of the proposed framework is that it is applicable to different staining histopathology images. Due to the feature learning characteristic of the deep CNN and the high level shape prior modeling, the proposed method is general enough to perform well across multiple scenarios. We have tested the proposed algorithm on three large-scale pathology image datasets using a range of different tissue and stain preparations, and the comparative experiments with recent state of the arts demonstrate the superior performance of the proposed approach.","0278-0062;02780062","","10.1109/TMI.2015.2481436","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7274740","Deep convolutional neural network;nucleus segmentation;sparse representation","Breast cancer;Computational modeling;Image color analysis;Image segmentation;Robustness;Shape;Tumors","cancer;diagnostic radiography;image segmentation;iterative methods;learning (artificial intelligence);medical image processing;probability;tumours","automated nucleus segmentation;automatic learning-based framework;automatic morphological feature computation;brain tumor;breast cancer;computer-aided image analysis;deep CNN model;deep convolutional neural network model;diseases;early detection;feature learning characteristic;high level shape prior modeling;histopathology imaging;histopathology specimens;iterative region merging approach;large-scale pathology image datasets;local repulsive deformable model;pancreatic neuroendocrine tumor;probability map;quantitative analysis;robust nucleus segmentation;robust selection-based sparse shape model;staining histopathology images;tissue","","7","","83","","","20150923","Feb. 2016","","IEEE","IEEE Journals & Magazines"
"Prediction of driver's drowsy and alert states from EEG signals with deep learning","M. Hajinoroozi; Z. Mao; Y. Huang","Department of Electrical and Computer Engineering, University of Texas at San Antonio, One UTSA Circle, USA","2015 IEEE 6th International Workshop on Computational Advances in Multi-Sensor Adaptive Processing (CAMSAP)","20160121","2015","","","493","496","We investigate in this paper deep learning (DL) solutions for prediction of driver's cognitive states (drowsy or alert) using EEG data. We discussed the novel channel-wise convolutional neural network (CCNN) and CCNN-R which is a CCNN variation that uses Restricted Boltzmann Machine in order to replace the convolutional filter. We also consider bagging classifiers based on DL hidden units as an alternative to the conventional DL solutions. To test the performance of the proposed methods, a large EEG dataset from 3 studies of driver's fatigue that includes 70 sessions from 37 subjects is assembled. All proposed methods are tested on both raw EEG and Independent Component Analysis (ICA)-transformed data for cross-session predictions. The results show that CCNN and CCNN-R outperform deep neural networks (DNN) and convolutional neural networks (CNN) as well as other non-DL algorithms and DL with raw EEG inputs achieves better performance than ICA features.","","Electronic:978-1-4799-1963-5; POD:978-1-4799-1964-2","10.1109/CAMSAP.2015.7383844","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7383844","","Backpropagation;Bagging;Convolution;Electroencephalography;Feature extraction;Machine learning;Prediction algorithms","Boltzmann machines;driver information systems;electroencephalography;independent component analysis;learning (artificial intelligence);medical signal processing","CCNN-R;EEG signal;ICA;bagging classifier;channel-wise convolutional neural network;cognitive state;deep learning;driver alert state;driver drowsy state;independent component analysis;restricted Boltzmann machine","","1","","18","","","","13-16 Dec. 2015","","IEEE","IEEE Conference Publications"
"Maximum Margin Learning of t-SPNs for Cell Classification With Filtered Input","H. Kang; C. D. Yoo; Y. Na","School of Electrical Engineering, Korea Advanced Institute of Science and Technology, Yuseong Gu, Daejeon, South Korea","IEEE Journal of Selected Topics in Signal Processing","20160121","2016","10","1","130","139","An algorithm based on a deep probabilistic architecture referred to as tree-structured sum-product network (t-SPN) is considered for cells classification. The t-SPN is a rooted acyclic graph constructed as a tree of several sum-product networks where each network is constructed over a subset of most confusing class features. The constructed t-SPN architecture is learned by maximizing the margin which is defined to be the difference in the conditional probability between the true and the most competitive false labels. To enhance generalization, l<sub>2</sub>-regularization (REG) is considered along with the maximum margin (MM) criterion in the learning process. To highlight cell features, this paper investigates the effectiveness of two generic high-pass filters: ideal high-pass filtering and the Laplacian of Gaussian (LOG) filtering. On both HEp-2 and Feulgen benchmark datasets, the t-SPN architecture learned based on the max-margin criterion with regularization produced the highest accuracy rate compared to other state-of-the-art algorithms that include convolutional neural network (CNN) based algorithms. Ideal high-pass filter was more effective on the HEp-2 dataset which is based on immunofluorescence staining while the LOG was more effective on Feulgen dataset which is based on Feulgen staining.","1932-4553;19324553","","10.1109/JSTSP.2015.2502542","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7332738","confusing classes;maximum margin;sub-SPNs;t-SPNs","Computer architecture;Input variables;Microprocessors;Microscopy;Signal processing;Special issues and sections","biomedical optical imaging;cellular biophysics;fluorescence;high-pass filters;image classification;learning (artificial intelligence);medical image processing;neural nets;probability","Feulgen dataset;Feulgen staining;HEp-2 dataset;Laplacian-of-Gaussian filtering;cell classification;cell feature;convolutional neural network;deep probabilistic architecture;filtered input;generic high-pass filter;immunofluorescence staining;l2-regularization;learning process;maximum margin criterion;maximum margin learning;rooted acyclic graph;t-SPN architecture;tree-structured sum-product network","","","","18","","","20151120","Feb. 2016","","IEEE","IEEE Journals & Magazines"
"Rich feature hierarchies for cell detecting under phase contrast microscopy images","F. Deng; H. Hu; S. Chen; Q. Guan; Y. Zou","Dept. College of Computer Science and Technology, Zhejiang University of Technology, Hangzhou, 310023, P.R. China","2015 Sixth International Conference on Intelligent Control and Information Processing (ICICIP)","20160121","2015","","","348","353","R-CNN (region-convolutional neural network) has recently achieved very outstanding results in variety of visual detecting fields, and its function of object-proposal-generation can achieve effective training models by using as small samples as possible in the field of machine learning. In this paper, a modified R-CNN is proposed and applied to detect cells under phase contrast microscopy images by adopting multiple object-proposal-generations instead of a single one to extract candidate regions. The results show that the proposed method can obtain better performance than the traditional method by using a single object-proposal-generation.","","Electronic:978-1-4799-1717-4; POD:978-1-4799-1718-1","10.1109/ICICIP.2015.7388195","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7388195","R-CNN;cell detection;region proposed approach","Computer architecture;Feature extraction;Image edge detection;Microprocessors;Microscopy;Proposals;Training","biomedical optical imaging;cellular biophysics;learning (artificial intelligence);medical image processing;neural nets;object detection;optical microscopy","cell detection;machine learning;modified R-CNN;object-proposal-generation;phase contrast microscopy image;region-convolutional neural network;rich feature hierarchy;visual detecting field","","","","22","","","","26-28 Nov. 2015","","IEEE","IEEE Conference Publications"
"Human Epithelial Type 2 cell classification with convolutional neural networks","N. Bayramoglu; J. Kannala; J. Heikkilä","Center for Machine Vision Research, University of Oulu, Finland","2015 IEEE 15th International Conference on Bioinformatics and Bioengineering (BIBE)","20160104","2015","","","1","6","Automated cell classification in Indirect Immunofluorescence (IIF) images has potential to be an important tool in clinical practice and research. This paper presents a framework for classification of Human Epithelial Type 2 cell IIF images using convolutional neural networks (CNNs). Previuos state-of-the-art methods show classification accuracy of 75.6% on a benchmark dataset. We conduct an exploration of different strategies for enhancing, augmenting and processing training data in a CNN framework for image classification. Our proposed strategy for training data and pre-training and fine-tuning the CNN network led to a significant increase in the performance over other approaches that have been used until now. Specifically, our method achieves a 80.25% classification accuracy. Source code and models to reproduce the experiments in the paper is made publicly available.","","Electronic:978-1-4673-7983-0; POD:978-1-4673-7984-7","10.1109/BIBE.2015.7367705","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7367705","","Computer architecture;Histograms;Image segmentation;Microprocessors;Neural networks;Training;Training data","biomedical optical imaging;cellular biophysics;fluorescence;image classification;image enhancement;medical image processing","CNN framework;augmenting training data;benchmark dataset;classification accuracy;clinical practice;convolutional neural networks;enhancing training data;human epithelial type 2 cell classification;image classification;indirect immunofluorescence images;processing training data","","1","","21","","","","2-4 Nov. 2015","","IEEE","IEEE Conference Publications"
"Malphite: A convolutional neural network and ensemble learning based protein secondary structure predictor","Yang Li; T. Shibuya","Department of Computer Science, Graduate School of Information Science and Technology, University of Tokyo, Japan","2015 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)","20151217","2015","","","1260","1266","We developed a convolution neural networks (CNN) and ensemble learning based method, called Malphite, to predict protein secondary structures. Maphite has three sub-models: the 1st CNN, PSI-PRED and the 2nd CNN. The 1st CNN and PSI-PRED are used to predict the initial secondary structure based on the position specific scoring matrix generated from PSIBLAST. The 2nd CNN performs ensemble learning by combining the prediction result of the 1st CNN and PSI-PRED and generate the final predictions. Malphite achieved a Q3 score of 82.3% and 82.6% for independently built dataset of 400 and 538 proteins respectively, and 82.6% ten-fold-cross validated accuracy for a dataset of 3000 proteins. In addition, Malphite accomplished a remarkable Q3 score of 83.6% for 122 targets from CASP10 (Critical Assessment of protein Structure Prediction), surpassing any secondary structure prediction technique to date. For all four datasets, Malphite consistently makes 2% more accurate prediction than PSI-PRED, which is a significantly step towards the estimated upper limit of protein secondary structure prediction accuracy of 90%.","","Electronic:978-1-4673-6799-8; POD:978-1-4673-6800-1","10.1109/BIBM.2015.7359861","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7359861","convolutional neural network;ensemble learning;protein secondary structure","Bioinformatics;Genomics;Proteins","bioinformatics;molecular biophysics;molecular configurations;neural nets;proteins","CASP10;Critical Assessment of protein Structure Prediction;Malphite;PSI-PRED model;PSIBLAST;convolutional neural network;ensemble learning;first CNN model;position specific scoring matrix;protein secondary structure predictor;second CNN model","","","","36","","","","9-12 Nov. 2015","","IEEE","IEEE Conference Publications"
"Microvascular morphological type recognition using trainable feature extractor","D. X. Xue; R. Zhang; R. S. Zhu","Department of Electronic Engineering and Information Science, University of Science and Technology of China","2015 International Symposium on Bioelectronics and Bioinformatics (ISBB)","20151203","2015","","","67","70","This paper focuses on the problem of feature extraction and the classification task of microvascular morphological type to aid esophageal cancer detection. A specialized convolutional neural network (CNN) is designed to extract hierarchical features and Support Vector Machines (SVMs) are introduced to enhance the generalization ability of classifiers. Experiments are conducted on the NBI-ME dataset, achieving a recognition rate of 88.19% on patch level. The results show that the CNN-SVM model beats models of traditional features with SVM as well as the original CNN with softmax. The synthesis results indicate this system is able to assist clinical diagnose to a certain extent.","","Electronic:978-1-4673-6609-0; POD:978-1-4673-6610-6; USB:978-1-4673-6608-3","10.1109/ISBB.2015.7344925","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7344925","Caffe;Convolutional Neural Network;feature learning;microvascular type classification","Convolution;Feature extraction;Image recognition;Kernel;Neural networks;Support vector machines;Training","biomedical optical imaging;blood vessels;cancer;feature extraction;image classification;medical image processing;neural nets;support vector machines","NBI-ME dataset;SVM;classification task;classifier generalization ability;clinical diagnosis;esophageal cancer detection;hierarchical feature extraction;microvascular morphological type recognition;specialized convolutional neural network;support vector machines;trainable feature extractor","","","","12","","","","14-17 Oct. 2015","","IEEE","IEEE Conference Publications"
"Convolutional Neural Networks for patient-specific ECG classification","S. Kiranyaz; T. Ince; R. Hamila; M. Gabbouj","Electrical Engineering, College of Engineering, Qatar University, Qatar","2015 37th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)","20151105","2015","","","2608","2611","We propose a fast and accurate patient-specific electrocardiogram (ECG) classification and monitoring system using an adaptive implementation of 1D Convolutional Neural Networks (CNNs) that can fuse feature extraction and classification into a unified learner. In this way, a dedicated CNN will be trained for each patient by using relatively small common and patient-specific training data and thus it can also be used to classify long ECG records such as Holter registers in a fast and accurate manner. Alternatively, such a solution can conveniently be used for real-time ECG monitoring and early alert system on a light-weight wearable device. The experimental results demonstrate that the proposed system achieves a superior classification performance for the detection of ventricular ectopic beats (VEB) and supraventricular ectopic beats (SVEB).","1094-687X;1094687X","DVD:978-1-4244-9270-1; Electronic:978-1-4244-9271-8; POD:978-1-4244-9269-5","10.1109/EMBC.2015.7318926","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7318926","","Convolution;Databases;Electrocardiography;Feature extraction;Neural networks;Neurons;Training","electrocardiography;feature extraction;medical signal processing;neural nets;signal classification","1D convolutional neural network;ECG monitoring;ECG record classification;feature extraction;light-weight wearable device;patient-specific ECG classification;patient-specific electrocardiogram classification;supraventricular ectopic beat detection","","1","","20","","","","25-29 Aug. 2015","","IEEE","IEEE Conference Publications"
"A comparative study for chest radiograph image retrieval using binary texture and deep learning classification","Y. Anavi; I. Kogan; E. Gelbart; O. Geva; H. Greenspan","Medical Image Processing Lab, Department of Biomedical Engineering, Faculty of Engineering, Tel Aviv University, Israel","2015 37th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)","20151105","2015","","","2940","2943","In this work various approaches are investigated for X-ray image retrieval and specifically chest pathology retrieval. Given a query image taken from a data set of 443 images, the objective is to rank images according to similarity. Different features, including binary features, texture features, and deep learning (CNN) features are examined. In addition, two approaches are investigated for the retrieval task. One approach is based on the distance of image descriptors using the above features (hereon termed the “descriptor”-based approach); the second approach (“classification”-based approach) is based on a probability descriptor, generated by a pair-wise classification of each two classes (pathologies) and their decision values using an SVM classifier. Best results are achieved using deep learning features in a classification scheme.","1094-687X;1094687X","DVD:978-1-4244-9270-1; Electronic:978-1-4244-9271-8; POD:978-1-4244-9269-5","10.1109/EMBC.2015.7319008","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7319008","","Biomedical imaging;Feature extraction;Heart;Machine learning;Measurement;Pathology;Support vector machines","diagnostic radiography;image classification;image retrieval;image texture;learning (artificial intelligence);medical image processing;probability;support vector machines","CNN;SVM classifier;X-ray image retrieval;binary features;binary texture;chest pathology retrieval;chest radiograph image retrieval;classification-based approach;decision values;deep learning classification;deep learning features;descriptor-based approach;image descriptors;pair-wise classification;probability descriptor;query image;texture features","","3","","12","","","","25-29 Aug. 2015","","IEEE","IEEE Conference Publications"
"Automatic localization of the left ventricle in cardiac MRI images using deep learning","O. Emad; I. A. Yassine; A. S. Fahmy","Center for Informatics Science, Nile University, Giza, Egypt","2015 37th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)","20151105","2015","","","683","686","Automatic localization of the left ventricle (LV) in cardiac MRI images is an essential step for automatic segmentation, functional analysis, and content based retrieval of cardiac images. In this paper, we introduce a new approach based on deep Convolutional Neural Network (CNN) to localize the LV in cardiac MRI in short axis views. A six-layer CNN with different kernel sizes was employed for feature extraction, followed by Softmax fully connected layer for classification. The pyramids of scales analysis was introduced in order to take account of the different sizes of the heart. A publically-available database of 33 patients was used for learning and testing. The proposed method was able it localize the LV with 98.66%, 83.91% and 99.07% for accuracy, sensitivity and specificity respectively.","1094-687X;1094687X","DVD:978-1-4244-9270-1; Electronic:978-1-4244-9271-8; POD:978-1-4244-9269-5","10.1109/EMBC.2015.7318454","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7318454","","Biomedical imaging;Convolution;Feature extraction;Heart;Image segmentation;Magnetic resonance imaging;Sensitivity","biomedical MRI;cardiology;feature extraction;image classification;image segmentation;medical image processing;neural nets","Softmax;automatic segmentation;cardiac MRI images;deep convolutional neural network;deep learning;feature extraction;image classification;left ventricle automatic localization","","2","","21","","","","25-29 Aug. 2015","","IEEE","IEEE Conference Publications"
"Resting State EEG-based biometrics for individual identification using convolutional neural networks","L. Ma; J. W. Minett; T. Blu; W. S. Y. Wang","Department of Electronic Engineering, The Chinese University of Hong Kong, China","2015 37th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)","20151105","2015","","","2848","2851","Biometrics is a growing field, which permits identification of individuals by means of unique physical features. Electroencephalography (EEG)-based biometrics utilizes the small intra-personal differences and large inter-personal differences between individuals' brainwave patterns. In the past, such methods have used features derived from manually-designed procedures for this purpose. Another possibility is to use convolutional neural networks (CNN) to automatically extract an individual's best and most unique neural features and conduct classification, using EEG data derived from both Resting State with Open Eyes (REO) and Resting State with Closed Eyes (REC). Results indicate that this CNN-based joint-optimized EEG-based Biometric System yields a high degree of accuracy of identification (88%) for 10-class classification. Furthermore, rich inter-personal difference can be found using a very low frequency band (0-2Hz). Additionally, results suggest that the temporal portions over which subjects can be individualized is less than 200 ms.","1094-687X;1094687X","DVD:978-1-4244-9270-1; Electronic:978-1-4244-9271-8; POD:978-1-4244-9269-5","10.1109/EMBC.2015.7318985","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7318985","","Accuracy;Biological neural networks;Biometrics (access control);Convolution;Electroencephalography;Feature extraction;Security","biometrics (access control);electroencephalography;feature extraction;medical signal processing;neural nets;signal classification;visual evoked potentials","EEG based biometrics;brainwave patterns;convolutional neural networks;electroencephalography;individual identification;interpersonal differences;intrapersonal differences;neural feature classification;neural feature extraction;resting state EEG;resting state-closed eyes condition;resting state-open eyes condition","","","","14","","","","25-29 Aug. 2015","","IEEE","IEEE Conference Publications"
"Automatic detection of cell divisions (mitosis) in live-imaging microscopy images using Convolutional Neural Networks","A. Shkolyar; A. Gefen; D. Benayahu; H. Greenspan","Medical Image Processing Lab, Department of Biomedical Engineering, Faculty of Engineering, Tel Aviv University, Israel","2015 37th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)","20151105","2015","","","743","746","We propose a semi-automated pipeline for the detection of possible cell divisions in live-imaging microscopy and the classification of these mitosis candidates using a Convolutional Neural Network (CNN). We use time-lapse images of NIH3T3 scratch assay cultures, extract patches around bright candidate regions that then undergo segmentation and binarization, followed by a classification of the binary patches into either containing or not containing cell division. The classification is performed by training a Convolutional Neural Network on a specially constructed database. We show strong results of AUC = 0.91 and F-score = 0.89, competitive with state-of-the-art methods in this field.","1094-687X;1094687X","DVD:978-1-4244-9270-1; Electronic:978-1-4244-9271-8; POD:978-1-4244-9269-5","10.1109/EMBC.2015.7318469","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7318469","","Computer architecture;Feature extraction;Gray-scale;Microscopy;Testing;Training;Wounds","biomedical optical imaging;cellular biophysics;feature extraction;image classification;image segmentation;medical image processing;neural nets;optical microscopy","NIH3T3 scratch assay cultures;automatic cell division detection;binary patch classification;binary patch extraction;convolutional neural networks;image segmentation;live-imaging microscopy images;mitosis classification;time-lapse images","","","","10","","","","25-29 Aug. 2015","","IEEE","IEEE Conference Publications"
"Bacterial colony counting by Convolutional Neural Networks","A. Ferrari; S. Lombardi; A. Signoroni","Information Engineering Dept., University of Brescia, via Branze 38, I25123 (Italy)","2015 37th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)","20151105","2015","","","7458","7461","Counting bacterial colonies on microbiological culture plates is a time-consuming, error-prone, nevertheless fundamental task in microbiology. Computer vision based approaches can increase the efficiency and the reliability of the process, but accurate counting is challenging, due to the high degree of variability of agglomerated colonies. In this paper, we propose a solution which adopts Convolutional Neural Networks (CNN) for counting the number of colonies contained in confluent agglomerates, that scored an overall accuracy of the 92.8% on a large challenging dataset. The proposed CNN-based technique for estimating the cardinality of colony aggregates outperforms traditional image processing approaches, becoming a promising approach to many related applications.","1094-687X;1094687X","DVD:978-1-4244-9270-1; Electronic:978-1-4244-9271-8; POD:978-1-4244-9269-5","10.1109/EMBC.2015.7320116","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7320116","","Accuracy;Biological neural networks;Image segmentation;Microorganisms;Training;Transforms;Yttrium","blood;cellular biophysics;computer vision;image representation;image segmentation;medical image processing;microorganisms;neurophysiology","CNN-based technique;agglomerated colonies;agglomerates;bacterial colony counting;colony aggregates;computer vision;convolutional neural networks;microbiological culture plates;reliability;traditional image processing approaches","","2","","20","","","","25-29 Aug. 2015","","IEEE","IEEE Conference Publications"
"Interleaved text/image Deep Mining on a large-scale radiology database","H. C. Shin; Le Lu; L. Kim; A. Seff; J. Yao; R. M. Summers","Imaging Biomarkers and Computer-Aided Diagnosis Laboratory Radiology and Imaging Sciences, National Institutes of Health Clinical Center, Bethesda, MD 20892-1182, United States","2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)","20151015","2015","","","1090","1099","Despite tremendous progress in computer vision, effective learning on very large-scale (> 100K patients) medical image databases has been vastly hindered. We present an interleaved text/image deep learning system to extract and mine the semantic interactions of radiology images and reports from a national research hospital's picture archiving and communication system. Instead of using full 3D medical volumes, we focus on a collection of representative ~216K 2D key images/slices (selected by clinicians for diagnostic reference) with text-driven scalar and vector labels. Our system interleaves between unsupervised learning (e.g., latent Dirichlet allocation, recurrent neural net language models) on document- and sentence-level texts to generate semantic labels and supervised learning via deep convolutional neural networks (CNNs) to map from images to label spaces. Disease-related key words can be predicted for radiology images in a retrieval manner. We have demonstrated promising quantitative and qualitative results. The large-scale datasets of extracted key images and their categorization, embedded vector labels and sentence descriptions can be harnessed to alleviate the deep learning “data-hungry” obstacle in the medical domain.","1063-6919;10636919","Electronic:978-1-4673-6964-0; POD:978-1-4673-6965-7; USB:978-1-4673-6963-3","10.1109/CVPR.2015.7298712","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7298712","","Machine learning;Medical diagnostic imaging;Radiology;Semantics;Visualization","PACS;computer vision;data mining;image retrieval;learning (artificial intelligence);medical image processing;radiology;recurrent neural nets;text analysis","3D medical volume;CNN;computer vision;data-hungry obstacle;deep convolutional neural network;document-level text;embedded vector label;extracted key image;interleaved text/image deep learning system;interleaved text/image deep mining;large-scale radiology database;latent Dirichlet allocation;national research hospital;picture archiving and communication system;radiology image;recurrent neural net language model;retrieval manner;semantic interaction;semantic label;sentence description;sentence-level text;unsupervised learning;very large-scale medical image database","","3","","47","","","","7-12 June 2015","","IEEE","IEEE Conference Publications"
"Classifying digestive organs in wireless capsule endoscopy images based on deep convolutional neural network","Y. Zou; L. Li; Y. Wang; J. Yu; Y. Li; W. J. Deng","ADSPLAB/ELIP, School of ECE, Peking University, Shenzhen 518055, China","2015 IEEE International Conference on Digital Signal Processing (DSP)","20150910","2015","","","1274","1278","This paper studies the classification problem of the digestive organs in wireless capsule endoscopy (WCE) images based on deep convolutional neural network (DCNN) framework. Essentially, DCNN proves having powerful ability to learn layer-wise hierarchy models with huge training data, which works similar to human biological visual systems. Classifying digestive organs in WCE images intuitively means to recognize higher semantic image features. To achieve this, an effective deep CNN-based WCE classification system has been constructed (DCNN-WCE-CS). With about 1 million real WCE images, intensive experiments are conducted to evaluate its performance by setting different network parameters. Results illustrate its superior performance compared to traditional classification methods, where about 95% classification accuracy can be achieved in average. Moreover, it is observed that the DCNN-WCE-CS is robust to the large variations of the WCE images due to the individuals and complex digestive tract circumstance, including the rotation, the luminance change of the WCE images.","1546-1874;15461874","Electronic:978-1-4799-8058-1; POD:978-1-4799-8059-8; USB:978-1-4799-8057-4","10.1109/ICDSP.2015.7252086","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7252086","deep convolutional neural network;digestive organs classification;parameter selection;wireless capsule endoscopy","Accuracy;Convolution;Endoscopes;Feature extraction;Intestines;Training;Wireless communication","biological organs;biomedical optical imaging;brightness;endoscopes;feature extraction;feedforward neural nets;image classification;learning (artificial intelligence);medical image processing;object recognition","DCNN-WCE-CS;complex digestive tract circumstance;deep CNN-based WCE classification system;deep convolutional neural network;digestive organ classification problem;human biological visual systems;layer-wise hierarchy models;luminance change;semantic image feature recognition;training data;wireless capsule endoscopy images","","2","","14","","","","21-24 July 2015","","IEEE","IEEE Conference Publications"
"Cellular nonlinear network-based signal prediction in epilepsy: Method comparison","V. Senger; R. Tetzlaff","Chair of Fundamentals of Electrical Engineering, Faculty of Electrical Engineering and Information Technology, Technische Universit&#x00E4;t Dresden, Dresden, Germany","2015 IEEE International Symposium on Circuits and Systems (ISCAS)","20150730","2015","","","397","400","The seizure prediction problem has been addressed by many researchers from very different fields for more than three decades. The vision of an implantable seizure prediction device may become reality now: the first clinical study of such a device has been realized very recently and other realizations are not far behind. Cellular Nonlinear Networks (CNN) were firstly introduced by Chua and Yang in 1988 and later extended to an inherently parallel processing framework called the CNN Universal Machine (CNN-UM). This framework combines high computational power with low power consumption and miniaturized design - making it a very promising basis for the realization of a seizure warning device. In this contribution, we compare the seizure prediction performance of an eigenvalue based PCA-preprocessing followed by a nonlinear CNN signal prediction to the performance of a linear signal prediction approach followed by a level-crossing behavior analysis.","0271-4302;02714302","Electronic:978-1-4799-8391-9; POD:978-1-4799-8392-6","10.1109/ISCAS.2015.7168654","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7168654","","Eigenvalues and eigenfunctions;Electrodes;Electroencephalography;Epilepsy;Prediction algorithms;Principal component analysis;Signal processing algorithms","diseases;eigenvalues and eigenfunctions;medical signal detection;neurophysiology;principal component analysis","CNN universal machine;cellular nonlinear network;cellular nonlinear networks;epilepsy;implantable seizure prediction device;level-crossing behavior analysis;nonlinear CNN signal prediction","","1","","18","","","","24-27 May 2015","","IEEE","IEEE Conference Publications"
"CNN in drug design — Recent developments","J. D. Wichard; M. J. Ogorzałek; C. Merkwirth","Department of Investigational Toxicology, Bayer HealthCare, Berlin, Germany","2015 IEEE International Symposium on Circuits and Systems (ISCAS)","20150730","2015","","","405","408","We describe a method for construction of specific types of Neural Networks composed of structures directly linked to the structure of the molecule under consideration. Each molecule can be represented by a unique neural connectivity problem (graph) which can be programmed onto a Cellular Neural Network. The idea was to translate chemical structures like small organic molecules or peptides into a self learning environment which is CNN based. In the case of small molecules, each cell of the CNN stands for one atom of the molecule under consideration. But in contrast to the standard CNN architecture where each cell is connected to the neighboring cells, only those cells of the feature net are connected for which there also exists a chemical bond in the molecule under consideration. This implies that the feature net topology varies from molecule to molecule. In the case of peptides, the amino acids that form the building blocks of the peptide are reflected by the CNN cells wherein the amino acid sequence defines the network topology. Unlike the standard CNN used for image processing, there are no input values like the input image that are fed into the feature net. Instead, all information about the input molecule is supplied to the feature net by means of the topology. The output of several feature nets is fed into a supervisor neural network which computes the final output value. The combination of several feature nets and a supervisor networks constitutes the Molecular Graph Network (MGN). The designed networks are used for selection of molecules representing wanted properties such as activity against specific diseases, interactions with other compounds, toxicity etc. and possibly being candidates to be tested further as new drugs.","0271-4302;02714302","Electronic:978-1-4799-8391-9; POD:978-1-4799-8392-6","10.1109/ISCAS.2015.7168656","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7168656","","Amino acids;Computer architecture;Microprocessors;Network topology;Peptides;Topology;Training","cellular neural nets;drugs;graph theory;medical computing;organic compounds;unsupervised learning","MGN;amino acid sequence;cellular neural network;chemical structures;drug design;feature nets;image processing;molecular graph network;network topology;neural connectivity problem;peptides;self learning environment;small organic molecules;standard CNN architecture;supervisor neural network","","0","","14","","","","24-27 May 2015","","IEEE","IEEE Conference Publications"
"Iteratively training classifiers for circulating tumor cell detection","Y. Mao; Z. Yin; J. M. Schober","Missouri University of Science and Technology","2015 IEEE 12th International Symposium on Biomedical Imaging (ISBI)","20150723","2015","","","190","194","The number of Circulating Tumor Cells (CTCs) in blood provides an indication of disease progression and tumor response to chemotherapeutic agents. Hence, routine detection and enumeration of CTCs in clinical blood samples have significant applications in early cancer diagnosis and treatment monitoring. In this paper, we investigate two classifiers for image-based CTC detection: (1) Support Vector Machine (SVM) with hard-coded Histograms of Oriented Gradients (HoG) features; and (2) Convolutional Neural Network (CNN) with automatically learned features. For both classifiers, we present an effective and efficient training algorithm, by which the most representative negative samples are iteratively collected to accurately define the classification boundary between positive and negative samples. The two iteratively trained classifiers are validated on a challenging dataset with high performance.","1945-7928;19457928","Electronic:978-1-4799-2374-8; POD:978-1-4673-9330-0","10.1109/ISBI.2015.7163847","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7163847","circulating tumor cells;convolutional neural network;iterative training;support vector machine","Blood;Cancer;Cells (biology);Feature extraction;Support vector machines;Training;Tumors","biomedical optical imaging;cancer;cellular biophysics;image classification;iterative methods;medical image processing;neural nets;support vector machines;tumours","CNN;HoG features;SVM;cancer diagnosis;cancer treatment monitoring;chemotherapeutic agents;circulating tumor cell detection;clinical blood samples;convolutional neural network;disease progression;hard-coded histogram-of-oriented gradients;image-based CTC detection;iterative training classification;support vector machine;tumor response","","1","","14","","","","16-19 April 2015","","IEEE","IEEE Conference Publications"
"Region segmentation in histopathological breast cancer images using deep convolutional neural network","H. Su; F. Liu; Y. Xie; F. Xing; S. Meyyappan; L. Yang","J. Crayton Pruitt Family Dept. of Biomedical Engineering","2015 IEEE 12th International Symposium on Biomedical Imaging (ISBI)","20150723","2015","","","55","58","Computer aided diagnosis of breast cancers often relies on automatic image analysis of histopathology images. The automatic region segmentation in breast cancer is challenging due to: i) large regional variations, and ii) high computational costs of pixel-wise segmentation. Deep convolutional neural network (CNN) is proven to be an effective method for image recognition and classification. However, it is often computationally expensive. In this paper, we propose to apply a fast scanning deep convolutional neural network (fCNN) to pixel-wise region segmentation. The fCNN removes the redundant computations in the original CNN without sacrificing its performance. In our experiment it takes only 2.3 seconds to segment an image with size 1000 × 1000. The comparison experiments show that the proposed system outperforms both the LBP feature-based and texton-based pixel-wise methods.","1945-7928;19457928","Electronic:978-1-4799-2374-8; POD:978-1-4673-9330-0","10.1109/ISBI.2015.7163815","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7163815","","Breast cancer;Image segmentation;Kernel;Neural networks;Scalability;Training","cancer;image classification;image recognition;image segmentation;medical image processing;neural nets","LBP feature-based methods;automatic image analysis;breast cancers;computational costs;computer aided diagnosis;deep convolutional neural network;fCNN;fast scanning deep convolutional neural network;histopathological breast cancer images;image classification;image recognition;local binary pattern;pixel-wise segmentation;region segmentation;regional variations;texton-based pixel-wise methods","","3","","15","","","","16-19 April 2015","","IEEE","IEEE Conference Publications"
"Automatic muscle perimysium annotation using deep convolutional neural network","M. Sapkota; F. Xing; H. Su; L. Yang","Department of Electrical and Computer Engineering, University of Florida","2015 IEEE 12th International Symposium on Biomedical Imaging (ISBI)","20150723","2015","","","205","208","Diseased skeletal muscle expresses mononuclear cell infiltration in the regions of perimysium. Accurate annotation or segmentation of perimysium can help biologists and clinicians to determine individualized patient treatment and allow for reasonable prognostication. However, manual perimysium annotation is time consuming and prone to inter-observer variations. Meanwhile, the presence of ambiguous patterns in muscle images significantly challenge many traditional automatic annotation algorithms. In this paper, we propose an automatic perimysium annotation algorithm based on deep convolutional neural network (CNN). We formulate the automatic annotation of perimysium in muscle images as a pixel-wise classification problem, and the CNN is trained to label each image pixel with raw RGB values of the patch centered at the pixel. The algorithm is applied to 82 diseased skeletal muscle images. We have achieved an average precision of 94% on the test dataset.","1945-7928;19457928","Electronic:978-1-4799-2374-8; POD:978-1-4673-9330-0","10.1109/ISBI.2015.7163850","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7163850","Perimysium annotation;convolutional neural network;muscle","Image segmentation;Kernel;Muscles;Neural networks;Noise measurement;Testing;Training","convolution;diseases;image classification;image segmentation;medical image processing;muscle;neural nets","RGB value;automatic muscle perimysium annotation algorithm;deep convolutional neural network;image pixel;manual perimysium annotation;mononuclear cell infiltration;muscle images;patient treatment;perimysium segmentation;pixel-wise classification;skeletal muscle disease","","0","","17","","","","16-19 April 2015","","IEEE","IEEE Conference Publications"
"Deep learning for automatic cell detection in wide-field microscopy zebrafish images","B. Dong; L. Shao; M. Da Costa; O. Bandmann; A. F. Frangi","Centre of Computational Imaging & Simulation Technologies in Biomedicine (CISTIB)","2015 IEEE 12th International Symposium on Biomedical Imaging (ISBI)","20150723","2015","","","772","776","The zebrafish has become a popular experimental model organism for biomedical research. In this paper, a unique framework is proposed for automatically detecting Tyrosine Hydroxylase-containing (TH-labeled) cells in larval zebrafish brain z-stack images recorded through the wide-field microscope. In this framework, a supervised max-pooling Convolutional Neural Network (CNN) is trained to detect cell pixels in regions that are preselected by a Support Vector Machine (SVM) classifier. The results show that the proposed deep-learned method outperforms hand-crafted techniques and demonstrate its potential for automatic cell detection in wide-field microscopy z-stack zebrafish images.","1945-7928;19457928","Electronic:978-1-4799-2374-8; POD:978-1-4673-9330-0","10.1109/ISBI.2015.7163986","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7163986","","Computer architecture;Histograms;Microprocessors;Microscopy;Neurons;Three-dimensional displays;Training","biomedical optical imaging;brain;cellular biophysics;convolution;enzymes;feature extraction;image classification;learning (artificial intelligence);medical image processing;molecular biophysics;neural nets;neurophysiology;optical microscopy;support vector machines","SVM classifier;automatic TH-labeled cell detection;automatic tyrosine hydroxylase-containing cell detection;biomedical research;cell pixel detection;convolutional neural network;deep learning;experimental model organism;hand-crafted technique;larval zebrafish brain z-stack image recording;region preselection;supervised max-pooling CNN training;support vector machine;wide-field microscopy","","3","","26","","","","16-19 April 2015","","IEEE","IEEE Conference Publications"
"A Reliable Distributed Convolutional Neural Network for Biology Image Segmentation","X. Zhang; G. Tan; M. Chen","","2015 15th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing","20150709","2015","","","777","780","Many modern advanced biology experiments are carried on by Electron Microscope(EM) image analysis. Segmentation is one of the most important and complex steps in the process of image analysis. Previous ISBI contest results and related research show that Convolution Neural Network(CNN)has high classification accuracy in EM image segmentation. Besides it eliminates the pain of extracting complex features which's indispensable for traditional classification algorithms. However CNN's extremely time-consuming and fault vulnerability due to long time execution prevent it from being widely used in practice. In this paper, we try to address these problems by providing reliable high performance CNN framework for medial image segmentation. Our CNN has light weighted user level checkpoint, which costs seconds when doing one checkpoint and restart. On the fact of lacking in platform diversity in current parallel CNN framework, our CNN system tries to make it general by providing distributed cross-platform parallelism implementation. Currently we have integrated Theano's GPU implementation in our CNNsystem, and we explore parallelism potential on multi-core CPUs and many-core Intel Phi by testing performance of main kernel functions of CNN. In the future, we will integrate implementation son other two platforms into our CNN framework.","","Electronic:978-1-4799-8006-2; POD:978-1-4799-8007-9","10.1109/CCGrid.2015.108","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7152555","Convolutional Neural Network;Distributed system;Faula tolerant;GPU;Image segmentation;Intel Phi","Graphics processing units;Image segmentation;Microscopy;Microwave integrated circuits;Parallel processing;Reliability;Training","electron microscopes;feature extraction;image classification;image segmentation;medical image processing;neural nets","EM image segmentation;advanced biology experiments;biology image segmentation;classification algorithms;complex feature extraction;distributed cross-platform parallelism;electron microscope image analysis;fault vulnerability;high performance CNN framework;image processing analysis;integrated Theano GPU;kernel functions;lightweighted user level checkpoint;many-core Intel Phi;medial image segmentation;parallel CNN framework;reliable distributed convolutional neural network","","0","","16","","","","4-7 May 2015","","IEEE","IEEE Conference Publications"
"Morphological process based segmentation for the detection of exudates from the retinal images of diabetic patients","Mahendran G.; Dhanasekaran R.; Narmadha Devi K. N.","Syed Ammal Engineering College, Ramanathapuram, TamilNadu. India","2014 IEEE International Conference on Advanced Communications, Control and Computing Technologies","20150126","2014","","","1466","1470","Diabetic Retinopathy is an ocular systemic disease caused by complication of diabetes. It is a major cause of blindness in both middle and advanced age group. Earlier recognition of diabetic retinopathy shields understanding from visual impairment. The heading side effect of this difficulty seeing is the exudates. Exudates are the melted watery grasping solutes, proteins, cells, or cell garbage spilled from the harmed veins into near by tissues or on tissue surfaces in the retina. The spillage of these proteins or lipids causes vision misfortune to the patients. Distinguishing the exudates ahead of time can protect the diabetic patients from difficulty seeing. Ophthalmologists use widening system to identify the exudates. But it causes the irritation to the patients' eyes. This paper focuses on an automated method which detects the diabetic retinopathy through identifying exudates by Morphological process in colour fundus retinal images and then segregates the severity of the lesions. The severity level of the disease was achieved by Cascade Neural Network (CNN) classifier.","","CD-ROM:978-1-4799-3913-8; Electronic:978-1-4799-3914-5; POD:978-1-4799-3915-2","10.1109/ICACCCT.2014.7019345","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7019345","Cascade Neural Network;Diabetic Retinopathy;Dilation;Erosion;Exudates","Biomedical imaging;Character recognition;Image edge detection;Image segmentation;Lesions;Proteins;Retinopathy","diseases;image segmentation;medical image processing;neural nets","cascade neural network classifier;colour fundus retinal images;diabetic patients;diabetic retinopathy;morphological process based segmentation;ocular systemic disease;retinal images","","2","","17","","","","8-10 May 2014","","IEEE","IEEE Conference Publications"
"Motion correction of thermographic images in neurosurgery: Performance comparison","V. Senger; N. Hoffmann; J. Müller; J. Hollmach; C. Schnabel; Y. Radev; J. Müller; M. Kirsch; U. Petersohn; G. Steiner; E. Koch; R. Tetzlaff","Fundamentals of Electrical Engineering, Faculty of Electrical and Computer Engineering, Technische Universit&#x00E4;t Dresden, D-01062 Germany","2014 IEEE Biomedical Circuits and Systems Conference (BioCAS) Proceedings","20141211","2014","","","121","124","In this paper, the correction of motion-induced high frequency artifacts on sequences of thermographic images by a real-time capable approach based on Cellular Nonlinear Networks (CNN) is evaluated. For comparison, an offline analysis of frequency subspaces is presented and results will be compared. Both simulated data sets as well as data sets recorded during neurosurgery are considered as inputs and two measures are evaluated.","2163-4025;21634025","Electronic:978-1-4799-2346-5; POD:978-1-4799-2348-9","10.1109/BioCAS.2014.6981660","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6981660","","Cameras;Equations;Hardware;Mathematical model;Neurosurgery;Real-time systems","biomedical optical imaging;image motion analysis;image sequences;infrared imaging;medical image processing;neurophysiology;surgery","CNN;Cellular Nonlinear Networks;frequency subspaces;motion-induced high frequency artifact correction;neurosurgery;offline analysis;real-time capable approach;simulated data sets;thermographic image sequences","","1","","9","","","","22-24 Oct. 2014","","IEEE","IEEE Conference Publications"
"Real-time object recognition and orientation estimation using an event-based camera and CNN","R. Ghosh; A. Mishra; G. Orchard; N. V. Thakor","Singapore Institute for Neurotechnology (SINAPSE), National University of Singapore, Singapore","2014 IEEE Biomedical Circuits and Systems Conference (BioCAS) Proceedings","20141211","2014","","","544","547","Real-time visual identification and tracking of objects is a computationally intensive task, particularly in cluttered environments which contain many visual distracters. In this paper we describe a real-time bio-inspired system for object tracking and identification which combines an event-based vision sensor with a convolutional neural network running on FPGA for recognition. The event-based vision sensor detects only changes in the scene, naturally responding to moving objects and ignoring static distracters in the background. We present operation of the system for two tasks. The first is proof of concept for a remote monitoring application in which the system tracks and distinguishes between cars, bikes, and pedestrians on a road. The second task targets application to grasp planning for an upper limb prosthesis and involves detecting and identifying household objects, as well as determining their orientation relative to the camera. The second task is used to quantify performance of the system, which can discriminate between 8 different objects in 2.25 ms with accuracy of 99.10% and is able to determine object orientation with -4.5° accuracy in an additional 2.28 ms with accuracy of 97.76%.","2163-4025;21634025","Electronic:978-1-4799-2346-5; POD:978-1-4799-2348-9","10.1109/BioCAS.2014.6981783","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6981783","","Accuracy;Estimation;Neural networks;Real-time systems;Testing;Training;Visualization","biomedical telemetry;cameras;convolution;field programmable gate arrays;image sensors;medical image processing;neural nets;object recognition;object tracking;prosthetics","FPGA;convolutional neural network running;event-based camera;event-based vision sensor;grasp planning;real-time bioinspired system;real-time object orientation estimation;real-time object recognition;real-time object tracking;remote monitoring application;time 2.25 ms;upper limb prosthesis","","4","","8","","","","22-24 Oct. 2014","","IEEE","IEEE Conference Publications"
"A deep learning based framework for accurate segmentation of cervical cytoplasm and nuclei","Y. Song; L. Zhang; S. Chen; D. Ni; B. Li; Y. Zhou; B. Lei; T. Wang","Department of Biomedical Engineering, School of Medicine, Shenzhen University, National-Regional Key Technology Engineering Laboratory for Medical Ultrasound, Guangdong Key Laboratory for Biomedical Measurements and Ultrasound Imaging, Shenzhen, China","2014 36th Annual International Conference of the IEEE Engineering in Medicine and Biology Society","20141106","2014","","","2903","2906","In this paper, a superpixel and convolution neural network (CNN) based segmentation method is proposed for cervical cancer cell segmentation. Since the background and cytoplasm contrast is not relatively obvious, cytoplasm segmentation is first performed. Deep learning based on CNN is explored for region of interest detection. A coarse-to-fine nucleus segmentation for cervical cancer cell segmentation and further refinement is also developed. Experimental results show that an accuracy of 94.50% is achieved for nucleus region detection and a precision of 0.9143±0.0202 and a recall of 0.8726±0.0008 are achieved for nucleus cell segmentation. Furthermore, our comparative analysis also shows that the proposed method outperforms the related methods.","1094-687X;1094687X","Electronic:978-1-4244-7929-0; POD:978-1-4244-7927-6","10.1109/EMBC.2014.6944230","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6944230","","Accuracy;Cervical cancer;Image color analysis;Image segmentation;Neural networks;Training","biological organs;cancer;cellular biophysics;image segmentation;medical image processing;neural nets","CNN based segmentation method;cervical cancer cell segmentation;cervical cytoplasm;coarse-to-fine nucleus segmentation;convolution neural network;cytoplasm segmentation;deep learning based framework;nucleus cell segmentation;nucleus region detection","","1","","9","","","","26-30 Aug. 2014","","IEEE","IEEE Conference Publications"
"Modelling brain electrical activity by reaction diffusion cellular nonlinear networks (RD-CNN) in laplace domain","A. Osman; R. Tetzlaff","Fac. of Electr. Eng. & Comput. Sci., Tech. Univ. Dresden, Dresden, Germany","2014 14th International Workshop on Cellular Nanoscale Networks and their Applications (CNNA)","20140901","2014","","","1","2","In this contribution a RD-CNN model given in the Laplace domain is proposed in an identification approach using brain electrical activity in epilepsy. This work aimed at developing accurate and time efficient modeling techniques allowing the analysis of the local activity theory in epilepsy.","2165-0144;21650144","Electronic:978-1-4799-6007-1; POD:978-1-4799-6008-8","10.1109/CNNA.2014.6888661","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6888661","EEG;Epilepsy;Laplace Domain;RD-CNN;Seizure","Brain modeling;Computational modeling;Epilepsy;Indexes;Optimization","Laplace equations;electroencephalography;medical disorders;medical signal processing;neurophysiology;reaction-diffusion systems","Laplace domain;brain electrical activity;epilepsy;local activity theory;reaction diffusion cellular nonlinear networks;time efficient modeling techniques","","0","","4","","","","29-31 July 2014","","IEEE","IEEE Conference Publications"
"CNN based movement correction in thermography for intrasurgical diagnostics","V. Senger; L. Schierling; J. Müller; R. Tetzlaff","Fundamentals of Electr. Eng., Tech. Univ. Dresden, Dresden, Germany","2014 14th International Workshop on Cellular Nanoscale Networks and their Applications (CNNA)","20140901","2014","","","1","2","In this contribution, we present an algorithm aimed at the correction of a movement artifact in thermographic images recorded during neurosurgery. It is based on Cellular Nonlinear Networks (CNN) and was designed as a first step towards a platform capable of providing intraoperative feedback to a surgeon.","2165-0144;21650144","Electronic:978-1-4799-6007-1; POD:978-1-4799-6008-8","10.1109/CNNA.2014.6888660","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6888660","","Adaptive optics;Algorithm design and analysis;Equations;Image edge detection;Mathematical model;Neurosurgery","biomedical optical imaging;cellular neural nets;infrared imaging;medical image processing;neurophysiology;recurrent neural nets;surgery","CNN based movement correction;cellular nonlinear networks;intraoperative feedback;intrasurgical diagnostics;movement artifact;neurosurgery;thermographic images","","2","","4","","","","29-31 July 2014","","IEEE","IEEE Conference Publications"
"Realization of processing blocks of CNN based CASA system on CPU and FPGA","O. L. Şavkay; E. Cesur; N. Yıldız; M. E. Yalçın; V. Tavşanoğlu","Dept. of Electron. & Commun. Eng., Istanbul Tech. Univ., Istanbul, Turkey","2014 IEEE International Symposium on Circuits and Systems (ISCAS)","20140726","2014","","","2081","2084","In this paper, hardware optimization of the preprocessing and software implementation of the processing blocks of a computer-aided semen analysis (CASA) system are proposed, which is also implemented on an FPGA and ARM device as a working prototype. The software implementation of the track initialization, track maintenance, data validation and classification blocks of the processing part are implemented on a Zynq7000 ARM Cortex-A9 processor. In the preprocessing part, a real-time cellular neural network (CNN) emulator (RTCNNP-v2) is used for the realization of the image processing algorithms, whose regular, flexible and reconfigurable infrastructure simplifies the prototyping process. The CASA system introduced in this paper is capable of processing full-HD 1080p@60 (1080 × 1920) video images in real-time.","0271-4302;02714302","CD-ROM:978-1-4799-3431-7; Electronic:978-1-4799-3432-4; POD:978-1-4799-3433-1","10.1109/ISCAS.2014.6865576","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6865576","","Algorithm design and analysis;Field programmable gate arrays;Image processing;Microprocessors;Microscopy;Prototypes;Software","cellular neural nets;field programmable gate arrays;image classification;medical image processing;reduced instruction set computing;video signal processing","ARM device;CNN based CASA system;CNN emulator;CPU;FPGA;RTCNNP-v2;Zynq7000 ARM Cortex-A9 processor;classification blocks;computer-aided semen analysis system;data validation;flexible infrastructure;hardware optimization;image processing algorithms;processing blocks;prototyping process;real-time cellular neural network;real-time full-HD video image processing;reconfigurable infrastructure;regular infrastructure;software implementation;track initialization;track maintenance","","0","","15","","","","1-5 June 2014","","IEEE","IEEE Conference Publications"
"Potential of Ultralow-Power Cellular Neural Image Processing With Si/Ge Tunnel FET","A. R. Trivedi; S. Mukhopadhyay","Department of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, USA","IEEE Transactions on Nanotechnology","20140708","2014","13","4","627","629","This letter studies the application of tunnel FET (TFET) for ultralow power image processing through cellular neural network (CNN). Through steeper switching slope, and thereby higher g<sub>m</sub>/I<sub>DS</sub>, a TFET-based CNN synapse can deliver the same performance as MOSFET even with a lower power. A TFET-based synapse is also scalable to the ultralow power regime; hence, by comprising more cells than MOSFET at the same power, TFET can reduce the multiplexing overheads in image processing with CNN. Utilizing unique properties of TFET, we show an improved performance for low power image processing using TFET.","1536-125X;1536125X","","10.1109/TNANO.2014.2318046","Center Innovation Fund at NASA Ames Research Center; National Science Foundation and Office of Naval Research Young Investigator Award; ","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6800000","Cellular neural network (CNN);image processing;tunneling field effect transistor","Arrays;Cellular neural networks;FinFETs;Image processing;Low-power electronics;Silicon","cellular neural nets;field effect transistors;medical image processing;neurophysiology;tunnel transistors","MOSFET;TFET-based CNN synapse;cellular neural network;low power image processing;steeper switching slope;tunnel FET;ultralow power image processing;ultralow power regime;ultralow-power cellular neural image processing","","6","","12","","","20140417","July 1 2014","","IEEE","IEEE Journals & Magazines"
"Image-Based Quantitative Analysis of Gold Immunochromatographic Strip via Cellular Neural Network Approach","N. Zeng; Z. Wang; B. Zineddin; Y. Li; M. Du; L. Xiao; X. Liu; T. Young","College of Electrical Engineering and Automation, Fuzhou University, Fuzhou, P. R. China","IEEE Transactions on Medical Imaging","20140422","2014","33","5","1129","1136","Gold immunochromatographic strip assay provides a rapid, simple, single-copy and on-site way to detect the presence or absence of the target analyte. This paper aims to develop a method for accurately segmenting the test line and control line of the gold immunochromatographic strip (GICS) image for quantitatively determining the trace concentrations in the specimen, which can lead to more functional information than the traditional qualitative or semi-quantitative strip assay. The canny operator as well as the mathematical morphology method is used to detect and extract the GICS reading-window. Then, the test line and control line of the GICS reading-window are segmented by the cellular neural network (CNN) algorithm, where the template parameters of the CNN are designed by the switching particle swarm optimization (SPSO) algorithm for improving the performance of the CNN. It is shown that the SPSO-based CNN offers a robust method for accurately segmenting the test and control lines, and therefore serves as a novel image methodology for the interpretation of GICS. Furthermore, quantitative comparison is carried out among four algorithms in terms of the peak signal-to-noise ratio. It is concluded that the proposed CNN algorithm gives higher accuracy and the CNN is capable of parallelism and analog very-large-scale integration implementation within a remarkably efficient time.","0278-0062;02780062","","10.1109/TMI.2014.2305394","; ","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6734696","Cellular neural networks (CNNs);gold immuno chromatographic strip (GICS);image segmentation;mathematical morphology;switching particle swarm optimization","Algorithm design and analysis;Cellular neural networks;Chromatography;Image segmentation;Immune system;Neural networks","cellular neural nets;chromatography;edge detection;feature extraction;gold;image segmentation;mathematical morphology;medical image processing;particle swarm optimisation;strips","Au;CNN algorithm;CNN performance;CNN template parameter;Canny operator;GICS image;GICS interpretation;GICS reading-window detection;GICS reading-window extraction;SPSO algorithm;SPSO-based CNN;cellular neural network approach;control line segmentation;gold immunochromatographic strip assay;image-based quantitative analysis;mathematical morphology method;on-site target analyte detection;peak signal-to-noise ratio;qualitative strip assay;quantitatively trace concentration determination;rapid target analyte detection;robust method;semiquantitative strip assay;single-copy target analyte detection;switching particle swarm optimization;test line segmentation","Algorithms;Gold;Image Processing, Computer-Assisted;Immunochromatography;Models, Biological;Neural Networks (Computer);Signal-To-Noise Ratio","11","","38","","","20140207","May 2014","","IEEE","IEEE Journals & Magazines"
"An approach for chest tube detection in chest radiographs","C. A. Mercan; M. S. Celebi","Inf. Inst., Istanbul Tech. Univ. (ITU), Istanbul, Turkey","IET Image Processing","20140210","2014","8","2","122","129","It is known that overlapping tissues cause highly complex projections in chest radiographs. In addition, artificial objects, such as catheters, chest tubes and pacemakers can appear on these radiographs. It is important that the anomaly detection algorithms are not confused by these objects. To achieve this goal, the authors propose an approach to train a convolutional neural network (CNN) to detect chest tubes present on radiographs. To detect the chest tube skeleton as the final output in a better manner, non-uniform rational B-spline curves are used to automatically fit with the CNN output. This is the first study conducted to automatically detect artificial objects in the lung region of chest radiographs. Other automatic detection schemes work on the mediastinum. The authors evaluated the performance of the model using a pixel-based receiver operating characteristic (ROC) analysis. Each true positive, true negative, false positive and false negative pixel is counted and used for calculating average accuracy, sensitivity and specificity percentages. The results were 99.99% accuracy, 59% sensitivity and 99.99% specificity. Therefore they obtained promising results on the detection of artificial objects.","1751-9659;17519659","","10.1049/iet-ipr.2013.0239","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6733843","","","diagnostic radiography;learning (artificial intelligence);lung;medical image processing;object detection;sensitivity analysis;splines (mathematics)","anomaly detection algorithm;artificial object detection;automatic detection scheme;catheter;chest radiograph;chest tube skeleton detection;convolutional neural network;false negative pixel;false positive pixel;lung region;mediastinum;nonuniform rational B-spline curve;pacemaker;pixel-based ROC analysis;tissue;true negative pixel;true positive pixel","","0","","","","","","February 2014","","IET","IET Journals & Magazines"
"Realization of preprocessing blocks of CNN based CASA system on FPGA","O. L. Savkay; N. Yildiz; E. Cesur; M. E. Yalcin; V. Tavsanoglu","Dept. of Electron. & Commun. Eng., Istanbul Tech. Univ., Istanbul, Turkey","2013 European Conference on Circuit Theory and Design (ECCTD)","20131114","2013","","","1","4","In this paper, hardware optimization of the preprocessing part of a computer aided semen analysis (CASA) system is proposed, which is also implemented on an FPGA device as a working prototype. A real-time cellular neural network (CNN) emulator (RTCNNP-v2) is used for the realization of the image processing algorithms, whose regular, flexible and reconfigurable infrastructure simplifies the prototyping process. For future work, the post-processing part of the CASA system is proposed to be implemented on the same FPGA device as software, using either a soft or hard processor core. By the integration of the pre- and post-processing parts, the designed CASA system will be capable of processing full-HD 1080p@60 (1080×1920) video images in real-time.","","Electronic:978-3-00-043785-4; POD:978-1-4799-2857-6; USB:978-3-00-043430-3","10.1109/ECCTD.2013.6662238","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6662238","","Algorithm design and analysis;Computer architecture;Field programmable gate arrays;Hardware;Image processing;Prototypes;Software","cellular neural nets;field programmable gate arrays;medical image processing;optimisation;video signal processing","CNN based CASA system;FPGA;RTCNNP-v2;computer aided semen analysis;hardware optimization;image processing;real-time cellular neural network emulator;video images","","4","","13","","","","8-12 Sept. 2013","","IEEE","IEEE Conference Publications"
"Continuous Neural Networks for Electroencephalography Waveform Classification","M. Alfaro; A. Argüelles; C. Yañez; I. Chairez","Center for Comput. Res. of the IPN, Comput. Res. Lab., Mexico City, Mexico","2012 VI Andean Region International Conference","20130610","2012","","","153","156","Nowadays classification of electroencephalography (EEG) signals have brought new perspectives in the understanding of the brain. Establishing associated characteristics to certain stimulus in EEG is a monumental work due to complexity of the brain responses. For EEG classification several methods have been proposed. Among various statistical methods, Neural Networks (NN) have demonstrated capability in EEG classification using static and recurrent structures. In this paper, we propose a classification method based on Continuous Neural Networks (CNN). Such class of algorithm can handle the raw EEG signal. The method is divided in three stages, first the CNN is trained by using a part of a known database, secondly a parallel structure of the CNN is build with the weights obtained after training, third the parallel structure is tested with the rest of the database that was not used for the training process. All the previously mentioned process is developed by using the raw EEG signals presented on the database and introducing them directly to the CNN without any previously process. The classification algorithm produces a 97% of efficiency.","","Electronic:978-0-7695-4882-1; POD:978-1-4673-4427-2","10.1109/Andescon.2012.43","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6424140","Continuous neural networks;electroencephalography;pattern classification;signal processing","Artificial neural networks;Biological neural networks;Brain modeling;Classification algorithms;Databases;Electroencephalography;Training","electroencephalography;medical signal processing;neural nets;signal classification;statistical analysis;waveform analysis","CNN;EEG classification;associated characteristics;brain responses;classification method;continuous neural networks;electroencephalography signal classification;electroencephalography waveform classification;parallel structure;raw EEG signals;recurrent structure;static structure;statistical methods;training process","","0","","12","","","","7-9 Nov. 2012","","IEEE","IEEE Conference Publications"
"The Seizure Prediction Problem in Epilepsy: Cellular Nonlinear Networks","R. Tetzlaff; V. Senger","Technical University of Dresden, Germany","IEEE Circuits and Systems Magazine","20121129","2012","12","4","8","20","70 million people are affected by epilepsy which is the most common chronic neurological disorder worldwide. About 70% of patients can expect an effective seizure control with medication. The realization of an implantable device capable of detecting impending seizures, warning patients and rendering some kind of treatment would be of great benefit. In this contribution, a brief history of epilepsy and an introduction to terminology and symptoms are given followed by a short summary of current research going on in the field of seizure prediction. Afterwards, an introduction to Cellular Nonlinear Networks (CNN , a paradigm for high speed computation) is given and finally a presentation of 4 different CNN based approaches to epileptic seizure prediction will convey a vision of the methods possibly used one day on an implantable seizure warning device.","1531-636X;1531636X","","10.1109/MCAS.2012.2221519","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6362455","","Circuits and systems;Electroencephalography;Epilepsy;Implantable biomedical devices;Muscles;Neurophysiology;Neurosurgery","biomedical equipment;medical computing;medical control systems;medical disorders;neurophysiology;nomenclature;prosthetics","cellular nonlinear networks;chronic neurological disorder;epilepsy;implantable seizure warning device;seizure control;seizure prediction;seizure prediction problem;symptoms;terminology","","5","","80","","","","Fourthquarter 2012","","IEEE","IEEE Journals & Magazines"
"Analysis of sperm motility with CNN architecture","O. L. Şavkay; M. E. Yalçın","&#x0130;stanbul Technical University, Faculty of Electrical and Electronic Engineering, Electronics and Communication Engineering Department, Maslak, TR-34469, Istanbul, Turkey","2012 13th International Workshop on Cellular Nanoscale Networks and their Applications","20121018","2012","","","1","4","In this paper, we propose a CNN model based spermatozoa motility analysis, which is an important part of complete semen analysis. Sperm motility analysis is a good example of a multiple object tracking and video surveillance problem when viewed from engineering viewpoint. Our proposed system takes the video and images from a CCD camera, applies the front edge preprocessing tasks that uses uses CNN algorithms for spatial enhancement and preparation of image frames, combined with an appropriately designed cost function and a greedy assignment algorithm, that determines the objects-spermatozoa, traces their trajectories and classifies the obtained information for the use of biologists. The system composed of a digital CCD camera connected to the evaluation system. Here we showed the results by a simulation software running under a PC system. For the determination of sperm cells and and tracking the trajectories, we utilized the heuristic rules deduced from the dynamics of spermatozoa and investigation of the video obtained from real samples.","2165-0144;21650144","Electronic:978-1-4673-0289-0; POD:978-1-4673-0287-6","10.1109/CNNA.2012.6331420","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6331420","","Algorithm design and analysis;Cameras;Computer architecture;Noise;Software;Trajectory","CCD image sensors;cellular neural nets;digital simulation;image enhancement;medical image processing;object tracking;video surveillance","CNN architecture;CNN model based spermatozoa motility analysis;PC system;biologists;cost function;digital CCD camera;front edge preprocessing;greedy assignment algorithm;image frames;multiple object tracking;objects-spermatozoa;semen analysis;simulation software;spatial enhancement;video surveillance problem","","4","","10","","","","29-31 Aug. 2012","","IEEE","IEEE Conference Publications"
"CNN cell with memcapacitive synapses and threshold control circuit","J. Flak","VTT Technical Research Centre of Finland, FI-02044 VTT, Espoo, Finland","2012 13th International Workshop on Cellular Nanoscale Networks and their Applications","20121018","2012","","","1","5","This paper presents a concept of a solid-state memcapacitor based on a combination of memristor and capacitor, as well as its applications to cellular nanoscale networks. In addition to ultra-dense memories, memcapacitors can also be used for synaptic connections and threshold control in arrays with capacitively coupled processing units. In principle, the proposed CNN cell structure implements the basic McCulloch-Pitts neuron model. Although the cell relies on the binary programmability scheme with single-bit template coefficients, the proposed memcapacitive synapses allow for asynchronous processing of tasks, for which the traditional cloning templates contain both positive and negative values.","2165-0144;21650144","Electronic:978-1-4673-0289-0; POD:978-1-4673-0287-6","10.1109/CNNA.2012.6331414","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6331414","","Capacitance;Capacitors;Integrated circuit modeling;Memristors;Nanoscale devices;Neurons;Resistance","bioelectric phenomena;biomedical equipment;capacitors;cellular biophysics;medical computing;memristors;neural nets;neurophysiology","CNN cell;CNN cell structure;McCulloch-Pitts neuron model;binary programmability scheme;capacitively coupled processing unit;capacitor;cellular nanoscale network;memcapacitive synapse;memristor;single-bit template coefficient;solid-state memcapacitor;synaptic connection;threshold control circuit;ultra-dense memory","","1","","18","","","","29-31 Aug. 2012","","IEEE","IEEE Conference Publications"
"A Cephalometric educational tool with expert feedback","F. Maiorana; R. Leonardi","Department of Electrical, Electronics and Computer Engineering, University of Catania, Viale Andrea Doria, 6 - 95125, Italy","2012 International Symposium on Information Technologies in Medicine and Education","20120830","2012","1","","16","20","Cephalometric analysis involves the landmarking of several points which must be taken into consideration with great care since an error on only one point can have great impact on linear and angle measurements. For this reason we developed a software tool that allows student to practice in cephalometric landmarking. Their analysis can be saved and modified at a later time by the student or by the instructor. The student can also see the cephalometric analysis performed by the instructor, thus obtaining an immediate feedback that stimulates self-reflection. Finally the tool allows for CNN applications that highlight anatomical regions and landmarks and eases their detection. The tool was used in several situations with and without embossing and with different monitor size. The impact of the tool in the learning process is evaluated by analysis of the software log. Analysis of the application log revealed statistics about the time spent for the identification of each landmark, the improvements in landmarking performance are measured as a decrease in the time needed for the overall analysis or as distance from the gold standard computed as mean expert landmark coordinates. Finally, an analysis of a questionnaire administered to the users reveals an appreciation of the software tool that was considered very engaging.","","Electronic:978-1-4673-2108-2; POD:978-1-4673-2109-9","10.1109/ITiME.2012.6291237","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6291237","Computer-aided learning;Educational assessment;Educational learning tool;cephalometric analysis","Biomedical imaging;Computers;Dentistry;Internet;Software","biomedical education;computer aided instruction;medical computing;software tools;statistical analysis","CNN applications;cephalometric analysis;cephalometric educational tool;cephalometric landmarking;expert feedback;landmarking performance;learning process;mean expert landmark coordinates;software log;software tool;statistics","","1","","26","","","","3-5 Aug. 2012","","IEEE","IEEE Conference Publications"
"Conventional and multi-state cellular neural networks in segmenting breast region from MR images: Performance comparison","G. Ertaş; D. D. Demirgüneş; O. Eroğul","Biomedical Engineering Department, Faculty of Engineering and Architecture, Yeditepe University, Istanbul, Turkey","2012 International Symposium on Innovations in Intelligent Systems and Applications","20120723","2012","","","1","5","Automated evaluation of MR images for breast density assessment or lesion localization requires accurate segmentation of breast region from regions of the body, such as the chest muscle, lungs, heart and ribs. Breast region segmentation is very complicated in the presence of background noise, intensity inhomogeneity and partial volume artifacts on MR images. Cellular neural networks (CNNs) are massively parallel cellular structures with locally interconnected cells and learning abilities and offer efficient ways to perform many complex medical image segmentation tasks. In this study, the performance of two breast region segmentation methods based on conventional CNNs and multi-state CNNs have been compared using non fat-suppressed T2-weighted bilateral axial images selected from 23 healthy women examined using a 3 Tesla MR scanner. The images provide a range of breast fat content representing 48 fatty, 61 fibroglandular or heterogeneously dense and 28 dense breast slices. Statistical analyses show that multi-state based method performs significantly better with high average precision, high true positive volume fraction, and low false positive volume fraction with an overall performance of 99.3±1.8%, 99.5±1.3%, and 0.1±0.2%, respectively.","","Electronic:978-1-4673-1448-0; POD:978-1-4673-1446-6","10.1109/INISTA.2012.6246994","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6246994","MR;breast;cellular neural networks;segmentation","Biomedical imaging;Breast tissue;Cellular neural networks;Image resolution;Image segmentation;Nonhomogeneous media","biomedical MRI;cancer;cellular neural nets;image segmentation;medical image processing;statistical analysis","CNN;MR images;MR scanner;background noise;breast density assessment;breast region segmentation;chest muscle;conventional cellular neural networks;heart;high average precision;high true positive volume fraction;intensity inhomogeneity;learning ability;lesion localization;locally interconnected cells;low false positive volume fraction;lungs;medical image segmentation tasks;multistate based method;multistate cellular neural networks;non fat-suppressed T2-weighted bilateral axial images;parallel cellular structures;partial volume artifacts;ribs;statistical analysis","","0","","13","","","","2-4 July 2012","","IEEE","IEEE Conference Publications"
"Segmentation of breast region from MR images using multi-state cellular neural networks","D. D. Demirgüneş; G. Ertaş; T. Ilica; O. Eroğul; Z. Telatar","G&#x00FC;lhane Military Medical Academy, Biomedical Engineering Center, Ankara, Turkey","2011 7th International Conference on Electrical and Electronics Engineering (ELECO)","20120126","2011","","","II-306","II-310","Computer assisted evaluation of magnetic resonance (MR) images for breast density assessment or lesion localization requires accurate separation of breast tissues from other tissues and regions of the body, such as the chest muscle, lungs, heart and ribs. In this study, we introduce a semi-automated algorithm that segments breast region from non fat-suppressed T2-weighted axial breast MR images. The algorithm employs three specially designed multi-state cellular neural networks (CNNs) connected in cascade. Analysis of 106 high-resolution images from 23 women acquired using a 3T MR scanner shows that the algorithm is exceptionally effective with high precision, high true-positive volume fraction, and low false-positive volume fraction with an overall performance of 99.1±2.0%, 99.4±1.4%, and 0.1±0.2%, respectively. The use of multi-state CNN reduces the false segmentations on the images due to noise, intensity inhomogeneity and partial volume artifacts.","","Electronic:978-6-0501-0090-7; POD:978-1-4673-0160-2","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6140172","","Algorithm design and analysis;Breast;Cellular neural networks;Image segmentation;Magnetic resonance imaging;Muscles;Nonhomogeneous media","biological tissues;biomedical MRI;cellular neural nets;image resolution;image segmentation;medical image processing","Computer assisted evaluation;MRI;breast density assessment;breast region segmentation;breast tissue separation;chest muscle;false-positive volume fraction;heart;intensity inhomogeneity;lesion localization;lungs;magnetic resonance images;multistate cellular neural networks;noise;partial volume artifacts;ribs;semiautomated algorithm;true-positive volume fraction","","1","","20","","","","1-4 Dec. 2011","","IEEE","IEEE Conference Publications"
"Dynamic Analysis of Coupled Binary Stripe CNNs","Q. Zhang; L. Min","Sch. of Autom., Univ. of Sci. & Technol. Beijing, Beijing, China","2011 International Conference on Intelligent Computation and Bio-Medical Instrumentation","20120116","2011","","","236","240","The robust designs for cellular neural network (CNN) templates is one of the important issues for the practical applications of CNNs. This paper establishes 6 theorems for describe the performance of coupled binary stripe (CBS) CNNs. The theorems interpret why the CBS CNNs can generate always striped patterns from any random binary initial patterns. Three examples are presented to illustrate the effectiveness of the methodology.","","Electronic:978-1-4577-1151-0; POD:978-1-4577-1152-7","10.1109/ICBMI.2011.56","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6131780","Cellular neural network;numerical simulation;random binary input;striped pattern output","Arrays;Cellular neural networks;Educational institutions;Image edge detection;Numerical simulation;Passive networks;Robustness","cellular neural nets","cellular neural network templates;coupled binary stripe;random binary initial patterns","","4","","15","","","","14-17 Dec. 2011","","IEEE","IEEE Conference Publications"
"An integrated LOC hydrodynamic focuser with a CNN-based camera system for cell counting application","A. Laki; I. Rattalino; F. Corinto; K. Iván; D. Demarchi; P. Civera","MiNES Laboratory, Department of Electronics, Politecnico di Torino, Italy","2011 IEEE Biomedical Circuits and Systems Conference (BioCAS)","20111219","2011","","","301","304","A microfluidic analyzer system and a cell detection algorithm were developed to analyze biomedical fluids. The obtained microfluidic device is based on the integration of different fluidic systems: the SensoNor glass/silicon/glass multilayer microchip and ThinXXS plastic slide. A hydrodynamic focuser was designed to sort and analyze cells/particles in a 100μm wide channel. The advantages of this Lab-On-a-Chip (LOC) structure are the easy interfaceability with electrodes and optical systems, biocompatibility and ability of optical analysis and morphologic recognition. The proposed CNN-based (Cellular Neural Network) algorithm is real-time and scalable. This constructed microfluidic and optical system is able to analyze and measure any biological liquid, which contain less than 10μm size particles or cells, and count the number of morphologically well-separated different elements in the focused liquid flow using real-time image processing algorithms.","2163-4025;21634025","Electronic:978-1-4577-1470-2; POD:978-1-4577-1469-6","10.1109/BioCAS.2011.6107787","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6107787","","Blood;Cameras;Glass;Hydrodynamics;Image processing;Optical imaging;Optical sensors","bioMEMS;biomedical electrodes;cameras;cellular biophysics;cellular neural nets;hydrodynamics;lab-on-a-chip;medical image processing;microfluidics","CNN-based algorithm;CNN-based camera system;SensoNor glass-silicon-glass multilayer microchip;ThinXXS plastic slide;biocompatibility;biological liquid;biomedical fluid;cell counting application;cell detection algorithm;cellular neural network;electrodes;focused liquid flow;integrated LOC hydrodynamic focuser;lab-on-a-chip structure;microfluidic analyzer system;microfluidic device;morphologic recognition;optical analysis;optical systems;real-time image processing algorithm","","0","","11","","","","10-12 Nov. 2011","","IEEE","IEEE Conference Publications"
"Osteophyte detection for hand osteoarthritis identification in x-ray images using CNNs","S. Banerjee; S. Bhunia; G. Schaefer","Natural Sciences Department, West Bengal University of Technology, Calcutta, India","2011 Annual International Conference of the IEEE Engineering in Medicine and Biology Society","20111201","2011","","","6196","6199","In this paper we describe a class of analog algorithms based on the concept of cellular neural networks (CNNs) for detecting osteoarthritis (OA) from x-ray images. The indicator of OA that we examine is the presence of bony spurs or osteophytes in the vicinity of the weight bearing joints of the fingers. Results on a series of hand x-ray images are shown to be promising.","1094-687X;1094687X","Electronic:978-1-4577-1589-1; POD:978-1-4244-4121-1; USB:978-1-4244-4122-8","10.1109/IEMBS.2011.6091530","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6091530","","Arrays;Bones;Electronics packaging;Joints;Osteoarthritis;Radiography;X-ray imaging","bone;cellular neural nets;diagnostic radiography;diseases;medical image processing;object detection;orthopaedics","CNN;X-ray images;bony spurs;cellular neural networks;hand osteoarthritis identification;osteophyte detection;osteophytes;weight bearing joints","Aged;Algorithms;Bone and Bones;Hand;Humans;Image Processing, Computer-Assisted;Models, Statistical;Neural Networks (Computer);Osteoarthritis;Osteophyte;Reproducibility of Results;Sensitivity and Specificity;X-Rays","2","","14","","","","Aug. 30 2011-Sept. 3 2011","","IEEE","IEEE Conference Publications"
"Classification of multichannel uterine EMG signals by using unsupervised competitive learning","B. Moslem; M. O. Diab; M. Khalil; C. Marque","UMR CNRS 6600, Biom&#x00E9;canique et Bioing&#x00E9;nierie, Universit&#x00E9; of Technologie de Compi&#x00E8;gne, 60205, Compi&#x00E8;gne, France","2011 IEEE Workshop on Signal Processing Systems (SiPS)","20111201","2011","","","267","272","Multichannel analysis is an innovative technique used for the analysis of bioelectrical signals. In this paper, we analyzed uterine Electromyogram (EMG) signals recorded by means of a 4×4 electrode matrix positioned on the woman's abdomen by using a multichannel approach. Relevant features were extracted from each channel and fed to a competitive neural network (CNN). First, we evaluated the classification performance of each channel. Then, we compared these performances to see which channel ranks better than the others. Finally, a decision fusion method based on the weighted sum of the individual decision of each channel was tested. The results showed that data can be grouped into 2 different groups. Furthermore, they showed that the classification performance varies according to the position of the electrode. Therefore, when a decision fusion rule was applied, the network yielded better classification accuracy than any individual channel could provide. These encouraging results prove that multichannel analysis can improve the classification of uterine EMG signals.","2162-3562;21623562","Electronic:978-1-4577-1921-9; POD:978-1-4577-1920-2","10.1109/SiPS.2011.6088987","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6088987","Data fusion;Multichannel analysis;Unsupervised Classification;Uterine Electromyogram (EMG)","Accuracy;Educational institutions;Electrodes;Electromyography;Feature extraction;Neurons;Pregnancy","electromyography;feature extraction;medical signal processing;neural nets;sensor fusion;signal classification;unsupervised learning","bioelectrical signal analysis;channel ranking;competitive neural network;decision fusion rule;electrode matrix;feature extraction;multichannel analysis;multichannel approach;multichannel uterine EMG signal classification;unsupervised competitive learning;uterine electromyogram signal","","1","","29","","","","4-7 Oct. 2011","","IEEE","IEEE Conference Publications"
"On the design of a class of CNN's for ECG classification","I. Vornicu; L. Goras","&#x201C;Gheorghe Asachi&#x201D; Technical University of Iasi, Romania","2011 20th European Conference on Circuit Theory and Design (ECCTD)","20111013","2011","","","150","153","The paper discusses the possibility of using the dynamics of a class of Cellular Neural Networks (CNN's) for electrocardiogram (ECG) signals classification. The main idea is that of segmentation and transformation of the temporal signal into a 1D spatial one which is further processed by means of a bank of linear spatial filters using a parallel architecture of CNN type. A major advantage of the proposed solution is the independence of the filters spatial frequency characteristics on the number of samples of the ECG pattern, which allows dealing very easily with the heart rate variability. The principle of the proposed architecture is briefly discussed and the design of a bank of spatial filters for ECG classification is presented. Transistor level simulation and considerations regarding the architecture reconfiguration are given as well.","","Electronic:978-1-4577-0618-9; POD:978-1-4577-0617-2; USB:978-1-4577-0616-5","10.1109/ECCTD.2011.6043304","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6043304","CNN;ECG signal classification;programmable analog parallel network;spatio-temporal filtering","Computer architecture;Electrocardiography;Filter banks;Low pass filters;Maximum likelihood detection;Nonlinear filters","cellular neural nets;channel bank filters;electrocardiography;medical signal processing;parallel architectures;signal classification;spatial filters","CNN;ECG classification;cellular neural networks;electrocardiogram signals classification;heart rate variability;linear spatial filter bank;parallel architecture;spatial frequency characteristics;temporal signal segmentation;temporal signal transformation;transistor level simulation","","0","","7","","","","29-31 Aug. 2011","","IEEE","IEEE Conference Publications"
"MVN_CNN and UBN_CNN for endocardial edge detection","H. Ketout; J. Gu; G. Horne","Electr. &amp; Comput. Eng., Dalhousie Univ., Halifax, NS, Canada","2011 Seventh International Conference on Natural Computation","20110919","2011","2","","781","785","In this paper, Universal Binary Neurons Cellular Neural Networks (UBN_CNN) endocardial edge detection is proposed. The echocardiographic image is preprocessed to enhance the contrast and smoothness by utilizing Multi Valued Neural Cellular Neural Networks (MVN_CNN) non linear filter. UBN_CNN is applied to the smoothed image to extract the heart boundaries. A non threshold Boolean function with nine variables is utilized to detect the edges corresponding to the upward and downward brightness overleaps. Some experimental results are given for different echocardiographic images. The combination of MVN_CNN and UBN_CNN approach showed better results for extracting the LV endocardial boundaries.","2157-9555;21579555","Electronic:978-1-4244-9953-3; POD:978-1-4244-9950-2","10.1109/ICNC.2011.6022163","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6022163","CNN;Echocardiography;Endocardial;MVN_CNN;UBN_CNN;artifacts;edge detection","Cellular neural networks;Equations;Heart;Image edge detection;Neurons;Nonlinear filters","Boolean functions;biomedical ultrasonics;cellular neural nets;edge detection;feature extraction;image enhancement;medical image processing;nonlinear filters","LV endocardial boundary extraction;MVN_CNN;UBN_CNN;contrast enhancement;echocardiographic image;endocardial edge detection;heart boundary extraction;multivalued neural cellular neural networks;nonlinear filter;nonthreshold Boolean function;smoothness enhancement;universal binary neurons cellular neural networks","","0","","13","","","","26-28 July 2011","","IEEE","IEEE Conference Publications"
"MVN_CNN and FCNN for endocardial edge detection","H. Ketout; J. Gu; G. Horne","Dalhousie University, Electrical and Computer Engineering, 1360 Barrington Street Halifax, Nova Scotia, Canada, B3J 2&#x00D7;4","2011 1st Middle East Conference on Biomedical Engineering","20110419","2011","","","208","212","In this paper, Fuzzy Cellular Neural Networks (FCNN) endocardial edge detection is proposed. The echocardiographic image is preprocessed to enhance the contrast and smoothness by utilizing MVN_CNN filtering. FCNN is applied to the smoothed image to extract the heart boundaries. Fuzzy min and max functions are employed. The comparison was made between Fuzzy, CNN and FCNN edge detectors. The FCNN approach showed better results for extracting the LV endocardial edges. Some experimental results are given for different echocardiographic images.","0018-9294;00189294","Electronic:978-1-4244-7000-6; POD:978-1-4244-6998-7","10.1109/MECBME.2011.5752102","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5752102","CNN;Echocardiography;Endocardial;FCNN;Fuzzy;MVN_CNN;edge detection","Cellular neural networks;Equations;Image edge detection;Mathematical model;Maximum likelihood detection;Nonlinear filters","echocardiography;edge detection;fuzzy neural nets;medical image processing","FCNN filtering;Fuzzy Cellular Neural Network;MVN_CNN filtering;echocardiographic image;endocardial edge detection;heart boundary","","1","","11","","","","21-24 Feb. 2011","","IEEE","IEEE Conference Publications"
"Development of cellular neural network algorithm for detecting lung cancer symptoms","A. A. Abdullah; H. Mohamaddiah","School of Mechatronic Engineering, Universiti Malaysia Perlis (UniMAP), Kampus Ulu Pauh, 02600 Arau, Malaysia","2010 IEEE EMBS Conference on Biomedical Engineering and Sciences (IECBES)","20110405","2010","","","138","143","Lung cancer is the most common of lethal types of cancer. One of the most important and difficult tasks a doctor has to carry out is the detection and diagnosis of cancerous lung nodules from x-ray image's result. Some of these lesions may not be detected because of camouflaged by the underlying anatomical structure, the low-quality of the images or the subjective and variable decision criteria used by doctors. Hence, a detection system using cellular neural network (CNN) is developed in order to help the doctors to recognize the doubtful lung cancer regions in x-ray films. In this study, a CNN algorithm for detecting the boundary and area of lung cancer in x-ray image has been proposed. Computer simulation result shows that our CNN algorithm is verified to detect some key lung cancer symptoms successfully and has been proved by radiologist.","","Electronic:978-1-4244-7600-8; POD:978-1-4244-7599-5","10.1109/IECBES.2010.5742216","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5742216","Lung cancer;cellular neural networks;image processing;x-ray films","Biomedical imaging;Cancer;Computational modeling;Diseases;Educational institutions;Heating;Image edge detection","cancer;diagnostic radiography;image classification;image recognition;lung;medical image processing;neural nets;object detection","CNN;X-ray image;cellular neural network algorithm;detection system;lesions;lung cancer;lung nodules","","2","","8","","","","Nov. 30 2010-Dec. 2 2010","","IEEE","IEEE Conference Publications"
"Convolutional Neural Networks for P300 Detection with Application to Brain-Computer Interfaces","H. Cecotti; A. Graser","University of Bremen, Bremen","IEEE Transactions on Pattern Analysis and Machine Intelligence","20110117","2011","33","3","433","445","A Brain-Computer Interface (BCI) is a specific type of human-computer interface that enables the direct communication between human and computers by analyzing brain measurements. Oddball paradigms are used in BCI to generate event-related potentials (ERPs), like the P300 wave, on targets selected by the user. A P300 speller is based on this principle, where the detection of P300 waves allows the user to write characters. The P300 speller is composed of two classification problems. The first classification is to detect the presence of a P300 in the electroencephalogram (EEG). The second one corresponds to the combination of different P300 responses for determining the right character to spell. A new method for the detection of P300 waves is presented. This model is based on a convolutional neural network (CNN). The topology of the network is adapted to the detection of P300 waves in the time domain. Seven classifiers based on the CNN are proposed: four single classifiers with different features set and three multiclassifiers. These models are tested and compared on the Data set II of the third BCI competition. The best result is obtained with a multiclassifier solution with a recognition rate of 95.5 percent, without channel selection before the classification. The proposed approach provides also a new way for analyzing brain activities due to the receptive field of the CNN models.","0162-8828;01628828","","10.1109/TPAMI.2010.125","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5492691","Neural network;P300.;brain-computer interface (BCI);convolution;electroencephalogram (EEG);gradient-based learning;spatial filters","Application software;Biological neural networks;Brain computer interfaces;Brain modeling;Cellular neural networks;Computer interfaces;Electroencephalography;Enterprise resource planning;Humans;Network topology","brain-computer interfaces;electroencephalography;human computer interaction;medical signal processing;neural nets;signal classification","Data set II;Oddball paradigm;P300 detection;brain computer interface;convolutional neural network;electroencephalogram;event related potential;human computer interface;multiclassifier;pattern classification","Algorithms;Artificial Intelligence;Brain;Electroencephalography;Event-Related Potentials, P300;Evoked Potentials;Humans;Neural Networks (Computer);Pattern Recognition, Automated;Signal Processing, Computer-Assisted;Software;User-Computer Interface","70","","44","","","20100628","March 2011","","IEEE","IEEE Journals & Magazines"
"Implementation of cellular neural networks in image preprocessing for left ventricular filling velocity evaluation","P. S. Molcer; M. Paskaš; V. Delić; B. Reljin","College of Applied Sciences SuboticaTech/Department of Informatics, Subotica, Serbia","IEEE 8th International Symposium on Intelligent Systems and Informatics","20101129","2010","","","569","573","Beside the measurement of flow velocity through mitral valve by pulsed Doppler, and measurement of velocity of myocardium by tissue Doppler imaging, estimation of diastolic function of left ventricle can also be made by measuring velocity of propagation of vortex using color Doppler M-mod imaging. Automated measurement has not become a practice yet because different methods produce different results and there has not been achieved a consensus about method to be applied. The goal of our research is to investigate the possibility of enchancement in automated estimation of propagation of left ventricular filling by implementing cellular neural network (CNN) in image preprocessing phase.","1949-047X;1949047X","Electronic:978-1-4244-7396-0; POD:978-1-4244-7394-6","10.1109/SISY.2010.5647136","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5647136","","Adaptive filters;Blood;Doppler effect;Filling;Filtering algorithms;Image color analysis;Wiener filter","Doppler effect;brain;cellular neural nets;medical image processing;velocity measurement","automated measurement;cellular neural networks;color Doppler M-mod imaging;diastolic function;flow velocity measurement;image preprocessing;left ventricular filling velocity evaluation;myocardium;tissue Doppler imaging;vortex propagation","","0","","10","","","","10-11 Sept. 2010","","IEEE","IEEE Conference Publications"
"Region-based phonocardiogram event segmentation in spectrogram image","A. M. Gavrovska; M. P. Paskaš; D. Dujković; I. S. Reljin","Ministry of Science and Technological Development, Republic of Serbia","10th Symposium on Neural Network Applications in Electrical Engineering","20101129","2010","","","69","72","Assisting physicians in the auscultation of the patients by providing cost effective, automatic and accurate signal processing module for the heart event detection and recognition is of importance. We suggest that the segmentation of time-frequency representation image of one-dimensional phonocardiogram signals (PCGs) could be effective for observing possible abnormal heart events. The fact that frequency bands of cardiac events overlap and that different heart dysfunctions can occur simultaneously make image event segmentation a difficult task. Ambient noise and artifact burden make the segmentation problem even more difficult. A method of “splitting and merging” algorithm involving region-growing based on seeds is presented. We demonstrate that this method contributes to design of patterns required for cardiac event recognition and identification on several examples presented here.","","Electronic:978-1-4244-8820-9; POD:978-1-4244-8821-6","10.1109/NEUREL.2010.5644108","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5644108","CNN;PCG;region-based segmentation;spectrogram","Artificial neural networks;Heart;Image segmentation;Merging;Spectrogram;Time frequency analysis","bioacoustics;cardiology;image representation;image segmentation;medical image processing;pattern recognition","1D phonocardiogram signal;abnormal heart events;ambient noise;artifact;cardiac events;heart dysfunction;heart event detection;heart event recognition;patient auscultation;pattern recognition;region-based phonocardiogram event segmentation;signal processing module;spectrogram image;splitting-and-merging algorithm;time-frequency image representation","","1","","11","","","","23-25 Sept. 2010","","IEEE","IEEE Conference Publications"
"3D Oncological PET volume analysis using CNN and LVQNN","M. S. Sharif; A. Amira; H. Zaidi","School of Engineering and Design Brunei University, West London, United Kingdom","Proceedings of 2010 IEEE International Symposium on Circuits and Systems","20100803","2010","","","1783","1786","The increasing numbers of patient scans and the prevailing application of positron emission tomography (PET) in clinical oncology have led to a need for efficient PET volume handling and the development of new volume analysis approaches to aid clinicians in the diagnosis of disease and planning of treatment. A novel automated system for oncological PET volume segmentation is proposed in this paper. The proposed intelligent system is using competitive neural network (CNN) and learning vector quantisation neural network (LVQNN) for clustering and quantifying phantom and real PET volumes. Bayesian information criterion (BIC) has been used in this system to assess the optimal number of clusters for each PET data set. The experimental study using phantom PET volume was conducted for quantitative evaluation of the performance of the proposed segmentation algorithm. The analysis of the resulting segmentation of clinical oncological PET data seems to confirm that this approach shows promise and can successfully segment patient lesion.","0271-4302;02714302","Electronic:978-1-4244-5309-2; POD:978-1-4244-5308-5","10.1109/ISCAS.2010.5537649","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5537649","Bayesian Information Criterion;Medical Volume Analysis;Positron Emission Tomography;Tumour","Cellular neural networks;Competitive intelligence;Diseases;Imaging phantoms;Intelligent networks;Intelligent systems;Medical treatment;Neural networks;Oncology;Positron emission tomography","Bayes methods;cancer;image segmentation;learning (artificial intelligence);medical image processing;neural nets;positron emission tomography;tumours;vector quantisation","3D oncological PET volume analysis;Bayesian information criterion;CNN;LVQNN;clinical oncology;competitive neural network;learning vector quantisation neural network;oncological PET volume segmentation;positron emission tomography","","0","","19","","","","May 30 2010-June 2 2010","","IEEE","IEEE Conference Publications"
"Brain-Computer Interfacing [In the Spotlight]","R. P. N. Rao; R. Scherer","An associate professor in the Department of Computer Science and Engineering at the University of Washington, Seattle.","IEEE Signal Processing Magazine","20100614","2010","27","4","152","150","Recently, CNN reported on the future of brain-computer interfaces (BCIs). BCIs are devices that process a user's brain signals to allow direct communication and interaction with the environment. BCIs bypass the normal neuromuscular output pathways and rely on digital signal processing and machine learning to translate brain signals to action (Figure 1). Historically, BCIs were developed with biomedical applications in mind, such as restoring communication in completely paralyzed individuals and replacing lost motor function. More recent applications have targeted nondisabled individuals by exploring the use of BCIs as a novel input device for entertainment and gaming. The task of the BCI is to identify and predict behaviorally induced changes or ""cognitive states"" in a user's brain signals. Brain signals are recorded either noninvasively from electrodes placed on the scalp [electroencephalogram (EEG)] or invasively from electrodes placed on the surface of or inside the brain. BCIs based on these recording techniques have allowed healthy and disabled individuals to control a variety of devices. In this article, we will describe different challenges and proposed solutions for noninvasive brain-computer interfacing.","1053-5888;10535888","","10.1109/MSP.2010.936774","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5484181","","Brain computer interfaces;Cellular neural networks;Digital signal processing;Electrodes;Electroencephalography;Machine learning;Neuromuscular;Scalp;Signal processing;Signal restoration","brain-computer interfaces;electroencephalography;medical signal processing","EEG;brain signals;brain-computer interface;digital signal processing;electroencephalogram;machine learning;neuromuscular output pathways","","14","","7","","","","July 2010","","IEEE","IEEE Journals & Magazines"
"Intuitive Fuzzy C-Means Algorithm for MRI Segmentation","D. C. Park","Dept. of Electron. Eng., Myong Ji Univ., Yong In, South Korea","2010 International Conference on Information Science and Applications","20100607","2010","","","1","7","A new model called intuitive fuzzy c-means (IFCM) model is proposed for the segmentation of magnetic resonance image in this paper. Fuzzy c-means (FCM) is one of the most widely used clustering algorithms and assigns memberships to which are inversely related to the relative distance to the point prototypes that are cluster centers in the FCM model. In order to overcome the problem of outliers in data, several models including possibilistic c-means (PCM) and possibilistic-fuzzy c-means (PFCM) models have been proposed. In IFCM, a new measurement called intuition level is introduced so that the intuition level helps to alleviate the effect of noise. Several numerical examples are first used for experiments to compare the clustering performance of IFCM with those of FCM, PCM, and PFCM. A practical magnetic resonance image data set is then used for image segmentation experiment. Results show that IFCM compares favorably to several clustering algorithms including the SOM, FCM, CNN, PCM, and PFCM models. Since IFCM produces cluster prototypes less sensitive to outliers and to the selection of involved parameters than the other algorithms, IFCM is a good candidate for data clustering and image segmentation problems.","2162-9048;21629048","Electronic:978-1-4244-5943-8; POD:978-1-4244-5942-1","10.1109/ICISA.2010.5480541","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5480541","","Cellular neural networks;Clustering algorithms;Image segmentation;Magnetic noise;Magnetic resonance;Magnetic resonance imaging;Noise level;Noise measurement;Phase change materials;Prototypes","fuzzy set theory;image segmentation;magnetic resonance imaging;medical image processing;pattern clustering;possibility theory","MRI segmentation;data clustering;intuitive fuzzy c-means;magnetic resonance image;possibilistic c-means;possibilistic-fuzzy c-means","","3","","23","","","","21-23 April 2010","","IEEE","IEEE Conference Publications"
"Cellular Neural Networks for high energy physics","X. Vilasís-Cardona","LIFAELS, La Salle, Universit&#228;t Ramon Lllull Quatre Camins 2-4, 08022 Barcelona, Spain","2010 12th International Workshop on Cellular Nanoscale Networks and their Applications (CNNA 2010)","20100329","2010","","","1","6","Cellular Neural Networks (CNN) [1] main assets are quoted to be their capacity for parallel hardware implementation and their universality. On top, the possibility to add the information of a local sensor on every cell, provides a unique system for massive parallel signal processing responding in hardware time. Image processing has been, for a long time, the main field where the community has focussed its efforts to prove the excellence of CNNs. And, still, they are not used at large scale for image applications, probably because few cases are so demanding in terms of computation complexity and short response time not to be afforded by a standard sequential CPU","2165-0144;21650144","Electronic:978-1-4244-6680-1; POD:978-1-4244-6679-5","10.1109/CNNA.2010.5430343","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5430343","","Cellular neural networks;Detectors;Hardware;High energy physics instrumentation computing;Image reconstruction;Large Hadron Collider;Particle measurements;Particle tracking;Space technology;Trajectory","Cherenkov counters;biomedical imaging;cellular neural nets;high energy physics instrumentation computing;particle calorimetry","CALICE;ILC;cellular neural networks;cellular paradigms;medical imaging;medipix chips;particle flow algorithm;pixel calorimeters;ring imaging cherenkov detector","","2","","34","","","","3-5 Feb. 2010","","IEEE","IEEE Conference Publications"
"Analysis of biomédical textured images with application of synchronized oscillator-based CNN","M. Strzelecki; J. Lee; S. H. Jeong","Institute of Electronics Technical University of Lodz Lodz, Poland","2010 12th International Workshop on Cellular Nanoscale Networks and their Applications (CNNA 2010)","20100329","2010","","","1","6","This paper is focused on the analysis of biomedical images, including textured ones. A segmentation method, based on network of synchronized oscillators is presented. Oscillator networks can be considered as a special case of the CNN. Its oscillatory dynamics allows encoding the different features of objects forming the visual scene, thus makes these network suitable for medium level image processing, like image segmentation. Oscillator networks can process both two and three dimensional images. The proposed method was tested on several biomedical images acquired with the use of different modalities. Principles of operation of the oscillator networks are described and discussed. Obtained segmentation results for sample 2D and 3D biomedical images are presented and compared to image segmentation based on multilayer perceptron network (MLP).","2165-0144;21650144","Electronic:978-1-4244-6680-1; POD:978-1-4244-6679-5","10.1109/CNNA.2010.5430254","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5430254","biomedical textured images;oscillator network;segmentation","Biomedical imaging;Cellular neural networks;Image analysis;Image coding;Image processing;Image segmentation;Image texture analysis;Layout;Oscillators;Testing","cellular neural nets;image segmentation;medical image processing;multilayer perceptrons;oscillators","biomedical textured images;cellular neural networks;image segmentation;medium level image processing;multilayer perceptron network;oscillator networks;synchronized oscillator-based CNN","","0","","16","","","","3-5 Feb. 2010","","IEEE","IEEE Conference Publications"
"Towards an automated seizure anticipation device based on Cellular Neural Networks (CNN)","G. Geis; F. Gollas; R. Tetzlaff","Institute of Applied Physics, J. W. Goethe University Frankfurt, Frankfurt am Main, Germany","2010 12th International Workshop on Cellular Nanoscale Networks and their Applications (CNNA 2010)","20100329","2010","","","1","6","The epileptic disorder, already mentioned in a Babylonian text dated from the middle of the first millenium BC, nowadays is known to be the most common chronical disorder of the nervous system. Epileptic seizures are phenonema of abnormal synchronization of neural activity with symptoms like convulsions and generally strike without warning. Epileptic drugs, taken in the most important therapy, have the disadvantage of adverse effects and possible habituation. A reliably, automated seizure warning system would not only provide valuable information to the patient, but also enable an efficient, event specific therapy. The problem of detecting a possible pre-seizure state in epilepsy from electroencephalogram (EEG) signals, has been addressed by many authors over the past decades but still remains unsolved. Provided that the transition between interictal state and the ictal event is not an abrupt phenomenon but a gradual change in dynamics [1], [2], precursors could be detected by analyzing brain electrical activity. Several publications report evidence that a preictal state can be detected in focal epilepsy by considering multi-variate measures [3], [4], [5], [6], [7], [8], [9] in particular, although seizures cannot be anticipated with necessary sensitivity and specificity up to now. In this contribution models based on CNN are considered in order to analyze signals from intracranial EEG, taking into account mutual dependencies between signals of neighboring electrodes. Due to their inherently parallel paradigm of computation and their high processing speed under real-time conditions combined with low power consumption, CNN are well suited to a great extent for the processing of multi-dimensional bio-electrical activity and a promising candidate for a future implantable seizure warning and preventing device. In the first proposed algorithm, solutions of Reaction-Diffusion CNN (RD-CNN) models are used in order to approximate short segments of EEG-signals. In a second - lgorithm, the behavior of linear spatio-temporal systems represented by discrete-time CNN (DT-CNN), are used for signal prediction of intracranial EEG. Results for the analysis of long-time recordings gained during presurgical diagnostics in temporal lobe epilepsy are given regardimg both algorithms and their predictive performance with respect to impending epileptic seizures is evaluated statistically. Additionally, the second above mentioned algorithm has been implemented on the Eyes-RIS 1.1 system [10], [11]. First results for the analysis of intracranial long-time recordings carried out on this system are given.","2165-0144;21650144","Electronic:978-1-4244-6680-1; POD:978-1-4244-6679-5","10.1109/CNNA.2010.5430287","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5430287","","Alarm systems;Brain modeling;Cellular neural networks;Drugs;Electroencephalography;Epilepsy;Event detection;Medical treatment;Nervous system;Particle measurements","cellular neural nets;electroencephalography;medical computing;neurophysiology","Eyes-RIS 1.1 system;automated seizure anticipation device;automated seizure warning system;cellular neural networks;discrete-time CNN;electroencephalogram signals;epileptic disorder;epileptic drugs;linear spatio-temporal systems;multidimensional bioelectrical activity;neural activity;presurgical diagnostics;reaction-diffusion CNN models;temporal lobe epilepsy","","0","","37","","","","3-5 Feb. 2010","","IEEE","IEEE Conference Publications"
"A bio-inspired CNN with re-indexing engine for lossless DNA microarray compression and segmentation","S. Battiato; F. Rundo","University of Catania, Dipartimento di Matematica ed Informatica, Italy","2009 16th IEEE International Conference on Image Processing (ICIP)","20100217","2009","","","1737","1740","The DNA microarray images allow to analyze the natural gene expressions. In this paper we propose an advanced method to efficiently address the imaging storage as well as the performance of the algorithm used to retrieve information from DNA images. The cellular neural networks (CNNs) based core is able to provide a method to extract foreground (the DNA gene expression information) from DNA images. It is also proposed an innovative method to compress the DNA image by re-organizing the signal data belonging to the background by making use of a novel way to apply the re-indexing techniques to almost Â¿uncorrelatedÂ¿ signal. Experiments confirm how the proposed method outperform previous solution in almost all cases.","1522-4880;15224880","Electronic:978-1-4244-5654-3; POD:978-1-4244-5653-6","10.1109/ICIP.2009.5413629","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5413629","CNNs;DNA microarray;lossless compression;re-indexing","Cellular neural networks;DNA;Engines;Gene expression;Image analysis;Image coding;Image retrieval;Image segmentation;Image storage;Information retrieval","DNA;cellular neural nets;data compression;image coding;image retrieval;image segmentation;indexing;lab-on-a-chip;medical image processing","bioinspired CNN;cellular neural network;image segmentation;imaging storage;information retrieval;lossless DNA microarray image compression;natural gene expression;reindexing engine;signal data reorganizing;uncorrelated signal","","3","","11","","","","7-10 Nov. 2009","","IEEE","IEEE Conference Publications"
"Online 3-D Reconstruction of the Right Atrium From Echocardiography Data via a Topographic Cellular Contour Extraction Algorithm","D. Hillier; Z. Czeilinger; A. Vobornik; C. Rekeczky","P&#201;ter P&#193;zm&#193;ny Catholic University, Budapest, Hungary","IEEE Transactions on Biomedical Engineering","20100119","2010","57","2","384","396","A computational method providing online, automated 3-D reconstruction of the right atrium of the human heart is presented in this paper. Endocardial boundaries were extracted from transesophageal ultrasound data by a topographic cellular contour extraction (TCCE) algorithm. The TCCE method was implemented on a continuous-time, analog, massively parallel processor, and on a digital serial processor. Processing speeds were 500 or 40 frames per second, depending on the hardware used. Extracted boundary point sets were rendered into a 3-D mesh and the volume of the cavity was quantified. Accuracy of volume quantification was validated on 60 <i>in vitro</i> static phantoms and 12 clinical subjects. For the clinical recordings, reference volumes were estimated from manually delineated endocardial boundaries. The average error of volume quantification by the TCCE method was 8% ¿¿5% (<i>n</i> = 12), the average of the interobserver variability between two independent human experts was 5% ¿¿2% (<i>n</i> = 6). Interactive planning of atrial septal defect closure in pediatric cardiology is presented as an example that demonstrates a potential clinical application of the method.","0018-9294;00189294","","10.1109/TBME.2009.2024315","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5075584","Cellular nonlinear network (CNN);echocardiography;multi-core;online 3-D;parallel;topographic","Cardiology;Data mining;Echocardiography;Hardware;Heart;Humans;Imaging phantoms;In vitro;Three dimensional displays;Ultrasonic imaging","echocardiography;edge detection;feature extraction;image reconstruction;medical image processing;paediatrics;parallel processing;volume measurement","3D mesh;TCCE algorithm;atrial septal defect closure;automated 3D reconstruction;cavity volume quantification;clinical subjects;continuous time analog massively parallel processor;digital serial processor;echocardiography data;endocardial boundary extraction;human heart;in vitro static phantoms;online 3D reconstruction;pediatric cardiology;right atrium;topographic cellular contour extraction algorithm;transesophageal ultrasound data","0","0","","51","","","20090616","Feb. 2010","","IEEE","IEEE Journals & Magazines"
"Implementation of a CNN based object counting algorithm on bi-i cellular vision system","S. Sevgen; F. Karabiber; E. Yucel; S. Arik","Istanbul University, Department of Computer Engineering, Turkey","2009 International Conference on Electrical and Electronics Engineering - ELECO 2009","20091218","2009","","","II-394","II-397","Object counting has been used in many areas such as medical and industrial applications. It is a challenging problem to count the target objects in high speed. It is useful to implement image processing applications using the high capability computational power offered by Cellular Neural Network type analog processor named as ACE16k. In this paper, we implement an efficient object counting algorithm working on ACE16k chip. Our results have proved that the proposed algorithm can count objects on a given image rapidly and accurately.","","POD:978-1-4244-5106-7","10.1109/ELECO.2009.5355280","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5355280","","Application software;Biomedical engineering;Cellular neural networks;Computer vision;Humans;Image processing;Machine vision;Power engineering and energy;Power engineering computing;Signal processing algorithms","cellular neural nets;microprocessor chips;neural chips;object detection","ACE16k analog processor;bi-i cellular vision system;cellular neural network;image processing applications;object counting algorithm","","0","","14","","","","5-8 Nov. 2009","","IEEE","IEEE Conference Publications"
"Associative memories with multi-valued cellular neural networks and their application to disease diagnosis","T. Akiduki; Z. Zhong; T. Imamura; T. Miyake","Department of Production Systems Engineering, Toyohashi University of Technology, Aichi, Japan","2009 IEEE International Conference on Systems, Man and Cybernetics","20091204","2009","","","3824","3829","Cellular neural networks (CNNs) are one type of interconnected neural network and differ from the well-known Hopfield model in that each cell has a piecewise linear output characteristic. In this paper, we present a multi-valued CNN model in which each nonlinear element consists of a multi-valued output function. The function is defined by a linear combination of piecewise linear functions. We conduct computer experiments of auto-associative recall to verify our multi-valued CNN's ability as an associative memory. In addition, we also apply our multivalued CNN to a disease diagnosis problem. The results obtained show that the multi-valued CNN improves classification accuracy by selecting the output level q properly. Moreover, these results also show that the multi-valued associative memory can expand both the flexibility of designing the memory pattern and its applicability.","1062-922X;1062922X","POD:978-1-4244-2793-2","10.1109/ICSMC.2009.5346618","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5346618","Associative memory;Diagnosis of disease;Multi-valued cellular neural networks","Associative memory;Blood;Cellular neural networks;Design methodology;Hopfield neural networks;Inspection;Liver diseases;Neural networks;Piecewise linear techniques;Testing","Hopfield neural nets;cellular neural nets;content-addressable storage;diseases;medical diagnostic computing;pattern classification;piecewise linear techniques","Hopfield model;associative memory;autoassociative recall;computer experiment;disease diagnosis problem;interconnected neural network;multivalued CNN model;multivalued cellular neural network;multivalued piecewise linear function output characteristic;nonlinear element;pattern classification","","1","","10","","","","11-14 Oct. 2009","","IEEE","IEEE Conference Publications"
"Analysis of local activity in reaction-diffusion networks: EEG signals in epilepsy","F. Gollas; R. Tetzlaff","Institute of Applied Physics Johann Wolfgang Goethe-University Frankfurt/Main, Germany","2009 European Conference on Circuit Theory and Design","20091002","2009","","","429","432","In this contribution a new algorithm based on the spatio-temporal dynamics of reaction-diffusion cellular nonlinear networks (RD-CNN) for analyzing brain electrical activity in epilepsy is proposed. RD-CNN are determined in an identification process and then analyzed by means of Chuas Local Activity theory. Clinical manifestations of epileptic seizures are phenomena of abnormal, excessive, or synchronous neuronal activity in the brain. The epileptic disorder is the most common chronic disorder of the central nervous system. Generally seizures appear without sign or warning and the problem of detecting a possible pre-seizure state in epilepsy from electroencephalogram (EEG) time series analysis has already been addressed in many publications. Up to now the identification of an impending epileptic seizure with sufficient specificity and reliability cannot be performed in an automated procedure. An algorithm for a reliable prediction of epileptic seizures would enable the realization of implantable seizure warning devices, which could provide valuable information to the patient and time/event specific drug delivery or direct electric nerve stimulation. CNN are characterized by local couplings of comparatively simple dynamical systems. With this property these networks are well suited to be realized as parallel, analog computing architectures. Recently developed CNN hardware realizations exhibit high parallel computing capacity together with low power consumption. Thus CNN platforms could provide a basis for future implantable seizure warning and preventing devices. In the proposed procedure, RD-CNN are considered for an identification of consecutive segments of intracranial EEG using supervised parameter optimization procedure. These networks are deduced from Reaction-Diffusion Systems, which are applied in different fields of science to describe various complex phenomena like nonlinear wave propagation or pattern formation. Especially, Chua derived the Local Activity - Theory, which provides a quantitative, necessary condition for emergent behavior in RD-CNN. The aim of these first investigations is to apply the Local Activity Theory to the networks obtained in the proposed identification procedure. Results for long time recordings gained during presurgical diagnostics in temporal lobe epilepsy are presented.","","CD-ROM:978-1-4244-3896-9","10.1109/ECCTD.2009.5275013","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5275013","","Algorithm design and analysis;Brain;Cellular networks;Cellular neural networks;Central nervous system;Electroencephalography;Epilepsy;Local activities;Signal analysis;Time series analysis","cellular neural nets;drugs;electroencephalography;feature extraction;medical disorders;medical signal processing;neurophysiology;nonlinear network analysis;reaction-diffusion systems","EEG signals;RD-CNN;brain electrical activity;central nervous system;direct electric nerve stimulation;drug delivery;electroencephalogram;feature extraction;local activity theory;nonlinear wave propagation;reaction-diffusion cellular nonlinear networks;spatio-temporal dynamics;temporal lobe epilepsy;time series analysis","","0","","23","","","","23-27 Aug. 2009","","IEEE","IEEE Conference Publications"
"A digital cellular-based system for retinal vessel-tree extraction","C. D. Resco; A. Nieto; R. R. Osorio; V. M. Brea; D. L. Vilarino","Departament of Electronics and Computer Science University of Santiago de Compostela E-15782 Santiago de Compostela, Spain","2009 European Conference on Circuit Theory and Design","20091002","2009","","","835","838","Nowadays, the advances in the semiconductor industry allow to include a considerable number of fully digital processing elements on a chip. These massively parallel processor arrays are already able to host cellular wave computing algorithms with acceptable time performance. In this paper we approach the implementation of an originally CNN based algorithm for retinal vessel tree extraction on the Ambric's parallel processor array Am2045, provided with 336 32bit processing elements. Results and measured data are included.","","CD-ROM:978-1-4244-3896-9","10.1109/ECCTD.2009.5275113","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5275113","","Computer science;Concurrent computing;Data mining;Electronics industry;Frequency;Hardware;Image processing;Industrial electronics;Microprocessors;Retina","cellular neural nets;lab-on-a-chip;medical image processing;microprocessor chips;parallel processing","Ambrics parallel processor array Am2045;CNN based algorithm;acceptable time performance;digital cellular based system;digital processing chip;host cellular wave computing algorithm;massively parallel processor array;retinal vessel tree extraction;semiconductor industry;storage capacity 32 bit","","0","","14","","","","23-27 Aug. 2009","","IEEE","IEEE Conference Publications"
"A Heuristic Chaotic Neural Network: Candidate Model for Perception","M. Ahmadlou; F. Mamashli; M. R. H. Golpayegani","Dept. of Biomed. Eng., Amirkabir Univ. of Technol., Tehran, Iran","2008 First International Conference on Complexity and Intelligence of the Artificial and Natural Complex Systems. Medical Applications of the Complex Systems. Biomedical Computing","20090904","2008","","","85","93","In this paper a new Chaotic Neural Network (CNN) have been made. This network contains desired number of interacting units and each one has its own chaotic dynamic and strange attractor caused by creating convex hull among output units. Having a special interaction characteristic, the model is able to create enormous different chaotic behaviors. Lyapunov Exponent and phase space plane criteria have been used for demonstrating discrimination between behaviors. Making use of convex hull for trapping generated outputs of each unit in subsequent iteration, its folding characteristic and stretching property of logistic function, emerging of arbitrary number of various strange attractors have been accomplished. Therefore, based on desired criterion, this network is able to assign each strange attractor to each sensory input. In other words the network has the ability of being a candidate for modeling perception.","","POD:978-0-7695-3621-7","10.1109/CANS.2008.18","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5231508","Logistic function;chaotic dynamic;convexity;perception;strange attractor","Artificial intelligence;Artificial neural networks;Biological neural networks;Biological system modeling;Cellular neural networks;Chaos;Delay;Logistics;Neural networks;Neurons","Lyapunov methods;chaos;logistics;neural nets;phase space methods","Lyapunov exponent;candidate model;chaotic behavior;chaotic dynamic attractor;convex hull;folding characteristics;heuristic chaotic neural network;interaction characteristics;logistic function;phase space plane criteria;stretching property","","0","","10","","","","8-10 Nov. 2008","","IEEE","IEEE Conference Publications"
"Edge Detection and Image Segmentation Based on Cellular Neural Network","M. Tang","Coll. of Electr. Eng., Nantong Univ., Nantong, China","2009 3rd International Conference on Bioinformatics and Biomedical Engineering","20090714","2009","","","1","4","On the basis of brief description of cellular neural network, the process of edge detection based on CNN is introduced with the flow chart of whole algorithm designed, and several kernel techniques are explained respectively in details. As far as binary and gray images, the two simulation models for image edge detection based on CNN and traditional arithmetic operators (prewitt, sobel, canny) respectively are designed and compared their performance. Experimental results demonstrate that the CNN algorithm has several advantages, such as high speed parallel calculation on hardware, calculation speed independent of image size, real-time performance and so on. Therefore, CNN is an effective method for edge detection and image segmentation.","2151-7614;21517614","POD:978-1-4244-2901-1","10.1109/ICBBE.2009.5162679","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5162679","","Algorithm design and analysis;Biomedical signal processing;Cellular neural networks;Flowcharts;Hardware;Image edge detection;Image processing;Image segmentation;Kernel;Signal processing algorithms","cellular biophysics;edge detection;image segmentation;medical image processing;neural nets","arithmetic operators;binary image;canny operator;cellular neural network;edge detection;flow chart;gray image;hardware;high-speed parallel calculation;image edge detection;image segmentation;image size calculation;kernel techniques;prewitt operator;real-time performance;simulation models;sobel operator","","3","","10","","","","11-13 June 2009","","IEEE","IEEE Conference Publications"
"Eigenvector Methods for Automated Detection of Electrocardiographic Changes in Partial Epileptic Patients","E. D. Übeyli","Dept. of Electr. & Electron. Eng., TOBB Ekonomi ve Teknoloji Univ., Ankara, Turkey","IEEE Transactions on Information Technology in Biomedicine","20090706","2009","13","4","478","485","In this paper, the automated diagnostic systems trained on diverse and composite features were presented for detection of electrocardiographic changes in partial epileptic patients. In practical applications of pattern recognition, there are often diverse features extracted from raw data that require recognizing. Methods of combining multiple classifiers with diverse features are viewed as a general problem in various application areas of pattern recognition. Two types (normal and partial epilepsy) of ECG beats (180 records from each class) were obtained from the Physiobank database. The multilayer perceptron neural network (MLPNN), combined neural network (CNN), mixture of experts (ME), and modified mixture of experts (MME) were tested and benchmarked for their performance on the classification of the studied ECG signals, which were trained on diverse or composite features. Decision making was performed in two stages: feature extraction by eigenvector methods and classification using the classifiers trained on the extracted features. The present research demonstrated that the MME trained on the diverse features achieved accuracy rates (total classification accuracy is 99.44%) that were higher than that of the other automated diagnostic systems.","1089-7771;10897771","","10.1109/TITB.2008.920614","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4472853","Combined neural network (CNN);electrocardiographic changes;mixture of experts (ME);modified mixture of experts (MME);multilayer perceptron neural network (MLPNN);partial epilepsy","","decision making;eigenvalues and eigenfunctions;electrocardiography;feature extraction;learning (artificial intelligence);medical disorders;medical expert systems;medical signal detection;multilayer perceptrons;neurophysiology;signal classification","Eigenvector method;automated detection;combined neural network;decision making;electrocardiographic change;features extraction;multilayer perceptron neural network;multiple classifier;partial epileptic patient;pattern recognition","Algorithms;Electrocardiography;Epilepsies, Partial;Humans;Neural Networks (Computer);Pattern Recognition, Automated;ROC Curve;Sensitivity and Specificity","4","","26","","","20080321","July 2009","","IEEE","IEEE Journals & Magazines"
"Multi-category human motion recognition based on MEMS inertial sensing data","Guangyi Shi; Yuexian Zoui; Yufeng Jin; Yali Zheng; W. J. Li","The Key Laboratory of Integrated Microsystems, Shenzhen Graduate School of Peking University, China","2009 4th IEEE International Conference on Nano/Micro Engineered and Molecular Systems","20090605","2009","","","489","493","This paper presents multi-category human motion recognition methods based on MEMS inertial sensing data. A micro inertial measurement unit (muIMU) that is 56 mm*23 mm*15 mm in size was built. This unit consists of three dimensional MEMS accelerometers, gyroscopes, a Bluetooth module and a MCU (Micro Controller Unit), which can record and transfer inertial data to a computer through serial port wirelessly. Five categories of human motion were recorded including walking, running, going upstairs, fall and standing. Fourier transform was used to extract the feature from the human motion data. The concentrated information was finally used to categorize the human motions through CNN (cascade neural network) SVM (support vector machine) and HMM (hidden Markov model) respectively. Experimental results showed that for the given 5 human motions, HMM have the best classification result with correct recognition rate range from 90%-100%.","","POD:978-1-4244-4629-2","10.1109/NEMS.2009.5068625","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5068625","µIMU;CNN;HMM;Human Motion;MEMS;SVM","Accelerometers;Bluetooth;Gyroscopes;Hidden Markov models;Humans;Legged locomotion;Measurement units;Micromechanical devices;Support vector machine classification;Support vector machines","Bluetooth;Fourier transforms;accelerometers;bioMEMS;biomedical measurement;feature extraction;gait analysis;gyroscopes;hidden Markov models;image recognition;medical image processing;support vector machines","Bluetooth module;Fourier transform;MEMS;accelerometers;cascade neural network;feature extraction;gyroscopes;hidden Markov model;human motion recognition;inertial sensing;size 15 mm;size 23 mm;size 56 mm;support vector machine","","0","","14","","","","5-8 Jan. 2009","","IEEE","IEEE Conference Publications"
"Colon segmentation and the detection of colonic polyp with template matching in CT images","N. Kilic; O. Osman; O. N. Ucan","Elektrik ve Elektronik M&#252;hendisli&#191;i B&#246;l&#252;m&#252;, &#191;stanbul &#220;niversitesi, Turkey","2008 IEEE 16th Signal Processing, Communication and Applications Conference","20080926","2008","","","1","4","In this paper, we introduced a novel Computer Aided Detection (CAD) system for colonic polyp detection in CT data. The CAD system extracts colon region from CT images using cellular neural network (CNN) which its parameters of A,B and I templates are optimized by genetic algorithm in order to improve segmentation performance. Region of interest (ROI) of all slices were combined together to acquire a 3D ROI image and then we generate a 3D ROI image 3D segmented colon. Then the system performs 3D template matching with four layers of 12times12 cells to detect polyps. The CAD system was evaluated with 1148 CT images from 11 patients containing 15 marked polyps. The overall sensitivity of our CAD system is, 100% with the level of 10 FPs per case.","2165-0608;21650608","CD-ROM:978-1-4244-1999-9; POD:978-1-4244-1998-2","10.1109/SIU.2008.4632731","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4632731","","Circuit faults;Colon;Computed tomography;Current transformers;Design automation;Fault currents;Three dimensional displays","cellular neural nets;computerised tomography;genetic algorithms;image matching;image segmentation;medical image processing","CT images;cellular neural network;colon segmentation;colonic polyp detection;computer aided detection system;genetic algorithm;image segmentation;region of interest;segmentation performance;template matching","","0","","9","","","","20-22 April 2008","","IEEE","IEEE Conference Publications"
"Bio-Microfluidics Real-Time Monitoring Using CNN Technology","F. Sapuppo; M. Intaglietta; M. Bucolo","Dept. of Electr., Electron. & Syst. Eng., Univ. di Catania, Catania","IEEE Transactions on Biomedical Circuits and Systems","20080909","2008","2","2","78","87","A new non-invasive real-time system for the monitoring and control of microfluidodynamic phenomena involving transport of particles and two phase fluids is proposed. The general purpose design of such system is suitable for in vitro and in vivo experimental setup and, therefore, for microfluidic applications in the biomedical field, such as lab-on-chip and for research studies in the field of microcirculation. The system consists of an ad hoc optical setup for image magnification providing images suitable for acquisition and processing. The main feature of the optical system is the accessibility of the information at any point of the optical path. It was designed and developed using discrete opto-mechanic components mounted on a breadboard. The optical sensing, acquisition, and processing were all performed using an integrated vision system based on cellular nonlinear networks (CNNs) analogic (analog plus logic) technology called focal plane processor (FPP, Eye-RIS, Anafocus) that was inserted in the optical path. Ad hoc algorithms were implemented for the real-time analysis and extraction of fluidodynamic parameters in micro-channels. They were firstly tested on sequences of images recorded during in vivo microcirculation experiments on hamsters and then applied on images acquired and processed in real-time during in vitro experiments on two-phase fluid flow in a continuous microfluidic device (serpentine mixer, ThinXXS).","1932-4545;19324545","","10.1109/TBCAS.2008.925642","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4579126","Microcirculation;morphology;parallel image processing;particle transport;two-phase flow","Biomedical optical imaging;Cellular neural networks;In vitro;In vivo;Microfluidics;Monitoring;Nonlinear optical devices;Nonlinear optics;Optical sensors;Real time systems","analogue circuits;bioMEMS;biomedical electronics;biomedical equipment;biomedical optical imaging;biorheology;biotransport;image sequences;lab-on-a-chip;logic circuits;medical image processing;microchannel flow","CNN technology;ad hoc algorithms;ad hoc optical setup;analogic technology;bio-microfluidics real-time monitoring;biomedical field;cellular nonlinear networks;continuous microfluidic device;discrete opto-mechanic components;fluidodynamic parameters extraction;focal plane processor;image acquisition;image magnification;image processing;image sequence recording;in vitro experimental setup;in vivo experimental setup;in vivo microcirculation experiments;integrated vision system;lab-on-chip;microchannels;microfluidodynamic phenomena;optical sensing;particles transport;two phase fluids","","8","","29","","","20080725","June 2008","","IEEE","IEEE Journals & Magazines"
"Contrast co-occurrence and polyfit for analysis B-Scan image","Guodong Li; Degang Chen; Honglan Zhang","School of Mathematics and Physics, North China Electric Power University Beijing 102206, China","2008 International Conference on Machine Learning and Cybernetics","20080905","2008","5","","2820","2824","In this paper, we contrast two way for processed ultrasound. One is B-scan images of chronic hepatitis B (CHB) patientspsila livers analysis by polyfit with CNN. The other is analyzed by co-occurrence with CNN to process fat livers. We find those are useful way for patient diagnose.","2160-133X;2160133X","POD:978-1-4244-2095-7","10.1109/ICMLC.2008.4620888","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4620888","B-Scan image;edge detection;liver damges 10-degree polynomials fitting","Cybernetics;Image analysis;Machine learning","biomedical ultrasonics;cellular neural nets;liver;medical image processing;ultrasonic imaging","B-scan image analysis;cellular neural nets;chronic hepatitis B;contrast cooccurrence;patient diagnosis;patient livers analysis;ultrasound processing","","0","","6","","","","12-15 July 2008","","IEEE","IEEE Conference Publications"
"EEG analysis by multi layer Cellular Nonlinear Networks (CNN)","C. Niederhoefer; F. Gollas; R. Tetzlaff","Institute of Applied Physics, J. W. Goethe-University, Frankfurt, Germany","2006 IEEE Biomedical Circuits and Systems Conference","20080815","2006","","","25","28","The analyses of EEG-signals of patients suffering from epilepsy have been performed by many authors during the last years. The main goal of these analyses is to enable a detection of seizure precursors. Several methods based on CNN - e.g. the approximation of the correlation dimension, the prediction of EEG-signals, the pattern detection algorithm - have been proposed and studied in detail. Yielding interesting results, the signal prediction algorithm has been analyzed in more detail in order to optimize the obtained results of the predictor system, both for quality and computational complexity. Applying a CNN predictor to recordings of multi EEG electrodes results in a so called prediction error profile. Electrodes which show the most significant changes before epileptic seizures could be identified by using these profiles.","2163-4025;21634025","CD-ROM:978-1-4244-0437-7; POD:978-1-4244-0436-0","10.1109/BIOCAS.2006.4600299","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4600299","","Algorithm design and analysis;Cellular networks;Cellular neural networks;Detection algorithms;Electrodes;Electroencephalography;Epilepsy;Performance analysis;Prediction algorithms;Signal analysis","cellular neural nets;electroencephalography;medical signal processing","EEG analysis;cellular nonlinear networks;electrodes;epilepsy;prediction error profile;seizure precursors","","3","","22","","","","Nov. 29 2006-Dec. 1 2006","","IEEE","IEEE Conference Publications"
"Diabetic damage detection in retinal images via a cellular neurofuzzy network","L. Carnimeo; A. Giaquinto","Dipartimento di Elettrotecnica ed Elettronica, Politecnico di Bari, Italy","2006 IEEE Biomedical Circuits and Systems Conference","20080815","2006","","","138","141","In this paper a contribution to diabetic damage detection in retinal images via a cellular neurofuzzy network is proposed. Fundus symptomatic pale regions are firstly highlighted by enhancing image contrast with a neurofuzzy subnet, which is synthesized using a Cellular Neural Network (CNN). After an optimal thresholding performed by a neural subsystem, obtained contrast-enhanced images with bimodal histograms are globally segmented. In output binary images, suspect diabetic areas are then isolated by a CNN-based subnet. Performances are evaluated by percentage measures of exactness in the detection of suspect damaged areas via a comparison with gold standard images provided by clinicians. Results are discussed and compared with other researcherspsila ones.","2163-4025;21634025","CD-ROM:978-1-4244-0437-7; POD:978-1-4244-0436-0","10.1109/BIOCAS.2006.4600327","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4600327","","Area measurement;Cellular networks;Cellular neural networks;Diabetes;Gold;Histograms;Image segmentation;Network synthesis;Performance evaluation;Retina","diseases;eye;fuzzy neural nets;image enhancement;image segmentation;medical image processing","bimodal histograms;cellular neural network;cellular neurofuzzy network;diabetic damage detection;fundus symptomatic pale regions;image contrast enhancement;image segmentation;retinal images","","0","","14","","","","Nov. 29 2006-Dec. 1 2006","","IEEE","IEEE Conference Publications"
"A CNN-based synchronization analysis for epileptic seizure prediction: Inter- and intraindividual generalization properties","D. Krug; C. E. Elger; K. Lehnertz","Department of Epileptology, University of Bonn, Sigmund-Freud Str. 25, 53105, Germany","2008 11th International Workshop on Cellular Neural Networks and Their Applications","20080805","2008","","","92","95","We investigate the generalization capability of our proposed CNN-based approach to measure the strength of generalized synchronization in EEG recordings from epilepsy patients. With an in-sample optimization on short-lasting EEG data taken from two recording sites of a single patient we obtain a CNN with polynomial-type templates that allows us to approximate the strength of generalized synchronization in continuous long-lasting multichannel EEG recordings from this patient at a high accuracy. In an out-of-sample study we use the same CNN to analyze days of multichannel EEG data from other patients and observe that the strength of generalized synchronization between different brain regions in different patients can be approximated with a sufficient accuracy. These inter- and intraindividual generalization properties render CNN highly attractive for the development of miniaturized seizure prediction devices.","2165-0144;21650144","CD-ROM:978-1-4244-2090-2; POD:978-1-4244-2089-6","10.1109/CNNA.2008.4588656","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4588656","","Cellular neural networks;Delay effects;Electrodes;Electroencephalography;Epilepsy;Frequency synchronization;Humans;Polynomials;State-space methods;Time measurement","cellular neural nets;electroencephalography;medical computing;polynomial approximation;prediction theory;synchronisation","EEG recordings;cellular neural network-based synchronization analysis;epilepsy patients;epileptic seizure prediction;in-sample optimization;inter-individual generalization properties;intraindividual generalization properties;miniaturized seizure prediction devices;polynomial-type templates;strength approximation;strength measurement","","3","","27","","","","14-16 July 2008","","IEEE","IEEE Conference Publications"
"Analysis of EEG-signals in epilepsy: Spatio-temporal models","F. Gollas; R. Tetzlaff","Institute of Applied Physics, Johann Wolfgang Goethe University, Frankfurt, Germany","2008 11th International Workshop on Cellular Neural Networks and Their Applications","20080805","2008","","","96","101","The problem of detecting a possible pre-seizure state in epilepsy from EEG signals, has been addressed by many authors over the past decades but still remains unsolved up to now. Different approaches of time series analysis of brain electrical activity are already providing valuable insights into the complex dynamics of the brain and may lead to the extraction of signal features that are able to identify an impending epileptic seizure with sufficient specificity and reliability. In this contribution models based on Cellular Nonlinear Networks (CNN) are considered to analyze intracranial EEG, taking into account mutual dependencies between neighboring electrodes. Solutions of Reaction-Diffusion CNN (RD-CNN) models are used in order to approximate short segments of EEG-signals. In comparison the behaviour of linear spatio-temporal systems is evaluated.","2165-0144;21650144","CD-ROM:978-1-4244-2090-2; POD:978-1-4244-2089-6","10.1109/CNNA.2008.4588657","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4588657","","Brain modeling;Cellular networks;Cellular neural networks;Electrodes;Electroencephalography;Epilepsy;Feature extraction;Signal analysis;Signal processing;Time series analysis","cellular neural nets;electroencephalography;medical signal detection;time series","EEG-signals;Reaction-Diffusion CNN models;brain electrical activity;cellular nonlinear networks;epilepsy;epileptic seizure;neighboring electrodes;preseizure state;spatio-temporal models;time series analysis","","0","","29","","","","14-16 July 2008","","IEEE","IEEE Conference Publications"
"Postural kyphosis detection using intelligent shoes","M. Chen; B. Huang; Y. Xu","Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong, Shatin N.T., Hong Kong","2008 IEEE International Conference on Robotics and Automation","20080613","2008","","","2954","2958","Postural kyphosis as one of the most common kinds of kyphosis is usually diagnosed in adolescents and young adults. Long-term kyphosis will not only affect the persons' appearance, but also result in thoracic deformity accompanied by pain. In this paper, we introduce a cost-effective shoe-integrated system which mainly consists of 8 force sensing resistors (FSRs) for gathering the pressure information under the 8 bony prominences. Based on the gathered plantar pressure information, the methodology of cascade neural networks with node-decoupled extended Kalman filtering (CNN-NDEKF) is applied for training the model of detecting the gait pattern associated with postural kyphosis. Experimental results demonstrate that the proposed approach is efficient. This device is of particular significance to provide feedback in the application of postural kyphosis rectification.","1050-4729;10504729","POD:978-1-4244-1646-2","10.1109/ROBOT.2008.4543658","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4543658","","Capacitance;Clothing;Footwear;Intelligent systems;Legged locomotion;Pain;Pressure measurement;Resistors;Spine;Transducers","Kalman filters;biomechanics;force sensors;medical diagnostic computing;neural nets;orthopaedics","cascade neural networks;cost-effective shoe-integrated system;force sensing resistors;intelligent shoes;node-decoupled extended Kalman filtering;postural kyphosis;postural kyphosis detection","","2","","12","","","","19-23 May 2008","","IEEE","IEEE Conference Publications"
"B-Scan Images Analyzed By CNN and Co-Occerrence Matrix","G. Li; H. Song; W. Wang; J. Wang; H. Hong; Y. Liu","Sch. of Math. & Phys., North China Electr. Power Univ., Beijing","2008 2nd International Conference on Bioinformatics and Biomedical Engineering","20080603","2008","","","2434","2437","In this paper, we combine cellular neural network (CNN) and gray step co-occurrence matrix to process B-scan images of fatty patients' livers. We deal with the B-scan images of fatty patients' livers by the edge detection cellular neural network, and then analyze the B-scan image features, including the co-occurrence matrix's contrast (Contrast), correlation (Correlation), energy (Energy) and homogeneity (Homogeneity). The value of Contrast on 0deg direction seems to correlate to the degree of the damage of patients' livers. It is expected that the method provided in this paper will be helpful to the diagnosis of biomedical images.","2151-7614;21517614","CD-ROM:978-1-4244-1748-3; POD:978-1-4244-1747-6","10.1109/ICBBE.2008.941","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4535821","","Biomedical image processing;Biomedical imaging;Cellular neural networks;Image analysis;Image edge detection;Laplace equations;Liver;Medical diagnostic imaging;Object detection;Robustness","biomedical ultrasonics;cellular neural nets;edge detection;feature extraction;image texture;liver;matrix algebra;medical image processing","B-scan image analysis;CNN;biomedical image diagnosis;cellular neural network;edge detection;fatty patient liver;gray step co-occurrence matrix;image feature;texture analysis","","1","","11","","","","16-18 May 2008","","IEEE","IEEE Conference Publications"
"Cellular Neural Network Based Urinary Image Segmentation","Z. Zhang; S. Xia; H. Duan","Zhejiang University, China","Third International Conference on Natural Computation (ICNC 2007)","20071105","2007","2","","285","289","A novel approach for urinary image segmentation based on cellular neural network (CNN) was presented in this paper. Before the image segmentation, a preprocessing by stretching the difference between every pixel and the local gray mean value for eliminating the disequilibrium of illumination and enhancing the edges of objects is considered here. The experiment results with more than 100 clinical urinary images show that this approach provides more accurate objects detection compared with conventional threshold based ones.","2157-9555;21579555","POD:0-7695-2875-9","10.1109/ICNC.2007.294","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4344361","Urinary microscopic image;cellular neural network (CNN);distance transform;grayaverage-;object enhancement;segmentation","Cellular neural networks;Diseases;Histograms;Image edge detection;Image segmentation;Lighting;Microscopy;Morphology;Pixel;Sediments","cellular neural nets;image segmentation;medical image processing;object detection","cellular neural network;illumination disequilibrium;local gray mean value;objects detection;urinary image segmentation","","3","","14","","","","24-27 Aug. 2007","","IEEE","IEEE Conference Publications"
"B-Scan Image That Processed by CNN and Wavelets","G. D. Li; L. Q. Min; H. Y. Zang; J. H. Wang; H. W. Hong; Y. L. Liu","School of Mathematics and Physics, North China Electric Power University Beijing 102206, PR China; School of Applied Science University of Science and Technology Beijing Beijing 100083, PR China. E-MAIL: lgdzhy@ncepu.edu.cn","2007 International Conference on Machine Learning and Cybernetics","20071029","2007","3","","1521","1525","In this paper, the edge detection cellular neural network (CNN) has been applied to preprocess ultrasound B-Scan images of Chronic Hepatitis B(CHB) patients' livers. The preprocessed images are further converted via the wavelet transform. The ratio of the standard deviation of the coefficients of diagonal detail to the standard deviation of the preprocessed image seems to correlate with the degrees of the damage of patient's livers. It is expected that the method provided in this paper will be helpful for the diagnosis of biomedical images.","2160-133X;2160133X","CD-ROM:978-1-4244-0973-0; POD:978-1-4244-0972-3","10.1109/ICMLC.2007.4370386","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4370386","B-Scan image;CNN;Wavelet transform","Biomedical imaging;Cellular neural networks;Cybernetics;Image edge detection;Liver diseases;Machine learning;Object detection;Signal resolution;Ultrasonic imaging;Wavelet transforms","biomedical ultrasonics;cellular neural nets;diseases;edge detection;liver;medical image processing;wavelet transforms","B-scan image;CNN;biomedical images;cellular neural network;chronic hepatitis;edge detection;image processing;livers;ultrasound B-Scan images;wavelet transform","","0","","9","","","","19-22 Aug. 2007","","IEEE","IEEE Conference Publications"
"A Cellular Neurofuzzy Network for Supporting Detection of Diabetic Symptoms in Retinal Images","L. Carnimeo; A. Giaquinto","Dipartimento di Elettrotecnica ed Elettronica, Politecnico di Bari, Bari, Italy, e-mail: carnimeo@deemail.poliba.it","2007 International Symposium on Signals, Circuits and Systems","20070820","2007","1","","1","4","In this paper a contribution for supporting diabetic symptoms detection in retinal images is proposed by synthesizing a cellular neurofuzzy network able to provide informations on vague pale regions of fundus images with suspect diabetic damages. After highlighting pale regions in input images by an intensity difference map evaluation, their contrast is enhanced by means of a CNN-based fuzzy subnet. After an adaptive thresholding evaluation, contrast-enhanced images with bimodal histograms are globally segmented by a CNN-based subsystem, providing binary output images, in which suspect diabetic areas are easily isolated. Performances are evaluated by means of the correct recognition rate, which provides percentage measures of exactness in the detection of suspect damaged areas. Results are discussed and compared with other researchers' ones.","","CD-ROM:1-4244-0969-1; POD:1-4244-0968-3","10.1109/ISSCS.2007.4292700","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4292700","","Area measurement;Brightness;Cellular networks;Cellular neural networks;Diabetes;Image processing;Image segmentation;Network synthesis;Performance evaluation;Retina","cellular neural nets;diseases;eye;fuzzy neural nets;image segmentation;medical image processing;statistical analysis","adaptive thresholding evaluation;cellular neurofuzzy network;diabetic symptom;histogram analysis;image segmentation;retinal image","","0","","11","","","","13-14 July 2007","","IEEE","IEEE Conference Publications"
"Segmentation of Ovarian Ultrasound Images Using Single Template Cellular Neural Networks Trained with Support Vector Machines","M. Lenic; D. Zazula; B. Cigale","University of Maribor, Slovenia","Twentieth IEEE International Symposium on Computer-Based Medical Systems (CBMS'07)","20070625","2007","","","205","212","Various applications of cellular neural networks (CNNs) on complex image processing tasks raise questions about an appropriate selection of template elements that determine the CNN's behavior. In previous research we utilized multiple time variant template elements cellular neural networks for segmentation, which has many advantages compared to conventional search space approaches. In this paper a novel approach which utilizes the formalism of support vector machines (SVMs) that utilizes only single time invariant set of CNN template elements, is introduced. The main advantage of this approach is reduction of the number of CNNs templates and confirms to the conventional applications of CNN.","1063-7125;10637125","POD:0-7695-2905-4","10.1109/CBMS.2007.97","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4262651","","Application software;Biomedical imaging;Cellular neural networks;Computer applications;Computer performance;Costs;Image processing;Image segmentation;Support vector machines;Ultrasonic imaging","biomedical ultrasonics;cellular neural nets;image segmentation;medical computing;medical image processing;support vector machines","cellular neural networks;image segmentation;ovarian ultrasound images;support vector machines","","0","","8","","","","20-22 June 2007","","IEEE","IEEE Conference Publications"
"Concordance Analysis of DEXA Data","R. R. Hashemi; A. A. Tyler; C. Childers; A. Chausmer","Armstrong Atlantic State University","Information Technology, 2007. ITNG '07. Fourth International Conference on","20070416","2007","","","414","419","The bone density measurements done by DEXA scanning approach are used in diagnosis of osteoporosis. There are six major sites used for DEXA scanning of each hip (three sites on the left and three sites on the right) including: the femoral neck, the trochanteric site, and Ward's Triangle with or without corresponding total hip measurements. In the past, two separate researches conducted by the authors to determine whether all six measurements are needed for diagnosis of osteoporosis. The results revealed that none of the six measurements are redundant. The null hypothesis that we investigate in this paper is that having non-redundant sites means the measurements of bone density for these sites are in concordance. The concordance analysis is implemented using a new neural network (CNN). The results reveal that the null hypothesis is true","","POD:0-7695-2776-0","10.1109/ITNG.2007.58","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4151719","Concordance Neural Network.;Concordance analysis;DEXA scanning;Osteoporosis","Cellular neural networks;Computer science;Data analysis;Density measurement;Hip;Humans;Informatics;Neck;Neural networks;Osteoporosis","X-ray absorption;bone;diseases;medical computing;neural nets;patient diagnosis","DEXA scanning;Ward Triangle;bone density measurements;concordance analysis;dual energy X-ray absorptiometry;femoral neck;neural network;osteoporosis diagnosis;trochanteric site","","0","","9","","","","2-4 April 2007","","IEEE","IEEE Conference Publications"
"CNNUM-Based Methods Using Deformable Contours on Smooth Boundaries","T. Szabo; P. Szolgay","Department of Image Processing and Neurocomputing, Faculty of Information Technology, University of Pannonia, Veszpr&#233;m, Hungary. e-mail: tszabo@almos.vein.hu","2006 10th International Workshop on Cellular Neural Networks and Their Applications","20070410","2006","","","1","5","In this paper two methods are presented. A CNNUM-based method is shown to quantify the displacement of the normal interhemisperic bilateral symmetry line. The method uses a deformable open contouring technique. Another method has been developed to detect bilateral asymmetries. These methods are implemented on the CNN-UM","2165-0144;21650144","CD-ROM:1-4244-0640-4; POD:1-4244-0639-0","10.1109/CNNA.2006.341651","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4145891","contour;deformable;segmentation;snake","Active contours;Anatomical structure;Biomedical imaging;Computed tomography;Computer networks;Electronic mail;Image resolution;Image segmentation;Magnetic resonance;Pixel","brain;cellular neural nets;edge detection;image segmentation;medical image processing","cellular neural network;deformable open contouring technique;interhemisperic bilateral symmetry line;universal machine","","0","","26","","","","28-30 Aug. 2006","","IEEE","IEEE Conference Publications"
"An New Automatic Nucleated Cell Counting Method With Improved Cellular Neural Networks (ICNN)","Q. Feng; S. Yu; H. Wang","Automation Engeering, Nanjing University of Aeronautics and Astronautics, Nanjing 210016, China. e-mail: nuaafengq@163.com","2006 10th International Workshop on Cellular Neural Networks and Their Applications","20070410","2006","","","1","4","The number of nucleated cells in a bone marrow slice image is an important sign of the degree of hyperplasia. But because of the complex components in the bone marrow slice image, there are only a few methods available for cell detection or segmentation with poor effect. This paper focuses on this issue. A new automatic nucleated cell counting method based on improve cellular neural networks (ICNN) is proposed. We improve the CNN output function and practically design all the templates, then prove the stability. The process details are also presented. Experimental results show good performance. ICNN can detect almost all nucleated cells. Its running speed is expected to be comparatively high due to the easy hardware implementation and high speed of CNN","2165-0144;21650144","CD-ROM:1-4244-0640-4; POD:1-4244-0639-0","10.1109/CNNA.2006.341635","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4145875","Cellular neural networks;automatic counting;edge detection","Automation;Biology computing;Bone diseases;Cellular neural networks;Hardware;Image edge detection;Image processing;Image segmentation;Microscopy;Stability","bone;cellular neural nets;edge detection;image segmentation;medical image processing","automatic nucleated cell counting;bone marrow slice image;cell detection;cell segmentation;edge detection;hyperplasia;improved cellular neural networks","","1","","9","","","","28-30 Aug. 2006","","IEEE","IEEE Conference Publications"
"Some information of B-Scan image that detected by CNN","G. Li; L. Min; H. Zang; J. Wang; H. Hong; Y. Liu","School of Mathematics and Physics, North China Electric Power University, Beijing 102206, PR China; School of Applied Science University of Science and Technology Beijing Beijing 100083, PR China, lgdzhy@ncepu.edu.cn","2006 IEEE International Conference on Information Acquisition","20070212","2006","","","819","823","In this paper, first, the counter detection (CD) cell nerve net (CNN) has been applied to preprocessing ultrasound B-scan images of patients' livers. Second, the preprocessed images are further converted via Fourier transform. The maximal elements of the transformed matrix of the ultrasound B-scan images seem to be relation with the degrees of the damages of patient's livers. If using Fourier transform processes directly the original ultrasound B-scan images of patients' livers. Some relationships among the maximal elements and the damages of patient's lives count are found easily. It is expected that the result in this paper can be helpful for the diagnosis","","CD-ROM:1-4244-0529-7; POD:1-4244-0528-9","10.1109/ICIA.2006.305837","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4097770","CNN B-Scan image fourier transform","Biomedical imaging;Cellular neural networks;Counting circuits;Fourier transforms;Liver diseases;Medical diagnostic imaging;Physics;Pixel;Robustness;Ultrasonic imaging","Fourier transforms;biomedical ultrasonics;cellular neural nets;liver;matrix algebra;medical image processing","Fourier transform;cellular neural net;counter detection;patient liver;transformed matrix;ultrasound B-Scan image","","0","","8","","","","20-23 Aug. 2006","","IEEE","IEEE Conference Publications"
"Medical Image Noise Reduction Using Cellular Neural Networks","T. j. Su; J. w. Jhang","National Kaohsiung University of Applied Sciences, Taiwan","2006 International Conference on Intelligent Information Hiding and Multimedia","20061226","2006","","","228","231","In this paper, a novel method for designing templates of cellular neural networks to reduce the image noise is discussed. The discrete-time cellular neural network (DTCNN) combining with genetic algorithm (GA) is applied to image noise reducing. Based on GA method, the templates of CNN are optimized to diminish noise interference in polluted image. The demonstrated examples are presented to illustrate the better performance of the proposed methodology (GA-CNN).","","POD:0-7695-2745-0","10.1109/IIH-MSP.2006.264986","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4041706","","Biomedical engineering;Biomedical imaging;Cellular neural networks;Design engineering;Genetic algorithms;Interference;Noise reduction;Nonlinear dynamical systems;Signal processing;Signal processing algorithms","","","","1","","13","","","","Dec. 2006","","IEEE","IEEE Conference Publications"
"A Cellular Neural Network Methodology for Deformable Object Simulation","Y. Zhong; B. Shirinzadeh; G. Alici; J. Smith","Robotics & Mechatronics Res. Lab., Monash Univ., Clayton, Vic.","IEEE Transactions on Information Technology in Biomedicine","20061009","2006","10","4","749","762","This paper presents a new methodology to simulate soft object deformation by drawing an analogy between a cellular neural network (CNN) and elastic deformation. The potential energy stored in an elastic body as a result of a deformation caused by an external force is propagated among mass points by a nonlinear CNN. The novelty of the methodology is that: 1) CNN techniques are established to describe the potential energy distribution of the deformation for extrapolating internal forces and 2) nonlinear materials are modeled with nonlinear CNNs rather than geometric nonlinearity. Integration with a haptic device has been achieved for deformable object simulation with force feedback. The proposed methodology not only predicts the typical behaviors of living tissues, but it also accommodates isotropic, anisotropic, and inhomogeneous materials, as well as local and large-range deformation","1089-7771;10897771","","10.1109/TITB.2006.875679","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1707688","Analogy systems;cellular neural networks (CNNs);deformation;haptic feedback","Anisotropic magnetoresistance;Cellular neural networks;Computational modeling;Deformable models;Finite element methods;Haptic interfaces;Material properties;Potential energy;Solid modeling;Surgery","biological tissues;cellular neural nets;extrapolation;haptic interfaces;medical computing","cellular neural network methodology;deformable object simulation;elastic deformation;extrapolating internal forces;haptic device;haptic feedback;living tissues;nonlinear materials;potential energy distribution","","10","3","33","","","","Oct. 2006","","IEEE","IEEE Journals & Magazines"
"Automated Diagnostic Systems With Diverse and Composite Features for Doppler Ultrasound Signals","I. Guler; E. D. Ubeyli","Dept. of Electron.-Comput. Educ., Gazi Univ.","IEEE Transactions on Biomedical Engineering","20060918","2006","53","10","1934","1942","In this paper, we present the automated diagnostic systems for Doppler ultrasound signals classification with diverse and composite features and determine their accuracies. We compared the classification accuracies of six different classifiers, namely multilayer perceptron neural network (MLP), combined neural network (CNN), mixture of experts (ME), modified mixture of experts (MME), probabilistic neural network (PNN), and support vector machine (SVM), which were trained on diverse or composite features. The present study was conducted with the purpose of answering the question of whether the automated diagnostic systems improve the capability of classification of ophthalmic arterial (OA) and internal carotid arterial (ICA) Doppler signals. Our research demonstrated that the SVM trained on composite feature and the MME trained on diverse features achieved accuracy rates which were higher than that of the other automated diagnostic systems","0018-9294;00189294","","10.1109/TBME.2005.863929","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1703744","Combined neural network (CNN);Doppler ultrasound signals;composite feature;diverse features;mixture of experts (ME);modified mixture of experts (MME);multilayer perceptron neural network (MLP);probabilistic neural network (PNN);support vector machine (SVM)","Cellular neural networks;Diseases;Feature extraction;Independent component analysis;Multi-layer neural network;Multilayer perceptrons;Neural networks;Support vector machine classification;Support vector machines;Ultrasonic imaging","Doppler measurement;biomedical ultrasonics;blood vessels;eye;medical signal processing;multilayer perceptrons;signal classification;support vector machines","Doppler Ultrasound signals;automated diagnostic systems;combined neural network;composite features;diverse features;internal carotid arterial Doppler signals;mixture of experts;modified mixture of experts;multilayer perceptron neural network;ophthalmic arterial Doppler signals;probabilistic neural network;signal classification;support vector machine","Algorithms;Artificial Intelligence;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Information Storage and Retrieval;Pattern Recognition, Automated;Reproducibility of Results;Sensitivity and Specificity;Ultrasonography, Doppler;Vascular Diseases","7","","29","","","","Oct. 2006","","IEEE","IEEE Journals & Magazines"
"CNN-based algorithm for drusen identification","P. Checco; F. Corinto","Dept. of Electron., Politecnico di Torino, Italy","2006 IEEE International Symposium on Circuits and Systems","20060911","2006","","","4 pp.","","Drusen characterize the age-related macular degeneration. Automatic procedures for their identification have been recently developed. In this paper a cellular neural network based algorithm for drusen identification in fundus photograph is proposed. The algorithm is composed by different image processing steps: noise reduction, histogram normalization and a novel procedure of adaptive segmentation. The algorithm has been validated by using images provided from an ophthalmic medical center","0271-4302;02714302","POD:0-7803-9389-9","10.1109/ISCAS.2006.1693051","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1693051","","Biomedical imaging;Cellular neural networks;Colored noise;Histograms;Image color analysis;Image processing;Image segmentation;Medical diagnostic imaging;Noise reduction;Nonlinear filters","cellular neural nets;eye;image segmentation;medical image processing","CNN;adaptive segmentation;age related macular degeneration;cellular neural network;drusen identification;fundus photograph;histogram normalization;image processing;noise reduction","","6","","11","","","","21-24 May 2006","","IEEE","IEEE Conference Publications"
"Detection of a preseizure state in epilepsy: signal prediction by maximally weakly nonlinear networks?","C. Niederhofer; R. Tetzlaff","Inst. of Appl. Phys., Johann Wolfgang Goethe Univ., Frankfurt, Germany","2006 IEEE International Symposium on Circuits and Systems","20060911","2006","","","4 pp.","","We have shown in different studies (Gollas et al., 2004; Niederhofer and Tetzlaff, 2005; Weib and Tetzlaff, 2002) that the analysis of EEG-signals in epilepsy (Engels, 1989) using algorithms based on cellular nonlinear networks (CNN) (Leon and Chua, 1998) can contribute to the unsolved seizure prediction problem. For an automated prediction of impending epileptic seizures a precursor detection has to be performed which is based on an extraction of signal features in an pre-processing step. In different approaches (Fischer and Tetzlaff; Niederhofer et al., 2003, 2002; Kunz et al., 2000) to the feature extraction problem, weakly nonlinear discrete-time (DT) CNN with polynomial weight functions have been used especially for the signal prediction. In this paper the signal prediction by DT-CNN will be treated for increasing order of the polynomial weight functions. The aim of our work is to find out whether an increasing nonlinear degree will lead to more accurate results. Thereby the effects of taking EEG data as network boundary conditions will be studied","0271-4302;02714302","POD:0-7803-9389-9","10.1109/ISCAS.2006.1692548","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1692548","","Algorithm design and analysis;Brain;Cellular networks;Couplings;Electroencephalography;Epilepsy;Feature extraction;Intelligent networks;Physics;Polynomials","cellular neural nets;diseases;electroencephalography;medical signal processing;polynomials;prediction theory","EEG-signals;automated prediction;cellular nonlinear networks;epileptic seizures;feature extraction problem;maximally weakly nonlinear networks;network boundary conditions;polynomial weight functions;preseizure state detection;seizure prediction problem;signal prediction;weakly nonlinear discrete-time CNN","","5","","18","","","","21-24 May 2006","","IEEE","IEEE Conference Publications"
"Eigenvector methods for automated detection of time-varying biomedical signals","I. Guler; E. D. Ubeyli","Dept. of Electron. & Comput. Educ., Gazi Univ., Turkey","2005 ICSC Congress on Computational Intelligence Methods and Applications","20060807","2005","","","6 pp.","","In this paper, we present the automated diagnostic systems for time-varying biomedical signals classification and determine their accuracies. The combined neural network (CNN) and mixture of experts (ME) were tested and benchmarked for their performance on the classification of the studied time-varying biomedical signals (ophthalmic arterial Doppler signals and electroencephalogram signals). Decision making was performed in two stages: feature extraction by eigenvector methods and classification using the classifiers trained on the extracted features. The purpose was to determine an optimum classification scheme for the problem and also to infer clues about the extracted features. Our research demonstrated that the power levels of power spectral density (PSD) estimations obtained by the eigenvector methods are the valuable features which are representing the time-varying biomedical signals and the CNN and ME trained on these features achieved high classification accuracies","","POD:1-4244-0020-1","10.1109/CIMA.2005.1662296","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1662296","Combined neural network (CNN);Eigenvector methods;Mixture of experts (ME);Time-varying biomedical signals","Biomedical engineering;Cellular neural networks;Computer science education;Data mining;Epilepsy;Feature extraction;Frequency estimation;Neural networks;Signal processing;Systems engineering education","Doppler measurement;eigenvalues and eigenfunctions;electroencephalography;eye;feature extraction;medical diagnostic computing;medical signal processing;neural nets;signal classification","automated diagnostic systems;combined neural network;eigenvector methods;electroencephalogram signals;feature extraction;mixture of experts;ophthalmic arterial Doppler signals;power spectral density estimations;time-varying biomedical signals classification","","0","","10","","","","0-0 0","","IEEE","IEEE Conference Publications"
"Cellular neural network based deformation simulation with haptic force feedback","Y. Zhong; B. Shirinzadeh; G. Alici; J. Smith","Robotics & Mechatronics Res. Laboratory, Monash Univ., Clayton, Vic.","9th IEEE International Workshop on Advanced Motion Control, 2006.","20060530","2006","","","380","385","This paper presents a new methodology for deformable object modelling by drawing an analogy between cellular neural network (CNN) and elastic deformation. The potential energy stored in an elastic body as a result of a deformation caused by an external force is propagated among mass points by the non-linear CNN activity. An improved CNN model is developed for propagating the energy generated by the external force on the object surface in the natural manner of Poisson equation. The proposed methodology models non-linear materials with nonlinear CNN rather than geometric non-linearity in the most existing deformation methods. It can not only deal with large-range deformations, but it can also accommodate isotropic, anisotropic and inhomogeneous materials by simply modifying constitutive constants","1943-6572;19436572","POD:0-7803-9511-1","10.1109/AMC.2006.1631688","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1631688","","Anisotropic magnetoresistance;Cellular neural networks;Computational modeling;Deformable models;Force feedback;Haptic interfaces;Medical simulation;Potential energy;Solid modeling;Surgery","cellular neural nets;elastic deformation;force feedback;haptic interfaces;medical computing;stochastic processes;surgery;virtual reality","Poisson equation;anisotropic materials;cellular neural network;deformable object modelling;deformation simulation;elastic deformation;haptic force feedback;inhomogeneous materials;isotropic materials;nonlinear materials;virtual reality based surgery simulation","","2","","25","","","","0-0 0","","IEEE","IEEE Conference Publications"
"CNN-based automatic retinal vascular tree extraction","C. Alonso-Montes; D. L. Vilarino; M. G. Penedo","Dept. of Comput. Sci., Coruna Univ., Spain","2005 9th International Workshop on Cellular Neural Networks and Their Applications","20051205","2005","","","61","64","The retinal vascular tree has become an important task of medical image processing in different scientific areas. Many studies have focused on developing an automatic algorithm, however little attention has been paid to improve computational processing time of these algorithms. In this paper, an automatic methodology for retinal vascular tree extraction using cellular neural networks (CNNs) is proposed. The aim of using CNNs is to improve computational time in order to achieve real-time requirements.","2165-0144;21650144","POD:0-7803-9185-3","10.1109/CNNA.2005.1543161","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1543161","","Active contours;Angiography;Biomedical image processing;Biomedical imaging;Cellular neural networks;Computer architecture;Computer science;Histograms;Image segmentation;Retina","blood vessels;cellular neural nets;eye;medical image processing","CNN-based automatic retinal vascular tree extraction;cellular neural networks;medical image processing","","4","","8","","","","28-30 May 2005","","IEEE","IEEE Conference Publications"
"A CNN for biomedical image processing","A. Anzalone; F. Bizzarri; M. Parodi; M. Storace","Dept. of Biophys. & Electron. Eng., Genoa Univ., Genova, Italy","Proceedings of the 2005 European Conference on Circuit Theory and Design, 2005.","20051031","2005","3","","III/169","III/172 vol. 3","In this paper the minimization of a functional defined in the context of biomedical image processing is obtained through a cellular nonlinear network (CNN). The CNN performs noise removal in grey-level biomedical images. The performances of the circuit at behavioural level are shown in a case study concerning retinal images.","","POD:0-7803-9066-0","10.1109/ECCTD.2005.1523087","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1523087","","Biomedical image processing;Biomedical imaging;Biomedical optical imaging;Cellular networks;Cellular neural networks;Circuit noise;Image processing;Image restoration;Minimization;Retina","cellular neural nets;eye;image denoising;medical image processing","biomedical image processing;cellular nonlinear network;grey-level biomedical images;noise removal;retinal images","","2","","6","","","","28 Aug.-2 Sept. 2005","","IEEE","IEEE Conference Publications"
"Artificial immune systems based sound event detection with CNN-UM","J. Stolte; G. Cserey","Dept. of Electr. Eng. & Inf. Technol., Eindhoven Univ. of Technol., Netherlands","Proceedings of the 2005 European Conference on Circuit Theory and Design, 2005.","20051031","2005","3","","III/11","III/14 vol. 3","In this paper, we are presenting an artificial immune system based spatial-temporal CNN algorithm framework for sound event detection problems. We also introduce a pattern detection algorithm in grayscale images. Our results show that these algorithms can be implemented in real-time applications.","","POD:0-7803-9066-0","10.1109/ECCTD.2005.1523048","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1523048","","Adaptive systems;Artificial immune systems;Biology computing;Cellular neural networks;Computer networks;Event detection;Humans;Immune system;Information technology;Organisms","audio signal processing;biology computing;cellular biophysics;cellular neural nets;medical image processing;pattern recognition","CNN-UM;artificial immune systems;grayscale images;pattern detection algorithm;sound event detection;spatial-temporal CNN algorithm framework","","1","","11","","","","28 Aug.-2 Sept. 2005","","IEEE","IEEE Conference Publications"
"Design for robustness counter detection CNN with applications","Hongyan Zang; Guodong Li; Lequan Min; Jianghe Wang; Huiwen Hong; Yanling Liu","Sch. of Appl. Sci. & Sch. of Inf. Eng., Univ.of Sci. & Technol. Beijing","Proceedings. 2005 International Conference on Communications, Circuits and Systems, 2005.","20050815","2005","2","","953","","This paper presents a theorem for designing the robustness template parameters of a cellular neural network (CNN) to detect contours in images. The theorem provides parameter inequalities for determining parameter intervals to implement corresponding tasks. As two first examples, the contour detection (CD) CNN has successfully detected contours in a grey pattern image and the Lena portrait. As the third example, the CD CNN has been used to analyze the characteristics of ultrasound B-scan images of six patients' livers. Using polynomials of order 10 approximates the data of the ultrasound B-scan images processed by the CD CNN. Primary analysis seems to display some relationships between the polynomial coefficients and the damage in the patients' livers","","POD:0-7803-9015-6","10.1109/ICCCAS.2005.1495266","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1495266","","Biomedical imaging;Cellular neural networks;Counting circuits;Gray-scale;Image analysis;Image edge detection;Liver;Object detection;Polynomials;Robustness","biomedical ultrasonics;cellular neural nets;edge detection;liver;medical image processing;polynomial approximation","CNN;Lena portrait;cellular neural network;grey pattern image;livers;parameter inequalities;parameter intervals;polynomial coefficients;robust contour detection;robustness template parameters;ultrasound B-scan images","","9","","13","","","","27-30 May 2005","","IEEE","IEEE Conference Publications"
"Recent results on the prediction of EEG signals in epilepsy by discrete-time cellular neural networks (DTCNN)","C. Niederhofer; R. Tetzlaff","Inst. fur Angewandte Phys., Johann Wolfgang Goethe Univ., Frankfurt, Germany","2005 IEEE International Symposium on Circuits and Systems","20050725","2005","","","5218","5221 Vol. 5","In different investigations it has been shown that nonlinear signal processing can contribute to the task of finding precursors of impending epileptic seizures in the case of a focal epilepsy. Various approaches to this feature extraction problem have been made including Volterra-systems, wavelet-analysis and cellular neural networks (CNN). This paper gives a detailed analysis of a recently proposed prediction algorithm based on a multi-layer delay-time DTCNN. The aim of this contribution is to reduce the high computation complexity caused by the permanent application of a supervised optimization procedure for successive data segments of an EEG recording. Thereby, the prediction algorithm is studied by using different optimization procedures, different network topologies and different template symmetries.","0271-4302;02714302","POD:0-7803-8834-8","10.1109/ISCAS.2005.1465811","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1465811","","Algorithm design and analysis;Cellular neural networks;Delay;Electrodes;Electroencephalography;Epilepsy;Intelligent networks;Physics;Prediction algorithms;Signal processing algorithms","cellular neural nets;electroencephalography;feature extraction;medical signal processing;optimisation","EEG signal epilepsy prediction;discrete-time cellular neural networks;feature extraction;focal epilepsy;impending epileptic seizure precursors;multilayer delay-time DTCNN;network topologies;nonlinear signal processing;successive data segments optimization;supervised optimization procedure;template symmetries","","4","","11","","","","23-26 May 2005","","IEEE","IEEE Conference Publications"
"Cellular neural network (CNN) circuit design for modeling of early-stage human visual system","Shi-An Chen; Jen-Feng Chung; Sheng-Fu Liang; Chin-Teng Lin","Dept. of Electr. & Control Eng., Nat. Chiao Tung Univ., Hsinchu, Taiwan","IEEE International Workshop on Biomedical Circuits and Systems, 2004.","20050627","2004","","","S1/4/INV","S1/49-12","This paper proposes a novel CNN-based biological visual processing for hybrid-order texture boundary detection. The texture boundary detection is based on the first- and second-order features to model pre-attentive stage of human visual system. This system is implemented by using a parallel computing neural network, called cellular neural networks (CNN). This CNN design adopts the multi-layer architecture involving a 5×5 large neighborhood and is extended to be the 16×16 array size for image processing. The proposed circuit models have been verified and the proposed method can successfully detect the texture boundary in an image.","","POD:0-7803-8665-5","10.1109/BIOCAS.2004.1454129","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1454129","","Biological system modeling;Biology computing;Brain modeling;Cellular neural networks;Circuit synthesis;Gabor filters;Humans;Neural networks;Nonlinear filters;Visual system","cellular neural nets;edge detection;image texture;medical image processing;visual perception","biological visual processing;cellular neural network circuit design;early-stage human visual system;hybrid-order texture boundary detection;image processing;parallel computing neural network","","2","","11","","","","1-3 Dec. 2004","","IEEE","IEEE Conference Publications"
"Pattern detection by cellular neuronal networks (CNN) in long-term recordings of a brain electrical activity in epilepsy","P. Fischer; R. Tetzlaff","Inst. of Appl. Phys., Frankfurt Univ., Germany","2004 IEEE International Joint Conference on Neural Networks (IEEE Cat. No.04CH37541)","20050117","2004","1","","","169","About 0.5% of the world population is suffering from a focal epilepsy (J. Engel et al., 2003), which is a widely spread disease. The goal of the investigations discussed in this paper is an early detection of precursors of an impending epileptic seizure by the analysis of brain electrical activity of multi-electrode EEG recordings. Therefore, methods of nonlinear signal processing were used in CNN simulations. This investigation is based on long-term recordings of approximately one week length, where analysis algorithms proposed in previous investigations (C. Niederhoefer et al., 2003) have been generalised toward new feature extraction methods which are presented in this paper.","1098-7576;10987576","POD:0-7803-8359-1","10.1109/IJCNN.2004.1379891","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1379891","","Algorithm design and analysis;Biological neural networks;Brain modeling;Cellular networks;Cellular neural networks;Diseases;Disk recording;Electroencephalography;Epilepsy;Signal processing algorithms","cellular neural nets;electroencephalography;feature extraction;medical signal processing","brain electrical activity;cellular neuronal network;feature extraction methods;focal epilepsy;long-term recording;multielectrode EEG recordings;nonlinear signal processing;pattern detection","","1","","14","","","","25-29 July 2004","","IEEE","IEEE Conference Publications"
"Feature extraction in epilepsy using a cellular neural network based device - first results","R. Tetzlaff; C. Niederhofer; P. Fischer","Inst. of Appl. Phys., Frankfurt Univ., Germany","Circuits and Systems, 2003. ISCAS '03. Proceedings of the 2003 International Symposium on","20030620","2003","3","","III-850","III-853 vol.3","In this paper, the bioelectrical activity of a human brain in epilepsy is analyzed using a cellular neural network-universal machine (CNN-UM) proposed by T. Roska and L.O. Chua (IEEE Trans. Circuits and Systems II, vol. 40, pp. 163-173, 1993). Therefore a feature extraction method based on binary input-output patterns and Boolean CNN with linear weight functions called pattern detection algorithm (R. Tetzlaff et al, IEEE Int. Workshop on Cellular Neural Networks and Their Appl., pp. 259-266, 2002) is used. First results of a hardware application with a CNN-UM realized as a mixed-mode array processor (M. Laiho et al, Int. J. Circuit Theory and Appl., pp. 165-180, 2002) are presented.","","POD:0-7803-7761-3","10.1109/ISCAS.2003.1205153","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1205153","","Bioelectric phenomena;Biological neural networks;Cellular networks;Cellular neural networks;Circuits and systems;Detection algorithms;Epilepsy;Feature extraction;Humans;Neural networks","bioelectric phenomena;biomedical electronics;biomedical engineering;brain;cellular neural nets;feature extraction;medical diagnostic computing;medical signal processing;mixed analogue-digital integrated circuits;neural chips","Boolean CNN;CNN-UM;binary input-output patterns;bioelectrical activity;cellular neural network based device;cellular neural network-universal machine;epilepsy;feature extraction;hardware application;linear weight functions;mixed-mode array processor;pattern detection algorithm","","4","","8","","","","25-28 May 2003","","IEEE","IEEE Conference Publications"
"A new composite ICA algorithm and its application in fMRI data processing","Huafu Chen; Dezhong Yao; Ting Fu","Sch. of Life Sci. & Technol., Univ. of Electron. Sci. & Technol. of China, Chengdu, China","IEEE 2002 International Conference on Communications, Circuits and Systems and West Sino Expositions","20030219","2002","2","","1098","1102 vol.2","Independent component analysis (ICA) is a new technique in signal processing to extract statistically independent components from an observed multidimensional mixture of data. A composite algorithm of Newton iteration and natural gradient descent (CNN) is presented to implement ICA by maximizing the sum of marginal Negentropies which is equivalent to minimizing the mutual information of independent signals. The CNN algorithm avoids the singularity of Newton iteration. At the same time, it possesses higher convergence speed than the natural gradient algorithm. We specifically apply the algorithm to functional magnetic resonance imaging (fMRI) data, and the results lend validity to the proposed method as providing a reasonable physiological explanation for the fMRI data.","","POD:0-7803-7547-5","10.1109/ICCCAS.2002.1178977","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1178977","","Cellular neural networks;Covariance matrix;Data mining;Data processing;Independent component analysis;Magnetic resonance imaging;Multidimensional signal processing;Mutual information;Partial response channels;Signal processing algorithms","Newton method;biomedical MRI;convergence of numerical methods;gradient methods;independent component analysis;medical signal processing;minimisation","Newton iteration;composite ICA algorithm;composite algorithm;fMRI data processing;functional magnetic resonance imaging;independent component analysis;marginal Negentropies;natural gradient descent;signal processing","","0","","11","","","","29 June-1 July 2002","","IEEE","IEEE Conference Publications"
"Colour space transformation, colour correction and exact colour reproduction with CNN technology","N. Kozma; B. Kranicz; P. Szolgay","Dept. of Image Process. & Neurocomputing, Univ. of Veszprem, Hungary","9th International Conference on Electronics, Circuits and Systems","20021210","2002","3","","1259","1262 vol.3","Nowadays many problems requiring huge computing power have arisen. Although the performance of digital processors doubles every year, there are certain tasks where the computation cannot be carried out within a reasonable time interval. Such hard problems are the analysis of big dynamical systems or real-time exact colour reproduction. The exact colour visualization of motion pictures is necessary in industrial, medical and scientific research areas. Thus, for example, exact colour reproduction is required for remote medical diagnosis or remote operation. The doctor has to see the same image that appears in reality. Device dependent colour appearance may cause faulty decisions. Nowadays these problems cannot be solved perfectly because many steps of the transformation are not completely known and the huge number of computations cannot be done in real-time even by the fastest PC. In this article we describe some methods to produce exact colours in a remote medical diagnostic system.","","POD:0-7803-7596-3","10.1109/ICECS.2002.1046483","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1046483","","Biomedical imaging;Cellular neural networks;Color;Image processing;Magnetic resonance imaging;Medical diagnosis;Medical diagnostic imaging;Motion pictures;Real time systems;Space technology","cellular neural nets;image colour analysis;image resolution;medical image processing","CNN technology;colour correction;colour space transformation;colour visualization;device dependent colour appearance;exact colour reproduction;motion pictures;remote medical diagnostic system","","0","","8","","","","2002","","IEEE","IEEE Conference Publications"
"A CNN based system to blind sources separation of MEG signals","M. Bucolo; L. Fortuna; M. Frasca; M. La Rosa","Dipt. Elettrico, Elettronico e Sistemistico, Universita degli Studi di Catania","Proceedings of the 2002 7th IEEE International Workshop on Cellular Neural Networks and Their Applications","20021107","2002","","","195","201","In this paper a cellular neural network (CNN) based system to perform a real-time, parallel processing of magetoencephalographic data is proposed. In particular, a nonlinear approach to blind sources separation, instead of the linear procedure performed by independent component analysis, is introduced. Moreover, the characteristic spatial distribution of the cells in the CNN system has been exploited to reproduce the topology of the acquisition channels over the scalp.","","POD:981-238-121-X","10.1109/CNNA.2002.1035053","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1035053","","Cellular neural networks;Electroencephalography;Heart beat;Hemodynamics;Humans;Independent component analysis;Magnetic separation;Real time systems;SQUIDs;Scalp","blind source separation;cellular neural nets;magnetoencephalography;medical diagnostic computing;medical signal processing;parallel processing;real-time systems","CNN based system;MEG signals;acquisition channel topology;blind sources separation;cellular neural network;magetoencephalography;real-time parallel processing;scalp;spatial distribution","","0","","8","","","","22-24 Jul 2002","","IEEE","IEEE Conference Publications"
"Analyzing multidimensional neural activity via CNN-UM","V. Gal; S. Grun; R. Tetzlaff","Inst. for Appl. Phys., Univ. of Frankfurt, Frankfurt/Main, Germany","Proceedings of the 2002 7th IEEE International Workshop on Cellular Neural Networks and Their Applications","20021107","2002","","","243","250","In this paper we show that CNN-UM is an excellent tool for analyzing time series of multidimensional binary signals. The developed algorithm is dedicated to process electrophysiological multi-neuron recordings: our aim is to find specific multidimensional activity patterns, which may reflect higher order functional cell-assemblies. The analysis consists of two parts: the occurrences of different patterns are first counted, then the statistical significance of each occurrence frequency is calculated separately.","","POD:981-238-121-X","10.1109/CNNA.2002.1035057","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1035057","","Cellular neural networks;Electrodes;Electrophysiology;Frequency synchronization;Multidimensional systems;Neurons;Neurophysiology;Physics;Signal analysis;Time series analysis","bioelectric potentials;cellular neural nets;medical signal processing;neurophysiology;pattern classification;statistical analysis;time series","CNN-UM;cellular neural nets;electrophysiological multineuron recordings;multidimensional activity patterns;multidimensional binary signals;pattern classification;spike activity;statistical analysis;time series","","0","","10","","","","22-24 Jul 2002","","IEEE","IEEE Conference Publications"
"Colour space transformation and exact colour reproduction with CNN technology","P. Kozma; B. Kranicz; P. Szolgay","Dept. of Image Process. & Neurocomputing, Univ. of Veszprem, Hungary","Proceedings of the 2002 7th IEEE International Workshop on Cellular Neural Networks and Their Applications","20021107","2002","","","555","562","Nowadays many problems requiring huge computing power have risen. Although the performance of digital processors doubles every year, there are certain tasks where the computation cannot be carried out within a reasonable time interval. Such hard problems are the analysis of big dynamical systems or real-time exact colour reproduction. The exact colour visualization of motion pictures is necessary in industrial, medical and scientific research areas. Thus, for example, exact colour reproduction is required for remote medical diagnosis or remote operation. The doctor has to see the same image that appears in reality. Device dependent colour appearance may cause faulty decisions. Nowadays these problems cannot be solved perfectly because many steps of the transformation are not completely known and the huge number of computations cannot be done in real-time even by the fastest PC. In this article we describe some methods to produce exact colours in a remote medical diagnostic system.","","POD:981-238-121-X","10.1109/CNNA.2002.1035095","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1035095","","Analog computers;Application software;Cellular neural networks;Computer architecture;Hardware;Image processing;Magnetic resonance imaging;Medical diagnosis;Real time systems;Space technology","cellular neural nets;image colour analysis;medical image processing;telemedicine","colour space transformation;exact colour reproduction;motion pictures;remote medical diagnosis;remote medical diagnostic system;remote operation","","0","","7","","","","22-24 Jul 2002","","IEEE","IEEE Conference Publications"
"Application of analogic CNN algorithms in telemedical neuroradiology","T. Szabo; P. Barsi; P. Szolgay","Image Process. & Neurocomputing Dept., Univ. of Veszprem, Hungary","Proceedings of the 2002 7th IEEE International Workshop on Cellular Neural Networks and Their Applications","20021107","2002","","","579","586","A CNN-based image processing system as a part of a telemedical consulting system is introduced in this paper. A consulting network for early detection of acute ischemic stroke is outlined. CT images are processed by analogic CNN algorithms.","","POD:981-238-121-X","10.1109/CNNA.2002.1035098","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1035098","","Biomedical imaging;Cellular neural networks;Computed tomography;Gray-scale;Humans;Image processing;Magnetic resonance imaging;Medical diagnostic imaging;Pathology;X-ray imaging","analogue integrated circuits;cellular neural nets;computerised tomography;medical image processing;neurophysiology;radiology;telemedicine","CT images;acute ischemic stroke detection;analogic CNN algorithms;telemedical neuroradiology","","3","","9","","","","22-24 Jul 2002","","IEEE","IEEE Conference Publications"
"Prediction of epileptic seizures by CNN with linear weight functions","R. Kunz; C. Niederhofer; R. Tetzlaff","IBM Germany, Frankfurt, Germany","Proceedings of the 2002 7th IEEE International Workshop on Cellular Neural Networks and Their Applications","20021107","2002","","","259","266","In this contribution, a novel approach for the prediction of epileptic seizures is introduced using binary input-output patterns and Boolean CNN with linear weight functions. Two different algorithms are introduced and verified on invasive recordings of different patients.","","POD:981-238-121-X","10.1109/CNNA.2002.1035059","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1035059","","Alarm systems;Brain;Cellular neural networks;Decoding;Disk recording;Electric variables measurement;Epilepsy;Frequency;Physics;Surgery","Boolean functions;bioelectric phenomena;brain;cellular neural nets;diseases;medical signal processing","Boolean cellular neural net;algorithms;binary input-output patterns;epileptic seizure prediction;invasive recordings;linear weight functions;patients","","5","","7","","","","22-24 Jul 2002","","IEEE","IEEE Conference Publications"
"DNA chip image processing via cellular neural networks","P. Arena; L. Fortuna; L. Occhipinti","Dipt. Elettrico, Elettronico e Sistemistica, Catania Univ., Italy","ISCAS 2001. The 2001 IEEE International Symposium on Circuits and Systems (Cat. No.01CH37196)","20020807","2001","3","","345","348 vol. 2","In this work, a new cellular neural network algorithm for DNA-chip automatic analysis is outlined. It allows to automatically classify in real-time fluorescence images from DNA microarray after the hybridization process. The paper introduces the main issues in DNA-chip technology and reports the key features of CNN application in this field, together with the description of a sample CNN algorithm and simulation results.","","POD:0-7803-6685-9","10.1109/ISCAS.2001.921318","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=921318","","Cellular neural networks;DNA;Diseases;Fluorescence;Genetics;Image processing;Microorganisms;Proteins;Sequences;Turing machines","DNA;cellular neural nets;fluorescence;image classification;medical image processing;real-time systems","DNA chip;DNA microarray;automatic analysis;cellular neural network algorithm;hybridization;image processing;real-time fluorescence image classification","","1","1","11","","","","6-9 May 2001","06 May 2001-09 May 2001","IEEE","IEEE Conference Publications"
"Spatio-temporal distribution of brain electrical activity patterns in epilepsy: inputs for cellular neural networks","R. Tetzlaff; R. Kunz","Inst. fur Angewandte Phys., Frankfurt Univ.","ISCAS 2001. The 2001 IEEE International Symposium on Circuits and Systems (Cat. No.01CH37196)","20020807","2001","3","","329","332 vol. 2","A new approach to the analysis of brain electrical activity in epilepsy is introduced. It is based on Cellular Neural Networks (CNN) with linear weight functions and nonpropagating templates. For a CNN with binary steady state outputs and binary inputs (Boolean CNN) the measured relative frequency of different CNN input patterns of brain electrical activity is discussed applying focal and non-focal electrodes","","POD:0-7803-6685-9","10.1109/ISCAS.2001.921314","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=921314","","Artificial intelligence;Brain;Cellular neural networks;Decoding;Electric variables measurement;Electrodes;Epilepsy;Frequency measurement;Intelligent networks;Steady-state","cellular neural nets;diseases;electroencephalography;medical signal processing;pattern recognition","Boolean CNN;CNN inputs;binary inputs;binary steady state outputs;brain electrical activity patterns;cellular neural networks;epilepsy;focal electrodes;linear weight functions;nonfocal electrodes;nonpropagating templates;spatio-temporal distribution","","2","","13","","","","6-9 May 2001","06 May 2001-09 May 2001","IEEE","IEEE Conference Publications"
"CNN-based modeling of the human early vision system","Seung-Pyo Chae; Jeong-Woo Lee; Myoung-Nam Kim; Si-Yeol Kim; Jin-Ho Cho","Sch. of Electron. & Electr. Eng., Kyungpook Nat. Univ., Taegu, South Korea","ISIE 2001. 2001 IEEE International Symposium on Industrial Electronics Proceedings (Cat. No.01TH8570)","20020807","2001","1","","192","194 vol.1","CNN (cellular neural network)-based retina model is introduced to simulate the human early vision system. By considering the retinal activity using CNN, we can begin to think about whole retinal interactions in space/time and consider the mechanism of a large population of cells as the edge detection and detection of moving stimuli. Furthermore, after simulating the output response of each retinal neuron, ERG, which is volume conductor potential recorded at the cornea and used as important diagnostic measure in eye clinic, is calculated. Each wavelet which composes the typical ERG has close relationship with the mechanism of a special retinal layer and by analyzing the each wavelet form we can guess the clinical state of special retinal layer.","","POD:0-7803-7090-2","10.1109/ISIE.2001.931780","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=931780","","Cellular networks;Cellular neural networks;Conductors;Humans;Image edge detection;Machine vision;Neural networks;Neurons;Retina;Wavelet analysis","cellular biophysics;cellular neural nets;edge detection;electroretinography;image motion analysis;medical signal processing;patient diagnosis;visual evoked potentials;wavelet transforms","CNN-based retina model;ERG;cellular neural network;cornea;diagnostic measure;edge detection;eye clinic;human early vision system;moving stimuli;output response;retinal activity;retinal interactions;retinal neuron;special retinal layer;volume conductor potential;wavelet","","0","","5","","","","12-16 June 2001","12 Jun 2001-16 Jun 2001","IEEE","IEEE Conference Publications"
"A CNN algorithm for real time analysis of DNA microarrays","P. Arena; L. Fortuna; L. Occhipinti","Dipt. Elettrico, Catania Univ., Italy","IEEE Transactions on Circuits and Systems I: Fundamental Theory and Applications","20020807","2002","49","3","335","340","The work focuses on a new approach for DNA-chip image processing by using the cellular neural network (CNN) paradigm. In particular, the work aims to solve the main issues in automatic classification and spot validation that arise during an automatic DNA microarray analysis procedure. This contribution briefly presents the basic DNA micro-array technique and the state-of-the-art technologies, and introduces the idea of processing DNA chip data via CNNs, reporting suitable examples. The algorithm described has been developed using a high level language, dedicated to CNN universal machine (CNNUM) chip programming, and validated on a typical fluorescence image from a DNA microarray after hybridization","1057-7122;10577122","","10.1109/81.989167","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=989167","","Algorithm design and analysis;Cellular neural networks;DNA;Diseases;Fluorescence;Gene expression;Genetics;Image processing;Performance analysis;Turing machines","DNA;biological techniques;biology computing;bioluminescence;biotechnology;cellular neural nets;fluorescence;image classification;medical image processing","CNN algorithm;CNN paradigm;CNN universal machine chip programming;CNNUM chip programming;DNA chip data processing;DNA micro-array technique;DNA microarray hybridization;DNA microarrays;DNA-chip image processing;automatic DNA microarray analysis procedure;automatic classification;cellular neural network paradigm;fluorescence image;high level language;real time analysis;spot validation","","16","","17","","","","Mar 2002","","IEEE","IEEE Journals & Magazines"
"Detection of masses on mammograms using a convolution neural network","Datong Wei; B. Sahiner; Heang-Ping Chan; N. Petrick","Dept. of Radiol., Michigan Univ., Ann Arbor, MI, USA","1995 International Conference on Acoustics, Speech, and Signal Processing","20020806","1995","5","","3483","3486 vol.5","A convolution neural network (CNN) was used for classification of masses and normal tissue on mammograms. A generalized CNN was developed that uses multiple images derived from a single region of interest (ROI) as the input. The CNN input images were obtained from the ROIs using (i) averaging and subsampling; and (ii) texture feature extraction methods on smaller sub-regions inside the ROI. In (ii), features computed over different sub-regions were arranged as texture-images, and subsequently used as inputs to the CNN. The results indicate that using texture-images improves the classification accuracy","1520-6149;15206149","POD:0-7803-2431-5","10.1109/ICASSP.1995.479736","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=479736","","Backpropagation;Breast cancer;Cellular neural networks;Computer aided diagnosis;Convolution;Feature extraction;Kernel;Lesions;Neural networks;Radiology","backpropagation;convolution;diagnostic radiography;feature extraction;image sampling;image texture;medical image processing;neural nets","averaging;classification accuracy;convolution neural network;generalized neural network;mammograms;masses classification;multiple images;normal tissue classification;region of interest;subsampling;texture feature extraction methods;texture images","","0","","7","","","","9-12 May 1995","09 May 1995-12 May 1995","IEEE","IEEE Conference Publications"
"CNN implementation of seed growth algorithm for fuzzy segmentation of images","P. Kies","Inst. of Fundamental Technol. Res., Polish Acad. of Sci., Warsaw, Poland","1996 Fourth IEEE International Workshop on Cellular Neural Networks and their Applications Proceedings (CNNA-96)","20020806","1996","","","197","200","This paper describes a cellular neural network implementation of the seed growth algorithms for fuzzy segmentation of images. Some examples with medical images are presented","","POD:0-7803-3261-X","10.1109/CNNA.1996.566550","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=566550","","Biomedical imaging;Cellular neural networks;Data mining;Electronic mail;Fuzzy neural networks;Fuzzy sets;Image processing;Image segmentation;Lattices;Pixel","cellular neural nets;fuzzy set theory;image segmentation;medical image processing","cellular neural network;fuzzy segmentation;medical images;seed growth algorithm","","1","","10","","","","24-26 Jun 1996","24 Jun 1996-26 Jun 1996","IEEE","IEEE Conference Publications"
"Improved scoring and semi-automatic screening of human peripheral blood chromosomes by CNN visual system","A. Tompa; T. Sziranyi; L. Nemes; C. Rekeczky; T. Roska","Dept. of Genotoxicology, Nat. Inst. of Occupational Health, Budapest, Hungary","1996 Fourth IEEE International Workshop on Cellular Neural Networks and their Applications Proceedings (CNNA-96)","20020806","1996","","","99","102","Many of the microscopic image processing tasks can be well implemented in the cellular neural net Universal Machine (CNN UM) architecture. We have developed a complex system for chromosome analysis. Our method, when implemented in hardware containing VLSI chips, can execute some important image processing steps at superior speed. The recent simulator based system is capable of helping the reliable chromosome analysis","","POD:0-7803-3261-X","10.1109/CNNA.1996.566501","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=566501","","Analytical models;Biological cells;Cellular neural networks;Hardware;Humans;Image processing;Microscopy;Neural networks;Turing machines;Very large scale integration","VLSI;biological techniques;biology computing;blood;cellular biophysics;cellular neural nets;digital signal processing chips;image classification;image recognition;medical image processing;optical microscopy","CNN visual system;Universal Machine;VLSI chips;cellular neural net;chromosome analysis;human peripheral blood chromosomes;image processing steps;microscopic image processing tasks;scoring;semi-automatic screening","","0","","12","","","","24-26 Jun 1996","24 Jun 1996-26 Jun 1996","IEEE","IEEE Conference Publications"
"Classification of mass and normal breast tissue: a convolution neural network classifier with spatial domain and texture images","B. Sahiner; Heang-Ping Chan; N. Petrick; Datong Wei; M. A. Helvie; D. D. Adler; M. M. Goodsitt","Dept. of Radiol., Michigan Univ., Ann Arbor, MI, USA","IEEE Transactions on Medical Imaging","20020806","1996","15","5","598","610","The authors investigated the classification of regions of interest (ROI's) on mammograms as either mass or normal tissue using a convolution neural network (CNN). A CNN is a backpropagation neural network with two-dimensional (2-D) weight kernels that operate on images. A generalized, fast and stable implementation of the CNN was developed. The input images to the CNN were obtained from the ROI's using two techniques. The first technique employed averaging and subsampling. The second technique employed texture feature extraction methods applied to small subregions inside the ROI. Features computed over different subregions were arranged as texture images, which were subsequently used as CNN inputs. The effects of CNN architecture and texture feature parameters on classification accuracy were studied. Receiver operating characteristic (ROC) methodology was used to evaluate the classification accuracy. A data set consisting of 168 ROIs containing biopsy-proven masses and 504 ROI's containing normal breast tissue was extracted from 168 mammograms by radiologists experienced in mammography. This data set was used for training and testing the CNN. With the best combination of CNN architecture and texture feature parameters, the area under the test ROC curve reached 0.87, which corresponded to a true-positive fraction of 90% at a false positive fraction of 31%. The authors' results demonstrate the feasibility of using a CNN for classification of masses and normal tissue on mammograms","0278-0062;02780062","","10.1109/42.538937","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=538937","","Backpropagation;Breast tissue;Cellular neural networks;Computer architecture;Convolution;Feature extraction;Kernel;Neural networks;Testing;Two dimensional displays","diagnostic radiography;image classification;image texture;medical image processing;neural nets","biopsy-proven masses;breast cancer;convolution neural network;mammograms;mass classification;medical diagnostic imaging;normal breast tissue;regions of interest;spatial domain images;texture images;two-dimensional weight kernels","","122","3","26","","","","Oct 1996","","IEEE","IEEE Journals & Magazines"
"Analogic algorithm for point pattern matching with application to mammogram follow-up","N. S. Vujovic; P. R. Bakic; D. P. Brzakovic","Dept. of Comput. Sci. & Electr. Eng., Lehigh Univ., Bethlehem, PA, USA","1996 Fourth IEEE International Workshop on Cellular Neural Networks and their Applications Proceedings (CNNA-96)","20020806","1996","","","75","80","An analogic algorithm for registering control points in pairs of nonstructured texture images is described. The algorithm is particularly suitable in problems where precise pixel-wise registration is intractable, e.g., in registration of non-rigid objects. The algorithm is simulated on a digital computer as a sequence of cellular neural network (CNN) transients and logic operations. The proposed algorithm was applied to solve the correspondence problem in mammogram follow-up, the results of the performance evaluation of the algorithm are presented and discussed. We present a CNN realization of the proposed regional registration algorithm as an alternative to standard image processing implementation","","POD:0-7803-3261-X","10.1109/CNNA.1996.566496","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=566496","","Anatomical structure;Breast tissue;Cellular neural networks;Elasticity;Image coding;Image processing;Logic;Pattern matching;Pixel;Robust control","cellular neural nets;diagnostic radiography;feature extraction;image matching;image registration;medical image processing;parallel processing","cellular neural network;control point registration;elongated structure extraction;image processing;image registration;logic operations;mammogram;nonstructured texture images;pixel-wise registration;point pattern matching;transients","","1","","7","","","","24-26 Jun 1996","24 Jun 1996-26 Jun 1996","IEEE","IEEE Conference Publications"
"Tri-output cellular neural network and its application to diagnosing liver diseases","Zhong Zhang; Zhi-Qiang Liu; H. Kawabata","Dept. of Syst. Eng., Ind. Technol. Center of Okayama Prefecture, Japan","Systems, Man, and Cybernetics, 1999. IEEE SMC '99 Conference Proceedings. 1999 IEEE International Conference on","20020806","1999","3","","372","377 vol.3","The saturation (output) function is important to cellular neural networks (CNN) because it affects the operation, stable equilibrium points, and the performance of CNN. However, to the best of our knowledge, a systematic design procedure for the output function is not available in the literature. In this paper, we present a simple, yet effective design method for the tri-output cellular neural network (TCNN). To demonstrate the effectiveness of the output function using our design procedure, we tested TCNN on synthesized images. In addition, we applied the tri-output cellular neural network to the diagnosis of liver diseases and obtained very encouraging results","1062-922X;1062922X","POD:0-7803-5731-0","10.1109/ICSMC.1999.823233","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=823233","","Application software;Cellular neural networks;Computer industry;Computer science;Design methodology;Differential equations;Liver diseases;Network synthesis;Systems engineering and theory;Testing","cellular neural nets;diseases;liver;medical diagnostic computing;medical expert systems","liver disease diagnosis;output function;stable equilibrium point;synthesized images;systematic design procedure;tri-output cellular neural network","","1","","7","","","","1999","12 Oct 1999-15 Oct 1999","IEEE","IEEE Conference Publications"
"Extraction of rounded and line objects for the improvement of medical image pattern recognition","S. C. B. Lo; M. Chien; S. Jong; H. Li; M. T. Freedman; J. S. J. Lin; S. K. Mun","Dept. of Radiol., Georgetown Univ. Hospital, Washington, DC, USA","Nuclear Science Symposium and Medical Imaging Conference, 1994., 1994 IEEE Conference Record","20020806","1994","4","","1802","1806 vol.4","In the field of computer-aided diagnosis (CADx), the investigators have encountered various diseases and normal anatomical structure patterns. Two major image patterns that are often targeted for extraction prior to further analyses are rounded and line objects. Here, the authors employed an enhanced Hough transform to extract both objects from the pre-defined image areas. This method can also be applied to the high frequency associated subbands of the wavelet domain where line objects are more distinct. Typically, rounded objects are associated with disease and need to be further analyzed. High intensity line objects are related to normal anatomical structures. Once the line objects are extracted and eliminated, a compensation process must be taken so that the modified pixels are filled by the gray value of the surrounding area. The authors used the ellipse extraction method to search for suspected lung nodules on chest radiographs. The line extraction method was used to detect the edge of ribs which can interfere with the final determination process analyzed by a convolution neural network (CNN). In this experiment, the authors found that the ellipse extraction method performed slightly better than the previous proposed profile matching method. The line removal technique, however, improved the performance of the convolution neural network by 4%. The receiver operating characteristic (ROC) studies indicated that the convolution neural network can achieve a performance of Az=0.90 based on the authors' database when each suspected area was processed by the line removal technique","","POD:0-7803-2544-3","10.1109/NSSMIC.1994.474714","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=474714","","Anatomical structure;Computer aided diagnosis;Convolution;Diseases;Frequency;Image analysis;Lungs;Neural networks;Pattern analysis;Wavelet domain","Hough transforms;diagnostic radiography;image recognition;lung;medical image processing","chest radiographs;computer-aided diagnosis;convolution neural network;diseases;ellipse extraction method;enhanced Hough transform;high frequency associated subbands;line objects extraction;line removal technique;major image patterns;medical diagnostic imaging;medical image pattern recognition improvement;normal anatomical structure patterns;rib edge;rounded objects extraction;suspected lung nodules;wavelet domain","","0","7","10","","","","30 Oct-5 Nov 1994","30 Oct 1994-05 Nov 1994","IEEE","IEEE Conference Publications"
"Design of analogic CNN algorithms for mammogram analysis","A. Zarandy; T. Roska; G. Liszka; J. Hegyesi; L. Kek; C. Rekeczky","Analogical & Neural Comput. Lab., Hungarian Acad. of Sci., Budapest, Hungary","Proceedings of the Third IEEE International Workshop on Cellular Neural Networks and their Applications (CNNA-94)","20020806","1994","","","255","260","CNN analogic algorithms were developed for detecting the features of breast cancer on X-ray mammograms","","POD:0-7803-2070-0","10.1109/CNNA.1994.381670","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=381670","","Algorithm design and analysis;Breast neoplasms;Cancer;Cellular neural networks;Image analysis;Image restoration;Malignant tumors;Testing;Turing machines;X-ray imaging","cellular neural nets;diagnostic radiography;medical image processing","Analogic CNN Universal Machine;Cellular Neural Networks;X-ray mammograms;analogic CNN algorithms;breast cancer;image analysis;mammogram analysis","","4","","11","","","","18-21 Dec 1994","18 Dec 1994-21 Dec 1994","IEEE","IEEE Conference Publications"
"An application of convolution neural networks: reducing false-positives in lung nodule detection","J. S. Lin; P. A. Ligomenides; S. C. B. Lo; A. Hasegawa; M. T. Freedman; S. K. Mun","Cybernetics Res. Lab., Maryland Univ., College Park, MD, USA","Nuclear Science Symposium and Medical Imaging Conference, 1994., 1994 IEEE Conference Record","20020806","1994","4","","1842","1846 vol.4","Recently, various computer-aided diagnosis (CADx) schemes have been proposed to tackle the problem of detecting lung nodules on digital chest radiographs. The research efforts are aimed at increasing the “true-positive fraction” while decreasing the “false-positive fraction” of the CADx. Among the problems of decreasing the number of false-positives, the differentiation between nodules and end-on vessels is one of the most challenging tasks performed by computers. Most investigators have used a conventional two-step pattern recognition approach, i.e., feature extraction followed by feature classification, The principal difficulty in those methodologies is in specifying the kind of features which will differentiate nodules from end-on vessels. Unfortunately, suitable feature definition, and corresponding extraction implementation algorithms, proved to be very difficult to define and specify. A convolution neural network (CNN) architecture, trained by direct connection to the raw image is proposed to tackle the problem. The CNN, which used locally responsive activation function, was directly and locally connected to the raw image. The performance of the CNN is evaluated in comparison to an expert radiologist. We employed receiver operating characteristics (ROC) method with A<sub>z</sub> as the performance index to evaluate all the simulation results. The CNN showed superior performance (A<sub>z</sub>=0.99) to the radiologist's (A<sub>z </sub>=0.83)","","POD:0-7803-2544-3","10.1109/NSSMIC.1994.474706","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=474706","","Application software;Cellular neural networks;Computer aided diagnosis;Convolution;Diagnostic radiography;Feature extraction;Lungs;Neural networks;Pattern recognition;Performance analysis","convolution;diagnostic radiography;feature extraction;image classification;learning (artificial intelligence);lung;medical image processing;neural nets","computer-aided diagnosis;convolution neural networks;digital chest radiographs;end-on vessels;extraction implementation algorithms;false-positives;feature classification;feature extraction;lung nodule detection;performance;receiver operating characteristics;true-positive fraction;two-step pattern recognition","","1","","17","","","","30 Oct-5 Nov 1994","30 Oct 1994-05 Nov 1994","IEEE","IEEE Conference Publications"
"A new CNN based tool for an automated morphometry analysis of the corneal endothelium","M. Salerno; F. Sargeni; V. Bonaiuto; P. Amerini; L. Cerulli; F. Ricci","Dept. of Electron. Eng., Univ. of Rome Tor Vergata, Italy","1998 Fifth IEEE International Workshop on Cellular Neural Networks and their Applications. Proceedings (Cat. No.98TH8359)","20020806","1998","","","169","174","Cellular neural networks show high performance capabilities in real time image processing applications. For this reason, their use in biomedical image analysis can be a useful aid to the doctor in clinical diagnosis. In this research area the improvements in systems for clinical specular microscopy in vivo made a strong contribution to the study and the comprehension of the physiopathology of corneal endothelium. The more recent systems allow acquisition of the images and morphometric analysis. Nevertheless, the results (i.e. the automated reconstruction of the endothelium cell borders) are often inaccurate. Moreover, they do not allow the correct recognition of the cell shapes. On the other hand, even if the semiautomatic systems allow an effective evaluation of the cell shape, they are highly time consuming and provide results that could be affected by the criterion used by the operator in the cell corner detection. In this paper a software tool for the full automated morphometric analysis of corneal endothelium images is presented. The tool makes use of an analogue cellular neural network algorithm that allows both cell shape recognition and endothelial cell area measurement","","POD:0-7803-4867-2","10.1109/CNNA.1998.685358","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=685358","","Biomedical imaging;Cellular neural networks;Clinical diagnosis;Image analysis;Image processing;Image reconstruction;In vivo;Microscopy;Shape;Software tools","area measurement;cellular biophysics;cellular neural nets;eye;image recognition;medical image processing;optical microscopy;real-time systems","CNN based tool;analogue cellular neural network algorithm;biomedical image analysis;cell shape recognition;cellular neural net;clinical diagnosis;clinical specular microscopy;corneal endothelium;endothelial cell area measurement;endothelium cell border reconstruction;morphometric analysis;physiopathology;real time image processing applications;software tool","","2","","29","","","","14-17 Apr 1998","14 Apr 1998-17 Apr 1998","IEEE","IEEE Conference Publications"
